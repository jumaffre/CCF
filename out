Searching for include files...
Searching for example files...
Searching for images...
Searching for dot files...
Searching for msc files...
Searching for dia files...
Searching for files to exclude
Searching INPUT for files to process...
Searching for files in directory /data/git/CCF/src
Searching for files in directory /data/git/CCF/src/apps
Searching for files in directory /data/git/CCF/src/apps/batched
Searching for files in directory /data/git/CCF/src/apps/batched/src
Searching for files in directory /data/git/CCF/src/apps/js_generic
Searching for files in directory /data/git/CCF/src/apps/smallbank
Searching for files in directory /data/git/CCF/src/apps/smallbank/app
Searching for files in directory /data/git/CCF/src/apps/smallbank/clients
Searching for files in directory /data/git/CCF/src/apps/smallbank/tests
Searching for files in directory /data/git/CCF/src/clients
Searching for files in directory /data/git/CCF/src/consensus
Searching for files in directory /data/git/CCF/src/consensus/aft
Searching for files in directory /data/git/CCF/src/consensus/aft/impl
Searching for files in directory /data/git/CCF/src/consensus/aft/test
Searching for files in directory /data/git/CCF/src/crypto
Searching for files in directory /data/git/CCF/src/crypto/test
Searching for files in directory /data/git/CCF/src/ds
Searching for files in directory /data/git/CCF/src/ds/test
Searching for files in directory /data/git/CCF/src/enclave
Searching for files in directory /data/git/CCF/src/host
Searching for files in directory /data/git/CCF/src/host/test
Searching for files in directory /data/git/CCF/src/http
Searching for files in directory /data/git/CCF/src/http/authentication
Searching for files in directory /data/git/CCF/src/http/test
Searching for files in directory /data/git/CCF/src/kv
Searching for files in directory /data/git/CCF/src/kv/test
Searching for files in directory /data/git/CCF/src/libmerklecpp
Searching for files in directory /data/git/CCF/src/libmerklecpp/test
Searching for files in directory /data/git/CCF/src/lua_interp
Searching for files in directory /data/git/CCF/src/lua_interp/test
Searching for files in directory /data/git/CCF/src/node
Searching for files in directory /data/git/CCF/src/node/html
Searching for files in directory /data/git/CCF/src/node/html/search
Searching for files in directory /data/git/CCF/src/node/latex
Searching for files in directory /data/git/CCF/src/node/rpc
Searching for files in directory /data/git/CCF/src/node/rpc/test
Searching for files in directory /data/git/CCF/src/node/tables
Searching for files in directory /data/git/CCF/src/node/test
Searching for files in directory /data/git/CCF/src/perf_client
Searching for files in directory /data/git/CCF/src/runtime_config
Searching for files in directory /data/git/CCF/src/tls
Searching for files in directory /data/git/CCF/src/tls/test
Reading and parsing tag files
Parsing files
Preprocessing /data/git/CCF/src/apps/js_generic/js_generic.cpp...
#include enclave/app_interface.h: not found! skipping...
#include kv/untyped_map.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include tls/rsa_key_pair.h: not found! skipping...
#include memory: not found! skipping...
#include quickjs/quickjs-exports.h: not found! skipping...
#include quickjs/quickjs.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 38132 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ccfapp
00015 {
00016   using namespace std;
00017   using namespace kv;
00018   using namespace ccf;
00019 
00020   using KVMap = kv::untyped::Map;
00021 
00022   JSClassID kv_class_id;
00023   JSClassID kv_map_view_class_id;
00024   JSClassID body_class_id;
00025 
00026 
00027 
00028 
00029   static JSValue js_print(
00030     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00031   {
00032     int i;
00033     const char* str;
00034     std::stringstream ss;
00035 
00036     for (i = 0; i < argc; i++)
00037     {
00038       if (i != 0)
00039         ss << ' ';
00040       if (!JS_IsError(ctx, argv[i]) && JS_IsObject(argv[i]))
00041       {
00042         JSValue rval = JS_JSONStringify(ctx, argv[i], JS_NULL, JS_NULL);
00043         str = JS_ToCString(ctx, rval);
00044         JS_FreeValue(ctx, rval);
00045       }
00046       else
00047         str = JS_ToCString(ctx, argv[i]);
00048       if (!str)
00049         return JS_EXCEPTION;
00050       ss << str;
00051       JS_FreeCString(ctx, str);
00052     }
00053     LOG_INFO << ss.str() << std::endl;
00054     return JS_UNDEFINED;
00055   }
00056 
00057   void js_dump_error(JSContext* ctx)
00058   {
00059     JSValue exception_val = JS_GetException(ctx);
00060 
00061     JSValue val;
00062     const char* stack;
00063     bool is_error;
00064 
00065     is_error = JS_IsError(ctx, exception_val);
00066     if (!is_error)
00067       LOG_INFO_FMT("Throw: ");
00068     js_print(ctx, JS_NULL, 1, (JSValueConst*)&exception_val);
00069     if (is_error)
00070     {
00071       val = JS_GetPropertyStr(ctx, exception_val, "stack");
00072       if (!JS_IsUndefined(val))
00073       {
00074         stack = JS_ToCString(ctx, val);
00075         LOG_INFO_FMT("{}", stack);
00076 
00077         JS_FreeCString(ctx, stack);
00078       }
00079       JS_FreeValue(ctx, val);
00080     }
00081 
00082     JS_FreeValue(ctx, exception_val);
00083   }
00084 
00085   struct JSAutoFreeRuntime
00086   {
00087     JSRuntime* rt;
00088 
00089     JSAutoFreeRuntime(JSRuntime* rt) : rt(rt) {}
00090     ~JSAutoFreeRuntime()
00091     {
00092       JS_FreeRuntime(rt);
00093     }
00094   };
00095 
00096   struct JSAutoFreeCtx
00097   {
00098     JSContext* ctx;
00099 
00100     JSAutoFreeCtx(JSContext* ctx) : ctx(ctx) {}
00101     ~JSAutoFreeCtx()
00102     {
00103       JS_FreeContext(ctx);
00104     }
00105 
00106     struct JSWrappedValue
00107     {
00108       JSWrappedValue(JSContext* ctx, JSValue&& val) :
00109         ctx(ctx),
00110         val(std::move(val))
00111       {}
00112       ~JSWrappedValue()
00113       {
00114         JS_FreeValue(ctx, val);
00115       }
00116       operator const JSValue&() const
00117       {
00118         return val;
00119       }
00120       JSContext* ctx;
00121       JSValue val;
00122     };
00123 
00124     struct JSWrappedCString
00125     {
00126       JSWrappedCString(JSContext* ctx, const char* cstr) : ctx(ctx), cstr(cstr)
00127       {}
00128       ~JSWrappedCString()
00129       {
00130         JS_FreeCString(ctx, cstr);
00131       }
00132       operator const char*() const
00133       {
00134         return cstr;
00135       }
00136       operator std::string() const
00137       {
00138         return std::string(cstr);
00139       }
00140       operator std::string_view() const
00141       {
00142         return std::string_view(cstr);
00143       }
00144       JSContext* ctx;
00145       const char* cstr;
00146     };
00147 
00148     JSWrappedValue operator()(JSValue&& val)
00149     {
00150       return JSWrappedValue(ctx, std::move(val));
00151     };
00152 
00153     JSWrappedCString operator()(const char* cstr)
00154     {
00155       return JSWrappedCString(ctx, cstr);
00156     };
00157   };
00158 
00159   static JSValue js_generate_aes_key(
00160     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00161   {
00162     if (argc != 1)
00163       return JS_ThrowTypeError(
00164         ctx, "Passed %d arguments, but expected 1", argc);
00165 
00166     int32_t key_size;
00167     if (JS_ToInt32(ctx, &key_size, argv[0]) < 0)
00168     {
00169       js_dump_error(ctx);
00170       return JS_EXCEPTION;
00171     }
00172     // Supported key sizes for AES.
00173     if (key_size != 128 && key_size != 192 && key_size != 256)
00174     {
00175       JS_ThrowRangeError(ctx, "invalid key size");
00176       js_dump_error(ctx);
00177       return JS_EXCEPTION;
00178     }
00179 
00180     std::vector<uint8_t> key = tls::create_entropy()->random(key_size / 8);
00181 
00182     return JS_NewArrayBufferCopy(ctx, key.data(), key.size());
00183   }
00184 
00185   static JSValue js_wrap_key(
00186     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00187   {
00188     if (argc != 3)
00189       return JS_ThrowTypeError(
00190         ctx, "Passed %d arguments, but expected 3", argc);
00191 
00192     // API loosely modeled after
00193     // https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto/wrapKey.
00194 
00195     size_t key_size;
00196     uint8_t* key = JS_GetArrayBuffer(ctx, &key_size, argv[0]);
00197     if (!key)
00198     {
00199       js_dump_error(ctx);
00200       return JS_EXCEPTION;
00201     }
00202 
00203     size_t wrapping_key_size;
00204     uint8_t* wrapping_key = JS_GetArrayBuffer(ctx, &wrapping_key_size, argv[1]);
00205     if (!wrapping_key)
00206     {
00207       js_dump_error(ctx);
00208       return JS_EXCEPTION;
00209     }
00210 
00211     void* auto_free_ptr = JS_GetContextOpaque(ctx);
00212     JSAutoFreeCtx& auto_free = *(JSAutoFreeCtx*)auto_free_ptr;
00213 
00214     JSValue wrap_algo = argv[2];
00215     auto wrap_algo_name_val =
00216       auto_free(JS_GetPropertyStr(ctx, wrap_algo, "name"));
00217     auto wrap_algo_name_cstr = auto_free(JS_ToCString(ctx, wrap_algo_name_val));
00218 
00219     if (!wrap_algo_name_cstr)
00220     {
00221       js_dump_error(ctx);
00222       return JS_EXCEPTION;
00223     }
00224 
00225     if (std::string(wrap_algo_name_cstr) != "RSA-OAEP")
00226     {
00227       JS_ThrowRangeError(
00228         ctx, "unsupported key wrapping algorithm, supported: RSA-OAEP");
00229       js_dump_error(ctx);
00230       return JS_EXCEPTION;
00231     }
00232 
00233     // key can in principle be arbitrary data (see note on maximum size
00234     // in rsa_key_pair.h). wrapping_key is a public RSA key.
00235 
00236     auto label_val = auto_free(JS_GetPropertyStr(ctx, wrap_algo, "label"));
00237     size_t label_buf_size;
00238     uint8_t* label_buf = JS_GetArrayBuffer(ctx, &label_buf_size, label_val);
00239 
00240     auto wrapped_key = tls::make_rsa_public_key(wrapping_key, wrapping_key_size)
00241                          ->wrap(key, key_size, label_buf, label_buf_size);
00242 
00243     return JS_NewArrayBufferCopy(ctx, wrapped_key.data(), wrapped_key.size());
00244   }
00245 
00246   static void js_free_arraybuffer_cstring(JSRuntime*, void* opaque, void* ptr)
00247   {
00248     JS_FreeCString((JSContext*)opaque, (char*)ptr);
00249   }
00250 
00251   static JSValue js_str_to_buf(
00252     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00253   {
00254     if (argc != 1)
00255       return JS_ThrowTypeError(
00256         ctx, "Passed %d arguments, but expected 1", argc);
00257 
00258     if (!JS_IsString(argv[0]))
00259       return JS_ThrowTypeError(ctx, "Argument must be a string");
00260 
00261     size_t str_size = 0;
00262     const char* str = JS_ToCStringLen(ctx, &str_size, argv[0]);
00263 
00264     if (!str)
00265     {
00266       js_dump_error(ctx);
00267       return JS_EXCEPTION;
00268     }
00269 
00270     JSValue buf = JS_NewArrayBuffer(
00271       ctx, (uint8_t*)str, str_size, js_free_arraybuffer_cstring, ctx, false);
00272 
00273     if (JS_IsException(buf))
00274       js_dump_error(ctx);
00275 
00276     return buf;
00277   }
00278 
00279   static JSValue js_buf_to_str(
00280     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00281   {
00282     if (argc != 1)
00283       return JS_ThrowTypeError(
00284         ctx, "Passed %d arguments, but expected 1", argc);
00285 
00286     size_t buf_size;
00287     uint8_t* buf = JS_GetArrayBuffer(ctx, &buf_size, argv[0]);
00288 
00289     if (!buf)
00290       return JS_ThrowTypeError(ctx, "Argument must be an ArrayBuffer");
00291 
00292     JSValue str = JS_NewStringLen(ctx, (char*)buf, buf_size);
00293 
00294     if (JS_IsException(str))
00295       js_dump_error(ctx);
00296 
00297     return str;
00298   }
00299 
00300   static JSValue js_json_compatible_to_buf(
00301     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00302   {
00303     if (argc != 1)
00304       return JS_ThrowTypeError(
00305         ctx, "Passed %d arguments, but expected 1", argc);
00306 
00307     JSValue str = JS_JSONStringify(ctx, argv[0], JS_NULL, JS_NULL);
00308 
00309     if (JS_IsException(str))
00310     {
00311       js_dump_error(ctx);
00312       return str;
00313     }
00314 
00315     JSValue buf = js_str_to_buf(ctx, JS_NULL, 1, &str);
00316     JS_FreeValue(ctx, str);
00317     return buf;
00318   }
00319 
00320   static JSValue js_buf_to_json_compatible(
00321     JSContext* ctx, JSValueConst, int argc, JSValueConst* argv)
00322   {
00323     if (argc != 1)
00324       return JS_ThrowTypeError(
00325         ctx, "Passed %d arguments, but expected 1", argc);
00326 
00327     size_t buf_size;
00328     uint8_t* buf = JS_GetArrayBuffer(ctx, &buf_size, argv[0]);
00329 
00330     if (!buf)
00331       return JS_ThrowTypeError(ctx, "Argument must be an ArrayBuffer");
00332 
00333     std::vector<uint8_t> buf_null_terminated(buf_size + 1);
00334     buf_null_terminated[buf_size] = 0;
00335     buf_null_terminated.assign(buf, buf + buf_size);
00336 
00337     JSValue obj =
00338       JS_ParseJSON(ctx, (char*)buf_null_terminated.data(), buf_size, "<json>");
00339 
00340     if (JS_IsException(obj))
00341       js_dump_error(ctx);
00342 
00343     return obj;
00344   }
00345 
00346   static JSValue js_kv_map_has(
00347     JSContext* ctx, JSValueConst this_val, int argc, JSValueConst* argv)
00348   {
00349     auto map_view =
00350       static_cast<KVMap::TxView*>(JS_GetOpaque(this_val, kv_map_view_class_id));
00351 
00352     if (argc != 1)
00353       return JS_ThrowTypeError(
00354         ctx, "Passed %d arguments, but expected 1", argc);
00355 
00356     size_t key_size;
00357     uint8_t* key = JS_GetArrayBuffer(ctx, &key_size, argv[0]);
00358 
00359     if (!key)
00360       return JS_ThrowTypeError(ctx, "Argument must be an ArrayBuffer");
00361 
00362     auto has = map_view->has({key, key + key_size});
00363 
00364     return JS_NewBool(ctx, has);
00365   }
00366 
00367   static JSValue js_kv_map_get(
00368     JSContext* ctx, JSValueConst this_val, int argc, JSValueConst* argv)
00369   {
00370     auto map_view =
00371       static_cast<KVMap::TxView*>(JS_GetOpaque(this_val, kv_map_view_class_id));
00372 
00373     if (argc != 1)
00374       return JS_ThrowTypeError(
00375         ctx, "Passed %d arguments, but expected 1", argc);
00376 
00377     size_t key_size;
00378     uint8_t* key = JS_GetArrayBuffer(ctx, &key_size, argv[0]);
00379 
00380     if (!key)
00381       return JS_ThrowTypeError(ctx, "Argument must be an ArrayBuffer");
00382 
00383     auto val = map_view->get({key, key + key_size});
00384 
00385     if (!val.has_value())
00386       return JS_UNDEFINED;
00387 
00388     JSValue buf =
00389       JS_NewArrayBufferCopy(ctx, val.value().data(), val.value().size());
00390 
00391     if (JS_IsException(buf))
00392       js_dump_error(ctx);
00393 
00394     return buf;
00395   }
00396 
00397   static JSValue js_kv_map_delete(
00398     JSContext* ctx, JSValueConst this_val, int argc, JSValueConst* argv)
00399   {
00400     auto map_view =
00401       static_cast<KVMap::TxView*>(JS_GetOpaque(this_val, kv_map_view_class_id));
00402 
00403     if (argc != 1)
00404       return JS_ThrowTypeError(
00405         ctx, "Passed %d arguments, but expected 1", argc);
00406 
00407     size_t key_size;
00408     uint8_t* key = JS_GetArrayBuffer(ctx, &key_size, argv[0]);
00409 
00410     if (!key)
00411       return JS_ThrowTypeError(ctx, "Argument must be an ArrayBuffer");
00412 
00413     auto val = map_view->remove({key, key + key_size});
00414 
00415     return JS_NewBool(ctx, val);
00416   }
00417 
00418   static JSValue js_kv_map_delete_read_only(
00419     JSContext* ctx, JSValueConst, int, JSValueConst*)
00420   {
00421     return JS_ThrowTypeError(ctx, "Cannot call delete on read-only map");
00422   }
00423 
00424   static JSValue js_kv_map_set(
00425     JSContext* ctx, JSValueConst this_val, int argc, JSValueConst* argv)
00426   {
00427     auto map_view =
00428       static_cast<KVMap::TxView*>(JS_GetOpaque(this_val, kv_map_view_class_id));
00429 
00430     if (argc != 2)
00431       return JS_ThrowTypeError(
00432         ctx, "Passed %d arguments, but expected 2", argc);
00433 
00434     size_t key_size;
00435     uint8_t* key = JS_GetArrayBuffer(ctx, &key_size, argv[0]);
00436 
00437     size_t val_size;
00438     uint8_t* val = JS_GetArrayBuffer(ctx, &val_size, argv[1]);
00439 
00440     if (!key || !val)
00441       return JS_ThrowTypeError(ctx, "Arguments must be ArrayBuffers");
00442 
00443     if (!map_view->put({key, key + key_size}, {val, val + val_size}))
00444       return JS_ThrowRangeError(ctx, "Could not insert at key");
00445 
00446     return JS_DupValue(ctx, this_val);
00447   }
00448 
00449   static JSValue js_kv_map_set_read_only(
00450     JSContext* ctx, JSValueConst, int, JSValueConst*)
00451   {
00452     return JS_ThrowTypeError(ctx, "Cannot call set on read-only map");
00453   }
00454 
00455   static JSValue js_kv_map_foreach(
00456     JSContext* ctx, JSValueConst this_val, int argc, JSValueConst* argv)
00457   {
00458     auto map_view =
00459       static_cast<KVMap::TxView*>(JS_GetOpaque(this_val, kv_map_view_class_id));
00460 
00461     if (argc != 1)
00462       return JS_ThrowTypeError(
00463         ctx, "Passed %d arguments, but expected 1", argc);
00464 
00465     JSValue func = argv[0];
00466 
00467     if (!JS_IsFunction(ctx, func))
00468       return JS_ThrowTypeError(ctx, "Argument must be a function");
00469 
00470     bool failed = false;
00471     map_view->foreach(
00472       [ctx, this_val, func, &failed](const auto& k, const auto& v) {
00473         JSValue args[3];
00474 
00475         // JS forEach expects (v, k, map) rather than (k, v)
00476         args[0] = JS_NewArrayBufferCopy(ctx, v.data(), v.size());
00477         args[1] = JS_NewArrayBufferCopy(ctx, k.data(), k.size());
00478         args[2] = JS_DupValue(ctx, this_val);
00479 
00480         auto val = JS_Call(ctx, func, JS_UNDEFINED, 3, args);
00481 
00482         JS_FreeValue(ctx, args[0]);
00483         JS_FreeValue(ctx, args[1]);
00484         JS_FreeValue(ctx, args[2]);
00485 
00486         if (JS_IsException(val))
00487         {
00488           js_dump_error(ctx);
00489           failed = true;
00490           return false;
00491         }
00492 
00493         JS_FreeValue(ctx, val);
00494 
00495         return true;
00496       });
00497 
00498     if (failed)
00499     {
00500       return JS_EXCEPTION;
00501     }
00502 
00503     return JS_UNDEFINED;
00504   }
00505 
00506   static int js_kv_lookup(
00507     JSContext* ctx,
00508     JSPropertyDescriptor* desc,
00509     JSValueConst this_val,
00510     JSAtom property)
00511   {
00512     const auto property_name = JS_AtomToCString(ctx, property);
00513     LOG_TRACE_FMT("Looking for kv map '{}'", property_name);
00514 
00515     const auto [security_domain, access_category] =
00516       kv::parse_map_name(property_name);
00517 
00518     auto read_only = false;
00519     switch (access_category)
00520     {
00521       case kv::AccessCategory::INTERNAL:
00522       {
00523         if (security_domain == kv::SecurityDomain::PUBLIC)
00524         {
00525           read_only = true;
00526         }
00527         else
00528         {
00529           throw std::runtime_error(fmt::format(
00530             "JS application cannot access private internal CCF table '{}'",
00531             property_name));
00532         }
00533         break;
00534       }
00535       case kv::AccessCategory::GOVERNANCE:
00536       {
00537         read_only = true;
00538         break;
00539       }
00540       case kv::AccessCategory::APPLICATION:
00541       {
00542         break;
00543       }
00544       default:
00545       {
00546         throw std::logic_error(fmt::format(
00547           "Unhandled AccessCategory for table '{}'", property_name));
00548       }
00549     }
00550 
00551     auto tx_ptr = static_cast<kv::Tx*>(JS_GetOpaque(this_val, kv_class_id));
00552     auto view = tx_ptr->get_view<KVMap>(property_name);
00553 
00554     // This follows the interface of Map:
00555     // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map
00556     // Keys and values are ArrayBuffers. Keys are matched based on their
00557     // contents.
00558     auto view_val = JS_NewObjectClass(ctx, kv_map_view_class_id);
00559     JS_SetOpaque(view_val, view);
00560 
00561     JS_SetPropertyStr(
00562       ctx,
00563       view_val,
00564       "has",
00565       JS_NewCFunction(ctx, ccfapp::js_kv_map_has, "has", 1));
00566 
00567     JS_SetPropertyStr(
00568       ctx,
00569       view_val,
00570       "get",
00571       JS_NewCFunction(ctx, ccfapp::js_kv_map_get, "get", 1));
00572 
00573     auto setter = ccfapp::js_kv_map_set;
00574     auto deleter = ccfapp::js_kv_map_delete;
00575 
00576     if (read_only)
00577     {
00578       setter = ccfapp::js_kv_map_set_read_only;
00579       deleter = ccfapp::js_kv_map_delete_read_only;
00580     }
00581 
00582     JS_SetPropertyStr(
00583       ctx, view_val, "set", JS_NewCFunction(ctx, setter, "set", 2));
00584     JS_SetPropertyStr(
00585       ctx, view_val, "delete", JS_NewCFunction(ctx, deleter, "delete", 1));
00586 
00587     JS_SetPropertyStr(
00588       ctx,
00589       view_val,
00590       "forEach",
00591       JS_NewCFunction(ctx, ccfapp::js_kv_map_foreach, "forEach", 1));
00592 
00593     desc->flags = 0;
00594     desc->value = view_val;
00595 
00596     return true;
00597   }
00598 
00599   static JSValue js_body_text(
00600     JSContext* ctx,
00601     JSValueConst this_val,
00602     int argc,
00603     [[maybe_unused]] JSValueConst* argv)
00604   {
00605     if (argc != 0)
00606       return JS_ThrowTypeError(
00607         ctx, "Passed %d arguments, but expected none", argc);
00608 
00609     auto body = static_cast<const std::vector<uint8_t>*>(
00610       JS_GetOpaque(this_val, body_class_id));
00611     auto body_ = JS_NewStringLen(ctx, (const char*)body->data(), body->size());
00612     return body_;
00613   }
00614 
00615   static JSValue js_body_json(
00616     JSContext* ctx,
00617     JSValueConst this_val,
00618     int argc,
00619     [[maybe_unused]] JSValueConst* argv)
00620   {
00621     if (argc != 0)
00622       return JS_ThrowTypeError(
00623         ctx, "Passed %d arguments, but expected none", argc);
00624 
00625     auto body = static_cast<const std::vector<uint8_t>*>(
00626       JS_GetOpaque(this_val, body_class_id));
00627     std::string body_str(body->begin(), body->end());
00628     auto body_ = JS_ParseJSON(ctx, body_str.c_str(), body->size(), "<body>");
00629     return body_;
00630   }
00631 
00632   static JSValue js_body_array_buffer(
00633     JSContext* ctx,
00634     JSValueConst this_val,
00635     int argc,
00636     [[maybe_unused]] JSValueConst* argv)
00637   {
00638     if (argc != 0)
00639       return JS_ThrowTypeError(
00640         ctx, "Passed %d arguments, but expected none", argc);
00641 
00642     auto body = static_cast<const std::vector<uint8_t>*>(
00643       JS_GetOpaque(this_val, body_class_id));
00644     auto body_ = JS_NewArrayBufferCopy(ctx, body->data(), body->size());
00645     return body_;
00646   }
00647 
00648   // Partially replicates https://developer.mozilla.org/en-US/docs/Web/API/Body
00649   // with a synchronous interface.
00650   static const JSCFunctionListEntry js_body_proto_funcs[] = {
00651     JS_CFUNC_DEF("text", 0, js_body_text),
00652     JS_CFUNC_DEF("json", 0, js_body_json),
00653     JS_CFUNC_DEF("arrayBuffer", 0, js_body_array_buffer),
00654   };
00655 
00656   struct JSModuleLoaderArg
00657   {
00658     ccf::NetworkTables* network;
00659     kv::Tx* tx;
00660   };
00661 
00662   static JSModuleDef* js_module_loader(
00663     JSContext* ctx, const char* module_name, void* opaque)
00664   {
00665     // QuickJS resolves relative paths but in some cases omits leading slashes.
00666     std::string module_name_kv(module_name);
00667     if (module_name_kv[0] != '/')
00668     {
00669       module_name_kv.insert(0, "/");
00670     }
00671 
00672     LOG_TRACE_FMT("Loading module '{}'", module_name_kv);
00673 
00674     auto arg = (JSModuleLoaderArg*)opaque;
00675 
00676     const auto modules = arg->tx->get_view(arg->network->modules);
00677     auto module = modules->get(module_name_kv);
00678     if (!module.has_value())
00679     {
00680       JS_ThrowReferenceError(ctx, "module '%s' not found in kv", module_name);
00681       return nullptr;
00682     }
00683     std::string js = module->js;
00684 
00685     const char* buf = js.c_str();
00686     size_t buf_len = js.size();
00687     JSValue func_val = JS_Eval(
00688       ctx,
00689       buf,
00690       buf_len,
00691       module_name,
00692       JS_EVAL_TYPE_MODULE | JS_EVAL_FLAG_COMPILE_ONLY);
00693     if (JS_IsException(func_val))
00694     {
00695       js_dump_error(ctx);
00696       return nullptr;
00697     }
00698 
00699     auto m = (JSModuleDef*)JS_VALUE_GET_PTR(func_val);
00700     // module already referenced, decrement ref count
00701     JS_FreeValue(ctx, func_val);
00702     return m;
00703   }
00704 
00705   class JSHandlers : public UserEndpointRegistry
00706   {
00707   private:
00708     NetworkTables& network;
00709 
00710     JSClassDef kv_class_def = {};
00711     JSClassExoticMethods kv_exotic_methods = {};
00712 
00713     JSClassDef kv_map_view_class_def = {};
00714 
00715     JSClassDef body_class_def = {};
00716 
00717     static JSValue create_ccf_obj(EndpointContext& args, JSContext* ctx)
00718     {
00719       auto ccf = JS_NewObject(ctx);
00720 
00721       JS_SetPropertyStr(
00722         ctx,
00723         ccf,
00724         "strToBuf",
00725         JS_NewCFunction(ctx, ccfapp::js_str_to_buf, "strToBuf", 1));
00726       JS_SetPropertyStr(
00727         ctx,
00728         ccf,
00729         "bufToStr",
00730         JS_NewCFunction(ctx, ccfapp::js_buf_to_str, "bufToStr", 1));
00731       JS_SetPropertyStr(
00732         ctx,
00733         ccf,
00734         "jsonCompatibleToBuf",
00735         JS_NewCFunction(
00736           ctx, ccfapp::js_json_compatible_to_buf, "jsonCompatibleToBuf", 1));
00737       JS_SetPropertyStr(
00738         ctx,
00739         ccf,
00740         "bufToJsonCompatible",
00741         JS_NewCFunction(
00742           ctx, ccfapp::js_buf_to_json_compatible, "bufToJsonCompatible", 1));
00743       JS_SetPropertyStr(
00744         ctx,
00745         ccf,
00746         "generateAesKey",
00747         JS_NewCFunction(ctx, ccfapp::js_generate_aes_key, "generateAesKey", 1));
00748       JS_SetPropertyStr(
00749         ctx,
00750         ccf,
00751         "wrapKey",
00752         JS_NewCFunction(ctx, ccfapp::js_wrap_key, "wrapKey", 3));
00753 
00754       auto kv = JS_NewObjectClass(ctx, kv_class_id);
00755       JS_SetOpaque(kv, &args.tx);
00756       JS_SetPropertyStr(ctx, ccf, "kv", kv);
00757 
00758       return ccf;
00759     }
00760 
00761     static JSValue create_console_obj(JSContext* ctx)
00762     {
00763       auto console = JS_NewObject(ctx);
00764 
00765       JS_SetPropertyStr(
00766         ctx, console, "log", JS_NewCFunction(ctx, ccfapp::js_print, "log", 1));
00767 
00768       return console;
00769     }
00770 
00771     static void populate_global_obj(EndpointContext& args, JSContext* ctx)
00772     {
00773       auto global_obj = JS_GetGlobalObject(ctx);
00774 
00775       JS_SetPropertyStr(ctx, global_obj, "console", create_console_obj(ctx));
00776       JS_SetPropertyStr(ctx, global_obj, "ccf", create_ccf_obj(args, ctx));
00777 
00778       JS_FreeValue(ctx, global_obj);
00779     }
00780 
00781     static JSValue create_request_obj(EndpointContext& args, JSContext* ctx)
00782     {
00783       auto request = JS_NewObject(ctx);
00784 
00785       auto headers = JS_NewObject(ctx);
00786       for (auto& [header_name, header_value] :
00787            args.rpc_ctx->get_request_headers())
00788       {
00789         JS_SetPropertyStr(
00790           ctx,
00791           headers,
00792           header_name.c_str(),
00793           JS_NewStringLen(ctx, header_value.c_str(), header_value.size()));
00794       }
00795       JS_SetPropertyStr(ctx, request, "headers", headers);
00796 
00797       const auto& request_query = args.rpc_ctx->get_request_query();
00798       auto query_str =
00799         JS_NewStringLen(ctx, request_query.c_str(), request_query.size());
00800       JS_SetPropertyStr(ctx, request, "query", query_str);
00801 
00802       auto params = JS_NewObject(ctx);
00803       for (auto& [param_name, param_value] :
00804            args.rpc_ctx->get_request_path_params())
00805       {
00806         JS_SetPropertyStr(
00807           ctx,
00808           params,
00809           param_name.c_str(),
00810           JS_NewStringLen(ctx, param_value.c_str(), param_value.size()));
00811       }
00812       JS_SetPropertyStr(ctx, request, "params", params);
00813 
00814       const auto& request_body = args.rpc_ctx->get_request_body();
00815       auto body_ = JS_NewObjectClass(ctx, body_class_id);
00816       JS_SetOpaque(body_, (void*)&request_body);
00817       JS_SetPropertyStr(ctx, request, "body", body_);
00818 
00819       return request;
00820     }
00821 
00822     void execute_request(
00823       const std::string& method,
00824       const ccf::RESTVerb& verb,
00825       EndpointContext& args)
00826     {
00827       const auto local_method = method.substr(method.find_first_not_of('/'));
00828 
00829       const auto scripts = args.tx.get_view(this->network.app_scripts);
00830 
00831       // Try to find script for method
00832       // - First try a script called "foo"
00833       // - If that fails, try a script called "POST foo"
00834       auto handler_script = scripts->get(local_method);
00835       if (!handler_script)
00836       {
00837         const auto verb_prefixed =
00838           fmt::format("{} {}", verb.c_str(), local_method);
00839         handler_script = scripts->get(verb_prefixed);
00840         if (!handler_script)
00841         {
00842           args.rpc_ctx->set_error(
00843             HTTP_STATUS_NOT_FOUND,
00844             ccf::errors::ResourceNotFound,
00845             fmt::format(
00846               "No handler script found for method '{}'.", verb_prefixed));
00847           return;
00848         }
00849       }
00850 
00851       JSRuntime* rt = JS_NewRuntime();
00852       if (rt == nullptr)
00853       {
00854         throw std::runtime_error("Failed to initialise QuickJS runtime");
00855       }
00856       JSAutoFreeRuntime auto_free_rt(rt);
00857 
00858       JS_SetMaxStackSize(rt, 1024 * 1024);
00859 
00860       JSModuleLoaderArg js_module_loader_arg{&this->network, &args.tx};
00861       JS_SetModuleLoaderFunc(
00862         rt, nullptr, js_module_loader, &js_module_loader_arg);
00863 
00864       // Register class for KV
00865       {
00866         auto ret = JS_NewClass(rt, kv_class_id, &kv_class_def);
00867         if (ret != 0)
00868         {
00869           throw std::logic_error(
00870             "Failed to register JS class definition for KV");
00871         }
00872       }
00873 
00874       // Register class for KV map views
00875       {
00876         auto ret =
00877           JS_NewClass(rt, kv_map_view_class_id, &kv_map_view_class_def);
00878         if (ret != 0)
00879         {
00880           throw std::logic_error(
00881             "Failed to register JS class definition for KVMap");
00882         }
00883       }
00884 
00885       // Register class for request body
00886       {
00887         auto ret = JS_NewClass(rt, body_class_id, &body_class_def);
00888         if (ret != 0)
00889         {
00890           throw std::logic_error(
00891             "Failed to register JS class definition for Body");
00892         }
00893       }
00894 
00895       JSContext* ctx = JS_NewContext(rt);
00896       if (ctx == nullptr)
00897       {
00898         throw std::runtime_error("Failed to initialise QuickJS context");
00899       }
00900       JSAutoFreeCtx auto_free(ctx);
00901       JS_SetContextOpaque(ctx, &auto_free);
00902 
00903       // Set prototype for request body class
00904       JSValue body_proto = JS_NewObject(ctx);
00905       size_t func_count =
00906         sizeof(js_body_proto_funcs) / sizeof(js_body_proto_funcs[0]);
00907       JS_SetPropertyFunctionList(
00908         ctx, body_proto, js_body_proto_funcs, func_count);
00909       JS_SetClassProto(ctx, body_class_id, body_proto);
00910 
00911       // Populate globalThis with console and ccf globals
00912       populate_global_obj(args, ctx);
00913 
00914       // Compile module
00915       if (!handler_script.value().text.has_value())
00916       {
00917         throw std::runtime_error("Could not find script text");
00918       }
00919       std::string code = handler_script.value().text.value();
00920       const std::string path = "/__endpoint__.js";
00921       JSValue module = JS_Eval(
00922         ctx,
00923         code.c_str(),
00924         code.size(),
00925         path.c_str(),
00926         JS_EVAL_TYPE_MODULE | JS_EVAL_FLAG_COMPILE_ONLY);
00927 
00928       if (JS_IsException(module))
00929       {
00930         js_dump_error(ctx);
00931 
00932         args.rpc_ctx->set_error(
00933           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00934           ccf::errors::InternalError,
00935           "Exception thrown while compiling.");
00936         return;
00937       }
00938 
00939       // Evaluate module
00940       auto eval_val = JS_EvalFunction(ctx, module);
00941       if (JS_IsException(eval_val))
00942       {
00943         js_dump_error(ctx);
00944         args.rpc_ctx->set_error(
00945           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00946           ccf::errors::InternalError,
00947           "Exception thrown while executing.");
00948         return;
00949       }
00950       JS_FreeValue(ctx, eval_val);
00951 
00952       // Get exported function from module
00953       assert(JS_VALUE_GET_TAG(module) == JS_TAG_MODULE);
00954       auto module_def = (JSModuleDef*)JS_VALUE_GET_PTR(module);
00955       if (JS_GetModuleExportEntriesCount(module_def) != 1)
00956       {
00957         throw std::runtime_error(
00958           "Endpoint module exports more than one function");
00959       }
00960       auto export_func = JS_GetModuleExportEntry(ctx, module_def, 0);
00961       if (!JS_IsFunction(ctx, export_func))
00962       {
00963         JS_FreeValue(ctx, export_func);
00964         throw std::runtime_error(
00965           "Endpoint module exports something that is not a function");
00966       }
00967 
00968       // Call exported function
00969       auto request = create_request_obj(args, ctx);
00970       int argc = 1;
00971       JSValueConst* argv = (JSValueConst*)&request;
00972       auto val = auto_free(JS_Call(ctx, export_func, JS_UNDEFINED, argc, argv));
00973       JS_FreeValue(ctx, request);
00974       JS_FreeValue(ctx, export_func);
00975 
00976       if (JS_IsException(val))
00977       {
00978         js_dump_error(ctx);
00979         args.rpc_ctx->set_error(
00980           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00981           ccf::errors::InternalError,
00982           "Exception thrown while executing.");
00983         return;
00984       }
00985 
00986       // Handle return value: {body, headers, statusCode}
00987       if (!JS_IsObject(val))
00988       {
00989         args.rpc_ctx->set_error(
00990           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00991           ccf::errors::InternalError,
00992           "Invalid endpoint function return value (not an object).");
00993         return;
00994       }
00995 
00996       // Response body (also sets a default response content-type header)
00997       {
00998         auto response_body_js = auto_free(JS_GetPropertyStr(ctx, val, "body"));
00999         std::vector<uint8_t> response_body;
01000         size_t buf_size;
01001         size_t buf_offset;
01002         JSValue typed_array_buffer = JS_GetTypedArrayBuffer(
01003           ctx, response_body_js, &buf_offset, &buf_size, nullptr);
01004         uint8_t* array_buffer;
01005         if (!JS_IsException(typed_array_buffer))
01006         {
01007           size_t buf_size_total;
01008           array_buffer =
01009             JS_GetArrayBuffer(ctx, &buf_size_total, typed_array_buffer);
01010           array_buffer += buf_offset;
01011           JS_FreeValue(ctx, typed_array_buffer);
01012         }
01013         else
01014         {
01015           array_buffer = JS_GetArrayBuffer(ctx, &buf_size, response_body_js);
01016         }
01017         if (array_buffer)
01018         {
01019           args.rpc_ctx->set_response_header(
01020             http::headers::CONTENT_TYPE,
01021             http::headervalues::contenttype::OCTET_STREAM);
01022           response_body =
01023             std::vector<uint8_t>(array_buffer, array_buffer + buf_size);
01024         }
01025         else
01026         {
01027           const char* cstr = nullptr;
01028           if (JS_IsString(response_body_js))
01029           {
01030             args.rpc_ctx->set_response_header(
01031               http::headers::CONTENT_TYPE,
01032               http::headervalues::contenttype::TEXT);
01033             cstr = JS_ToCString(ctx, response_body_js);
01034           }
01035           else
01036           {
01037             args.rpc_ctx->set_response_header(
01038               http::headers::CONTENT_TYPE,
01039               http::headervalues::contenttype::JSON);
01040             JSValue rval =
01041               JS_JSONStringify(ctx, response_body_js, JS_NULL, JS_NULL);
01042             if (JS_IsException(rval))
01043             {
01044               js_dump_error(ctx);
01045               args.rpc_ctx->set_error(
01046                 HTTP_STATUS_INTERNAL_SERVER_ERROR,
01047                 ccf::errors::InternalError,
01048                 "Invalid endpoint function return value (error during JSON "
01049                 "conversion of body).");
01050               return;
01051             }
01052             cstr = JS_ToCString(ctx, rval);
01053             JS_FreeValue(ctx, rval);
01054           }
01055           if (!cstr)
01056           {
01057             js_dump_error(ctx);
01058             args.rpc_ctx->set_error(
01059               HTTP_STATUS_INTERNAL_SERVER_ERROR,
01060               ccf::errors::InternalError,
01061               "Invalid endpoint function return value (error during string "
01062               "conversion of body).");
01063             return;
01064           }
01065           std::string str(cstr);
01066           JS_FreeCString(ctx, cstr);
01067 
01068           response_body = std::vector<uint8_t>(str.begin(), str.end());
01069         }
01070         args.rpc_ctx->set_response_body(std::move(response_body));
01071       }
01072 
01073       // Response headers
01074       {
01075         auto response_headers_js =
01076           auto_free(JS_GetPropertyStr(ctx, val, "headers"));
01077         if (JS_IsObject(response_headers_js))
01078         {
01079           uint32_t prop_count = 0;
01080           JSPropertyEnum* props = nullptr;
01081           JS_GetOwnPropertyNames(
01082             ctx,
01083             &props,
01084             &prop_count,
01085             response_headers_js,
01086             JS_GPN_STRING_MASK | JS_GPN_ENUM_ONLY);
01087           for (size_t i = 0; i < prop_count; i++)
01088           {
01089             auto prop_name = props[i].atom;
01090             auto prop_name_cstr = auto_free(JS_AtomToCString(ctx, prop_name));
01091             auto prop_val =
01092               auto_free(JS_GetProperty(ctx, response_headers_js, prop_name));
01093             auto prop_val_cstr = JS_ToCString(ctx, prop_val);
01094             if (!prop_val_cstr)
01095             {
01096               args.rpc_ctx->set_error(
01097                 HTTP_STATUS_INTERNAL_SERVER_ERROR,
01098                 ccf::errors::InternalError,
01099                 "Invalid endpoint function return value (header value type).");
01100               return;
01101             }
01102             args.rpc_ctx->set_response_header(prop_name_cstr, prop_val_cstr);
01103             JS_FreeCString(ctx, prop_val_cstr);
01104           }
01105           js_free(ctx, props);
01106         }
01107       }
01108 
01109       // Response status code
01110       {
01111         int response_status_code = HTTP_STATUS_OK;
01112         auto status_code_js =
01113           auto_free(JS_GetPropertyStr(ctx, val, "statusCode"));
01114         if (!JS_IsUndefined(status_code_js) && !JS_IsNull(status_code_js))
01115         {
01116           if (JS_VALUE_GET_TAG(status_code_js.val) != JS_TAG_INT)
01117           {
01118             args.rpc_ctx->set_error(
01119               HTTP_STATUS_INTERNAL_SERVER_ERROR,
01120               ccf::errors::InternalError,
01121               "Invalid endpoint function return value (status code type).");
01122             return;
01123           }
01124           response_status_code = JS_VALUE_GET_INT(status_code_js.val);
01125         }
01126         args.rpc_ctx->set_response_status(response_status_code);
01127       }
01128 
01129       return;
01130     }
01131 
01132     struct JSDynamicEndpoint : public EndpointDefinition
01133     {};
01134 
01135   public:
01136     JSHandlers(NetworkTables& network) :
01137       UserEndpointRegistry(network),
01138       network(network)
01139     {
01140       JS_NewClassID(&kv_class_id);
01141       kv_exotic_methods.get_own_property = js_kv_lookup;
01142       kv_class_def.class_name = "KV Tables";
01143       kv_class_def.exotic = &kv_exotic_methods;
01144 
01145       JS_NewClassID(&kv_map_view_class_id);
01146       kv_map_view_class_def.class_name = "KV View";
01147 
01148       JS_NewClassID(&body_class_id);
01149       body_class_def.class_name = "Body";
01150 
01151       auto default_handler = [this](EndpointContext& args) {
01152         execute_request(
01153           args.rpc_ctx->get_method(), args.rpc_ctx->get_request_verb(), args);
01154       };
01155 
01156       set_default(default_handler, no_auth_required);
01157     }
01158 
01159     EndpointDefinitionPtr find_endpoint(
01160       kv::Tx& tx, enclave::RpcContext& rpc_ctx) override
01161     {
01162       const auto method = fmt::format("/{}", rpc_ctx.get_method());
01163       const auto verb = rpc_ctx.get_request_verb();
01164 
01165       auto endpoints_view =
01166         tx.get_view<ccf::endpoints::EndpointsMap>(ccf::Tables::ENDPOINTS);
01167 
01168       const auto key = ccf::endpoints::EndpointKey{method, verb};
01169 
01170       // Look for a direct match of the given path
01171       const auto it = endpoints_view->get(key);
01172       if (it.has_value())
01173       {
01174         auto endpoint_def = std::make_shared<JSDynamicEndpoint>();
01175         endpoint_def->dispatch = key;
01176         endpoint_def->properties = it.value();
01177 
01178         if (endpoint_def->properties.require_client_identity)
01179         {
01180           endpoint_def->authn_policies.push_back(user_cert_auth_policy);
01181         }
01182         if (endpoint_def->properties.require_client_signature)
01183         {
01184           endpoint_def->authn_policies.push_back(user_signature_auth_policy);
01185         }
01186         if (endpoint_def->properties.require_jwt_authentication)
01187         {
01188           endpoint_def->authn_policies.push_back(jwt_auth_policy);
01189         }
01190 
01191         return endpoint_def;
01192       }
01193 
01194       // If that doesn't exist, look through _all_ the endpoints to find
01195       // templated matches. If there is one, that's a match. More is an error,
01196       // none means delegate to the base class.
01197       {
01198         std::vector<EndpointDefinitionPtr> matches;
01199 
01200         endpoints_view->foreach(
01201           [&matches, &key, &rpc_ctx](
01202             const auto& other_key, const auto& properties) {
01203             if (key.verb == other_key.verb)
01204             {
01205               const auto opt_spec =
01206                 EndpointRegistry::parse_path_template(other_key.uri_path);
01207               if (opt_spec.has_value())
01208               {
01209                 const auto& template_spec = opt_spec.value();
01210                 // This endpoint has templates in its path, and the correct verb
01211                 // - now check if template matches the current request's path
01212                 std::smatch match;
01213                 if (std::regex_match(
01214                       key.uri_path, match, template_spec.template_regex))
01215                 {
01216                   if (matches.empty())
01217                   {
01218                     // Populate the request_path_params while we have the match,
01219                     // though this will be discarded on error if we later find
01220                     // multiple matches
01221                     auto& path_params = rpc_ctx.get_request_path_params();
01222                     for (size_t i = 0;
01223                          i < template_spec.template_component_names.size();
01224                          ++i)
01225                     {
01226                       const auto& template_name =
01227                         template_spec.template_component_names[i];
01228                       const auto& template_value = match[i + 1].str();
01229                       path_params[template_name] = template_value;
01230                     }
01231                   }
01232 
01233                   auto endpoint = std::make_shared<JSDynamicEndpoint>();
01234                   endpoint->dispatch = other_key;
01235                   endpoint->properties = properties;
01236                   matches.push_back(endpoint);
01237                 }
01238               }
01239             }
01240             return true;
01241           });
01242 
01243         if (matches.size() > 1)
01244         {
01245           report_ambiguous_templated_path(key.uri_path, matches);
01246         }
01247         else if (matches.size() == 1)
01248         {
01249           return matches[0];
01250         }
01251       }
01252 
01253       return EndpointRegistry::find_endpoint(tx, rpc_ctx);
01254     }
01255 
01256     void execute_endpoint(
01257       EndpointDefinitionPtr e, EndpointContext& args) override
01258     {
01259       auto endpoint = dynamic_cast<const JSDynamicEndpoint*>(e.get());
01260       if (endpoint != nullptr)
01261       {
01262         execute_request(
01263           endpoint->dispatch.uri_path, endpoint->dispatch.verb, args);
01264         return;
01265       }
01266 
01267       EndpointRegistry::execute_endpoint(e, args);
01268     }
01269 
01270     static std::pair<llhttp_method, std::string> split_script_key(
01271       const std::string& key)
01272     {
01273       size_t s = key.find(' ');
01274       if (s != std::string::npos)
01275       {
01276         return std::make_pair(
01277           http::http_method_from_str(key.substr(0, s).c_str()),
01278           key.substr(s + 1, key.size() - (s + 1)));
01279       }
01280       else
01281       {
01282         return std::make_pair(HTTP_POST, key);
01283       }
01284     }
01285 
01286     // Since we do our own dispatch within the default handler, report the
01287     // supported methods here
01288     void build_api(nlohmann::json& document, kv::Tx& tx) override
01289     {
01290       UserEndpointRegistry::build_api(document, tx);
01291 
01292       auto endpoints_view =
01293         tx.get_view<ccf::endpoints::EndpointsMap>(ccf::Tables::ENDPOINTS);
01294 
01295       endpoints_view->foreach(
01296         [&document](const auto& key, const auto& properties) {
01297           const auto http_verb = key.verb.get_http_method();
01298           if (!http_verb.has_value())
01299           {
01300             return true;
01301           }
01302 
01303           if (!properties.openapi_hidden)
01304           {
01305             auto& path_op = ds::openapi::path_operation(
01306               ds::openapi::path(document, key.uri_path), http_verb.value());
01307             if (!properties.openapi.empty())
01308             {
01309               path_op.insert(
01310                 properties.openapi.cbegin(), properties.openapi.cend());
01311             }
01312           }
01313 
01314           return true;
01315         });
01316     }
01317   };
01318 
01319 
01320 
01321   class JS : public ccf::UserRpcFrontend
01322   {
01323   private:
01324     JSHandlers js_handlers;
01325 
01326   public:
01327     JS(NetworkTables& network) :
01328       ccf::UserRpcFrontend(*network.tables, js_handlers),
01329       js_handlers(network)
01330     {}
01331   };
01332 
01333   std::shared_ptr<ccf::UserRpcFrontend> get_rpc_handler(
01334     NetworkTables& network, ccfapp::AbstractNodeContext&)
01335   {
01336     return make_shared<JS>(network);
01337   }
01338 } // namespace ccfapp
01339 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/apps/js_generic/js_generic.cpp...
Preprocessing /data/git/CCF/src/apps/smallbank/app/smallbank.cpp...
#include ds/serialized.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
#include charconv: not found! skipping...
Preprocessor output (size: 14382 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/apps/smallbank/app/smallbank.cpp" 2
00004 
00005 
00006 
00007 
00008 
00009 using namespace std;
00010 using namespace nlohmann;
00011 using namespace ccf;
00012 
00013 namespace ccfapp
00014 {
00015   struct SmallBankTables
00016   {
00017     kv::Map<std::string, uint64_t> accounts;
00018     kv::Map<uint64_t, int64_t> savings;
00019     kv::Map<uint64_t, int64_t> checkings;
00020 
00021     SmallBankTables(kv::Store&) : accounts("a"), savings("b"), checkings("c") {}
00022   };
00023 
00024   class SmallBankHandlers : public UserEndpointRegistry
00025   {
00026   private:
00027     SmallBankTables tables;
00028 
00029     void set_error_status(
00030       EndpointContext& args, int status, std::string&& message)
00031     {
00032       args.rpc_ctx->set_response_status(status);
00033       args.rpc_ctx->set_response_header(
00034         http::headers::CONTENT_TYPE, http::headervalues::contenttype::TEXT);
00035       args.rpc_ctx->set_response_body(std::move(message));
00036     }
00037 
00038     void set_ok_status(EndpointContext& args)
00039     {
00040       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00041       args.rpc_ctx->set_response_header(
00042         http::headers::CONTENT_TYPE,
00043         http::headervalues::contenttype::OCTET_STREAM);
00044     }
00045 
00046     void set_no_content_status(EndpointContext& args)
00047     {
00048       args.rpc_ctx->set_response_status(HTTP_STATUS_NO_CONTENT);
00049     }
00050 
00051   public:
00052     SmallBankHandlers(kv::Store& store) :
00053       UserEndpointRegistry(store),
00054       tables(store)
00055     {}
00056 
00057     void init_handlers(kv::Store& store) override
00058     {
00059       UserEndpointRegistry::init_handlers(store);
00060 
00061       auto create = [this](auto& args) {
00062         // Create an account with a balance from thin air.
00063         const auto& body = args.rpc_ctx->get_request_body();
00064         auto ai = smallbank::AccountInfo::deserialize(body.data(), body.size());
00065         auto name = ai.name;
00066         uint64_t acc_id;
00067         std::from_chars(name.data(), name.data() + name.size(), acc_id);
00068         int64_t checking_amt = ai.checking_amt;
00069         int64_t savings_amt = ai.savings_amt;
00070         auto account_view = args.tx.get_view(tables.accounts);
00071         auto account_r = account_view->get(name);
00072 
00073         if (account_r.has_value())
00074         {
00075           set_error_status(
00076             args, HTTP_STATUS_BAD_REQUEST, "Account already exists");
00077           return;
00078         }
00079 
00080         account_view->put(name, acc_id);
00081 
00082         auto savings_view = args.tx.get_view(tables.savings);
00083         auto savings_r = savings_view->get(acc_id);
00084 
00085         if (savings_r.has_value())
00086         {
00087           set_error_status(
00088             args, HTTP_STATUS_BAD_REQUEST, "Account already exists");
00089           return;
00090         }
00091 
00092         savings_view->put(acc_id, savings_amt);
00093 
00094         auto checking_view = args.tx.get_view(tables.checkings);
00095         auto checking_r = checking_view->get(acc_id);
00096 
00097         if (checking_r.has_value())
00098         {
00099           set_error_status(
00100             args, HTTP_STATUS_BAD_REQUEST, "Account already exists");
00101           return;
00102         }
00103 
00104         checking_view->put(acc_id, checking_amt);
00105 
00106         set_no_content_status(args);
00107       };
00108 
00109       auto create_batch = [this](auto& args) {
00110         // Create N accounts with identical balances from thin air.
00111         const auto& body = args.rpc_ctx->get_request_body();
00112         auto ac =
00113           smallbank::AccountCreation::deserialize(body.data(), body.size());
00114 
00115         auto account_view = args.tx.get_view(tables.accounts);
00116         auto savings_view = args.tx.get_view(tables.savings);
00117         auto checking_view = args.tx.get_view(tables.checkings);
00118 
00119         for (auto acc_id = ac.new_id_from; acc_id < ac.new_id_to; ++acc_id)
00120         {
00121           std::string name = std::to_string(acc_id);
00122 
00123           auto account_r = account_view->get(name);
00124           if (account_r.has_value())
00125           {
00126             set_error_status(
00127               args,
00128               HTTP_STATUS_BAD_REQUEST,
00129               fmt::format(
00130                 "Account already exists in accounts table: '{}'", name));
00131             return;
00132           }
00133           account_view->put(name, acc_id);
00134 
00135           auto savings_r = savings_view->get(acc_id);
00136           if (savings_r.has_value())
00137           {
00138             set_error_status(
00139               args,
00140               HTTP_STATUS_BAD_REQUEST,
00141               fmt::format(
00142                 "Account already exists in savings table: '{}'", name));
00143             return;
00144           }
00145           savings_view->put(acc_id, ac.initial_savings_amt);
00146 
00147           auto checking_r = checking_view->get(acc_id);
00148           if (checking_r.has_value())
00149           {
00150             set_error_status(
00151               args,
00152               HTTP_STATUS_BAD_REQUEST,
00153               fmt::format(
00154                 "Account already exists in checkings table: '{}'", name));
00155             return;
00156           }
00157           checking_view->put(acc_id, ac.initial_checking_amt);
00158         }
00159 
00160         set_no_content_status(args);
00161       };
00162 
00163       auto balance = [this](auto& args) {
00164         // Check the combined balance of an account
00165         const auto& body = args.rpc_ctx->get_request_body();
00166         auto account =
00167           smallbank::AccountName::deserialize(body.data(), body.size());
00168         auto account_view = args.tx.get_view(tables.accounts);
00169         auto account_r = account_view->get(account.name);
00170 
00171         if (!account_r.has_value())
00172         {
00173           set_error_status(
00174             args, HTTP_STATUS_BAD_REQUEST, "Account does not exist");
00175           return;
00176         }
00177 
00178         auto savings_view = args.tx.get_view(tables.savings);
00179         auto savings_r = savings_view->get(account_r.value());
00180 
00181         if (!savings_r.has_value())
00182         {
00183           set_error_status(
00184             args, HTTP_STATUS_BAD_REQUEST, "Savings account does not exist");
00185           return;
00186         }
00187 
00188         auto checking_view = args.tx.get_view(tables.checkings);
00189         auto checking_r = checking_view->get(account_r.value());
00190 
00191         if (!checking_r.has_value())
00192         {
00193           set_error_status(
00194             args, HTTP_STATUS_BAD_REQUEST, "Checking account does not exist");
00195           return;
00196         }
00197 
00198         auto result = checking_r.value() + savings_r.value();
00199 
00200         set_ok_status(args);
00201 
00202         smallbank::Balance b;
00203         b.value = result;
00204         args.rpc_ctx->set_response_body(b.serialize());
00205       };
00206 
00207       auto transact_savings = [this](auto& args) {
00208         // Add or remove money to the savings account
00209         const auto& body = args.rpc_ctx->get_request_body();
00210         auto transaction =
00211           smallbank::Transaction::deserialize(body.data(), body.size());
00212         auto name = transaction.name;
00213         auto value = transaction.value;
00214 
00215         if (name.empty())
00216         {
00217           set_error_status(
00218             args, HTTP_STATUS_BAD_REQUEST, "A name must be specified");
00219           return;
00220         }
00221 
00222         auto account_view = args.tx.get_view(tables.accounts);
00223         auto account_r = account_view->get(name);
00224 
00225         if (!account_r.has_value())
00226         {
00227           set_error_status(
00228             args, HTTP_STATUS_BAD_REQUEST, "Account does not exist");
00229         }
00230 
00231         auto savings_view = args.tx.get_view(tables.savings);
00232         auto savings_r = savings_view->get(account_r.value());
00233 
00234         if (!savings_r.has_value())
00235         {
00236           set_error_status(
00237             args, HTTP_STATUS_BAD_REQUEST, "Savings account does not exist");
00238           return;
00239         }
00240 
00241         if (savings_r.value() + value < 0)
00242         {
00243           set_error_status(
00244             args,
00245             HTTP_STATUS_BAD_REQUEST,
00246             "Not enough money in savings account");
00247           return;
00248         }
00249 
00250         savings_view->put(account_r.value(), value + savings_r.value());
00251         set_no_content_status(args);
00252       };
00253 
00254       auto deposit_checking = [this](auto& args) {
00255         // Desposit money into the checking account out of thin air
00256         const auto& body = args.rpc_ctx->get_request_body();
00257         auto transaction =
00258           smallbank::Transaction::deserialize(body.data(), body.size());
00259         auto name = transaction.name;
00260         auto value = transaction.value;
00261 
00262         if (name.empty())
00263         {
00264           set_error_status(
00265             args, HTTP_STATUS_BAD_REQUEST, "A name must be specified");
00266           return;
00267         }
00268 
00269         if (value <= 0)
00270         {
00271           set_error_status(args, HTTP_STATUS_BAD_REQUEST, "Value <= 0");
00272           return;
00273         }
00274 
00275         auto account_view = args.tx.get_view(tables.accounts);
00276         auto account_r = account_view->get(name);
00277 
00278         if (!account_r.has_value())
00279         {
00280           set_error_status(
00281             args, HTTP_STATUS_BAD_REQUEST, "Account does not exist");
00282           return;
00283         }
00284 
00285         auto checking_view = args.tx.get_view(tables.checkings);
00286         auto checking_r = checking_view->get(account_r.value());
00287 
00288         if (!checking_r.has_value())
00289         {
00290           set_error_status(
00291             args, HTTP_STATUS_BAD_REQUEST, "Checking account does not exist");
00292           return;
00293         }
00294         checking_view->put(account_r.value(), value + checking_r.value());
00295         set_no_content_status(args);
00296       };
00297 
00298       auto amalgamate = [this](auto& args) {
00299         // Move the contents of one users account to another users account
00300         const auto& body = args.rpc_ctx->get_request_body();
00301         auto ad = smallbank::Amalgamate::deserialize(body.data(), body.size());
00302         auto name_1 = ad.src;
00303         auto name_2 = ad.dst;
00304         auto account_view = args.tx.get_view(tables.accounts);
00305         auto account_1_r = account_view->get(name_1);
00306 
00307         if (!account_1_r.has_value())
00308         {
00309           set_error_status(
00310             args, HTTP_STATUS_BAD_REQUEST, "Source account does not exist");
00311           return;
00312         }
00313 
00314         auto account_2_r = account_view->get(name_2);
00315 
00316         if (!account_2_r.has_value())
00317         {
00318           set_error_status(
00319             args,
00320             HTTP_STATUS_BAD_REQUEST,
00321             "Destination account does not exist");
00322           return;
00323         }
00324 
00325         auto savings_view = args.tx.get_view(tables.savings);
00326         auto savings_r = savings_view->get(account_1_r.value());
00327 
00328         if (!savings_r.has_value())
00329         {
00330           set_error_status(
00331             args,
00332             HTTP_STATUS_BAD_REQUEST,
00333             "Source savings account does not exist");
00334           return;
00335         }
00336 
00337         auto checking_view = args.tx.get_view(tables.checkings);
00338         auto checking_r = checking_view->get(account_1_r.value());
00339 
00340         if (!checking_r.has_value())
00341         {
00342           set_error_status(
00343             args,
00344             HTTP_STATUS_BAD_REQUEST,
00345             "Source checking account does not exist");
00346           return;
00347         }
00348 
00349         auto sum_account_1 = checking_r.value() + savings_r.value();
00350         checking_view->put(account_1_r.value(), 0);
00351         savings_view->put(account_1_r.value(), 0);
00352 
00353         auto checking_2_view = args.tx.get_view(tables.checkings);
00354         auto checking_2_r = checking_2_view->get(account_2_r.value());
00355 
00356         if (!checking_2_r.has_value())
00357         {
00358           set_error_status(
00359             args,
00360             HTTP_STATUS_BAD_REQUEST,
00361             "Destination checking account does not exist");
00362           return;
00363         }
00364 
00365         checking_2_view->put(
00366           account_2_r.value(), checking_2_r.value() + sum_account_1);
00367 
00368         set_no_content_status(args);
00369       };
00370 
00371       auto writeCheck = [this](auto& args) {
00372         // Write a check, if not enough funds then also charge an extra 1 money
00373         const auto& body = args.rpc_ctx->get_request_body();
00374         auto transaction =
00375           smallbank::Transaction::deserialize(body.data(), body.size());
00376         auto name = transaction.name;
00377         auto amount = transaction.value;
00378 
00379         auto account_view = args.tx.get_view(tables.accounts);
00380         auto account_r = account_view->get(name);
00381 
00382         if (!account_r.has_value())
00383         {
00384           set_error_status(
00385             args, HTTP_STATUS_BAD_REQUEST, "Account does not exist");
00386           return;
00387         }
00388 
00389         auto savings_view = args.tx.get_view(tables.savings);
00390         auto savings_r = savings_view->get(account_r.value());
00391 
00392         if (!savings_r.has_value())
00393         {
00394           set_error_status(
00395             args, HTTP_STATUS_BAD_REQUEST, "Savings account does not exist");
00396           return;
00397         }
00398 
00399         auto checking_view = args.tx.get_view(tables.checkings);
00400         auto checking_r = checking_view->get(account_r.value());
00401 
00402         if (!checking_r.has_value())
00403         {
00404           set_error_status(
00405             args, HTTP_STATUS_BAD_REQUEST, "Checking account does not exist");
00406           return;
00407         }
00408 
00409         auto account_value = checking_r.value() + savings_r.value();
00410         if (account_value < amount)
00411         {
00412           ++amount;
00413         }
00414         checking_view->put(account_r.value(), account_value - amount);
00415         set_no_content_status(args);
00416       };
00417 
00418       const ccf::endpoints::AuthnPolicies user_sig_or_cert = {
00419         user_signature_auth_policy, user_cert_auth_policy};
00420 
00421       std::vector<ccf::RESTVerb> verbs = {HTTP_POST, ws::Verb::WEBSOCKET};
00422       for (auto verb : verbs)
00423       {
00424         make_endpoint("SmallBank_create", verb, create, user_sig_or_cert)
00425           .install();
00426         make_endpoint(
00427           "SmallBank_create_batch", verb, create_batch, user_sig_or_cert)
00428           .install();
00429         make_endpoint("SmallBank_balance", verb, balance, user_sig_or_cert)
00430           .install();
00431         make_endpoint(
00432           "SmallBank_transact_savings",
00433           verb,
00434           transact_savings,
00435           user_sig_or_cert)
00436           .install();
00437         make_endpoint(
00438           "SmallBank_deposit_checking",
00439           verb,
00440           deposit_checking,
00441           user_sig_or_cert)
00442           .install();
00443         make_endpoint(
00444           "SmallBank_amalgamate", verb, amalgamate, user_sig_or_cert)
00445           .install();
00446         make_endpoint(
00447           "SmallBank_write_check", verb, writeCheck, user_sig_or_cert)
00448           .install();
00449       }
00450     }
00451   };
00452 
00453   class SmallBank : public ccf::UserRpcFrontend
00454   {
00455   private:
00456     SmallBankHandlers sb_handlers;
00457 
00458   public:
00459     SmallBank(kv::Store& store) :
00460       UserRpcFrontend(store, sb_handlers),
00461       sb_handlers(store)
00462     {
00463       disable_request_storing();
00464     }
00465   };
00466 
00467   std::shared_ptr<ccf::UserRpcFrontend> get_rpc_handler(
00468     NetworkTables& nwt, ccfapp::AbstractNodeContext&)
00469   {
00470     return make_shared<SmallBank>(*nwt.tables);
00471   }
00472 }
00473 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/apps/smallbank/app/smallbank.cpp...
Preprocessing /data/git/CCF/src/apps/smallbank/clients/small_bank_client.cpp...
#include ../smallbank_serializer.h: already included! skipping...
#include perf_client.h: not found! skipping...
Preprocessor output (size: 8379 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 using namespace std;
00007 using namespace nlohmann;
00008 
00009 struct SmallBankClientOptions : public client::PerfOptions
00010 {
00011   size_t total_accounts = 10;
00012 
00013   SmallBankClientOptions(CLI::App& app, const std::string& default_pid_file) :
00014     client::PerfOptions("Small_Bank_ClientCpp", default_pid_file, app)
00015   {
00016     app.add_option("--accounts", total_accounts)->capture_default_str();
00017   }
00018 };
00019 
00020 using Base = client::PerfBase<SmallBankClientOptions>;
00021 
00022 class SmallBankClient : public Base
00023 {
00024 private:
00025   enum class TransactionTypes : uint8_t
00026   {
00027     TransactSavings = 0,
00028     Amalgamate,
00029     WriteCheck,
00030     DepositChecking,
00031     GetBalance,
00032 
00033     NumberTransactions
00034   };
00035 
00036   const char* OPERATION_C_STR[5]{"SmallBank_transact_savings",
00037                                  "SmallBank_amalgamate",
00038                                  "SmallBank_write_check",
00039                                  "SmallBank_deposit_checking",
00040                                  "SmallBank_balance"};
00041 
00042   void print_accounts(const string& header = {})
00043   {
00044     if (!header.empty())
00045     {
00046       LOG_INFO_FMT("Header: {}", header);
00047     }
00048 
00049     auto conn = create_connection(true, false);
00050 
00051     nlohmann::json accs = nlohmann::json::array();
00052 
00053     for (auto i = 0ul; i < options.total_accounts; i++)
00054     {
00055       const auto body = smallbank::AccountName{to_string(i)}.serialize();
00056       const auto response =
00057         conn->call("SmallBank_balance", CBuffer{body.data(), body.size()});
00058 
00059       check_response(response);
00060       auto balance = smallbank::Balance::deserialize(
00061         response.body.data(), response.body.size());
00062       accs.push_back({{"account", i}, {"balance", balance.value}});
00063     }
00064 
00065     LOG_INFO_FMT("Accounts:\n{}", accs.dump(4));
00066   }
00067 
00068   std::optional<RpcTlsClient::Response> send_creation_transactions() override
00069   {
00070     const auto from = 0;
00071     const auto to = options.total_accounts;
00072 
00073     auto connection = get_connection();
00074     LOG_INFO_FMT("Creating accounts from {} to {}", from, to);
00075     smallbank::AccountCreation ac;
00076     ac.new_id_from = from;
00077     ac.new_id_to = options.total_accounts;
00078     ac.initial_checking_amt = 1000;
00079     ac.initial_savings_amt = 1000;
00080     const auto body = ac.serialize();
00081     const auto response = connection->call(
00082       "SmallBank_create_batch", CBuffer{body.data(), body.size()});
00083     check_response(response);
00084 
00085     return response;
00086   }
00087 
00088   void prepare_transactions() override
00089   {
00090     // Reserve space for transfer transactions
00091     prepared_txs.resize(options.num_transactions);
00092 
00093     for (decltype(options.num_transactions) i = 0; i < options.num_transactions;
00094          i++)
00095     {
00096       uint8_t operation =
00097         rand_range((uint8_t)TransactionTypes::NumberTransactions);
00098 
00099       std::vector<uint8_t> serialized_body;
00100 
00101       switch ((TransactionTypes)operation)
00102       {
00103         case TransactionTypes::TransactSavings:
00104         {
00105           smallbank::Transaction t;
00106           t.name = to_string(rand_range(options.total_accounts));
00107           t.value = rand_range<int>(-50, 50);
00108           serialized_body = t.serialize();
00109         }
00110         break;
00111 
00112         case TransactionTypes::Amalgamate:
00113         {
00114           unsigned int src_account = rand_range(options.total_accounts);
00115           unsigned int dest_account = rand_range(options.total_accounts - 1);
00116           if (dest_account >= src_account)
00117           {
00118             dest_account += 1;
00119           }
00120           smallbank::Amalgamate a;
00121           a.src = to_string(src_account);
00122           a.dst = to_string(dest_account);
00123           serialized_body = a.serialize();
00124         }
00125         break;
00126 
00127         case TransactionTypes::WriteCheck:
00128         {
00129           smallbank::Transaction t;
00130           t.name = to_string(rand_range(options.total_accounts));
00131           t.value = rand_range<int>(50);
00132           serialized_body = t.serialize();
00133         }
00134         break;
00135 
00136         case TransactionTypes::DepositChecking:
00137         {
00138           smallbank::Transaction t;
00139           t.name = to_string(rand_range(options.total_accounts));
00140           t.value = rand_range<int>(50) + 1;
00141           serialized_body = t.serialize();
00142         }
00143         break;
00144 
00145         case TransactionTypes::GetBalance:
00146         {
00147           smallbank::AccountName a;
00148           a.name = to_string(rand_range(options.total_accounts));
00149           serialized_body = a.serialize();
00150         }
00151         break;
00152 
00153         default:
00154           throw logic_error("Unknown operation");
00155       }
00156 
00157       add_prepared_tx(
00158         OPERATION_C_STR[operation],
00159         CBuffer{serialized_body.data(), serialized_body.size()},
00160         operation != (uint8_t)TransactionTypes::GetBalance,
00161         i);
00162     }
00163   }
00164 
00165   bool check_response(const RpcTlsClient::Response& r) override
00166   {
00167     if (!http::status_success(r.status))
00168     {
00169       const std::string error_msg(r.body.begin(), r.body.end());
00170       if (
00171         error_msg.find("Not enough money in savings account") == string::npos &&
00172         error_msg.find("Account already exists in accounts table") ==
00173           string::npos)
00174       {
00175         throw logic_error(error_msg);
00176         return false;
00177       }
00178     }
00179 
00180     return true;
00181   }
00182 
00183   void pre_creation_hook() override
00184   {
00185     LOG_DEBUG_FMT("Creating {} accounts", options.total_accounts);
00186   }
00187 
00188   void post_creation_hook() override
00189   {
00190     LOG_TRACE_FMT("Initial accounts:");
00191   }
00192 
00193   void post_timing_body_hook() override
00194   {
00195     LOG_TRACE_FMT("Final accounts:");
00196   }
00197 
00198   void verify_params(const nlohmann::json& expected) override
00199   {
00200     Base::verify_params(expected);
00201 
00202     {
00203       const auto it = expected.find("accounts");
00204       if (it != expected.end())
00205       {
00206         const auto expected_accounts =
00207           it->get<decltype(options.total_accounts)>();
00208         if (expected_accounts != options.total_accounts)
00209         {
00210           throw std::runtime_error(
00211             "Verification file is only applicable for " +
00212             std::to_string(expected_accounts) +
00213             " accounts, but currently have " +
00214             std::to_string(options.total_accounts));
00215         }
00216       }
00217     }
00218   }
00219 
00220   void verify_state(const std::string& prefix, const nlohmann::json& expected)
00221   {
00222     if (expected.is_null())
00223     {
00224       return;
00225     }
00226 
00227     auto expected_type_msg = [&prefix](const nlohmann::json& problematic) {
00228       return prefix +
00229         " state should be a list of (account, balance) objects, not: " +
00230         problematic.dump();
00231     };
00232 
00233     if (!expected.is_array())
00234     {
00235       throw std::runtime_error(expected_type_msg(expected));
00236     }
00237 
00238     // Create new connection to read balances
00239     auto conn = create_connection(true, false);
00240 
00241     for (const auto& entry : expected)
00242     {
00243       auto account_it = entry.find("account");
00244       auto balance_it = entry.find("balance");
00245       if (account_it == entry.end() || balance_it == entry.end())
00246       {
00247         throw std::runtime_error(expected_type_msg(entry));
00248       }
00249 
00250       const auto body =
00251         smallbank::AccountName{to_string(account_it->get<size_t>())}
00252           .serialize();
00253       const auto response =
00254         conn->call("SmallBank_balance", CBuffer{body.data(), body.size()});
00255 
00256       if (!http::status_success(response.status))
00257       {
00258         throw std::runtime_error(fmt::format(
00259           "Error in verification response: {}", conn->get_error(response)));
00260       }
00261 
00262       auto balance = smallbank::Balance::deserialize(
00263         response.body.data(), response.body.size());
00264       auto expected_balance = balance_it->get<int64_t>();
00265       auto actual_balance = balance.value;
00266       if (expected_balance != actual_balance)
00267       {
00268         throw std::runtime_error(
00269           "Expected account " + account_it->dump() + " to have balance " +
00270           std::to_string(expected_balance) + ", actual balance is " +
00271           std::to_string(actual_balance));
00272       }
00273     }
00274 
00275     LOG_INFO_FMT("Verified {}", prefix);
00276   }
00277 
00278   void verify_initial_state(const nlohmann::json& expected) override
00279   {
00280     verify_state("Initial", expected);
00281   }
00282 
00283   void verify_final_state(const nlohmann::json& expected) override
00284   {
00285     verify_state("Final", expected);
00286   }
00287 
00288 public:
00289   SmallBankClient(const SmallBankClientOptions& o) : Base(o) {}
00290 };
00291 
00292 int main(int argc, char** argv)
00293 {
00294   CLI::App cli_app{"Small Bank Client"};
00295   SmallBankClientOptions options(cli_app, argv[0]);
00296   CLI11_PARSE(cli_app, argc, argv);
00297 
00298   SmallBankClient client(options);
00299   client.run();
00300 
00301   return 0;
00302 }
00303 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/apps/smallbank/clients/small_bank_client.cpp...
Preprocessing /data/git/CCF/src/apps/smallbank/smallbank_serializer.h...
#include ds/serialized.h: not found! skipping...
Preprocessor output (size: 4181 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace smallbank
00008 {
00009   struct Transaction
00010   {
00011     std::string name;
00012     int64_t value;
00013 
00014     std::vector<uint8_t> serialize() const
00015     {
00016       auto size = sizeof(name.size()) + name.size() + sizeof(value);
00017       std::vector<uint8_t> v(size);
00018       auto data = v.data();
00019       serialized::write(data, size, name);
00020       serialized::write(data, size, value);
00021       return v;
00022     }
00023 
00024     static Transaction deserialize(const uint8_t* data, size_t size)
00025     {
00026       Transaction t;
00027       t.name = serialized::read<decltype(name)>(data, size);
00028       t.value = serialized::read<decltype(value)>(data, size);
00029       return t;
00030     }
00031   };
00032 
00033   struct Amalgamate
00034   {
00035     std::string src;
00036     std::string dst;
00037 
00038     std::vector<uint8_t> serialize() const
00039     {
00040       auto size =
00041         sizeof(src.size()) + src.size() + sizeof(dst.size()) + dst.size();
00042       std::vector<uint8_t> v(size);
00043       auto data = v.data();
00044       serialized::write(data, size, src);
00045       serialized::write(data, size, dst);
00046       return v;
00047     }
00048 
00049     static Amalgamate deserialize(const uint8_t* data, size_t size)
00050     {
00051       Amalgamate a;
00052       a.src = serialized::read<decltype(src)>(data, size);
00053       a.dst = serialized::read<decltype(dst)>(data, size);
00054       return a;
00055     }
00056   };
00057 
00058   struct Balance
00059   {
00060     int64_t value;
00061 
00062     std::vector<uint8_t> serialize() const
00063     {
00064       auto size = sizeof(value);
00065       std::vector<uint8_t> v(size);
00066       auto data = v.data();
00067       serialized::write(data, size, value);
00068       return v;
00069     }
00070 
00071     static Balance deserialize(const uint8_t* data, size_t size)
00072     {
00073       Balance b;
00074       b.value = serialized::read<decltype(value)>(data, size);
00075       return b;
00076     }
00077   };
00078 
00079   struct AccountName
00080   {
00081     std::string name;
00082 
00083     std::vector<uint8_t> serialize() const
00084     {
00085       auto size = sizeof(name.size()) + name.size();
00086       std::vector<uint8_t> v(size);
00087       auto data = v.data();
00088       serialized::write(data, size, name);
00089       return v;
00090     }
00091 
00092     static AccountName deserialize(const uint8_t* data, size_t size)
00093     {
00094       AccountName a;
00095       a.name = serialized::read<decltype(name)>(data, size);
00096       return a;
00097     }
00098   };
00099 
00100   struct AccountInfo
00101   {
00102     std::string name;
00103     int64_t checking_amt;
00104     int64_t savings_amt;
00105 
00106     std::vector<uint8_t> serialize() const
00107     {
00108       auto size = sizeof(name.size()) + name.size() + sizeof(checking_amt) +
00109         sizeof(savings_amt);
00110       std::vector<uint8_t> v(size);
00111       auto data = v.data();
00112       serialized::write(data, size, name);
00113       serialized::write(data, size, checking_amt);
00114       serialized::write(data, size, savings_amt);
00115       return v;
00116     }
00117 
00118     static AccountInfo deserialize(const uint8_t* data, size_t size)
00119     {
00120       AccountInfo a;
00121       a.name = serialized::read<decltype(name)>(data, size);
00122       a.checking_amt = serialized::read<decltype(checking_amt)>(data, size);
00123       a.savings_amt = serialized::read<decltype(savings_amt)>(data, size);
00124       return a;
00125     }
00126   };
00127 
00128   struct AccountCreation
00129   {
00130     uint64_t new_id_from;
00131     uint64_t new_id_to;
00132     int64_t initial_checking_amt;
00133     int64_t initial_savings_amt;
00134 
00135     std::vector<uint8_t> serialize() const
00136     {
00137       auto size = sizeof(new_id_from) + sizeof(new_id_to) +
00138         sizeof(initial_checking_amt) + sizeof(initial_savings_amt);
00139       std::vector<uint8_t> v(size);
00140       auto data = v.data();
00141       serialized::write(data, size, new_id_from);
00142       serialized::write(data, size, new_id_to);
00143       serialized::write(data, size, initial_checking_amt);
00144       serialized::write(data, size, initial_savings_amt);
00145       return v;
00146     }
00147 
00148     static AccountCreation deserialize(const uint8_t* data, size_t size)
00149     {
00150       AccountCreation a;
00151       a.new_id_from = serialized::read<decltype(new_id_from)>(data, size);
00152       a.new_id_to = serialized::read<decltype(new_id_to)>(data, size);
00153       a.initial_checking_amt =
00154         serialized::read<decltype(initial_checking_amt)>(data, size);
00155       a.initial_savings_amt =
00156         serialized::read<decltype(initial_savings_amt)>(data, size);
00157       return a;
00158     }
00159   };
00160 }
00161 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/apps/smallbank/smallbank_serializer.h...
Reading /data/git/CCF/src/apps/smallbank/tests/small_bank_client.py...
Parsing file /data/git/CCF/src/apps/smallbank/tests/small_bank_client.py...
Preprocessing /data/git/CCF/src/apps/smallbank/tests/small_bank_serdes_bench.cpp...
#include consensus/aft/request.h: not found! skipping...
#include node/encryptor.h: not found! skipping...
#include node/history.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 5222 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 const std::string account_name = "10";
00014 const int transaction_value = 50;
00015 
00016 inline void clobber_memory()
00017 {
00018   asm volatile("" : : : "memory");
00019 }
00020 
00021 // Helper functions
00022 std::shared_ptr<ccf::LedgerSecrets> create_ledger_secrets()
00023 {
00024   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00025   secrets->init();
00026 
00027   return secrets;
00028 }
00029 
00030 static std::vector<uint8_t> raw_tx_buffer()
00031 {
00032   const auto size =
00033     sizeof(size_t) + account_name.size() + sizeof(transaction_value);
00034   std::vector<uint8_t> v(size);
00035   auto data = v.data();
00036   auto remaining = v.size();
00037 
00038   serialized::write(data, remaining, account_name);
00039   serialized::write(data, remaining, transaction_value);
00040 
00041   return v;
00042 }
00043 
00044 static std::vector<uint8_t> packed_json_tx()
00045 {
00046   nlohmann::json j;
00047   j["name"] = account_name;
00048   j["value"] = transaction_value;
00049   return serdes::pack(j, serdes::Pack::MsgPack);
00050 }
00051 
00052 std::vector<uint8_t> large_payload(size_t size)
00053 {
00054   std::vector<uint8_t> payload;
00055   for (size_t i = 0; i < size; i++)
00056   {
00057     payload.push_back(i);
00058   }
00059   return payload;
00060 }
00061 
00062 static std::vector<uint8_t> kv_serialized_data(std::vector<uint8_t>& data)
00063 {
00064   kv::Store kv_store;
00065   auto secrets = create_ledger_secrets();
00066   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00067   kv_store.set_encryptor(encryptor);
00068 
00069   aft::RequestsMap map0("map0");
00070 
00071   auto tx = kv_store.create_reserved_tx(kv_store.next_version());
00072   auto tx0 = tx.get_view(map0);
00073 
00074   tx0->put(0, {{}, data, {}});
00075 
00076   auto pending_tx = tx.commit_reserved();
00077   return pending_tx.data;
00078 }
00079 // End Helper functions
00080 
00081 // Test functions
00082 static void raw_ser(picobench::state& s)
00083 {
00084   s.start_timer();
00085   for (int i = 0; i < s.iterations(); i++)
00086   {
00087     auto buf = raw_tx_buffer();
00088     clobber_memory();
00089   }
00090   s.stop_timer();
00091 }
00092 
00093 static void raw_des(picobench::state& s)
00094 {
00095   const auto buf = raw_tx_buffer();
00096   s.start_timer();
00097   for (int i = 0; i < s.iterations(); i++)
00098   {
00099     auto data = buf.data();
00100     auto size = buf.size();
00101 
00102     auto name =
00103       serialized::read<std::remove_cv_t<typeof(account_name)>>(data, size);
00104     auto value =
00105       serialized::read<std::remove_cv_t<typeof(transaction_value)>>(data, size);
00106     clobber_memory();
00107   }
00108   s.stop_timer();
00109 }
00110 
00111 static void json_msgpack_ser(picobench::state& s)
00112 {
00113   s.start_timer();
00114   for (int i = 0; i < s.iterations(); i++)
00115   {
00116     auto p = packed_json_tx();
00117     clobber_memory();
00118   }
00119   s.stop_timer();
00120 }
00121 
00122 static void json_msgpack_des(picobench::state& s)
00123 {
00124   auto p = packed_json_tx();
00125   s.start_timer();
00126   for (int i = 0; i < s.iterations(); i++)
00127   {
00128     auto params = serdes::unpack(p, serdes::Pack::MsgPack);
00129     std::string name = params["name"];
00130     int64_t value = params["value"];
00131     clobber_memory();
00132   }
00133   s.stop_timer();
00134 }
00135 
00136 static void run_mt_benchmark(picobench::state& s, std::vector<uint8_t> data)
00137 {
00138   ccf::MerkleTreeHistory tree;
00139   s.start_timer();
00140   for (int i = 0; i < s.iterations(); i++)
00141   {
00142     crypto::Sha256Hash rh({data.data(), data.size()});
00143     tree.append(rh);
00144     clobber_memory();
00145   }
00146   s.stop_timer();
00147 }
00148 
00149 static void raw_mt_append(picobench::state& s)
00150 {
00151   auto data = raw_tx_buffer();
00152   auto serialized_data = kv_serialized_data(data);
00153   run_mt_benchmark(s, serialized_data);
00154 }
00155 
00156 static void json_msgpack_mt_append(picobench::state& s)
00157 {
00158   auto data = packed_json_tx();
00159   auto serialized_data = kv_serialized_data(data);
00160   run_mt_benchmark(s, serialized_data);
00161 }
00162 
00163 template <size_t S>
00164 static void raw_large_payload(picobench::state& s)
00165 {
00166   auto payload = large_payload(S);
00167   auto data = kv_serialized_data(payload);
00168   run_mt_benchmark(s, data);
00169 }
00170 
00171 template <size_t S>
00172 static void jm_large_payload(picobench::state& s)
00173 {
00174   auto payload = large_payload(S);
00175   nlohmann::json j;
00176   j["data"] = payload;
00177   auto d = serdes::pack(j, serdes::Pack::MsgPack);
00178   auto data = kv_serialized_data(d);
00179   run_mt_benchmark(s, data);
00180 }
00181 
00182 const std::vector<int> iters = {10, 100, 1000};
00183 const std::vector<int> iter = {100};
00184 
00185 PICOBENCH_SUITE("smallbank payload serialize");
00186 PICOBENCH(raw_ser).iterations(iters).samples(10);
00187 PICOBENCH(json_msgpack_ser).iterations(iters).samples(10);
00188 
00189 PICOBENCH_SUITE("smallbank payload deserialize");
00190 PICOBENCH(raw_des).iterations(iters).samples(10);
00191 PICOBENCH(json_msgpack_des).iterations(iters).samples(10);
00192 
00193 PICOBENCH_SUITE("smallbank payload merkle tree bench");
00194 PICOBENCH(raw_mt_append).iterations(iters).samples(10);
00195 PICOBENCH(json_msgpack_mt_append).iterations(iters).samples(10);
00196 
00197 PICOBENCH_SUITE("large payload merkle tree bench");
00198 PICOBENCH(raw_large_payload<10>).iterations(iter).samples(10);
00199 PICOBENCH(jm_large_payload<10>).iterations(iter).samples(10);
00200 PICOBENCH(raw_large_payload<100>).iterations(iter).samples(10);
00201 PICOBENCH(jm_large_payload<100>).iterations(iter).samples(10);
00202 PICOBENCH(raw_large_payload<1000>).iterations(iter).samples(10);
00203 PICOBENCH(jm_large_payload<1000>).iterations(iter).samples(10);
00204 PICOBENCH(raw_large_payload<10000>).iterations(iter).samples(10);
00205 PICOBENCH(jm_large_payload<10000>).iterations(iter).samples(10);
00206 
00207 int main(int argc, char* argv[])
00208 {
00209   picobench::runner runner;
00210   runner.parse_cmd_line(argc, argv);
00211   return runner.run();
00212 }
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT 
---------
Parsing file /data/git/CCF/src/apps/smallbank/tests/small_bank_serdes_bench.cpp...
Preprocessing /data/git/CCF/src/clients/rpc_tls_client.h...
#include http/http_builder.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/http_parser.h: not found! skipping...
#include http/ws_builder.h: not found! skipping...
#include http/ws_parser.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
  #include assert.h: not found! skipping...
#include atomic: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include type_traits: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
  #include ../ds/buffer.h: already included! skipping...
    #include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/gcm.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/sha256.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include mbedtls/x509.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include mbedtls/x509_csr.h: not found! skipping...
#include memory: not found! skipping...
    #include ds/buffer.h: not found! skipping...
#include ds/json.h: not found! skipping...
      #include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/debug.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/entropy_poll.h: not found! skipping...
#include mbedtls/error.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/oid.h: not found! skipping...
#include mbedtls/rsa.h: not found! skipping...
#include mbedtls/sha256.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include mbedtls/x509.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include mbedtls/x509_csr.h: not found! skipping...
#include cstring: not found! skipping...
#include exception: not found! skipping...
#include memory: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
#include exception: not found! skipping...
  #include ca.h: already included! skipping...
    #include mbedtls/error.h: not found! skipping...
#include string: not found! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include cstring: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
#include ../tls/error_string.h: already included! skipping...
#include cstdint: not found! skipping...
#include cstring: not found! skipping...
#include iostream: not found! skipping...
#include mbedtls/config.h: not found! skipping...
#include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/error.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include netinet/in.h: not found! skipping...
#include netinet/tcp.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include fmt/format.h: not found! skipping...
#include http/http_sig.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include optional: not found! skipping...
#include thread: not found! skipping...
#include tls/key_pair.h: not found! skipping...
Preprocessor output (size: 6588 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 # 11 "/data/git/CCF/src/clients/rpc_tls_client.h" 2
00012 
00013 #define FMT_HEADER_ONLY
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 class HttpRpcTlsClient : public TlsClient, public http::ResponseProcessor
00022 {
00023 public:
00024   struct PreparedRpc
00025   {
00026     std::vector<uint8_t> encoded;
00027     size_t id;
00028   };
00029 
00030   struct Response
00031   {
00032     size_t id;
00033     http_status status;
00034     http::HeaderMap headers;
00035     std::vector<uint8_t> body;
00036   };
00037 
00038 protected:
00039   http::ResponseParser parser;
00040   ws::ResponseParser ws_parser;
00041   std::optional<std::string> prefix;
00042   tls::KeyPairPtr key_pair = nullptr;
00043   bool is_ws = false;
00044 
00045   size_t next_send_id = 0;
00046   size_t next_recv_id = 0;
00047 
00048   std::vector<uint8_t> gen_ws_upgrade_request()
00049   {
00050     auto r = http::Request("/", HTTP_GET);
00051     r.set_header("Upgrade", "websocket");
00052     r.set_header("Connection", "Upgrade");
00053     r.set_header("Sec-WebSocket-Key", "iT9AbE3Q96TfyWZ+3gQdfg==");
00054     r.set_header("Sec-WebSocket-Version", "13");
00055 
00056     return r.build_request();
00057   }
00058 
00059   std::vector<uint8_t> gen_http_request_internal(
00060     const std::string& method,
00061     const CBuffer params,
00062     const std::string& content_type,
00063     llhttp_method verb)
00064   {
00065     auto path = method;
00066     if (prefix.has_value())
00067     {
00068       path = fmt::format("/{}/{}", prefix.value(), path);
00069     }
00070 
00071     auto r = http::Request(path, verb);
00072     r.set_body(params.p, params.n);
00073     r.set_header(http::headers::CONTENT_TYPE, content_type);
00074 
00075     if (key_pair != nullptr)
00076     {
00077       http::sign_request(r, key_pair);
00078     }
00079 
00080     return r.build_request();
00081   }
00082 
00083   std::vector<uint8_t> gen_ws_request_internal(
00084     const std::string& method, const CBuffer params)
00085   {
00086     auto path = method;
00087     if (prefix.has_value())
00088     {
00089       path = fmt::format("/{}/{}", prefix.value(), path);
00090     }
00091     std::vector<uint8_t> body(params.p, params.p + params.n);
00092     return ws::make_in_frame(path, body);
00093   }
00094 
00095   std::vector<uint8_t> gen_request_internal(
00096     const std::string& method,
00097     const CBuffer params,
00098     const std::string& content_type,
00099     llhttp_method verb)
00100   {
00101     if (is_ws)
00102       return gen_ws_request_internal(method, params);
00103     else
00104       return gen_http_request_internal(method, params, content_type, verb);
00105   }
00106 
00107   Response call_raw(const std::vector<uint8_t>& raw)
00108   {
00109     CBuffer b(raw);
00110     write(b);
00111     return read_response();
00112   }
00113 
00114   Response call_raw(const PreparedRpc& prep)
00115   {
00116     return call_raw(prep.encoded);
00117   }
00118 
00119   std::optional<Response> last_response;
00120 
00121 public:
00122   using TlsClient::TlsClient;
00123 
00124   HttpRpcTlsClient(
00125     const std::string& host,
00126     const std::string& port,
00127     std::shared_ptr<tls::CA> node_ca = nullptr,
00128     std::shared_ptr<tls::Cert> cert = nullptr) :
00129     TlsClient(host, port, node_ca, cert),
00130     parser(*this),
00131     ws_parser(*this)
00132   {}
00133 
00134   HttpRpcTlsClient(const HttpRpcTlsClient& c) :
00135     TlsClient(c),
00136     parser(*this),
00137     ws_parser(*this)
00138   {}
00139 
00140   void upgrade_to_ws()
00141   {
00142     auto upgrade = gen_ws_upgrade_request();
00143     auto response = call_raw(upgrade);
00144     if (response.headers.find("sec-websocket-accept") == response.headers.end())
00145       throw std::logic_error("Failed to upgrade to websockets");
00146     is_ws = true;
00147   }
00148 
00149   void create_key_pair(const tls::Pem priv_key)
00150   {
00151     key_pair = tls::make_key_pair(priv_key);
00152   }
00153 
00154   PreparedRpc gen_request(
00155     const std::string& method,
00156     const CBuffer params,
00157     const std::string& content_type,
00158     llhttp_method verb = HTTP_POST)
00159   {
00160     return {gen_request_internal(method, params, content_type, verb),
00161             next_send_id++};
00162   }
00163 
00164   PreparedRpc gen_request(
00165     const std::string& method,
00166     const nlohmann::json& params = nullptr,
00167     llhttp_method verb = HTTP_POST)
00168   {
00169     std::vector<uint8_t> body;
00170     if (!params.is_null())
00171     {
00172       body = serdes::pack(params, serdes::Pack::MsgPack);
00173     }
00174     return gen_request(
00175       method,
00176       {body.data(), body.size()},
00177       http::headervalues::contenttype::MSGPACK,
00178       verb);
00179   }
00180 
00181   Response call(
00182     const std::string& method,
00183     const nlohmann::json& params = nullptr,
00184     llhttp_method verb = HTTP_POST)
00185   {
00186     return call_raw(gen_request(method, params, verb));
00187   }
00188 
00189   Response call(
00190     const std::string& method,
00191     const CBuffer& params,
00192     llhttp_method verb = HTTP_POST)
00193   {
00194     return call_raw(
00195       gen_request(method, params, http::headervalues::contenttype::JSON, verb));
00196   }
00197 
00198   Response post(const std::string& method, const nlohmann::json& params)
00199   {
00200     return call(method, params, HTTP_POST);
00201   }
00202 
00203   Response get(
00204     const std::string& method, const nlohmann::json& params = nullptr)
00205   {
00206     // GET body is ignored, so params must be placed in query
00207     auto full_path = method;
00208     if (!params.is_null())
00209     {
00210       for (auto it = params.begin(); it != params.end(); ++it)
00211       {
00212         full_path += fmt::format(
00213           "{}{}={}",
00214           it == params.begin() ? "?" : "&",
00215           it.key(),
00216           it.value().dump());
00217       }
00218     }
00219     return call(full_path, nullptr, HTTP_GET);
00220   }
00221 
00222   nlohmann::json unpack_body(const Response& resp)
00223   {
00224     if (resp.body.empty())
00225     {
00226       return nullptr;
00227     }
00228     else if (http::status_success(resp.status))
00229     {
00230       const auto& content_type = resp.headers.find(http::headers::CONTENT_TYPE);
00231       return serdes::unpack(resp.body, serdes::Pack::MsgPack);
00232     }
00233     else
00234     {
00235       return std::string(resp.body.begin(), resp.body.end());
00236     }
00237   }
00238 
00239   std::string get_error(const Response& resp)
00240   {
00241     return std::string(resp.body.begin(), resp.body.end());
00242   }
00243 
00244   Response read_response()
00245   {
00246     last_response = std::nullopt;
00247 
00248     while (!last_response.has_value())
00249     {
00250       if (is_ws)
00251       {
00252         auto buf = read(ws::INITIAL_READ);
00253         size_t n = ws_parser.consume(buf.data(), buf.size());
00254         buf = read(n);
00255         n = ws_parser.consume(buf.data(), buf.size());
00256         assert(n == ws::INITIAL_READ);
00257       }
00258       else
00259       {
00260         const auto next = read_all();
00261         parser.execute(next.data(), next.size());
00262       }
00263     }
00264 
00265     return std::move(last_response.value());
00266   }
00267 
00268   std::optional<Response> read_response_non_blocking()
00269   {
00270     if (bytes_available())
00271     {
00272       return read_response();
00273     }
00274 
00275     return std::nullopt;
00276   }
00277 
00278   virtual void handle_response(
00279     http_status status,
00280     http::HeaderMap&& headers,
00281     std::vector<uint8_t>&& body) override
00282   {
00283     last_response = {
00284       next_recv_id++, status, std::move(headers), std::move(body)};
00285   }
00286 
00287   void set_prefix(const std::string& prefix_)
00288   {
00289     prefix = prefix_;
00290   }
00291 };
00292 
00293 using RpcTlsClient = HttpRpcTlsClient;
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/clients/rpc_tls_client.h...
Preprocessing /data/git/CCF/src/clients/tls_client.h...
#include ../ds/buffer.h: already included! skipping...
#include ../tls/ca.h: already included! skipping...
#include ../tls/cert.h: already included! skipping...
#include ../tls/error_string.h: already included! skipping...
#include cstdint: not found! skipping...
#include cstring: not found! skipping...
#include iostream: not found! skipping...
#include mbedtls/config.h: not found! skipping...
#include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/error.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include netinet/in.h: not found! skipping...
#include netinet/tcp.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 4536 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 class TlsClient
00025 {
00026 private:
00027   std::string host;
00028   std::string port;
00029   std::shared_ptr<tls::CA> node_ca;
00030   std::shared_ptr<tls::Cert> cert;
00031   bool connected = false;
00032 
00033   mbedtls::NetContext server_fd;
00034   mbedtls::Entropy entropy;
00035   mbedtls::CtrDrbg ctr_drbg;
00036   mbedtls::SSLContext ssl;
00037   mbedtls::SSLConfig conf;
00038 
00039   void init()
00040   {
00041     auto tmp_server_fd = mbedtls::make_unique<mbedtls::NetContext>();
00042     auto tmp_entropy = mbedtls::make_unique<mbedtls::Entropy>();
00043     auto tmp_ctr_drbg = mbedtls::make_unique<mbedtls::CtrDrbg>();
00044     auto tmp_ssl = mbedtls::make_unique<mbedtls::SSLContext>();
00045     auto tmp_conf = mbedtls::make_unique<mbedtls::SSLConfig>();
00046 
00047     auto err = mbedtls_ctr_drbg_seed(
00048       tmp_ctr_drbg.get(), mbedtls_entropy_func, tmp_entropy.get(), nullptr, 0);
00049     if (err)
00050       throw std::logic_error(tls::error_string(err));
00051 
00052     err = mbedtls_net_connect(
00053       tmp_server_fd.get(), host.c_str(), port.c_str(), MBEDTLS_NET_PROTO_TCP);
00054     if (err)
00055       throw std::logic_error(tls::error_string(err));
00056 
00057     err = mbedtls_ssl_config_defaults(
00058       tmp_conf.get(),
00059       MBEDTLS_SSL_IS_CLIENT,
00060       MBEDTLS_SSL_TRANSPORT_STREAM,
00061       MBEDTLS_SSL_PRESET_DEFAULT);
00062     if (err)
00063       throw std::logic_error(tls::error_string(err));
00064 
00065     if (cert != nullptr)
00066       cert->use(tmp_ssl.get(), tmp_conf.get());
00067     if (node_ca != nullptr)
00068       node_ca->use(tmp_conf.get());
00069 
00070     mbedtls_ssl_conf_rng(
00071       tmp_conf.get(), mbedtls_ctr_drbg_random, tmp_ctr_drbg.get());
00072     mbedtls_ssl_conf_authmode(tmp_conf.get(), MBEDTLS_SSL_VERIFY_REQUIRED);
00073 
00074     err = mbedtls_ssl_setup(tmp_ssl.get(), tmp_conf.get());
00075     if (err)
00076       throw std::logic_error(tls::error_string(err));
00077 
00078     if (err)
00079       throw std::logic_error(tls::error_string(err));
00080 
00081     mbedtls_ssl_set_bio(
00082       tmp_ssl.get(),
00083       tmp_server_fd.get(),
00084       mbedtls_net_send,
00085       mbedtls_net_recv,
00086       nullptr);
00087 
00088     while (true)
00089     {
00090       err = mbedtls_ssl_handshake(tmp_ssl.get());
00091       if (err == 0)
00092         break;
00093       if (
00094         (err != MBEDTLS_ERR_SSL_WANT_READ) &&
00095         (err != MBEDTLS_ERR_SSL_WANT_WRITE))
00096         throw std::logic_error(tls::error_string(err));
00097     }
00098     connected = true;
00099 
00100     server_fd = std::move(tmp_server_fd);
00101     entropy = std::move(tmp_entropy);
00102     ctr_drbg = std::move(tmp_ctr_drbg);
00103     ssl = std::move(tmp_ssl);
00104     conf = std::move(tmp_conf);
00105   }
00106 
00107 public:
00108   TlsClient(
00109     const std::string& host,
00110     const std::string& port,
00111     std::shared_ptr<tls::CA> node_ca = nullptr,
00112     std::shared_ptr<tls::Cert> cert = nullptr) :
00113     host(host),
00114     port(port),
00115     node_ca(node_ca),
00116     cert(cert)
00117   {
00118     init();
00119   }
00120 
00121   TlsClient(const TlsClient& c) :
00122     host(c.host),
00123     port(c.port),
00124     node_ca(c.node_ca),
00125     cert(c.cert)
00126   {
00127     init();
00128   }
00129 
00130   virtual ~TlsClient()
00131   {
00132     // Signal the end of the connection
00133     if (connected)
00134       mbedtls_ssl_close_notify(ssl.get());
00135   }
00136 
00137   auto get_ciphersuite_name()
00138   {
00139     return mbedtls_ssl_get_ciphersuite(ssl.get());
00140   }
00141 
00142   void write(CBuffer b)
00143   {
00144     for (size_t written = 0; written < b.n;)
00145     {
00146       auto ret = mbedtls_ssl_write(ssl.get(), b.p + written, b.n - written);
00147       if (ret > 0)
00148         written += ret;
00149       else
00150         throw std::logic_error(tls::error_string(ret));
00151     }
00152   }
00153 
00154   std::vector<uint8_t> read(size_t read_size)
00155   {
00156     std::vector<uint8_t> buf(read_size);
00157     auto ret = mbedtls_ssl_read(ssl.get(), buf.data(), buf.size());
00158     if (ret > 0)
00159     {
00160       buf.resize(ret);
00161     }
00162     else if (ret == 0)
00163     {
00164       connected = false;
00165       throw std::logic_error("Underlying transport closed");
00166     }
00167     else
00168     {
00169       throw std::logic_error(tls::error_string(ret));
00170     }
00171 
00172     return buf;
00173   }
00174 
00175   bool bytes_available()
00176   {
00177     return mbedtls_ssl_get_bytes_avail(ssl.get()) > 0;
00178   }
00179 
00180   std::vector<uint8_t> read_all()
00181   {
00182     constexpr auto read_size = 4096;
00183     std::vector<uint8_t> buf(read_size);
00184     auto ret = mbedtls_ssl_read(ssl.get(), buf.data(), buf.size());
00185     if (ret > 0)
00186     {
00187       buf.resize(ret);
00188     }
00189     else if (ret == 0)
00190     {
00191       connected = false;
00192       throw std::logic_error("Underlying transport closed");
00193     }
00194     else
00195     {
00196       throw std::logic_error(tls::error_string(ret));
00197     }
00198 
00199     return buf;
00200   }
00201 
00202   void set_tcp_nodelay(bool on)
00203   {
00204     int option = on ? 1 : 0;
00205     setsockopt(
00206       server_fd->fd, IPPROTO_TCP, TCP_NODELAY, (char*)&option, sizeof(int));
00207   }
00208 };
00209 
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER 
---------
Parsing file /data/git/CCF/src/clients/tls_client.h...
Preprocessing /data/git/CCF/src/consensus/aft/impl/execution.cpp...
#include consensus/aft/raft_types.h: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
  #include consensus/aft/raft_types.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/rpc/tx_status.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include map: not found! skipping...
#include set: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include enclave/rpc_sessions.h: not found! skipping...
#include http/http_rpc_context.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include consensus/aft/raft_types.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
  #include cstdint: not found! skipping...
#include limits: not found! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 4205 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 # 4 "/data/git/CCF/src/consensus/aft/impl/execution.cpp" 2
00005 
00006 
00007 
00008 
00009 
00010 
00011 # 11 "/data/git/CCF/src/consensus/aft/impl/execution.cpp" 2
00012 
00013 namespace aft
00014 {
00015   std::unique_ptr<RequestCtx> ExecutorImpl::create_request_ctx(
00016     uint8_t* req_start, size_t req_size)
00017   {
00018     Request request;
00019     request.deserialise(req_start, req_size);
00020     return create_request_ctx(request);
00021   }
00022 
00023   std::unique_ptr<RequestCtx> ExecutorImpl::create_request_ctx(Request& request)
00024   {
00025     auto r_ctx = std::make_unique<RequestCtx>();
00026 
00027     auto session = std::make_shared<enclave::SessionContext>(
00028       enclave::InvalidSessionId, request.caller_cert);
00029 
00030     r_ctx->ctx = enclave::make_fwd_rpc_context(
00031       session, request.raw, (enclave::FrameFormat)request.frame_format);
00032 
00033     const auto actor_opt = http::extract_actor(*r_ctx->ctx);
00034     if (!actor_opt.has_value())
00035     {
00036       throw std::logic_error(fmt::format(
00037         "Failed to extract actor from BFT request. Method is '{}'",
00038         r_ctx->ctx->get_method()));
00039     }
00040 
00041     const auto& actor_s = actor_opt.value();
00042     const auto actor = rpc_map->resolve(actor_s);
00043     auto handler = rpc_map->find(actor);
00044     if (!handler.has_value())
00045       throw std::logic_error(
00046         fmt::format("No frontend associated with actor {}", actor_s));
00047 
00048     r_ctx->frontend = handler.value();
00049     return r_ctx;
00050   }
00051 
00052   kv::Version ExecutorImpl::execute_request(
00053     std::unique_ptr<RequestMessage> request,
00054     bool is_create_request,
00055     std::shared_ptr<aft::RequestTracker> request_tracker)
00056   {
00057     std::shared_ptr<enclave::RpcContext>& ctx = request->get_request_ctx().ctx;
00058     std::shared_ptr<enclave::RpcHandler>& frontend =
00059       request->get_request_ctx().frontend;
00060 
00061     ctx->bft_raw.resize(request->size());
00062     request->serialize_message(
00063       NoNode, ctx->bft_raw.data(), ctx->bft_raw.size());
00064 
00065     if (request_tracker != nullptr)
00066     {
00067       const auto& raw_request = ctx->get_serialised_request();
00068       auto data_ = raw_request.data();
00069       auto size_ = raw_request.size();
00070 
00071       crypto::Sha256Hash hash;
00072       tls::do_hash(data_, size_, hash.h, MBEDTLS_MD_SHA256);
00073 
00074       if (!request_tracker->remove(hash))
00075       {
00076         request_tracker->insert_deleted(
00077           hash,
00078           threading::ThreadMessaging::thread_messaging
00079             .get_current_time_offset());
00080       }
00081     }
00082 
00083     ctx->is_create_request = is_create_request;
00084     ctx->execute_on_node = true;
00085     ctx->set_apply_writes(true);
00086 
00087     enclave::RpcHandler::ProcessBftResp rep = frontend->process_bft(ctx);
00088 
00089     frontend->update_merkle_tree();
00090 
00091     request->callback(std::move(rep.result));
00092 
00093     return rep.version;
00094   }
00095 
00096   std::unique_ptr<aft::RequestMessage> ExecutorImpl::create_request_message(
00097     const kv::TxHistory::RequestCallbackArgs& args)
00098   {
00099     Request request = {
00100       args.rid, args.caller_cert, args.request, args.frame_format};
00101     auto serialized_req = request.serialise();
00102 
00103     auto rep_cb = [=](
00104                     void*,
00105                     kv::TxHistory::RequestID caller_rid,
00106                     int status,
00107                     std::vector<uint8_t>&& data) {
00108       LOG_DEBUG_FMT("AFT reply callback status {}", status);
00109 
00110       return rpc_sessions->reply_async(
00111         std::get<0>(caller_rid), std::move(data));
00112     };
00113 
00114     auto ctx = create_request_ctx(serialized_req.data(), serialized_req.size());
00115 
00116     return std::make_unique<RequestMessage>(
00117       std::move(serialized_req), args.rid, std::move(ctx), rep_cb);
00118   }
00119 
00120   kv::Version ExecutorImpl::commit_replayed_request(
00121     kv::Tx& tx, std::shared_ptr<aft::RequestTracker> request_tracker)
00122   {
00123     auto tx_view = tx.get_view<aft::RequestsMap>(ccf::Tables::AFT_REQUESTS);
00124     auto req_v = tx_view->get(0);
00125     CCF_ASSERT(
00126       req_v.has_value(),
00127       "Deserialised request but it was not found in the requests map");
00128     Request request = req_v.value();
00129 
00130     auto ctx = create_request_ctx(request);
00131 
00132     auto request_message = RequestMessage::deserialize(
00133       std::move(request.raw), request.rid, std::move(ctx), nullptr);
00134 
00135     return execute_request(
00136       std::move(request_message), state->commit_idx == 0, request_tracker);
00137   }
00138 }
00139 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/execution.cpp...
Preprocessing /data/git/CCF/src/consensus/aft/impl/execution.h...
#include consensus/aft/raft_types.h: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
#include state.h: already included! skipping...
Preprocessor output (size: 2160 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace enclave
00012 {
00013   class RPCSessions;
00014   class RPCMap;
00015 }
00016 
00017 namespace aft
00018 {
00019   class RequestMessage;
00020 
00021   struct RequestCtx
00022   {
00023     std::shared_ptr<enclave::RpcContext> ctx;
00024     std::shared_ptr<enclave::RpcHandler> frontend;
00025   };
00026 
00027   class Executor
00028   {
00029   public:
00030     virtual ~Executor() = default;
00031     virtual std::unique_ptr<RequestCtx> create_request_ctx(
00032       uint8_t* req_start, size_t req_size) = 0;
00033 
00034     virtual std::unique_ptr<RequestCtx> create_request_ctx(
00035       Request& request) = 0;
00036 
00037     virtual kv::Version execute_request(
00038       std::unique_ptr<RequestMessage> request,
00039       bool is_create_request,
00040       std::shared_ptr<aft::RequestTracker> request_tracker = nullptr) = 0;
00041 
00042     virtual std::unique_ptr<aft::RequestMessage> create_request_message(
00043       const kv::TxHistory::RequestCallbackArgs& args) = 0;
00044 
00045     virtual kv::Version commit_replayed_request(
00046       kv::Tx& tx, std::shared_ptr<aft::RequestTracker> request_tracker) = 0;
00047   };
00048 
00049   class ExecutorImpl : public Executor
00050   {
00051   public:
00052     ExecutorImpl(
00053       std::shared_ptr<State> state_,
00054       std::shared_ptr<enclave::RPCMap> rpc_map_,
00055       std::shared_ptr<enclave::RPCSessions> rpc_sessions_) :
00056       state(state_),
00057       rpc_map(rpc_map_),
00058       rpc_sessions(rpc_sessions_)
00059     {}
00060 
00061     std::unique_ptr<RequestCtx> create_request_ctx(
00062       uint8_t* req_start, size_t req_size) override;
00063 
00064     std::unique_ptr<RequestCtx> create_request_ctx(Request& request) override;
00065 
00066     kv::Version execute_request(
00067       std::unique_ptr<RequestMessage> request,
00068       bool is_create_request,
00069       std::shared_ptr<aft::RequestTracker> request_tracker = nullptr) override;
00070 
00071     std::unique_ptr<aft::RequestMessage> create_request_message(
00072       const kv::TxHistory::RequestCallbackArgs& args) override;
00073 
00074     kv::Version commit_replayed_request(
00075       kv::Tx& tx,
00076       std::shared_ptr<aft::RequestTracker> request_tracker) override;
00077 
00078   private:
00079     std::shared_ptr<State> state;
00080     std::shared_ptr<enclave::RPCMap> rpc_map;
00081     std::shared_ptr<enclave::RPCSessions> rpc_sessions;
00082   };
00083 }
00084 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/execution.h...
Preprocessing /data/git/CCF/src/consensus/aft/impl/message.h...
#include cstdint: not found! skipping...
#include limits: not found! skipping...
Preprocessor output (size: 430 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace aft
00009 {
00010   class AbstractMessage
00011   {
00012   public:
00013     AbstractMessage() = default;
00014     virtual ~AbstractMessage() = default;
00015 
00016     virtual bool should_encrypt() const = 0;
00017     virtual void serialize_message(
00018       aft::NodeId from_node, uint8_t* data, size_t size) const = 0;
00019     virtual size_t size() const = 0;
00020   };
00021 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/message.h...
Preprocessing /data/git/CCF/src/consensus/aft/impl/request_message.h...
#include consensus/aft/raft_types.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include message.h: already included! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2877 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace aft
00014 {
00015 // Request messages have the following format.
00016 
00017 
00018   struct RequestMessageRep : public consensus::ConsensusHeader<RaftMsgType>
00019   {
00020     RequestMessageRep() = default;
00021     RequestMessageRep(
00022       aft::NodeId from_node,
00023       uint16_t command_size_,
00024       uint16_t session_id_,
00025       kv::TxHistory::RequestID rid_) :
00026       consensus::ConsensusHeader<RaftMsgType>(
00027         RaftMsgType::bft_request, from_node),
00028       command_size(command_size_),
00029       session_id(session_id_),
00030       rid(rid_)
00031     {}
00032 
00033     uint16_t command_size;
00034     uint16_t session_id; // unique id of client who sends the request
00035     kv::TxHistory::RequestID rid; // unique request identifier
00036   };
00037 
00038 
00039   class RequestMessage : public AbstractMessage
00040   {
00041   public:
00042     RequestMessage(
00043       std::vector<uint8_t> request_,
00044       kv::TxHistory::RequestID rid_,
00045       std::unique_ptr<RequestCtx> ctx_,
00046       ReplyCallback cb_) :
00047       request(std::move(request_)),
00048       rid(rid_),
00049       ctx(std::move(ctx_)),
00050       cb(std::move(cb_))
00051     {}
00052 
00053     bool should_encrypt() const override
00054     {
00055       return true;
00056     }
00057 
00058     RequestCtx& get_request_ctx() const
00059     {
00060       return *ctx;
00061     }
00062 
00063     void callback(std::vector<uint8_t>&& data)
00064     {
00065       if (cb != nullptr)
00066       {
00067         cb(nullptr, rid, 0, std::move(data));
00068       }
00069     }
00070 
00071     void serialize_message(
00072       aft::NodeId from_node, uint8_t* data, size_t size) const override
00073     {
00074       RequestMessageRep rep(from_node, request.size(), 0, rid);
00075 
00076       serialized::write(
00077         data,
00078         size,
00079         reinterpret_cast<uint8_t*>(&rep),
00080         sizeof(RequestMessageRep));
00081       serialized::write(data, size, request.data(), request.size());
00082       CCF_ASSERT(size == 0, "allocated buffer is too large");
00083     }
00084 
00085     static std::unique_ptr<RequestMessage> deserialize(
00086       const uint8_t* data,
00087       size_t size,
00088       std::unique_ptr<RequestCtx> ctx,
00089       ReplyCallback cb)
00090     {
00091       auto rep = serialized::read<RequestMessageRep>(data, size);
00092       std::vector<uint8_t> request =
00093         serialized::read(data, size, rep.command_size);
00094       return std::make_unique<RequestMessage>(
00095         std::move(request), rep.rid, std::move(ctx), std::move(cb));
00096     }
00097 
00098     static std::unique_ptr<RequestMessage> deserialize(
00099       std::vector<uint8_t> request,
00100       kv::TxHistory::RequestID rid,
00101       std::unique_ptr<RequestCtx> ctx,
00102       ReplyCallback cb)
00103     {
00104       return std::make_unique<RequestMessage>(
00105         std::move(request), rid, std::move(ctx), std::move(cb));
00106     }
00107 
00108     size_t size() const override
00109     {
00110       return sizeof(RequestMessageRep) + request.size();
00111     }
00112 
00113   private:
00114     std::vector<uint8_t> request;
00115     kv::TxHistory::RequestID rid;
00116     std::unique_ptr<RequestCtx> ctx;
00117     ReplyCallback cb;
00118   };
00119 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/request_message.h...
Preprocessing /data/git/CCF/src/consensus/aft/impl/state.h...
#include consensus/aft/raft_types.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/rpc/tx_status.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include map: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 2632 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace aft
00017 {
00018   class ViewHistory
00019   {
00020     // Entry i stores the first version in view i+1
00021     std::vector<kv::Version> views;
00022 
00023   public:
00024     static constexpr kv::Consensus::View InvalidView = ccf::VIEW_UNKNOWN;
00025 
00026     void initialise(const std::vector<kv::Version>& terms_)
00027     {
00028       views.clear();
00029       for (size_t i = 0; i < terms_.size(); ++i)
00030       {
00031         update(terms_[i], i + 1);
00032       }
00033       LOG_DEBUG_FMT("Initialised views: {}", fmt::join(views, ", "));
00034     }
00035 
00036     void update(kv::Version idx, kv::Consensus::View view)
00037     {
00038       LOG_DEBUG_FMT("Updating view to: {} at version: {}", view, idx);
00039       if (!views.empty())
00040       {
00041         const auto current_latest_index = views.back();
00042         if (idx < current_latest_index)
00043         {
00044           throw std::logic_error(fmt::format(
00045             "version must not move backwards ({} < {})",
00046             idx,
00047             current_latest_index));
00048         }
00049       }
00050 
00051       for (int64_t i = views.size(); i < view; ++i)
00052       {
00053         views.push_back(idx);
00054       }
00055       LOG_DEBUG_FMT("Resulting views: {}", fmt::join(views, ", "));
00056     }
00057 
00058     kv::Consensus::View view_at(kv::Version idx)
00059     {
00060       auto it = upper_bound(views.begin(), views.end(), idx);
00061 
00062       // Indices before the version of the first view are unknown
00063       if (it == views.begin())
00064       {
00065         return InvalidView;
00066       }
00067 
00068       return (it - views.begin());
00069     }
00070 
00071     std::vector<kv::Version> get_history_until(
00072       kv::Version idx = std::numeric_limits<kv::Version>::max())
00073     {
00074       return {views.begin(), std::upper_bound(views.begin(), views.end(), idx)};
00075     }
00076   };
00077 
00078   class Replica
00079   {
00080   public:
00081     Replica(kv::NodeId id_, const std::vector<uint8_t>& cert_) :
00082       id(id_),
00083       verifier(tls::make_unique_verifier(cert_))
00084     {}
00085 
00086     kv::NodeId get_id() const
00087     {
00088       return id;
00089     }
00090 
00091   private:
00092     kv::NodeId id;
00093     tls::VerifierUniquePtr verifier;
00094   };
00095 
00096   struct State
00097   {
00098     State(kv::NodeId my_node_id_) :
00099       my_node_id(my_node_id_),
00100       current_view(0),
00101       last_idx(0),
00102       commit_idx(0),
00103       new_view_idx(0),
00104       requested_evidence_from(NoNode)
00105     {}
00106 
00107     SpinLock lock;
00108     std::map<kv::NodeId, std::shared_ptr<Replica>> configuration;
00109 
00110     kv::NodeId my_node_id;
00111     kv::Consensus::View current_view;
00112     kv::Version last_idx;
00113     kv::Version commit_idx;
00114 
00115     kv::Version cft_watermark_idx;
00116     kv::Version bft_watermark_idx;
00117 
00118     ViewHistory view_history;
00119     kv::Version new_view_idx;
00120     kv::NodeId requested_evidence_from;
00121   };
00122 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/state.h...
Preprocessing /data/git/CCF/src/consensus/aft/impl/view_change_tracker.h...
#include consensus/aft/raft_types.h: not found! skipping...
#include node/view_change.h: not found! skipping...
#include chrono: not found! skipping...
#include map: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 5270 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace aft
00013 {
00014   class ViewChangeTracker
00015   {
00016     struct ViewChange
00017     {
00018       ViewChange(kv::Consensus::View view_, kv::Consensus::SeqNo seqno_) :
00019         view(view_),
00020         seqno(seqno_),
00021         new_view_sent(false)
00022       {}
00023 
00024       kv::Consensus::View view;
00025       kv::Consensus::SeqNo seqno;
00026       bool new_view_sent;
00027 
00028       std::map<kv::NodeId, ccf::ViewChangeRequest> received_view_changes;
00029     };
00030 
00031   public:
00032     ViewChangeTracker(
00033       std::shared_ptr<ccf::ProgressTrackerStore> store_,
00034       std::chrono::milliseconds time_between_attempts_) :
00035       store(store_),
00036       last_view_change_sent(0),
00037       time_between_attempts(time_between_attempts_)
00038     {}
00039 
00040     bool should_send_view_change(std::chrono::milliseconds time)
00041     {
00042       if (time > time_between_attempts + time_previous_view_change_increment)
00043       {
00044         ++last_view_change_sent;
00045         time_previous_view_change_increment = time;
00046         return true;
00047       }
00048       return false;
00049     }
00050 
00051     bool is_view_change_in_progress(std::chrono::milliseconds time)
00052     {
00053       return time <=
00054         (time_between_attempts + time_previous_view_change_increment);
00055     }
00056 
00057     kv::Consensus::View get_target_view() const
00058     {
00059       return last_view_change_sent;
00060     }
00061 
00062     void set_current_view_change(kv::Consensus::View view)
00063     {
00064       view_changes.clear();
00065       last_view_change_sent = view;
00066     }
00067 
00068     enum class ResultAddView
00069     {
00070       OK,
00071       APPEND_NEW_VIEW_MESSAGE
00072     };
00073 
00074     ResultAddView add_request_view_change(
00075       ccf::ViewChangeRequest& v,
00076       kv::NodeId from,
00077       kv::Consensus::View view,
00078       kv::Consensus::SeqNo seqno,
00079       uint32_t node_count)
00080     {
00081       auto it = view_changes.find(view);
00082       if (it == view_changes.end())
00083       {
00084         ViewChange view_change(view, seqno);
00085         std::tie(it, std::ignore) =
00086           view_changes.emplace(view, std::move(view_change));
00087       }
00088       it->second.received_view_changes.emplace(from, v);
00089 
00090       if (
00091         should_send_new_view(
00092           it->second.received_view_changes.size(), node_count) &&
00093         it->second.new_view_sent == false)
00094       {
00095         it->second.new_view_sent = true;
00096         last_valid_view = view;
00097         return ResultAddView::APPEND_NEW_VIEW_MESSAGE;
00098       }
00099 
00100       return ResultAddView::OK;
00101     }
00102 
00103     kv::Consensus::SeqNo write_view_change_confirmation_append_entry(
00104       kv::Consensus::View view)
00105     {
00106       ccf::ViewChangeConfirmation nv =
00107         create_view_change_confirmation_msg(view);
00108       return store->write_view_change_confirmation(nv);
00109     }
00110 
00111     std::vector<uint8_t> get_serialized_view_change_confirmation(
00112       kv::Consensus::View view)
00113     {
00114       ccf::ViewChangeConfirmation nv =
00115         create_view_change_confirmation_msg(view);
00116       nlohmann::json j;
00117       to_json(j, nv);
00118       std::string s = j.dump();
00119       return {s.begin(), s.end() + 1};
00120     }
00121 
00122     bool add_unknown_primary_evidence(
00123       CBuffer data, kv::Consensus::View view, uint32_t node_count)
00124     {
00125       nlohmann::json j = nlohmann::json::parse(data.p);
00126       auto vc = j.get<ccf::ViewChangeConfirmation>();
00127 
00128       if (view != vc.view)
00129       {
00130         return false;
00131       }
00132 
00133       if (
00134         vc.view_change_messages.size() < ccf::get_message_threshold(node_count))
00135       {
00136         return false;
00137       }
00138 
00139       for (auto it : vc.view_change_messages)
00140       {
00141         if (!store->verify_view_change_request(
00142               it.second, it.first, vc.view, vc.seqno))
00143         {
00144           return false;
00145         }
00146       }
00147 
00148       last_valid_view = view;
00149       return true;
00150     }
00151 
00152     bool check_evidence(kv::Consensus::View view) const
00153     {
00154       return last_valid_view == view;
00155     }
00156 
00157     void clear(bool is_primary, kv::Consensus::View view)
00158     {
00159       for (auto it = view_changes.begin(); it != view_changes.end();)
00160       {
00161         if (is_primary && it->first != view)
00162         {
00163           it = view_changes.erase(it);
00164         }
00165         else
00166         {
00167           ++it;
00168         }
00169       }
00170       view_changes.clear();
00171       last_valid_view = view;
00172     }
00173 
00174   private:
00175     std::shared_ptr<ccf::ProgressTrackerStore> store;
00176     std::map<kv::Consensus::View, ViewChange> view_changes;
00177     std::chrono::milliseconds time_previous_view_change_increment =
00178       std::chrono::milliseconds(0);
00179     kv::Consensus::View last_view_change_sent = 0;
00180     kv::Consensus::View last_valid_view = aft::starting_view_change;
00181     const std::chrono::milliseconds time_between_attempts;
00182 
00183     ccf::ViewChangeConfirmation create_view_change_confirmation_msg(
00184       kv::Consensus::View view)
00185     {
00186       auto it = view_changes.find(view);
00187       if (it == view_changes.end())
00188       {
00189         throw std::logic_error(fmt::format(
00190           "Cannot write unknown view-change to ledger, view:{}", view));
00191       }
00192 
00193       auto& vc = it->second;
00194       ccf::ViewChangeConfirmation nv(vc.view, vc.seqno);
00195 
00196       for (auto it : vc.received_view_changes)
00197       {
00198         nv.view_change_messages.emplace(it.first, it.second);
00199       }
00200 
00201       return nv;
00202     }
00203 
00204     bool should_send_new_view(size_t received_requests, size_t node_count) const
00205     {
00206       return received_requests == ccf::get_message_threshold(node_count);
00207     }
00208   };
00209 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/impl/view_change_tracker.h...
Preprocessing /data/git/CCF/src/consensus/aft/raft.h...
#include ds/logger.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include impl/execution.h: already included! skipping...
#include impl/request_message.h: already included! skipping...
#include impl/state.h: already included! skipping...
#include consensus/aft/raft_types.h: not found! skipping...
#include node/view_change.h: not found! skipping...
#include chrono: not found! skipping...
#include map: not found! skipping...
#include set: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/node_to_node.h: not found! skipping...
#include node/node_types.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
#include node/rpc/tx_status.h: not found! skipping...
#include node/signatures.h: not found! skipping...
#include consensus/consensus_types.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include mbedtls/ecdsa.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include array: not found! skipping...
#include chrono: not found! skipping...
#include cstdint: not found! skipping...
#include limits: not found! skipping...
#include algorithm: not found! skipping...
#include deque: not found! skipping...
#include list: not found! skipping...
#include random: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 63467 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 # 11 "/data/git/CCF/src/consensus/aft/raft.h" 2
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 # 20 "/data/git/CCF/src/consensus/aft/raft.h" 2
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 namespace aft
00030 {
00031   using Configuration = kv::Consensus::Configuration;
00032 
00033   template <class LedgerProxy, class ChannelProxy, class SnapshotterProxy>
00034   class Aft
00035   {
00036   private:
00037     enum ReplicaState
00038     {
00039       Leader,
00040       Follower,
00041       Candidate,
00042       Retired
00043     };
00044 
00045     struct NodeState
00046     {
00047       Configuration::NodeInfo node_info;
00048 
00049       // the highest index sent to the node
00050       Index sent_idx;
00051 
00052       // the highest matching index with the node that was confirmed
00053       Index match_idx;
00054 
00055       NodeState() = default;
00056 
00057       NodeState(
00058         const Configuration::NodeInfo& node_info_,
00059         Index sent_idx_,
00060         Index match_idx_ = 0) :
00061         node_info(node_info_),
00062         sent_idx(sent_idx_),
00063         match_idx(match_idx_)
00064       {}
00065     };
00066 
00067     ConsensusType consensus_type;
00068     std::unique_ptr<Store<kv::DeserialiseSuccess>> store;
00069 
00070     // Persistent
00071     NodeId voted_for;
00072 
00073     // Volatile
00074     NodeId leader_id;
00075     std::unordered_set<NodeId> votes_for_me;
00076 
00077     ReplicaState replica_state;
00078     std::chrono::milliseconds timeout_elapsed;
00079     // Last (committable) index preceding the node's election, this is
00080     // used to decide when to start issuing signatures. While commit_idx
00081     // hasn't caught up with election_index, a newly elected leader is
00082     // effectively finishing establishing commit over the previous term
00083     // or even previous terms, and can therefore not meaningfully sign
00084     // over the commit level.
00085     kv::Version election_index = 0;
00086 
00087     // BFT
00088     std::shared_ptr<aft::State> state;
00089     std::shared_ptr<Executor> executor;
00090     std::shared_ptr<aft::RequestTracker> request_tracker;
00091     std::unique_ptr<aft::ViewChangeTracker> view_change_tracker;
00092 
00093     // Timeouts
00094     std::chrono::milliseconds request_timeout;
00095     std::chrono::milliseconds election_timeout;
00096     std::chrono::milliseconds view_change_timeout;
00097     size_t sig_tx_interval;
00098 
00099     // Configurations
00100     std::list<Configuration> configurations;
00101     std::unordered_map<NodeId, NodeState> nodes;
00102 
00103     size_t entry_size_not_limited = 0;
00104     size_t entry_count = 0;
00105     Index entries_batch_size = 1;
00106     static constexpr int batch_window_size = 100;
00107     int batch_window_sum = 0;
00108 
00109     // Indices that are eligible for global commit, from a Node's perspective
00110     std::deque<Index> committable_indices;
00111 
00112     // When this is set, only public domain is deserialised when receiving
00113     // append entries
00114     bool public_only = false;
00115 
00116     // Randomness
00117     std::uniform_int_distribution<int> distrib;
00118     std::default_random_engine rand;
00119 
00120   public:
00121     static constexpr size_t append_entries_size_limit = 20000;
00122     std::unique_ptr<LedgerProxy> ledger;
00123     std::shared_ptr<ccf::NodeToNode> channels;
00124     std::shared_ptr<SnapshotterProxy> snapshotter;
00125     std::shared_ptr<enclave::RPCSessions> rpc_sessions;
00126     std::shared_ptr<enclave::RPCMap> rpc_map;
00127     std::set<NodeId> backup_nodes;
00128 
00129   public:
00130     Aft(
00131       ConsensusType consensus_type_,
00132       std::unique_ptr<Store<kv::DeserialiseSuccess>> store_,
00133       std::unique_ptr<LedgerProxy> ledger_,
00134       std::shared_ptr<ccf::NodeToNode> channels_,
00135       std::shared_ptr<SnapshotterProxy> snapshotter_,
00136       std::shared_ptr<enclave::RPCSessions> rpc_sessions_,
00137       std::shared_ptr<enclave::RPCMap> rpc_map_,
00138       const std::vector<uint8_t>& /*cert*/,
00139       std::shared_ptr<aft::State> state_,
00140       std::shared_ptr<Executor> executor_,
00141       std::shared_ptr<aft::RequestTracker> request_tracker_,
00142       std::unique_ptr<aft::ViewChangeTracker> view_change_tracker_,
00143       std::chrono::milliseconds request_timeout_,
00144       std::chrono::milliseconds election_timeout_,
00145       std::chrono::milliseconds view_change_timeout_,
00146       size_t sig_tx_interval_ = 0,
00147       bool public_only_ = false) :
00148       consensus_type(consensus_type_),
00149       store(std::move(store_)),
00150       voted_for(NoNode),
00151 
00152       replica_state(Follower),
00153       timeout_elapsed(0),
00154 
00155       state(state_),
00156       executor(executor_),
00157       request_tracker(request_tracker_),
00158       view_change_tracker(std::move(view_change_tracker_)),
00159 
00160       request_timeout(request_timeout_),
00161       election_timeout(election_timeout_),
00162       view_change_timeout(view_change_timeout_),
00163       sig_tx_interval(sig_tx_interval_),
00164       public_only(public_only_),
00165 
00166       distrib(0, (int)election_timeout_.count() / 2),
00167       rand((int)(uintptr_t)this),
00168 
00169       ledger(std::move(ledger_)),
00170       channels(channels_),
00171       snapshotter(snapshotter_),
00172       rpc_sessions(rpc_sessions_),
00173       rpc_map(rpc_map_)
00174 
00175     {
00176       leader_id = NoNode;
00177       if (view_change_tracker != nullptr)
00178       {
00179         view_change_tracker->set_current_view_change(starting_view_change);
00180       }
00181 
00182       if (consensus_type == ConsensusType::BFT)
00183       {
00184         // Initialize view history for bft. We start on view 2 and the first
00185         // commit is always 1.
00186         state->view_history.update(1, starting_view_change);
00187       }
00188     }
00189 
00190     NodeId leader()
00191     {
00192       return leader_id;
00193     }
00194 
00195     std::set<NodeId> active_nodes()
00196     {
00197       // Find all nodes present in any active configuration.
00198       if (backup_nodes.empty())
00199       {
00200         Configuration::Nodes active_nodes;
00201 
00202         for (auto& conf : configurations)
00203         {
00204           for (auto node : conf.nodes)
00205           {
00206             backup_nodes.insert(node.first);
00207           }
00208         }
00209       }
00210 
00211       return backup_nodes;
00212     }
00213 
00214     NodeId id()
00215     {
00216       return state->my_node_id;
00217     }
00218 
00219     bool is_primary()
00220     {
00221       return replica_state == Leader;
00222     }
00223 
00224     bool is_follower()
00225     {
00226       return replica_state == Follower;
00227     }
00228 
00229     NodeId get_primary(kv::Consensus::View view)
00230     {
00231       // This will not work once we have reconfiguration support
00232       // https://github.com/microsoft/CCF/issues/1852
00233       return (view - starting_view_change) % active_nodes().size();
00234     }
00235 
00236     Index last_committable_index() const
00237     {
00238       return committable_indices.empty() ? state->commit_idx :
00239                                            committable_indices.back();
00240     }
00241 
00242     void enable_all_domains()
00243     {
00244       // When receiving append entries as a follower, all security domains will
00245       // be deserialised
00246       std::lock_guard<SpinLock> guard(state->lock);
00247       public_only = false;
00248     }
00249 
00250     void force_become_leader()
00251     {
00252       // This is unsafe and should only be called when the node is certain
00253       // there is no leader and no other node will attempt to force leadership.
00254       if (leader_id != NoNode)
00255       {
00256         throw std::logic_error(
00257           "Can't force leadership if there is already a leader");
00258       }
00259 
00260       std::lock_guard<SpinLock> guard(state->lock);
00261       state->current_view += starting_view_change;
00262       become_leader();
00263     }
00264 
00265     void force_become_leader(
00266       Index index,
00267       Term term,
00268       const std::vector<Index>& terms,
00269       Index commit_idx_)
00270     {
00271       // This is unsafe and should only be called when the node is certain
00272       // there is no leader and no other node will attempt to force leadership.
00273       if (leader_id != NoNode)
00274         throw std::logic_error(
00275           "Can't force leadership if there is already a leader");
00276       std::lock_guard<SpinLock> guard(state->lock);
00277       state->current_view = term;
00278       state->last_idx = index;
00279       state->commit_idx = commit_idx_;
00280       state->view_history.initialise(terms);
00281       state->view_history.update(index, term);
00282       state->current_view += starting_view_change;
00283       become_leader();
00284     }
00285 
00286     void init_as_follower(
00287       Index index, Term term, const std::vector<Index>& term_history)
00288     {
00289       // This should only be called when the node resumes from a snapshot and
00290       // before it has received any append entries.
00291       std::lock_guard<SpinLock> guard(state->lock);
00292 
00293       state->last_idx = index;
00294       state->commit_idx = index;
00295 
00296       state->view_history.initialise(term_history);
00297 
00298       ledger->init(index);
00299       snapshotter->set_last_snapshot_idx(index);
00300 
00301       become_follower(term);
00302     }
00303 
00304     Index get_last_idx()
00305     {
00306       return state->last_idx;
00307     }
00308 
00309     Index get_commit_idx()
00310     {
00311       if (consensus_type == ConsensusType::BFT && is_follower())
00312       {
00313         return state->commit_idx;
00314       }
00315       std::lock_guard<SpinLock> guard(state->lock);
00316       return state->commit_idx;
00317     }
00318 
00319     Term get_term()
00320     {
00321       if (consensus_type == ConsensusType::BFT && is_follower())
00322       {
00323         return state->current_view;
00324       }
00325       std::lock_guard<SpinLock> guard(state->lock);
00326       return state->current_view;
00327     }
00328 
00329     std::pair<Term, Index> get_commit_term_and_idx()
00330     {
00331       if (consensus_type == ConsensusType::BFT && is_follower())
00332       {
00333         return {get_term_internal(state->commit_idx), state->commit_idx};
00334       }
00335       std::lock_guard<SpinLock> guard(state->lock);
00336       return {get_term_internal(state->commit_idx), state->commit_idx};
00337     }
00338 
00339     std::optional<std::pair<Term, Index>> get_signable_commit_term_and_idx()
00340     {
00341       std::lock_guard<SpinLock> guard(state->lock);
00342       if (state->commit_idx >= election_index)
00343       {
00344         return std::pair<Term, Index>{get_term_internal(state->commit_idx),
00345                                       state->commit_idx};
00346       }
00347       else
00348       {
00349         return std::nullopt;
00350       }
00351     }
00352 
00353     Term get_term(Index idx)
00354     {
00355       if (consensus_type == ConsensusType::BFT && is_follower())
00356       {
00357         return get_term_internal(idx);
00358       }
00359       std::lock_guard<SpinLock> guard(state->lock);
00360       return get_term_internal(idx);
00361     }
00362 
00363     std::vector<Index> get_term_history(Index idx)
00364     {
00365       // This should only be called when the spin lock is held.
00366       return state->view_history.get_history_until(idx);
00367     }
00368 
00369     void initialise_term_history(const std::vector<Index>& term_history)
00370     {
00371       // This should only be called when the spin lock is held.
00372       return state->view_history.initialise(term_history);
00373     }
00374 
00375     void add_configuration(Index idx, const Configuration::Nodes& conf)
00376     {
00377       // This should only be called when the spin lock is held.
00378       configurations.push_back({idx, std::move(conf)});
00379       backup_nodes.clear();
00380       create_and_remove_node_state();
00381     }
00382 
00383     Configuration::Nodes get_latest_configuration() const
00384     {
00385       if (configurations.empty())
00386       {
00387         return {};
00388       }
00389 
00390       return configurations.back().nodes;
00391     }
00392 
00393     uint32_t node_count() const
00394     {
00395       return get_latest_configuration().size();
00396     }
00397 
00398     template <typename T>
00399     bool replicate(
00400       const std::vector<std::tuple<Index, T, bool>>& entries, Term term)
00401     {
00402       if (consensus_type == ConsensusType::BFT && is_follower())
00403       {
00404         return true;
00405       }
00406 
00407       std::lock_guard<SpinLock> guard(state->lock);
00408 
00409       if (replica_state != Leader)
00410       {
00411         LOG_FAIL_FMT(
00412           "Failed to replicate {} items: not leader", entries.size());
00413         rollback(state->last_idx);
00414         return false;
00415       }
00416 
00417       if (term != state->current_view)
00418       {
00419         LOG_FAIL_FMT(
00420           "Failed to replicate {} items at term {}, current term is {}",
00421           entries.size(),
00422           term,
00423           state->current_view);
00424         return false;
00425       }
00426 
00427       LOG_DEBUG_FMT("Replicating {} entries", entries.size());
00428 
00429       for (auto& [index, data, is_globally_committable] : entries)
00430       {
00431         bool globally_committable = is_globally_committable;
00432 
00433         if (index != state->last_idx + 1)
00434           return false;
00435 
00436         LOG_DEBUG_FMT(
00437           "Replicated on leader {}: {}{}",
00438           state->my_node_id,
00439           index,
00440           (globally_committable ? " committable" : ""));
00441 
00442         bool force_ledger_chunk = false;
00443         if (globally_committable)
00444         {
00445           committable_indices.push_back(index);
00446 
00447           // Only if globally committable, a snapshot requires a new ledger
00448           // chunk to be created
00449           force_ledger_chunk = snapshotter->requires_snapshot(index);
00450         }
00451 
00452         state->last_idx = index;
00453         ledger->put_entry(*data, globally_committable, force_ledger_chunk);
00454         entry_size_not_limited += data->size();
00455         entry_count++;
00456 
00457         state->view_history.update(index, state->current_view);
00458         if (entry_size_not_limited >= append_entries_size_limit)
00459         {
00460           update_batch_size();
00461           entry_count = 0;
00462           entry_size_not_limited = 0;
00463           for (const auto& it : nodes)
00464           {
00465             LOG_DEBUG_FMT("Sending updates to follower {}", it.first);
00466             send_append_entries(it.first, it.second.sent_idx + 1);
00467           }
00468         }
00469       }
00470 
00471       // If we are the only node, attempt to commit immediately.
00472       if (nodes.size() == 0)
00473       {
00474         update_commit();
00475       }
00476 
00477       return true;
00478     }
00479     void recv_message(const uint8_t* data, size_t size)
00480     {
00481       recv_message(OArray({data, data + size}));
00482     }
00483 
00484     void recv_message(OArray&& d)
00485     {
00486       const uint8_t* data = d.data();
00487       size_t size = d.size();
00488       // The host does a CALLIN to this when a Aft message
00489       // is received. Invalid or malformed messages are ignored
00490       // without informing the host. Messages are idempotent,
00491       // so it is not necessary to defend against replay attacks.
00492       switch (serialized::peek<RaftMsgType>(data, size))
00493       {
00494         case raft_append_entries:
00495           recv_append_entries(data, size);
00496           break;
00497 
00498         case raft_append_entries_response:
00499           recv_append_entries_response(data, size);
00500           break;
00501 
00502         case raft_append_entries_signed_response:
00503           recv_append_entries_signed_response(data, size);
00504           break;
00505 
00506         case raft_request_vote:
00507           recv_request_vote(data, size);
00508           break;
00509 
00510         case raft_request_vote_response:
00511           recv_request_vote_response(data, size);
00512           break;
00513 
00514         case bft_signature_received_ack:
00515           recv_signature_received_ack(data, size);
00516           break;
00517 
00518         case bft_nonce_reveal:
00519           recv_nonce_reveal(data, size);
00520           break;
00521 
00522         case bft_view_change:
00523           recv_view_change(data, size);
00524           break;
00525 
00526         case bft_view_change_evidence:
00527           recv_view_change_evidence(data, size);
00528           break;
00529 
00530         default:
00531         {
00532         }
00533       }
00534     }
00535 
00536     void periodic(std::chrono::milliseconds elapsed)
00537     {
00538       std::unique_lock<SpinLock> guard(state->lock);
00539       if (consensus_type == ConsensusType::BFT)
00540       {
00541         auto time = threading::ThreadMessaging::thread_messaging
00542                       .get_current_time_offset();
00543         request_tracker->tick(time);
00544 
00545         if (
00546           !view_change_tracker->is_view_change_in_progress(time) &&
00547           is_follower() && (has_bft_timeout_occurred(time)) &&
00548           view_change_tracker->should_send_view_change(time))
00549         {
00550           // We have not seen a request executed within an expected period of
00551           // time. We should invoke a view-change.
00552           //
00553           kv::Consensus::View new_view = view_change_tracker->get_target_view();
00554           kv::Consensus::SeqNo seqno;
00555           std::unique_ptr<ccf::ViewChangeRequest> vc;
00556 
00557           auto progress_tracker = store->get_progress_tracker();
00558           std::tie(vc, seqno) =
00559             progress_tracker->get_view_change_message(new_view);
00560 
00561           size_t vc_size = vc->get_serialized_size();
00562 
00563           RequestViewChangeMsg vcm = {
00564             {bft_view_change, state->my_node_id}, new_view, seqno};
00565 
00566           std::vector<uint8_t> m;
00567           m.resize(sizeof(RequestViewChangeMsg) + vc_size);
00568 
00569           uint8_t* data = m.data();
00570           size_t size = m.size();
00571 
00572           serialized::write(
00573             data, size, reinterpret_cast<uint8_t*>(&vcm), sizeof(vcm));
00574           vc->serialize(data, size);
00575           CCF_ASSERT_FMT(size == 0, "Did not write everything");
00576 
00577           LOG_INFO_FMT("Sending view change msg view:{}", vcm.view);
00578           for (auto it = nodes.begin(); it != nodes.end(); ++it)
00579           {
00580             auto send_to = it->first;
00581             if (send_to != state->my_node_id)
00582             {
00583               channels->send_authenticated(
00584                 ccf::NodeMsgType::consensus_msg, send_to, m);
00585             }
00586           }
00587 
00588           if (
00589             aft::ViewChangeTracker::ResultAddView::APPEND_NEW_VIEW_MESSAGE ==
00590               view_change_tracker->add_request_view_change(
00591                 *vc, id(), new_view, seqno, node_count()) &&
00592             get_primary(new_view) == id())
00593           {
00594             // We need to reobtain the lock when writing to the ledger so we
00595             // need to release it at this time.
00596             //
00597             // It is safe to release the lock here because there is no
00598             // concurrency based dependency between appending to the ledger and
00599             // replicating the ledger to other machines.
00600             guard.unlock();
00601             append_new_view(new_view);
00602             guard.lock();
00603           }
00604         }
00605       }
00606 
00607       timeout_elapsed += elapsed;
00608 
00609       if (replica_state == Leader)
00610       {
00611         if (timeout_elapsed >= request_timeout)
00612         {
00613           using namespace std::chrono_literals;
00614           timeout_elapsed = 0ms;
00615 
00616           update_batch_size();
00617           // Send newly available entries to all nodes.
00618           for (const auto& it : nodes)
00619           {
00620             send_append_entries(it.first, it.second.sent_idx + 1);
00621           }
00622         }
00623       }
00624       else if (consensus_type != ConsensusType::BFT)
00625       {
00626         if (replica_state != Retired && timeout_elapsed >= election_timeout)
00627         {
00628           // Start an election.
00629           become_candidate();
00630         }
00631       }
00632     }
00633 
00634     void recv_view_change(const uint8_t* data, size_t size)
00635     {
00636       RequestViewChangeMsg r;
00637       try
00638       {
00639         r =
00640           channels->template recv_authenticated_with_load<RequestViewChangeMsg>(
00641             data, size);
00642       }
00643       catch (const std::logic_error& err)
00644       {
00645         LOG_FAIL_EXC(err.what());
00646         return;
00647       }
00648 
00649       auto node = nodes.find(r.from_node);
00650       if (node == nodes.end())
00651       {
00652         // Ignore if we don't recognise the node.
00653         LOG_FAIL_FMT(
00654           "Recv nonce reveal to {} from {}: unknown node",
00655           state->my_node_id,
00656           r.from_node);
00657         return;
00658       }
00659 
00660       ccf::ViewChangeRequest v =
00661         ccf::ViewChangeRequest::deserialize(data, size);
00662       LOG_INFO_FMT(
00663         "Received view change from:{}, view:{}", r.from_node, r.view);
00664 
00665       auto progress_tracker = store->get_progress_tracker();
00666       if (!progress_tracker->apply_view_change_message(
00667             v, r.from_node, r.view, r.seqno))
00668       {
00669         return;
00670       }
00671 
00672       if (
00673         aft::ViewChangeTracker::ResultAddView::APPEND_NEW_VIEW_MESSAGE ==
00674           view_change_tracker->add_request_view_change(
00675             v, r.from_node, r.view, r.seqno, node_count()) &&
00676         get_primary(r.view) == id())
00677       {
00678         append_new_view(r.view);
00679       }
00680     }
00681 
00682     void recv_view_change_evidence(const uint8_t* data, size_t size)
00683     {
00684       ViewChangeEvidenceMsg r;
00685       try
00686       {
00687         r = channels
00688               ->template recv_authenticated_with_load<ViewChangeEvidenceMsg>(
00689                 data, size);
00690       }
00691       catch (const std::logic_error& err)
00692       {
00693         LOG_FAIL_EXC(err.what());
00694         return;
00695       }
00696 
00697       auto node = nodes.find(r.from_node);
00698       if (node == nodes.end())
00699       {
00700         // Ignore if we don't recognise the node.
00701         LOG_FAIL_FMT(
00702           "Recv nonce reveal to {} from {}: unknown node",
00703           state->my_node_id,
00704           r.from_node);
00705         return;
00706       }
00707 
00708       if (r.from_node != state->requested_evidence_from)
00709       {
00710         // Ignore if we didn't request this evidence.
00711         LOG_FAIL_FMT("Received unrequested evidence from {}", r.from_node);
00712         return;
00713       }
00714       state->requested_evidence_from = NoNode;
00715 
00716       view_change_tracker->add_unknown_primary_evidence(
00717         {data, size}, r.view, node_count());
00718     }
00719 
00720     bool is_first_request = true;
00721 
00722     bool on_request(const kv::TxHistory::RequestCallbackArgs& args)
00723     {
00724       auto request = executor->create_request_message(args);
00725       executor->execute_request(std::move(request), is_first_request);
00726       is_first_request = false;
00727 
00728       return true;
00729     }
00730 
00731   private:
00732     inline void update_batch_size()
00733     {
00734       auto avg_entry_size = (entry_count == 0) ?
00735         append_entries_size_limit :
00736         entry_size_not_limited / entry_count;
00737 
00738       auto batch_size = (avg_entry_size == 0) ?
00739         append_entries_size_limit / 2 :
00740         append_entries_size_limit / avg_entry_size;
00741 
00742       auto batch_avg = batch_window_sum / batch_window_size;
00743       // balance out total batch size across batch window
00744       batch_window_sum += (batch_size - batch_avg);
00745       entries_batch_size = std::max((batch_window_sum / batch_window_size), 1);
00746     }
00747 
00748     void append_new_view(kv::Consensus::View view)
00749     {
00750       state->current_view = view;
00751       become_leader();
00752       state->new_view_idx =
00753         view_change_tracker->write_view_change_confirmation_append_entry(view);
00754 
00755       view_change_tracker->clear(get_primary(view) == id(), view);
00756       request_tracker->clear();
00757     }
00758 
00759     bool has_bft_timeout_occurred(std::chrono::milliseconds time)
00760     {
00761       auto oldest_entry = request_tracker->oldest_entry();
00762       kv::Consensus::SeqNo last_sig_seqno;
00763       std::chrono::milliseconds last_sig_time;
00764       std::tie(last_sig_seqno, last_sig_time) =
00765         request_tracker->get_seqno_time_last_request();
00766 
00767       if (
00768         view_change_timeout != std::chrono::milliseconds(0) &&
00769         oldest_entry.has_value() &&
00770         oldest_entry.value() + view_change_timeout < time)
00771       {
00772         LOG_FAIL_FMT("Timeout waiting for request to be executed");
00773         return true;
00774       }
00775 
00776       // Check if any requests were added to the ledger since the last signature
00777       if (last_sig_seqno >= state->last_idx)
00778       {
00779         return false;
00780       }
00781 
00782       constexpr auto wait_factor = 10;
00783       std::chrono::milliseconds expire_time = last_sig_time +
00784         std::chrono::milliseconds(view_change_timeout.count() * wait_factor);
00785 
00786       // Check if we are waiting too long since the last signature
00787       if (expire_time < time)
00788       {
00789         LOG_FAIL_FMT(
00790           "Timeout waiting for global commit, last_sig_seqno:{}, last_idx:{}",
00791           last_sig_seqno,
00792           state->last_idx);
00793         return true;
00794       }
00795 
00796       // Check if there have been too many entried since the last signature
00797       if (
00798         sig_tx_interval != 0 &&
00799         last_sig_seqno + sig_tx_interval * wait_factor <
00800           static_cast<size_t>(state->last_idx))
00801       {
00802         LOG_FAIL_FMT(
00803           "Too many transactions occurred since last signature, "
00804           "last_sig_seqno:{}, "
00805           "last_idx:{}",
00806           last_sig_seqno,
00807           state->last_idx);
00808         return true;
00809       }
00810 
00811       return false;
00812     }
00813 
00814     Term get_term_internal(Index idx)
00815     {
00816       if (idx > state->last_idx)
00817         return ccf::VIEW_UNKNOWN;
00818 
00819       return state->view_history.view_at(idx);
00820     }
00821 
00822     void send_append_entries(NodeId to, Index start_idx)
00823     {
00824       Index end_idx = (state->last_idx == 0) ?
00825         0 :
00826         std::min(start_idx + entries_batch_size, state->last_idx);
00827 
00828       for (Index i = end_idx; i < state->last_idx; i += entries_batch_size)
00829       {
00830         send_append_entries_range(to, start_idx, i);
00831         start_idx = std::min(i + 1, state->last_idx);
00832       }
00833 
00834       if (state->last_idx == 0 || end_idx <= state->last_idx)
00835       {
00836         send_append_entries_range(to, start_idx, state->last_idx);
00837       }
00838     }
00839 
00840     void send_append_entries_range(NodeId to, Index start_idx, Index end_idx)
00841     {
00842       const auto prev_idx = start_idx - 1;
00843       const auto prev_term = get_term_internal(prev_idx);
00844       const auto term_of_idx = get_term_internal(end_idx);
00845       const bool contains_new_view =
00846         (state->new_view_idx > prev_idx) && (state->new_view_idx <= end_idx);
00847 
00848       LOG_DEBUG_FMT(
00849         "Send append entries from {} to {}: {} to {} ({})",
00850         state->my_node_id,
00851         to,
00852         start_idx,
00853         end_idx,
00854         state->commit_idx);
00855 
00856       AppendEntries ae = {{raft_append_entries, state->my_node_id},
00857                           {end_idx, prev_idx},
00858                           state->current_view,
00859                           prev_term,
00860                           state->commit_idx,
00861                           term_of_idx,
00862                           contains_new_view};
00863 
00864       auto& node = nodes.at(to);
00865 
00866       // The host will append log entries to this message when it is
00867       // sent to the destination node.
00868       if (!channels->send_authenticated(
00869             ccf::NodeMsgType::consensus_msg, to, ae))
00870       {
00871         return;
00872       }
00873 
00874       // Record the most recent index we have sent to this node.
00875       node.sent_idx = end_idx;
00876     }
00877 
00878     void recv_append_entries(const uint8_t* data, size_t size)
00879     {
00880       std::lock_guard<SpinLock> guard(state->lock);
00881       AppendEntries r;
00882 
00883       try
00884       {
00885         r = channels->template recv_authenticated<AppendEntries>(data, size);
00886       }
00887       catch (const std::logic_error& err)
00888       {
00889         LOG_FAIL_EXC(err.what());
00890         return;
00891       }
00892 
00893       LOG_DEBUG_FMT(
00894         "Received pt: {} pi: {} t: {} i: {} toi: {}",
00895         r.prev_term,
00896         r.prev_idx,
00897         r.term,
00898         r.idx,
00899         r.term_of_idx);
00900 
00901       // Don't check that the sender node ID is valid. Accept anything that
00902       // passes the integrity check. This way, entries containing dynamic
00903       // topology changes that include adding this new leader can be accepted.
00904 
00905       // When we are running with in a Byzantine model we cannot trust that the
00906       // replica is sending up this data is correct so we need to validate
00907       // additional properties that go above and beyond the non-byzantine
00908       // scenario.
00909       bool confirm_evidence = false;
00910       if (consensus_type == ConsensusType::BFT)
00911       {
00912         if (active_nodes().size() == 0)
00913         {
00914           // The replica is just starting up, we want to check that this replica
00915           // is part of the network we joined but that is dependent on Byzantine
00916           // identity
00917         }
00918         else if (get_primary(r.term) != r.from_node)
00919         {
00920           LOG_DEBUG_FMT(
00921             "Recv append entries to {} from {} at view:{} but the primary at "
00922             "this view should be {}",
00923             state->my_node_id,
00924             r.from_node,
00925             r.term,
00926             get_primary(r.term));
00927           send_append_entries_response(
00928             r.from_node, AppendEntriesResponseType::FAIL);
00929           return;
00930         }
00931         else if (!view_change_tracker->check_evidence(r.term))
00932         {
00933           if (r.contains_new_view)
00934           {
00935             confirm_evidence = true;
00936           }
00937           else
00938           {
00939             LOG_DEBUG_FMT(
00940               "Recv append entries to {} from {} at view:{} but we do not have "
00941               "the evidence to support this view",
00942               state->my_node_id,
00943               r.from_node,
00944               r.term);
00945             send_append_entries_response(
00946               r.from_node, AppendEntriesResponseType::REQUIRE_EVIDENCE);
00947             return;
00948           }
00949         }
00950       }
00951 
00952       // First, check append entries term against our own term, becoming
00953       // follower if necessary
00954       if (state->current_view == r.term && replica_state == Candidate)
00955       {
00956         // Become a follower in this term.
00957         become_follower(r.term);
00958       }
00959       else if (state->current_view < r.term)
00960       {
00961         // Become a follower in the new term.
00962         become_follower(r.term);
00963       }
00964       else if (state->current_view > r.term)
00965       {
00966         // Reply false, since our term is later than the received term.
00967         LOG_INFO_FMT(
00968           "Recv append entries to {} from {} but our term is later ({} > {})",
00969           state->my_node_id,
00970           r.from_node,
00971           state->current_view,
00972           r.term);
00973         send_append_entries_response(
00974           r.from_node, AppendEntriesResponseType::FAIL);
00975         return;
00976       }
00977 
00978       // Second, check term consistency with the entries we have so far
00979       const auto prev_term = get_term_internal(r.prev_idx);
00980       if (prev_term != r.prev_term)
00981       {
00982         LOG_DEBUG_FMT(
00983           "Previous term for {} should be {}", r.prev_idx, prev_term);
00984 
00985         // Reply false if the log doesn't contain an entry at r.prev_idx
00986         // whose term is r.prev_term.
00987         if (prev_term == 0)
00988         {
00989           LOG_DEBUG_FMT(
00990             "Recv append entries to {} from {} but our log does not yet "
00991             "contain index {}",
00992             state->my_node_id,
00993             r.from_node,
00994             r.prev_idx);
00995         }
00996         else
00997         {
00998           LOG_DEBUG_FMT(
00999             "Recv append entries to {} from {} but our log at {} has the wrong "
01000             "previous term (ours: {}, theirs: {})",
01001             state->my_node_id,
01002             r.from_node,
01003             r.prev_idx,
01004             prev_term,
01005             r.prev_term);
01006         }
01007         send_append_entries_response(
01008           r.from_node, AppendEntriesResponseType::FAIL);
01009         return;
01010       }
01011 
01012       // If the terms match up, it is sufficient to convince us that the sender
01013       // is leader in our term
01014       restart_election_timeout();
01015       if (leader_id != r.from_node)
01016       {
01017         leader_id = r.from_node;
01018         LOG_DEBUG_FMT(
01019           "Node {} thinks leader is {}", state->my_node_id, leader_id);
01020       }
01021 
01022       // Third, check index consistency, making sure entries are not in the past
01023       // or in the future
01024       if (r.prev_idx < state->commit_idx)
01025       {
01026         LOG_DEBUG_FMT(
01027           "Recv append entries to {} from {} but prev_idx ({}) < commit_idx "
01028           "({})",
01029           state->my_node_id,
01030           r.from_node,
01031           r.prev_idx,
01032           state->commit_idx);
01033         return;
01034       }
01035       else if (r.prev_idx > state->last_idx)
01036       {
01037         LOG_DEBUG_FMT(
01038           "Recv append entries to {} from {} but prev_idx ({}) > last_idx ({})",
01039           state->my_node_id,
01040           r.from_node,
01041           r.prev_idx,
01042           state->last_idx);
01043         return;
01044       }
01045 
01046       LOG_DEBUG_FMT(
01047         "Recv append entries to {} from {} for index {} and previous index {}",
01048         state->my_node_id,
01049         r.from_node,
01050         r.idx,
01051         r.prev_idx);
01052 
01053       // Finally, deserialise each entry in the batch
01054       for (Index i = r.prev_idx + 1; i <= r.idx; i++)
01055       {
01056         if (i <= state->last_idx)
01057         {
01058           // If the current entry has already been deserialised, skip the
01059           // payload for that entry
01060           ledger->skip_entry(data, size);
01061           continue;
01062         }
01063 
01064         LOG_DEBUG_FMT("Replicating on follower {}: {}", state->my_node_id, i);
01065 
01066         std::vector<uint8_t> entry;
01067         try
01068         {
01069           entry = ledger->get_entry(data, size);
01070         }
01071         catch (const std::logic_error& e)
01072         {
01073           // This should only fail if there is malformed data.
01074           LOG_FAIL_FMT(
01075             "Recv append entries to {} from {} but the data is malformed: {}",
01076             state->my_node_id,
01077             r.from_node,
01078             e.what());
01079           send_append_entries_response(
01080             r.from_node, AppendEntriesResponseType::FAIL);
01081           return;
01082         }
01083 
01084         state->last_idx = i;
01085 
01086         Term sig_term = 0;
01087         Index sig_index = 0;
01088         auto tx = store->create_tx();
01089         kv::DeserialiseSuccess deserialise_success;
01090         ccf::PrimarySignature sig;
01091         if (consensus_type == ConsensusType::BFT)
01092         {
01093           deserialise_success = store->deserialise_views(
01094             entry, public_only, &sig_term, &sig_index, &tx, &sig);
01095         }
01096         else
01097         {
01098           deserialise_success =
01099             store->deserialise(entry, public_only, &sig_term);
01100         }
01101 
01102         bool globally_committable =
01103           (deserialise_success == kv::DeserialiseSuccess::PASS_SIGNATURE);
01104         bool force_ledger_chunk = false;
01105         if (globally_committable)
01106         {
01107           force_ledger_chunk = snapshotter->requires_snapshot(i);
01108         }
01109 
01110         ledger->put_entry(entry, globally_committable, force_ledger_chunk);
01111 
01112         switch (deserialise_success)
01113         {
01114           case kv::DeserialiseSuccess::FAILED:
01115           {
01116             LOG_FAIL_FMT("Follower failed to apply log entry: {}", i);
01117             state->last_idx--;
01118             ledger->truncate(state->last_idx);
01119             send_append_entries_response(
01120               r.from_node, AppendEntriesResponseType::FAIL);
01121             break;
01122           }
01123 
01124           case kv::DeserialiseSuccess::PASS_SIGNATURE:
01125           {
01126             LOG_DEBUG_FMT("Deserialising signature at {}", i);
01127             auto prev_lci = last_committable_index();
01128             committable_indices.push_back(i);
01129 
01130             if (sig_term)
01131             {
01132               // A signature for sig_term tells us that all transactions from
01133               // the previous signature onwards (at least, if not further back)
01134               // happened in sig_term. We reflect this in the history.
01135               if (r.term_of_idx == aft::ViewHistory::InvalidView)
01136                 state->view_history.update(1, r.term);
01137               else
01138                 state->view_history.update(prev_lci + 1, sig_term);
01139               commit_if_possible(r.leader_commit_idx);
01140             }
01141             if (consensus_type == ConsensusType::BFT)
01142             {
01143               send_append_entries_signed_response(r.from_node, sig);
01144             }
01145             break;
01146           }
01147 
01148           case kv::DeserialiseSuccess::PASS_BACKUP_SIGNATURE:
01149           {
01150             break;
01151           }
01152           case kv::DeserialiseSuccess::PASS_NEW_VIEW:
01153           {
01154             view_change_tracker->clear(get_primary(sig_term) == id(), sig_term);
01155             request_tracker->clear();
01156             break;
01157           }
01158 
01159           case kv::DeserialiseSuccess::PASS_BACKUP_SIGNATURE_SEND_ACK:
01160           {
01161             try_send_sig_ack(
01162               {sig_term, sig_index},
01163               kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK);
01164             break;
01165           }
01166 
01167           case kv::DeserialiseSuccess::PASS_NONCES:
01168           {
01169             request_tracker->insert_signed_request(
01170               state->last_idx,
01171               threading::ThreadMessaging::thread_messaging
01172                 .get_current_time_offset());
01173             break;
01174           }
01175 
01176           case kv::DeserialiseSuccess::PASS:
01177           {
01178             if (consensus_type == ConsensusType::BFT)
01179             {
01180               state->last_idx =
01181                 executor->commit_replayed_request(tx, request_tracker);
01182             }
01183             break;
01184           }
01185 
01186           case kv::DeserialiseSuccess::PASS_SNAPSHOT_EVIDENCE:
01187           {
01188             break;
01189           }
01190 
01191           default:
01192           {
01193             throw std::logic_error("Unknown DeserialiseSuccess value");
01194           }
01195         }
01196       }
01197 
01198       if (
01199         consensus_type == ConsensusType::BFT && confirm_evidence &&
01200         !view_change_tracker->check_evidence(r.term))
01201       {
01202         rollback(last_committable_index());
01203         LOG_DEBUG_FMT(
01204           "Recv append entries to {} from {} at view:{} but we do not have "
01205           "the evidence to support this view, append message was marked as "
01206           "containing evidence",
01207           state->my_node_id,
01208           r.from_node,
01209           r.term);
01210         send_append_entries_response(
01211           r.from_node, AppendEntriesResponseType::REQUIRE_EVIDENCE);
01212         return;
01213       }
01214 
01215       // After entries have been deserialised, we try to commit the leader's
01216       // commit index and update our term history accordingly
01217       commit_if_possible(r.leader_commit_idx);
01218 
01219       // The term may have changed, and we have not have seen a signature yet.
01220       auto lci = last_committable_index();
01221       if (r.term_of_idx == aft::ViewHistory::InvalidView)
01222         state->view_history.update(1, r.term);
01223       else
01224         state->view_history.update(lci + 1, r.term_of_idx);
01225 
01226       send_append_entries_response(r.from_node, AppendEntriesResponseType::OK);
01227     }
01228 
01229     void send_append_entries_response(
01230       NodeId to, AppendEntriesResponseType answer)
01231     {
01232       LOG_DEBUG_FMT(
01233         "Send append entries response from {} to {} for index {}: {}",
01234         state->my_node_id,
01235         to,
01236         state->last_idx,
01237         answer);
01238 
01239       AppendEntriesResponse response = {
01240         {raft_append_entries_response, state->my_node_id},
01241         state->current_view,
01242         state->last_idx,
01243         answer};
01244 
01245       channels->send_authenticated(
01246         ccf::NodeMsgType::consensus_msg, to, response);
01247     }
01248 
01249     void send_append_entries_signed_response(
01250       NodeId to, ccf::PrimarySignature& sig)
01251     {
01252       LOG_DEBUG_FMT(
01253         "Send append entries signed response from {} to {} for index {}",
01254         state->my_node_id,
01255         to,
01256         state->last_idx);
01257 
01258       auto progress_tracker = store->get_progress_tracker();
01259       CCF_ASSERT(progress_tracker != nullptr, "progress_tracker is not set");
01260 
01261       SignedAppendEntriesResponse r = {
01262         {raft_append_entries_signed_response, state->my_node_id},
01263         state->current_view,
01264         state->last_idx,
01265         {},
01266         static_cast<uint32_t>(sig.sig.size()),
01267         {}};
01268 
01269       progress_tracker->get_my_hashed_nonce(
01270         {state->current_view, state->last_idx}, r.hashed_nonce);
01271 
01272       std::copy(sig.sig.begin(), sig.sig.end(), r.sig.data());
01273 
01274       auto result = progress_tracker->add_signature(
01275         {r.term, r.last_log_idx},
01276         r.from_node,
01277         r.signature_size,
01278         r.sig,
01279         r.hashed_nonce,
01280         node_count(),
01281         is_primary());
01282       for (auto it = nodes.begin(); it != nodes.end(); ++it)
01283       {
01284         auto send_to = it->first;
01285         if (send_to != state->my_node_id)
01286         {
01287           channels->send_authenticated(
01288             ccf::NodeMsgType::consensus_msg, send_to, r);
01289         }
01290       }
01291 
01292       try_send_sig_ack({r.term, r.last_log_idx}, result);
01293     }
01294 
01295     void recv_append_entries_signed_response(const uint8_t* data, size_t size)
01296     {
01297       SignedAppendEntriesResponse r;
01298 
01299       try
01300       {
01301         r = channels->template recv_authenticated<SignedAppendEntriesResponse>(
01302           data, size);
01303       }
01304       catch (const std::logic_error& err)
01305       {
01306         LOG_FAIL_EXC(err.what());
01307         return;
01308       }
01309 
01310       auto node = nodes.find(r.from_node);
01311       if (node == nodes.end())
01312       {
01313         // Ignore if we don't recognise the node.
01314         LOG_FAIL_FMT(
01315           "Recv signed append entries response to {} from {}: unknown node",
01316           state->my_node_id,
01317           r.from_node);
01318         return;
01319       }
01320 
01321       auto progress_tracker = store->get_progress_tracker();
01322       CCF_ASSERT(progress_tracker != nullptr, "progress_tracker is not set");
01323       auto result = progress_tracker->add_signature(
01324         {r.term, r.last_log_idx},
01325         r.from_node,
01326         r.signature_size,
01327         r.sig,
01328         r.hashed_nonce,
01329         node_count(),
01330         is_primary());
01331       try_send_sig_ack({r.term, r.last_log_idx}, result);
01332     }
01333 
01334     void try_send_sig_ack(kv::TxID tx_id, kv::TxHistory::Result r)
01335     {
01336       switch (r)
01337       {
01338         case kv::TxHistory::Result::OK:
01339         case kv::TxHistory::Result::FAIL:
01340         {
01341           break;
01342         }
01343         case kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK:
01344         {
01345           SignaturesReceivedAck r = {
01346             {bft_signature_received_ack, state->my_node_id},
01347             tx_id.term,
01348             tx_id.version};
01349           for (auto it = nodes.begin(); it != nodes.end(); ++it)
01350           {
01351             auto send_to = it->first;
01352             if (send_to != state->my_node_id)
01353             {
01354               channels->send_authenticated(
01355                 ccf::NodeMsgType::consensus_msg, send_to, r);
01356             }
01357           }
01358 
01359           auto progress_tracker = store->get_progress_tracker();
01360           CCF_ASSERT(
01361             progress_tracker != nullptr, "progress_tracker is not set");
01362           auto result = progress_tracker->add_signature_ack(
01363             tx_id, state->my_node_id, node_count());
01364           try_send_reply_and_nonce(tx_id, result);
01365           break;
01366         }
01367         default:
01368         {
01369           throw ccf::ccf_logic_error(fmt::format("Unknown enum type: {}", r));
01370         }
01371       }
01372     }
01373 
01374     void recv_signature_received_ack(const uint8_t* data, size_t size)
01375     {
01376       SignaturesReceivedAck r;
01377 
01378       try
01379       {
01380         r = channels->template recv_authenticated<SignaturesReceivedAck>(
01381           data, size);
01382       }
01383       catch (const std::logic_error& err)
01384       {
01385         LOG_FAIL_EXC(err.what());
01386         return;
01387       }
01388 
01389       auto node = nodes.find(r.from_node);
01390       if (node == nodes.end())
01391       {
01392         // Ignore if we don't recognise the node.
01393         LOG_FAIL_FMT(
01394           "Recv signature received ack to {} from {}: unknown node",
01395           state->my_node_id,
01396           r.from_node);
01397         return;
01398       }
01399 
01400       auto progress_tracker = store->get_progress_tracker();
01401       CCF_ASSERT(progress_tracker != nullptr, "progress_tracker is not set");
01402       LOG_TRACE_FMT(
01403         "processing recv_signature_received_ack, from:{} view:{}, seqno:{}",
01404         r.from_node,
01405         r.term,
01406         r.idx);
01407       auto result = progress_tracker->add_signature_ack(
01408         {r.term, r.idx}, r.from_node, node_count());
01409       try_send_reply_and_nonce({r.term, r.idx}, result);
01410     }
01411 
01412     void try_send_reply_and_nonce(kv::TxID tx_id, kv::TxHistory::Result r)
01413     {
01414       switch (r)
01415       {
01416         case kv::TxHistory::Result::OK:
01417         case kv::TxHistory::Result::FAIL:
01418         {
01419           break;
01420         }
01421         case kv::TxHistory::Result::SEND_REPLY_AND_NONCE:
01422         {
01423           Nonce nonce;
01424           auto progress_tracker = store->get_progress_tracker();
01425           CCF_ASSERT(
01426             progress_tracker != nullptr, "progress_tracker is not set");
01427           nonce = progress_tracker->get_my_nonce(tx_id);
01428           NonceRevealMsg r = {{bft_nonce_reveal, state->my_node_id},
01429                               tx_id.term,
01430                               tx_id.version,
01431                               nonce};
01432 
01433           for (auto it = nodes.begin(); it != nodes.end(); ++it)
01434           {
01435             auto send_to = it->first;
01436             if (send_to != state->my_node_id)
01437             {
01438               channels->send_authenticated(
01439                 ccf::NodeMsgType::consensus_msg, send_to, r);
01440             }
01441           }
01442           progress_tracker->add_nonce_reveal(
01443             tx_id, nonce, state->my_node_id, node_count(), is_primary());
01444           break;
01445         }
01446         default:
01447         {
01448           throw ccf::ccf_logic_error(fmt::format("Unknown enum type: {}", r));
01449         }
01450       }
01451     }
01452 
01453     void recv_nonce_reveal(const uint8_t* data, size_t size)
01454     {
01455       NonceRevealMsg r;
01456 
01457       try
01458       {
01459         r = channels->template recv_authenticated<NonceRevealMsg>(data, size);
01460       }
01461       catch (const std::logic_error& err)
01462       {
01463         LOG_FAIL_EXC(err.what());
01464         return;
01465       }
01466 
01467       auto node = nodes.find(r.from_node);
01468       if (node == nodes.end())
01469       {
01470         // Ignore if we don't recognise the node.
01471         LOG_FAIL_FMT(
01472           "Recv nonce reveal to {} from {}: unknown node",
01473           state->my_node_id,
01474           r.from_node);
01475         return;
01476       }
01477 
01478       auto progress_tracker = store->get_progress_tracker();
01479       CCF_ASSERT(progress_tracker != nullptr, "progress_tracker is not set");
01480       LOG_TRACE_FMT(
01481         "processing nonce_reveal, from:{} view:{}, seqno:{}",
01482         r.from_node,
01483         r.term,
01484         r.idx);
01485       progress_tracker->add_nonce_reveal(
01486         {r.term, r.idx}, r.nonce, r.from_node, node_count(), is_primary());
01487 
01488       update_commit();
01489     }
01490 
01491     void recv_append_entries_response(const uint8_t* data, size_t size)
01492     {
01493       std::lock_guard<SpinLock> guard(state->lock);
01494       // Ignore if we're not the leader.
01495       if (replica_state != Leader)
01496         return;
01497 
01498       AppendEntriesResponse r;
01499 
01500       try
01501       {
01502         r = channels->template recv_authenticated<AppendEntriesResponse>(
01503           data, size);
01504       }
01505       catch (const std::logic_error& err)
01506       {
01507         LOG_FAIL_EXC(err.what());
01508         return;
01509       }
01510 
01511       auto node = nodes.find(r.from_node);
01512       if (node == nodes.end())
01513       {
01514         // Ignore if we don't recognise the node.
01515         LOG_FAIL_FMT(
01516           "Recv append entries response to {} from {}: unknown node",
01517           state->my_node_id,
01518           r.from_node);
01519         return;
01520       }
01521       else if (state->current_view < r.term)
01522       {
01523         // We are behind, convert to a follower.
01524         LOG_DEBUG_FMT(
01525           "Recv append entries response to {} from {}: more recent term",
01526           state->my_node_id,
01527           r.from_node);
01528         become_follower(r.term);
01529         return;
01530       }
01531       else if (state->current_view != r.term)
01532       {
01533         // Stale response, discard if success.
01534         // Otherwise reset sent_idx and try again.
01535         LOG_DEBUG_FMT(
01536           "Recv append entries response to {} from {}: stale term",
01537           state->my_node_id,
01538           r.from_node);
01539         if (r.success == AppendEntriesResponseType::OK)
01540         {
01541           return;
01542         }
01543       }
01544       else if (r.last_log_idx < node->second.match_idx)
01545       {
01546         // Stale response, discard if success.
01547         // Otherwise reset sent_idx and try again.
01548         LOG_DEBUG_FMT(
01549           "Recv append entries response to {} from {}: stale idx",
01550           state->my_node_id,
01551           r.from_node);
01552         if (r.success == AppendEntriesResponseType::OK)
01553         {
01554           return;
01555         }
01556       }
01557 
01558       // Update next and match for the responding node.
01559       node->second.match_idx = std::min(r.last_log_idx, state->last_idx);
01560 
01561       if (r.success == AppendEntriesResponseType::REQUIRE_EVIDENCE)
01562       {
01563         // We need to provide evidence to the replica that we can send it append
01564         // entries. This should only happened if there is some kind of network
01565         // partition.
01566         state->requested_evidence_from = r.from_node;
01567         ViewChangeEvidenceMsg vw = {
01568           {bft_view_change_evidence, state->my_node_id}, state->current_view};
01569 
01570         std::vector<uint8_t> data =
01571           view_change_tracker->get_serialized_view_change_confirmation(
01572             state->current_view);
01573 
01574         data.insert(
01575           data.begin(),
01576           reinterpret_cast<uint8_t*>(&vw),
01577           reinterpret_cast<uint8_t*>(&vw) + sizeof(ViewChangeEvidenceMsg));
01578 
01579         channels->send_authenticated(
01580           ccf::NodeMsgType::consensus_msg, r.from_node, data);
01581       }
01582 
01583       if (r.success != AppendEntriesResponseType::OK)
01584       {
01585         // Failed due to log inconsistency. Reset sent_idx and try again.
01586         LOG_DEBUG_FMT(
01587           "Recv append entries response to {} from {}: failed",
01588           state->my_node_id,
01589           r.from_node);
01590         send_append_entries(r.from_node, node->second.match_idx + 1);
01591         return;
01592       }
01593 
01594       LOG_DEBUG_FMT(
01595         "Recv append entries response to {} from {} for index {}: success",
01596         state->my_node_id,
01597         r.from_node,
01598         r.last_log_idx);
01599       update_commit();
01600     }
01601 
01602     void send_request_vote(NodeId to)
01603     {
01604       LOG_INFO_FMT("Send request vote from {} to {}", state->my_node_id, to);
01605 
01606       auto last_committable_idx = last_committable_index();
01607       CCF_ASSERT(last_committable_idx >= state->commit_idx, "lci < ci");
01608 
01609       RequestVote rv = {{raft_request_vote, state->my_node_id},
01610                         state->current_view,
01611                         last_committable_idx,
01612                         get_term_internal(last_committable_idx)};
01613 
01614       channels->send_authenticated(ccf::NodeMsgType::consensus_msg, to, rv);
01615     }
01616 
01617     void recv_request_vote(const uint8_t* data, size_t size)
01618     {
01619       std::lock_guard<SpinLock> guard(state->lock);
01620       RequestVote r;
01621 
01622       try
01623       {
01624         r = channels->template recv_authenticated<RequestVote>(data, size);
01625       }
01626       catch (const std::logic_error& err)
01627       {
01628         LOG_FAIL_EXC(err.what());
01629         return;
01630       }
01631 
01632       // Ignore if we don't recognise the node.
01633       auto node = nodes.find(r.from_node);
01634       if (node == nodes.end())
01635       {
01636         LOG_FAIL_FMT(
01637           "Recv request vote to {} from {}: unknown node",
01638           state->my_node_id,
01639           r.from_node);
01640         return;
01641       }
01642 
01643       if (state->current_view > r.term)
01644       {
01645         // Reply false, since our term is later than the received term.
01646         LOG_DEBUG_FMT(
01647           "Recv request vote to {} from {}: our term is later ({} > {})",
01648           state->my_node_id,
01649           r.from_node,
01650           state->current_view,
01651           r.term);
01652         send_request_vote_response(r.from_node, false);
01653         return;
01654       }
01655       else if (state->current_view < r.term)
01656       {
01657         // Become a follower in the new term.
01658         LOG_DEBUG_FMT(
01659           "Recv request vote to {} from {}: their term is later ({} < {})",
01660           state->my_node_id,
01661           r.from_node,
01662           state->current_view,
01663           r.term);
01664         become_follower(r.term);
01665       }
01666 
01667       if ((voted_for != NoNode) && (voted_for != r.from_node))
01668       {
01669         // Reply false, since we already voted for someone else.
01670         LOG_DEBUG_FMT(
01671           "Recv request vote to {} from {}: already voted for {}",
01672           state->my_node_id,
01673           r.from_node,
01674           voted_for);
01675         send_request_vote_response(r.from_node, false);
01676         return;
01677       }
01678 
01679       // If the candidate's committable log is at least as up-to-date as ours,
01680       // vote yes
01681 
01682       auto last_committable_idx = last_committable_index();
01683       auto term_of_last_committable_index =
01684         get_term_internal(last_committable_idx);
01685 
01686       auto answer =
01687         (r.term_of_last_committable_idx > term_of_last_committable_index) ||
01688         ((r.term_of_last_committable_idx == term_of_last_committable_index) &&
01689          (r.last_committable_idx >= last_committable_idx));
01690 
01691       if (answer)
01692       {
01693         // If we grant our vote, we also acknowledge that an election is in
01694         // progress.
01695         restart_election_timeout();
01696         leader_id = NoNode;
01697         voted_for = r.from_node;
01698       }
01699 
01700       send_request_vote_response(r.from_node, answer);
01701     }
01702 
01703     void send_request_vote_response(NodeId to, bool answer)
01704     {
01705       LOG_INFO_FMT(
01706         "Send request vote response from {} to {}: {}",
01707         state->my_node_id,
01708         to,
01709         answer);
01710 
01711       RequestVoteResponse response = {
01712         {raft_request_vote_response, state->my_node_id},
01713         state->current_view,
01714         answer};
01715 
01716       channels->send_authenticated(
01717         ccf::NodeMsgType::consensus_msg, to, response);
01718     }
01719 
01720     void recv_request_vote_response(const uint8_t* data, size_t size)
01721     {
01722       if (replica_state != Candidate)
01723       {
01724         LOG_INFO_FMT(
01725           "Recv request vote response to {}: we aren't a candidate",
01726           state->my_node_id);
01727         return;
01728       }
01729 
01730       RequestVoteResponse r;
01731 
01732       try
01733       {
01734         r = channels->template recv_authenticated<RequestVoteResponse>(
01735           data, size);
01736       }
01737       catch (const std::logic_error& err)
01738       {
01739         LOG_FAIL_EXC(err.what());
01740         return;
01741       }
01742 
01743       // Ignore if we don't recognise the node.
01744       auto node = nodes.find(r.from_node);
01745       if (node == nodes.end())
01746       {
01747         LOG_INFO_FMT(
01748           "Recv request vote response to {} from {}: unknown node",
01749           state->my_node_id,
01750           r.from_node);
01751         return;
01752       }
01753 
01754       if (state->current_view < r.term)
01755       {
01756         // Become a follower in the new term.
01757         LOG_INFO_FMT(
01758           "Recv request vote response to {} from {}: their term is more recent "
01759           "({} < {})",
01760           state->my_node_id,
01761           r.from_node,
01762           state->current_view,
01763           r.term);
01764         become_follower(r.term);
01765         return;
01766       }
01767       else if (state->current_view != r.term)
01768       {
01769         // Ignore as it is stale.
01770         LOG_INFO_FMT(
01771           "Recv request vote response to {} from {}: stale ({} != {})",
01772           state->my_node_id,
01773           r.from_node,
01774           state->current_view,
01775           r.term);
01776         return;
01777       }
01778       else if (!r.vote_granted)
01779       {
01780         // Do nothing.
01781         LOG_INFO_FMT(
01782           "Recv request vote response to {} from {}: they voted no",
01783           state->my_node_id,
01784           r.from_node);
01785         return;
01786       }
01787 
01788       LOG_INFO_FMT(
01789         "Recv request vote response to {} from {}: they voted yes",
01790         state->my_node_id,
01791         r.from_node);
01792       add_vote_for_me(r.from_node);
01793     }
01794 
01795     void restart_election_timeout()
01796     {
01797       // Randomise timeout_elapsed to get a random election timeout
01798       // between 0.5x and 1x the configured election timeout.
01799       timeout_elapsed = std::chrono::milliseconds(distrib(rand));
01800     }
01801 
01802     void become_candidate()
01803     {
01804       replica_state = Candidate;
01805       leader_id = NoNode;
01806       voted_for = state->my_node_id;
01807       votes_for_me.clear();
01808       state->current_view++;
01809 
01810       restart_election_timeout();
01811       add_vote_for_me(state->my_node_id);
01812 
01813       LOG_INFO_FMT(
01814         "Becoming candidate {}: {}", state->my_node_id, state->current_view);
01815 
01816       if (consensus_type != ConsensusType::BFT)
01817       {
01818         for (auto it = nodes.begin(); it != nodes.end(); ++it)
01819         {
01820           channels->create_channel(
01821             it->first,
01822             it->second.node_info.hostname,
01823             it->second.node_info.port);
01824           send_request_vote(it->first);
01825         }
01826       }
01827     }
01828 
01829     void become_leader()
01830     {
01831       election_index = last_committable_index();
01832       LOG_DEBUG_FMT("Election index is {}", election_index);
01833       // Discard any un-committable updates we may hold,
01834       // since we have no signature for them. Except at startup,
01835       // where we do not want to roll back the genesis transaction.
01836       if (state->commit_idx)
01837       {
01838         rollback(election_index);
01839       }
01840       else
01841       {
01842         // but we still want the KV to know which term we're in
01843         store->set_term(state->current_view);
01844       }
01845 
01846       replica_state = Leader;
01847       leader_id = state->my_node_id;
01848 
01849       using namespace std::chrono_literals;
01850       timeout_elapsed = 0ms;
01851 
01852       LOG_INFO_FMT(
01853         "Becoming leader {}: {}", state->my_node_id, state->current_view);
01854 
01855       // Immediately commit if there are no other nodes.
01856       if (nodes.size() == 0)
01857       {
01858         commit(state->last_idx);
01859         return;
01860       }
01861 
01862       // Reset next, match, and sent indices for all nodes.
01863       auto next = state->last_idx + 1;
01864 
01865       for (auto it = nodes.begin(); it != nodes.end(); ++it)
01866       {
01867         it->second.match_idx = 0;
01868         it->second.sent_idx = next - 1;
01869 
01870         // Send an empty append_entries to all nodes.
01871         send_append_entries(it->first, next);
01872       }
01873     }
01874 
01875     void become_follower(Term term)
01876     {
01877       replica_state = Follower;
01878       leader_id = NoNode;
01879       restart_election_timeout();
01880 
01881       state->current_view = term;
01882       voted_for = NoNode;
01883       votes_for_me.clear();
01884 
01885       rollback(last_committable_index());
01886 
01887       LOG_INFO_FMT(
01888         "Becoming follower {}: {}", state->my_node_id, state->current_view);
01889 
01890       if (consensus_type != ConsensusType::BFT)
01891       {
01892         channels->close_all_outgoing();
01893       }
01894     }
01895 
01896     void become_retired()
01897     {
01898       replica_state = Retired;
01899       leader_id = NoNode;
01900 
01901       LOG_INFO_FMT(
01902         "Becoming retired {}: {}", state->my_node_id, state->current_view);
01903       channels->destroy_all_channels();
01904     }
01905 
01906     void add_vote_for_me(NodeId from)
01907     {
01908       // Need 50% + 1 of the total nodes, which are the other nodes plus us.
01909       votes_for_me.insert(from);
01910 
01911       if (votes_for_me.size() >= ((nodes.size() + 1) / 2) + 1)
01912         become_leader();
01913     }
01914 
01915     void update_commit()
01916     {
01917       // If there exists some idx in the current term such that
01918       // idx > commit_idx and a majority of nodes have replicated it,
01919       // commit to that idx.
01920       auto new_commit_cft_idx = std::numeric_limits<Index>::max();
01921       auto new_commit_bft_idx = std::numeric_limits<Index>::max();
01922 
01923       // Obtain BFT watermarks
01924       auto progress_tracker = store->get_progress_tracker();
01925       if (progress_tracker != nullptr)
01926       {
01927         new_commit_bft_idx = progress_tracker->get_highest_committed_nonce();
01928       }
01929 
01930       // Obtain CFT watermarks
01931       for (auto& c : configurations)
01932       {
01933         // The majority must be checked separately for each active
01934         // configuration.
01935         std::vector<Index> match;
01936         match.reserve(c.nodes.size() + 1);
01937 
01938         for (auto node : c.nodes)
01939         {
01940           if (node.first == state->my_node_id)
01941           {
01942             match.push_back(state->last_idx);
01943           }
01944           else
01945           {
01946             match.push_back(nodes.at(node.first).match_idx);
01947           }
01948         }
01949 
01950         sort(match.begin(), match.end());
01951         auto confirmed = match.at((match.size() - 1) / 2);
01952 
01953         if (confirmed < new_commit_cft_idx)
01954         {
01955           new_commit_cft_idx = confirmed;
01956         }
01957       }
01958       LOG_DEBUG_FMT(
01959         "In update_commit, new_commit_cft_idx: {}, new_commit_bft_idx:{}. "
01960         "last_idx: {}",
01961         new_commit_cft_idx,
01962         new_commit_bft_idx,
01963         state->last_idx);
01964 
01965       if (new_commit_cft_idx != std::numeric_limits<Index>::max())
01966       {
01967         state->cft_watermark_idx = new_commit_cft_idx;
01968       }
01969 
01970       if (new_commit_bft_idx != std::numeric_limits<Index>::max())
01971       {
01972         state->bft_watermark_idx = new_commit_bft_idx;
01973       }
01974 
01975       if (get_commit_watermark_idx() > state->last_idx)
01976       {
01977         throw std::logic_error(
01978           "Followers appear to have later match indices than leader");
01979       }
01980 
01981       commit_if_possible(get_commit_watermark_idx());
01982     }
01983 
01984     void commit_if_possible(Index idx)
01985     {
01986       LOG_DEBUG_FMT(
01987         "Commit if possible {} (ci: {}) (ti {})",
01988         idx,
01989         state->commit_idx,
01990         get_term_internal(idx));
01991       if (
01992         (idx > state->commit_idx) &&
01993         (get_term_internal(idx) <= state->current_view))
01994       {
01995         Index highest_committable = 0;
01996         bool can_commit = false;
01997         while (!committable_indices.empty() &&
01998                (committable_indices.front() <= idx))
01999         {
02000           highest_committable = committable_indices.front();
02001           committable_indices.pop_front();
02002           can_commit = true;
02003         }
02004 
02005         if (can_commit)
02006           commit(highest_committable);
02007       }
02008     }
02009 
02010     void commit(Index idx)
02011     {
02012       if (idx > state->last_idx)
02013       {
02014         throw std::logic_error(fmt::format(
02015           "Tried to commit {} but last_idx is {}", idx, state->last_idx));
02016       }
02017 
02018       LOG_DEBUG_FMT("Starting commit");
02019 
02020       // This could happen if a follower becomes the leader when it
02021       // has committed fewer log entries, although it has them available.
02022       if (idx <= state->commit_idx)
02023         return;
02024 
02025       state->commit_idx = idx;
02026 
02027       LOG_DEBUG_FMT("Compacting...");
02028       snapshotter->commit(idx);
02029       if (replica_state == Leader && consensus_type == ConsensusType::CFT)
02030       {
02031         // Snapshots are not yet supported with BFT
02032         snapshotter->snapshot(idx);
02033       }
02034       store->compact(idx);
02035       ledger->commit(idx);
02036 
02037       LOG_DEBUG_FMT("Commit on {}: {}", state->my_node_id, idx);
02038 
02039       // Examine all configurations that are followed by a globally committed
02040       // configuration.
02041       bool changed = false;
02042 
02043       while (true)
02044       {
02045         auto conf = configurations.begin();
02046         if (conf == configurations.end())
02047           break;
02048 
02049         auto next = std::next(conf);
02050         if (next == configurations.end())
02051           break;
02052 
02053         if (idx < next->idx)
02054           break;
02055 
02056         configurations.pop_front();
02057         backup_nodes.clear();
02058         changed = true;
02059       }
02060 
02061       if (changed)
02062       {
02063         create_and_remove_node_state();
02064       }
02065     }
02066 
02067     Index get_commit_watermark_idx()
02068     {
02069       if (consensus_type == ConsensusType::BFT)
02070       {
02071         return state->bft_watermark_idx;
02072       }
02073       else
02074       {
02075         return state->cft_watermark_idx;
02076       }
02077     }
02078 
02079     void rollback(Index idx)
02080     {
02081       snapshotter->rollback(idx);
02082       store->rollback(idx, state->current_view);
02083       LOG_DEBUG_FMT("Setting term in store to: {}", state->current_view);
02084       ledger->truncate(idx);
02085       state->last_idx = idx;
02086       LOG_DEBUG_FMT("Rolled back at {}", idx);
02087 
02088       while (!committable_indices.empty() && (committable_indices.back() > idx))
02089       {
02090         committable_indices.pop_back();
02091       }
02092 
02093       // Rollback configurations.
02094       bool changed = false;
02095 
02096       while (!configurations.empty() && (configurations.back().idx > idx))
02097       {
02098         configurations.pop_back();
02099         backup_nodes.clear();
02100         changed = true;
02101       }
02102 
02103       if (changed)
02104       {
02105         create_and_remove_node_state();
02106       }
02107     }
02108 
02109     void create_and_remove_node_state()
02110     {
02111       // Find all nodes present in any active configuration.
02112       Configuration::Nodes active_nodes;
02113 
02114       for (auto& conf : configurations)
02115       {
02116         for (auto node : conf.nodes)
02117         {
02118           active_nodes.emplace(node.first, node.second);
02119         }
02120       }
02121 
02122       // Remove all nodes in the node state that are not present in any active
02123       // configuration.
02124       std::vector<NodeId> to_remove;
02125 
02126       for (auto& node : nodes)
02127       {
02128         if (active_nodes.find(node.first) == active_nodes.end())
02129         {
02130           to_remove.push_back(node.first);
02131         }
02132       }
02133 
02134       for (auto node_id : to_remove)
02135       {
02136         if (replica_state == Leader || consensus_type == ConsensusType::BFT)
02137         {
02138           channels->destroy_channel(node_id);
02139         }
02140         nodes.erase(node_id);
02141         LOG_INFO_FMT("Removed raft node {}", node_id);
02142       }
02143 
02144       // Add all active nodes that are not already present in the node state.
02145       bool self_is_active = false;
02146 
02147       for (auto node_info : active_nodes)
02148       {
02149         if (node_info.first == state->my_node_id)
02150         {
02151           self_is_active = true;
02152           continue;
02153         }
02154 
02155         if (nodes.find(node_info.first) == nodes.end())
02156         {
02157           // A new node is sent only future entries initially. If it does not
02158           // have prior data, it will communicate that back to the leader.
02159           auto index = state->last_idx + 1;
02160           nodes.try_emplace(node_info.first, node_info.second, index, 0);
02161 
02162           if (replica_state == Leader || consensus_type == ConsensusType::BFT)
02163           {
02164             channels->create_channel(
02165               node_info.first,
02166               node_info.second.hostname,
02167               node_info.second.port);
02168           }
02169 
02170           if (replica_state == Leader)
02171           {
02172             send_append_entries(node_info.first, index);
02173           }
02174 
02175           LOG_INFO_FMT("Added raft node {}", node_info.first);
02176         }
02177       }
02178 
02179       if (!self_is_active)
02180       {
02181         LOG_INFO_FMT("Removed raft self {}", state->my_node_id);
02182         if (replica_state == Leader)
02183         {
02184           become_retired();
02185         }
02186       }
02187     }
02188   };
02189 }
02190 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/raft.h...
Preprocessing /data/git/CCF/src/consensus/aft/raft_consensus.h...
#include kv/kv_types.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include impl/execution.h: already included! skipping...
#include impl/request_message.h: already included! skipping...
#include impl/state.h: already included! skipping...
#include impl/view_change_tracker.h: already included! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/node_to_node.h: not found! skipping...
#include node/node_types.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
#include node/rpc/tx_status.h: not found! skipping...
#include node/signatures.h: not found! skipping...
#include raft_types.h: already included! skipping...
#include algorithm: not found! skipping...
#include deque: not found! skipping...
#include list: not found! skipping...
#include random: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
#include ds/json.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 3413 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/consensus/aft/raft_consensus.h" 2
00007 # 7 "/data/git/CCF/src/consensus/aft/raft_consensus.h" 2
00008 
00009 
00010 
00011 namespace aft
00012 {
00013   // This class acts as an adapter between the generic Consensus API and
00014   // the AFT API, allowing for a mapping between the generic consensus
00015   // terminology and the terminology that is specific to AFT
00016 
00017   template <class... T>
00018   class Consensus : public kv::Consensus
00019   {
00020   private:
00021     std::unique_ptr<Aft<T...>> aft;
00022     ConsensusType consensus_type;
00023 
00024   public:
00025     Consensus(std::unique_ptr<Aft<T...>> raft_, ConsensusType consensus_type_) :
00026       kv::Consensus(raft_->id()),
00027       aft(std::move(raft_)),
00028       consensus_type(consensus_type_)
00029     {}
00030 
00031     bool is_primary() override
00032     {
00033       return aft->is_primary();
00034     }
00035 
00036     bool is_backup() override
00037     {
00038       return aft->is_follower();
00039     }
00040 
00041     void force_become_primary() override
00042     {
00043       aft->force_become_leader();
00044     }
00045 
00046     void force_become_primary(
00047       SeqNo seqno,
00048       View view,
00049       const std::vector<kv::Version>& terms,
00050       SeqNo commit_seqno) override
00051     {
00052       aft->force_become_leader(seqno, view, terms, commit_seqno);
00053     }
00054 
00055     void init_as_backup(
00056       SeqNo seqno,
00057       View view,
00058       const std::vector<kv::Version>& view_history) override
00059     {
00060       aft->init_as_follower(seqno, view, view_history);
00061     }
00062 
00063     bool replicate(const kv::BatchVector& entries, View view) override
00064     {
00065       return aft->replicate(entries, view);
00066     }
00067 
00068     std::pair<View, SeqNo> get_committed_txid() override
00069     {
00070       return aft->get_commit_term_and_idx();
00071     }
00072 
00073     std::optional<std::pair<View, SeqNo>> get_signable_txid() override
00074     {
00075       return aft->get_signable_commit_term_and_idx();
00076     }
00077 
00078     View get_view(SeqNo seqno) override
00079     {
00080       return aft->get_term(seqno);
00081     }
00082 
00083     View get_view() override
00084     {
00085       return aft->get_term();
00086     }
00087 
00088     std::vector<SeqNo> get_view_history(SeqNo seqno) override
00089     {
00090       return aft->get_term_history(seqno);
00091     }
00092 
00093     void initialise_view_history(
00094       const std::vector<SeqNo>& view_history) override
00095     {
00096       aft->initialise_term_history(view_history);
00097     }
00098 
00099     SeqNo get_committed_seqno() override
00100     {
00101       return aft->get_commit_idx();
00102     }
00103 
00104     NodeId primary() override
00105     {
00106       return aft->leader();
00107     }
00108 
00109     std::set<NodeId> active_nodes() override
00110     {
00111       return aft->active_nodes();
00112     }
00113 
00114     void recv_message(OArray&& data) override
00115     {
00116       return aft->recv_message(std::move(data));
00117     }
00118 
00119     void add_configuration(
00120       SeqNo seqno, const Configuration::Nodes& conf) override
00121     {
00122       aft->add_configuration(seqno, conf);
00123     }
00124 
00125     Configuration::Nodes get_latest_configuration() const override
00126     {
00127       return aft->get_latest_configuration();
00128     }
00129 
00130     void periodic(std::chrono::milliseconds elapsed) override
00131     {
00132       aft->periodic(elapsed);
00133     }
00134 
00135     void enable_all_domains() override
00136     {
00137       aft->enable_all_domains();
00138     }
00139 
00140     uint32_t node_count() override
00141     {
00142       return aft->node_count();
00143     }
00144 
00145     void emit_signature() override {}
00146 
00147     bool on_request(const kv::TxHistory::RequestCallbackArgs& args) override
00148     {
00149       return aft->on_request(args);
00150     }
00151 
00152     ConsensusType type() override
00153     {
00154       return consensus_type;
00155     }
00156   };
00157 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/raft_consensus.h...
Preprocessing /data/git/CCF/src/consensus/aft/raft_tables.h...
#include kv/kv_types.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include unordered_set: not found! skipping...
Preprocessor output (size: 567 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace aft
00011 {
00012   static constexpr auto replicate_type_raft = kv::ReplicateType::ALL;
00013   static const std::unordered_set<std::string> replicated_tables_raft = {};
00014 
00015   static constexpr auto replicate_type_bft = kv::ReplicateType::SOME;
00016   static const std::unordered_set<std::string> replicated_tables_bft = {
00017     ccf::Tables::AFT_REQUESTS,
00018     ccf::Tables::SIGNATURES,
00019     ccf::Tables::BACKUP_SIGNATURES,
00020     ccf::Tables::NONCES,
00021     ccf::Tables::NEW_VIEWS};
00022 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/raft_tables.h...
Preprocessing /data/git/CCF/src/consensus/aft/raft_types.h...
#include consensus/consensus_types.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include mbedtls/ecdsa.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include array: not found! skipping...
#include chrono: not found! skipping...
#include cstdint: not found! skipping...
#include limits: not found! skipping...
Preprocessor output (size: 4660 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 namespace aft
00020 {
00021   using Index = int64_t;
00022   using Term = int64_t;
00023   using NodeId = uint64_t;
00024   using Node2NodeMsg = uint64_t;
00025   using Nonce = crypto::Sha256Hash;
00026 
00027   using ReplyCallback = std::function<bool(
00028     void* owner,
00029     kv::TxHistory::RequestID caller_rid,
00030     int status,
00031     std::vector<uint8_t>&& data)>;
00032 
00033   static constexpr NodeId NoNode = std::numeric_limits<NodeId>::max();
00034 
00035   static constexpr size_t starting_view_change = 2;
00036 
00037   template <typename S>
00038   class Store
00039   {
00040   public:
00041     virtual ~Store() {}
00042     virtual S deserialise(
00043       const std::vector<uint8_t>& data,
00044       bool public_only = false,
00045       Term* term = nullptr) = 0;
00046     virtual void compact(Index v) = 0;
00047     virtual void rollback(Index v, std::optional<Term> t = std::nullopt) = 0;
00048     virtual void set_term(Term t) = 0;
00049     virtual S deserialise_views(
00050       const std::vector<uint8_t>& data,
00051       bool public_only = false,
00052       kv::Term* term = nullptr,
00053       kv::Version* index_ = nullptr,
00054       kv::Tx* tx = nullptr,
00055       ccf::PrimarySignature* sig = nullptr) = 0;
00056     virtual std::shared_ptr<ccf::ProgressTracker> get_progress_tracker() = 0;
00057     virtual kv::Tx create_tx() = 0;
00058   };
00059 
00060   template <typename T, typename S>
00061   class Adaptor : public Store<S>
00062   {
00063   private:
00064     std::weak_ptr<T> x;
00065 
00066   public:
00067     Adaptor(std::shared_ptr<T> x) : x(x) {}
00068 
00069     S deserialise(
00070       const std::vector<uint8_t>& data,
00071       bool public_only = false,
00072       Term* term = nullptr) override
00073     {
00074       auto p = x.lock();
00075       if (p)
00076       {
00077         return p->deserialise(data, public_only, term);
00078       }
00079       return S::FAILED;
00080     }
00081 
00082     void compact(Index v) override
00083     {
00084       auto p = x.lock();
00085       if (p)
00086       {
00087         p->compact(v);
00088       }
00089     }
00090 
00091     void rollback(Index v, std::optional<Term> t = std::nullopt) override
00092     {
00093       auto p = x.lock();
00094       if (p)
00095       {
00096         p->rollback(v, t);
00097       }
00098     }
00099 
00100     void set_term(Term t) override
00101     {
00102       auto p = x.lock();
00103       if (p)
00104       {
00105         p->set_term(t);
00106       }
00107     }
00108 
00109     std::shared_ptr<ccf::ProgressTracker> get_progress_tracker() override
00110     {
00111       auto p = x.lock();
00112       if (p)
00113       {
00114         return p->get_progress_tracker();
00115       }
00116       return nullptr;
00117     }
00118 
00119     kv::Tx create_tx() override
00120     {
00121       auto p = x.lock();
00122       if (p)
00123       {
00124         return p->create_tx();
00125       }
00126       throw std::logic_error("Can't create a tx without a store");
00127     }
00128 
00129     S deserialise_views(
00130       const std::vector<uint8_t>& data,
00131       bool public_only = false,
00132       kv::Term* term = nullptr,
00133       kv::Version* index = nullptr,
00134       kv::Tx* tx = nullptr,
00135       ccf::PrimarySignature* sig = nullptr) override
00136     {
00137       auto p = x.lock();
00138       if (p)
00139         return p->deserialise_views(data, public_only, term, index, tx, sig);
00140       return S::FAILED;
00141     }
00142   };
00143 
00144   enum RaftMsgType : Node2NodeMsg
00145   {
00146     raft_append_entries = 0,
00147     raft_append_entries_response,
00148     raft_append_entries_signed_response,
00149     raft_request_vote,
00150     raft_request_vote_response,
00151 
00152     bft_request,
00153     bft_signature_received_ack,
00154     bft_nonce_reveal,
00155     bft_view_change,
00156     bft_view_change_evidence
00157   };
00158 
00159 
00160   struct RaftHeader
00161   {
00162     RaftMsgType msg;
00163     NodeId from_node;
00164   };
00165 
00166   struct AppendEntries : consensus::ConsensusHeader<RaftMsgType>,
00167                          consensus::AppendEntriesIndex
00168   {
00169     Term term;
00170     Term prev_term;
00171     Index leader_commit_idx;
00172     Term term_of_idx;
00173     bool contains_new_view;
00174   };
00175 
00176   enum class AppendEntriesResponseType : uint8_t
00177   {
00178     OK = 0,
00179     FAIL = 1,
00180     REQUIRE_EVIDENCE = 2
00181   };
00182 
00183   struct AppendEntriesResponse : RaftHeader
00184   {
00185     Term term;
00186     Index last_log_idx;
00187     AppendEntriesResponseType success;
00188   };
00189 
00190   struct SignedAppendEntriesResponse : RaftHeader
00191   {
00192     Term term;
00193     Index last_log_idx;
00194     Nonce hashed_nonce;
00195     uint32_t signature_size;
00196     std::array<uint8_t, MBEDTLS_ECDSA_MAX_LEN> sig;
00197   };
00198 
00199   struct SignaturesReceivedAck : RaftHeader
00200   {
00201     Term term;
00202     Index idx;
00203   };
00204 
00205   struct NonceRevealMsg : RaftHeader
00206   {
00207     Term term;
00208     Index idx;
00209     Nonce nonce;
00210   };
00211 
00212   struct RequestViewChangeMsg : RaftHeader
00213   {
00214     kv::Consensus::View view = 0;
00215     kv::Consensus::SeqNo seqno = 0;
00216   };
00217 
00218   struct ViewChangeEvidenceMsg : RaftHeader
00219   {
00220     kv::Consensus::View view = 0;
00221   };
00222 
00223   struct RequestVote : RaftHeader
00224   {
00225     Term term;
00226     Index last_committable_idx;
00227     Term term_of_last_committable_idx;
00228   };
00229 
00230   struct RequestVoteResponse : RaftHeader
00231   {
00232     Term term;
00233     bool vote_granted;
00234   };
00235 
00236 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/raft_types.h...
Preprocessing /data/git/CCF/src/consensus/aft/request.h...
#include ds/json.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2248 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace aft
00013 {
00014   struct Request
00015   {
00016     kv::TxHistory::RequestID rid;
00017     std::vector<uint8_t> caller_cert;
00018     std::vector<uint8_t> raw;
00019     uint8_t frame_format = enclave::FrameFormat::http;
00020 
00021     MSGPACK_DEFINE(rid, caller_cert, raw, frame_format);
00022 
00023     std::vector<uint8_t> serialise()
00024     {
00025       bool include_caller = false;
00026       size_t size = sizeof(rid) + sizeof(include_caller) + sizeof(size_t) +
00027         raw.size() + sizeof(enclave::FrameFormat);
00028       if (!caller_cert.empty())
00029       {
00030         size += sizeof(size_t) + caller_cert.size();
00031         include_caller = true;
00032       }
00033 
00034       std::vector<uint8_t> serialized_req(size);
00035       auto data_ = serialized_req.data();
00036       auto size_ = serialized_req.size();
00037       serialized::write(data_, size_, rid);
00038       serialized::write(data_, size_, include_caller);
00039       if (include_caller)
00040       {
00041         serialized::write(data_, size_, caller_cert.size());
00042         serialized::write(data_, size_, caller_cert.data(), caller_cert.size());
00043       }
00044       serialized::write(data_, size_, raw.size());
00045       serialized::write(data_, size_, raw.data(), raw.size());
00046 
00047       serialized::write(data_, size_, frame_format);
00048       return serialized_req;
00049     }
00050 
00051     void deserialise(const uint8_t* data_, size_t size_)
00052     {
00053       rid = serialized::read<kv::TxHistory::RequestID>(data_, size_);
00054       auto includes_caller = serialized::read<bool>(data_, size_);
00055       if (includes_caller)
00056       {
00057         auto caller_size = serialized::read<size_t>(data_, size_);
00058         caller_cert = serialized::read(data_, size_, caller_size);
00059       }
00060       auto raw_size = serialized::read<size_t>(data_, size_);
00061       raw = serialized::read(data_, size_, raw_size);
00062 
00063       frame_format = serialized::read<enclave::FrameFormat>(data_, size_);
00064     }
00065   };
00066 
00067   DECLARE_JSON_TYPE(Request);
00068   DECLARE_JSON_REQUIRED_FIELDS(Request, rid, caller_cert, raw, frame_format);
00069 
00070   // size_t is used as the key of the table. This key will always be 0 since we
00071   // don't want to store the requests in the kv over time, we just want to get
00072   // them into the ledger
00073   using RequestsMap = kv::Map<size_t, Request>;
00074 }
00075 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/request.h...
Preprocessing /data/git/CCF/src/consensus/aft/revealed_nonces.h...
#include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 776 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace aft
00012 {
00013   using Nonce = crypto::Sha256Hash;
00014   struct RevealedNonce
00015   {
00016     kv::NodeId node_id;
00017     Nonce nonce;
00018 
00019     MSGPACK_DEFINE(node_id, nonce);
00020 
00021     RevealedNonce(ccf::NodeId node_id_, Nonce nonce_) :
00022       node_id(node_id_),
00023       nonce(nonce_)
00024     {}
00025 
00026     RevealedNonce() = default;
00027   };
00028   DECLARE_JSON_TYPE(RevealedNonce);
00029 
00030 
00031   struct RevealedNonces
00032   {
00033     kv::TxID tx_id;
00034     std::vector<RevealedNonce> nonces;
00035 
00036     MSGPACK_DEFINE(tx_id, nonces);
00037 
00038     RevealedNonces() = default;
00039 
00040     RevealedNonces(kv::TxID tx_id_) : tx_id(tx_id_) {}
00041   };
00042   DECLARE_JSON_TYPE(RevealedNonces);
00043 
00044   using RevealedNoncesMap = kv::Map<ccf::ObjectId, RevealedNonces>;
00045 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/revealed_nonces.h...
Preprocessing /data/git/CCF/src/consensus/aft/test/driver.cpp...
#include consensus/aft/raft.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include chrono: not found! skipping...
#include set: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include unordered_map: not found! skipping...
#include unordered_set: not found! skipping...
  #include consensus/aft/raft.h: not found! skipping...
#include consensus/aft/raft_types.h: not found! skipping...
#include map: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
#include ds/hash.h: not found! skipping...
#include cassert: not found! skipping...
#include iostream: not found! skipping...
#include regex: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 2885 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/consensus/aft/test/driver.cpp" 2
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 using namespace std;
00013 
00014 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00015 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00016 
00017 namespace threading
00018 {
00019   std::map<std::thread::id, uint16_t> thread_ids;
00020 }
00021 
00022 constexpr auto shash = ds::fnv_1a<size_t>;
00023 
00024 int main(int argc, char** argv)
00025 {
00026   const regex delim{","};
00027   string line;
00028   size_t lineno = 1;
00029   auto driver = shared_ptr<RaftDriver>(nullptr);
00030 
00031   while (getline(cin, line))
00032   {
00033     line.erase(line.find_last_not_of(" \t\n\r\f\v") + 1);
00034     vector<string> items{
00035       sregex_token_iterator(line.begin(), line.end(), delim, -1),
00036       std::sregex_token_iterator()};
00037     std::shared_ptr<std::vector<uint8_t>> data;
00038     switch (shash(items[0].c_str()))
00039     {
00040       case shash("nodes"):
00041         assert(items.size() == 2);
00042         driver = make_shared<RaftDriver>(stoi(items[1]));
00043         break;
00044       case shash("connect"):
00045         assert(items.size() == 3);
00046         driver->connect(stoi(items[1]), stoi(items[2]));
00047         break;
00048       case shash("periodic_one"):
00049         assert(items.size() == 3);
00050         driver->periodic_one(stoi(items[1]), ms(stoi(items[2])));
00051         break;
00052       case shash("periodic_all"):
00053         assert(items.size() == 2);
00054         driver->periodic_all(ms(stoi(items[1])));
00055         break;
00056       case shash("state_one"):
00057         assert(items.size() == 2);
00058         driver->state_one(stoi(items[1]));
00059         break;
00060       case shash("dispatch_all"):
00061         assert(items.size() == 1);
00062         driver->dispatch_all();
00063         break;
00064       case shash("dispatch_all_once"):
00065         assert(items.size() == 1);
00066         driver->dispatch_all_once();
00067         break;
00068       case shash("state_all"):
00069         assert(items.size() == 1);
00070         driver->state_all();
00071         break;
00072       case shash("replicate"):
00073         assert(items.size() == 4);
00074         data = std::make_shared<std::vector<uint8_t>>(
00075           items[3].begin(), items[3].end());
00076         driver->replicate(stoi(items[1]), stoi(items[2]), data);
00077         break;
00078       case shash("disconnect"):
00079         assert(items.size() == 3);
00080         driver->disconnect(stoi(items[1]), stoi(items[2]));
00081         break;
00082       case shash("disconnect_node"):
00083         assert(items.size() == 2);
00084         driver->disconnect_node(stoi(items[1]));
00085         break;
00086       case shash("reconnect"):
00087         assert(items.size() == 3);
00088         driver->reconnect(stoi(items[1]), stoi(items[2]));
00089         break;
00090       case shash("reconnect_node"):
00091         assert(items.size() == 2);
00092         driver->reconnect_node(stoi(items[1]));
00093         break;
00094       default:
00095         cerr << "Unknown action '" << items[0] << "' at line " << lineno
00096              << endl;
00097     }
00098     ++lineno;
00099   }
00100 
00101   return 0;
00102 }
00103 
---------
Macros accessible in this file:
---------
STUB_LOG 
---------
Parsing file /data/git/CCF/src/consensus/aft/test/driver.cpp...
Preprocessing /data/git/CCF/src/consensus/aft/test/driver.h...
#include consensus/aft/raft.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include chrono: not found! skipping...
#include set: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include unordered_map: not found! skipping...
#include unordered_set: not found! skipping...
#include logging_stub.h: already included! skipping...
Preprocessor output (size: 7597 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 #define STUB_LOG
00016 
00017 
00018 using ms = std::chrono::milliseconds;
00019 using TRaft =
00020   aft::Aft<aft::LedgerStubProxy, aft::ChannelStubProxy, aft::StubSnapshotter>;
00021 using Store = aft::LoggingStubStore;
00022 using Adaptor = aft::Adaptor<Store, kv::DeserialiseSuccess>;
00023 
00024 std::vector<uint8_t> cert;
00025 
00026 class RaftDriver
00027 {
00028 private:
00029   struct NodeDriver
00030   {
00031     std::shared_ptr<Store> kv;
00032     std::shared_ptr<TRaft> raft;
00033   };
00034 
00035   std::unordered_map<aft::NodeId, NodeDriver> _nodes;
00036   std::set<std::pair<aft::NodeId, aft::NodeId>> _connections;
00037 
00038 public:
00039   RaftDriver(size_t number_of_nodes)
00040   {
00041     kv::Consensus::Configuration::Nodes configuration;
00042 
00043     for (size_t i = 0; i < number_of_nodes; ++i)
00044     {
00045       aft::NodeId node_id = i;
00046 
00047       auto kv = std::make_shared<Store>(node_id);
00048       auto raft = std::make_shared<TRaft>(
00049         ConsensusType::CFT,
00050         std::make_unique<Adaptor>(kv),
00051         std::make_unique<aft::LedgerStubProxy>(node_id),
00052         std::make_shared<aft::ChannelStubProxy>(),
00053         std::make_shared<aft::StubSnapshotter>(),
00054         nullptr,
00055         nullptr,
00056         cert,
00057         std::make_shared<aft::State>(node_id),
00058         nullptr,
00059         std::make_shared<aft::RequestTracker>(),
00060         nullptr,
00061         ms(10),
00062         ms(i * 100),
00063         ms(i * 100));
00064 
00065       _nodes.emplace(node_id, NodeDriver{kv, raft});
00066       configuration.try_emplace(node_id);
00067     }
00068 
00069     for (auto& node : _nodes)
00070     {
00071       node.second.raft->add_configuration(0, configuration);
00072     }
00073   }
00074 
00075   void log(aft::NodeId first, aft::NodeId second, const std::string& message)
00076   {
00077     std::cout << "  Node" << first << "->>"
00078               << "Node" << second << ": " << message << std::endl;
00079   }
00080 
00081   void rlog(aft::NodeId first, aft::NodeId second, const std::string& message)
00082   {
00083     std::cout << "  Node" << first << "-->>"
00084               << "Node" << second << ": " << message << std::endl;
00085   }
00086 
00087   void log_msg_details(
00088     aft::NodeId node_id, aft::NodeId tgt_node_id, aft::RequestVote rv)
00089   {
00090     std::ostringstream s;
00091     s << "request_vote t: " << rv.term << ", lci: " << rv.last_committable_idx
00092       << ", tolci: " << rv.term_of_last_committable_idx;
00093     log(node_id, tgt_node_id, s.str());
00094   }
00095 
00096   void log_msg_details(
00097     aft::NodeId node_id, aft::NodeId tgt_node_id, aft::RequestVoteResponse rv)
00098   {
00099     std::ostringstream s;
00100     s << "request_vote_response t: " << rv.term << ", vg: " << rv.vote_granted;
00101     rlog(node_id, tgt_node_id, s.str());
00102   }
00103 
00104   void log_msg_details(
00105     aft::NodeId node_id, aft::NodeId tgt_node_id, aft::AppendEntries ae)
00106   {
00107     std::ostringstream s;
00108     s << "append_entries i: " << ae.idx << ", t: " << ae.term
00109       << ", pi: " << ae.prev_idx << ", pt: " << ae.prev_term
00110       << ", lci: " << ae.leader_commit_idx;
00111     log(node_id, tgt_node_id, s.str());
00112   }
00113 
00114   void log_msg_details(
00115     aft::NodeId node_id,
00116     aft::NodeId tgt_node_id,
00117     aft::AppendEntriesResponse aer)
00118   {
00119     std::ostringstream s;
00120     s << "append_entries_response t: " << aer.term
00121       << ", lli: " << aer.last_log_idx
00122       << ", s: " << static_cast<uint8_t>(aer.success);
00123     rlog(node_id, tgt_node_id, s.str());
00124   }
00125 
00126   void connect(aft::NodeId first, aft::NodeId second)
00127   {
00128     std::cout << "  Node" << first << "-->Node" << second << ": connect"
00129               << std::endl;
00130     _connections.insert(std::make_pair(first, second));
00131     _connections.insert(std::make_pair(second, first));
00132   }
00133 
00134   void periodic_one(aft::NodeId node_id, ms ms_)
00135   {
00136     std::ostringstream s;
00137     s << "periodic for " << std::to_string(ms_.count()) << " ms";
00138     log(node_id, node_id, s.str());
00139     _nodes.at(node_id).raft->periodic(ms_);
00140   }
00141 
00142   void periodic_all(ms ms_)
00143   {
00144     for (auto& node : _nodes)
00145     {
00146       periodic_one(node.first, ms_);
00147     }
00148   }
00149 
00150   void state_one(aft::NodeId node_id)
00151   {
00152     std::cout << "  Note right of Node" << node_id << ": ";
00153     auto raft = _nodes.at(node_id).raft;
00154 
00155     if (raft->is_primary())
00156       std::cout << "L ";
00157 
00158     std::cout << " t: " << raft->get_term() << ", li: " << raft->get_last_idx()
00159               << ", ci: " << raft->get_commit_idx() << std::endl;
00160   }
00161 
00162   void state_all()
00163   {
00164     for (auto& node : _nodes)
00165     {
00166       state_one(node.first);
00167     }
00168   }
00169 
00170   template <class Messages>
00171   size_t dispatch_one_queue(aft::NodeId node_id, Messages& messages)
00172   {
00173     size_t count = 0;
00174 
00175     while (messages.size())
00176     {
00177       auto message = messages.front();
00178       messages.pop_front();
00179       auto tgt_node_id = std::get<0>(message);
00180 
00181       if (
00182         _connections.find(std::make_pair(node_id, tgt_node_id)) !=
00183         _connections.end())
00184       {
00185         auto contents = std::get<1>(message);
00186         log_msg_details(node_id, tgt_node_id, contents);
00187         _nodes.at(tgt_node_id)
00188           .raft->recv_message(
00189             reinterpret_cast<uint8_t*>(&contents), sizeof(contents));
00190         count++;
00191       }
00192     }
00193 
00194     return count;
00195   }
00196 
00197   void dispatch_one(aft::NodeId node_id)
00198   {
00199     auto raft = _nodes.at(node_id).raft;
00200     dispatch_one_queue(
00201       node_id,
00202       ((aft::ChannelStubProxy*)raft->channels.get())->sent_request_vote);
00203     dispatch_one_queue(
00204       node_id,
00205       ((aft::ChannelStubProxy*)raft->channels.get())
00206         ->sent_request_vote_response);
00207     dispatch_one_queue(
00208       node_id,
00209       ((aft::ChannelStubProxy*)raft->channels.get())->sent_append_entries);
00210     dispatch_one_queue(
00211       node_id,
00212       ((aft::ChannelStubProxy*)raft->channels.get())
00213         ->sent_append_entries_response);
00214   }
00215 
00216   void dispatch_all_once()
00217   {
00218     for (auto& node : _nodes)
00219     {
00220       dispatch_one(node.first);
00221     }
00222   }
00223 
00224   void dispatch_all()
00225   {
00226     size_t iterations = 0;
00227     while (std::accumulate(
00228              _nodes.begin(),
00229              _nodes.end(),
00230              0,
00231              [](int acc, auto& node) {
00232                return ((aft::ChannelStubProxy*)node.second.raft->channels.get())
00233                         ->sent_msg_count() +
00234                  acc;
00235              }) &&
00236            iterations++ < 5)
00237     {
00238       dispatch_all_once();
00239     }
00240   }
00241 
00242   void replicate(
00243     aft::NodeId node_id,
00244     aft::Index idx,
00245     std::shared_ptr<std::vector<uint8_t>> data)
00246   {
00247     std::cout << "  KV" << node_id << "->>Node" << node_id
00248               << ": replicate idx: " << idx << std::endl;
00249     _nodes.at(node_id).raft->replicate(kv::BatchVector{{idx, data, true}}, 1);
00250   }
00251 
00252   void disconnect(aft::NodeId left, aft::NodeId right)
00253   {
00254     bool noop = true;
00255     auto ltr = std::make_pair(left, right);
00256     auto rtl = std::make_pair(right, left);
00257     if (_connections.find(ltr) != _connections.end())
00258     {
00259       _connections.erase(ltr);
00260       noop = false;
00261     }
00262     if (_connections.find(rtl) != _connections.end())
00263     {
00264       _connections.erase(rtl);
00265       noop = false;
00266     }
00267     if (!noop)
00268     {
00269       std::cout << "  Node" << left << "-->Node" << right << ": disconnect"
00270                 << std::endl;
00271     }
00272   }
00273 
00274   void disconnect_node(aft::NodeId node_id)
00275   {
00276     for (auto& node : _nodes)
00277     {
00278       if (node.first != node_id)
00279       {
00280         disconnect(node_id, node.first);
00281       }
00282     }
00283   }
00284 
00285   void reconnect(aft::NodeId left, aft::NodeId right)
00286   {
00287     std::cout << "  Node" << left << "-->Node" << right << ": reconnect"
00288               << std::endl;
00289     _connections.insert(std::make_pair(left, right));
00290     _connections.insert(std::make_pair(right, left));
00291   }
00292 
00293   void reconnect_node(aft::NodeId node_id)
00294   {
00295     for (auto& node : _nodes)
00296     {
00297       if (node.first != node_id)
00298       {
00299         reconnect(node_id, node.first);
00300       }
00301     }
00302   }
00303 };
00304 
---------
Macros accessible in this file:
---------
STUB_LOG 
---------
Parsing file /data/git/CCF/src/consensus/aft/test/driver.h...
Preprocessing /data/git/CCF/src/consensus/aft/test/enclave.cpp...
#include consensus/ledger_enclave.h: not found! skipping...
#include ds/ring_buffer.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 4350 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 using namespace consensus;
00013 
00014 using WFactory = ringbuffer::WriterFactory;
00015 
00016 TEST_CASE("Enclave put")
00017 {
00018   constexpr auto buffer_size = 1024;
00019   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00020   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00021   ringbuffer::Circuit eio(in_buffer->bd, out_buffer->bd);
00022   std::unique_ptr<WFactory> writer_factory = std::make_unique<WFactory>(eio);
00023 
00024   auto enclave = LedgerEnclave(*writer_factory);
00025 
00026   bool globally_committable = false;
00027   bool force_ledger_chunk = false;
00028   const std::vector<uint8_t> tx = {'a', 'b', 'c'};
00029   enclave.put_entry(tx, globally_committable, force_ledger_chunk);
00030   size_t num_msgs = 0;
00031   eio.read_from_inside().read(
00032     -1, [&](ringbuffer::Message m, const uint8_t* data, size_t size) {
00033       switch (m)
00034       {
00035         case consensus::ledger_append:
00036         {
00037           REQUIRE(num_msgs == 0);
00038           REQUIRE(serialized::read<bool>(data, size) == globally_committable);
00039           REQUIRE(serialized::read<bool>(data, size) == force_ledger_chunk);
00040           auto entry = std::vector<uint8_t>(data, data + size);
00041           REQUIRE(entry == tx);
00042         }
00043         break;
00044         default:
00045           REQUIRE(false);
00046       }
00047       ++num_msgs;
00048     });
00049   REQUIRE(num_msgs == 1);
00050 }
00051 
00052 TEST_CASE("Enclave record")
00053 {
00054   constexpr auto buffer_size_leader = 1024;
00055   auto in_buffer_leader =
00056     std::make_unique<ringbuffer::TestBuffer>(buffer_size_leader);
00057   auto out_buffer_leader =
00058     std::make_unique<ringbuffer::TestBuffer>(buffer_size_leader);
00059   ringbuffer::Circuit eio_leader(in_buffer_leader->bd, out_buffer_leader->bd);
00060   std::unique_ptr<WFactory> writer_factory_leader =
00061     std::make_unique<WFactory>(eio_leader);
00062 
00063   constexpr auto buffer_size_follower = 1024;
00064   auto in_buffer_follower =
00065     std::make_unique<ringbuffer::TestBuffer>(buffer_size_follower);
00066   auto out_buffer_follower =
00067     std::make_unique<ringbuffer::TestBuffer>(buffer_size_follower);
00068   ringbuffer::Circuit eio_follower(
00069     in_buffer_follower->bd, out_buffer_follower->bd);
00070   std::unique_ptr<WFactory> writer_factory_follower =
00071     std::make_unique<WFactory>(eio_follower);
00072 
00073   auto leader_ledger_enclave = LedgerEnclave(*writer_factory_leader);
00074   auto follower_ledger_enclave = LedgerEnclave(*writer_factory_follower);
00075 
00076   bool globally_committable = false;
00077   bool force_ledger_chunk = false;
00078   const std::vector<uint8_t> tx = {'a', 'b', 'c'};
00079   leader_ledger_enclave.put_entry(tx, globally_committable, force_ledger_chunk);
00080   size_t num_msgs = 0;
00081   std::vector<uint8_t> record;
00082   eio_leader.read_from_inside().read(
00083     -1, [&](ringbuffer::Message m, const uint8_t* data, size_t size) {
00084       switch (m)
00085       {
00086         case consensus::ledger_append:
00087         {
00088           REQUIRE(num_msgs == 0);
00089           REQUIRE(serialized::read<bool>(data, size) == globally_committable);
00090           REQUIRE(serialized::read<bool>(data, size) == force_ledger_chunk);
00091           copy(data, data + size, back_inserter(record));
00092         }
00093         break;
00094         default:
00095           REQUIRE(false);
00096       }
00097       ++num_msgs;
00098     });
00099   REQUIRE(num_msgs == 1);
00100 
00101   std::vector<uint8_t> msg(sizeof(uint32_t), 0);
00102   uint8_t* data_ = msg.data();
00103   size_t size = msg.size();
00104   serialized::write(data_, size, static_cast<uint32_t>(record.size()));
00105   copy(record.begin(), record.end(), back_inserter(msg));
00106 
00107   const uint8_t* data__ = msg.data();
00108   auto size_ = msg.size();
00109 
00110   num_msgs = 0;
00111   auto r = follower_ledger_enclave.get_entry(data__, size_);
00112   REQUIRE(r == tx);
00113   follower_ledger_enclave.put_entry(
00114     r, globally_committable, force_ledger_chunk);
00115   eio_follower.read_from_inside().read(
00116     -1, [&](ringbuffer::Message m, const uint8_t* data, size_t size) {
00117       switch (m)
00118       {
00119         case consensus::ledger_append:
00120         {
00121           REQUIRE(num_msgs == 0);
00122           REQUIRE(serialized::read<bool>(data, size) == globally_committable);
00123           REQUIRE(serialized::read<bool>(data, size) == force_ledger_chunk);
00124           auto entry = std::vector<uint8_t>(data, data + size);
00125           REQUIRE(entry == tx);
00126         }
00127         break;
00128         default:
00129           REQUIRE(false);
00130       }
00131       ++num_msgs;
00132     });
00133   REQUIRE(num_msgs == 1);
00134 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/consensus/aft/test/enclave.cpp...
Preprocessing /data/git/CCF/src/consensus/aft/test/logging_stub.h...
#include consensus/aft/raft.h: not found! skipping...
#include consensus/aft/raft_types.h: not found! skipping...
#include map: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 5710 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace aft
00013 {
00014   class LedgerStubProxy
00015   {
00016   private:
00017     NodeId _id;
00018 
00019   public:
00020     std::vector<std::shared_ptr<std::vector<uint8_t>>> ledger;
00021     uint64_t skip_count = 0;
00022 
00023     LedgerStubProxy(NodeId id) : _id(id) {}
00024 
00025     void put_entry(
00026       const std::vector<uint8_t>& data,
00027       bool globally_committable,
00028       bool force_chunk)
00029     {
00030 
00031 
00032 
00033 
00034 
00035       auto size = data.size();
00036       auto buffer = std::make_shared<std::vector<uint8_t>>(size);
00037       auto ptr = buffer->data();
00038 
00039       serialized::write(ptr, size, data.data(), data.size());
00040 
00041       ledger.push_back(buffer);
00042     }
00043 
00044     void skip_entry(const uint8_t*& data, size_t& size)
00045     {
00046       skip_count++;
00047     }
00048 
00049     std::vector<uint8_t> get_entry(const uint8_t*& data, size_t& size)
00050     {
00051       return {data, data + size};
00052     }
00053 
00054     void truncate(Index idx)
00055     {
00056       ledger.resize(idx);
00057 
00058 
00059 
00060 
00061     }
00062 
00063     void reset_skip_count()
00064     {
00065       skip_count = 0;
00066     }
00067 
00068     void commit(Index idx) {}
00069   };
00070 
00071   class ChannelStubProxy : public ccf::NodeToNode
00072   {
00073   public:
00074     // Capture what is being sent out
00075     std::list<std::pair<NodeId, RequestVote>> sent_request_vote;
00076     std::list<std::pair<NodeId, AppendEntries>> sent_append_entries;
00077     std::list<std::pair<NodeId, RequestVoteResponse>>
00078       sent_request_vote_response;
00079     std::list<std::pair<NodeId, AppendEntriesResponse>>
00080       sent_append_entries_response;
00081 
00082     ChannelStubProxy() {}
00083 
00084     void create_channel(
00085       NodeId peer_id,
00086       const std::string& peer_hostname,
00087       const std::string& peer_service) override
00088     {}
00089 
00090     void destroy_channel(NodeId peer_id) override {}
00091 
00092     void destroy_all_channels() override {}
00093 
00094     void close_all_outgoing() override {}
00095 
00096     bool send_authenticated(
00097       const ccf::NodeMsgType& msg_type,
00098       NodeId to,
00099       const uint8_t* data,
00100       size_t size) override
00101     {
00102       switch (serialized::peek<RaftMsgType>(data, size))
00103       {
00104         case aft::RaftMsgType::raft_append_entries:
00105           sent_append_entries.push_back(
00106             std::make_pair(to, *(AppendEntries*)(data)));
00107           break;
00108         case aft::RaftMsgType::raft_request_vote:
00109           sent_request_vote.push_back(
00110             std::make_pair(to, *(RequestVote*)(data)));
00111           break;
00112         case aft::RaftMsgType::raft_request_vote_response:
00113           sent_request_vote_response.push_back(
00114             std::make_pair(to, *(RequestVoteResponse*)(data)));
00115           break;
00116         case aft::RaftMsgType::raft_append_entries_response:
00117           sent_append_entries_response.push_back(
00118             std::make_pair(to, *(AppendEntriesResponse*)(data)));
00119           break;
00120         default:
00121           throw std::logic_error("unexpected response type");
00122       }
00123 
00124       return true;
00125     }
00126 
00127     size_t sent_msg_count() const
00128     {
00129       return sent_request_vote.size() + sent_request_vote_response.size() +
00130         sent_append_entries.size() + sent_append_entries_response.size();
00131     }
00132 
00133     bool recv_authenticated(
00134       NodeId from_node, CBuffer cb, const uint8_t*& data, size_t& size) override
00135     {
00136       return true;
00137     }
00138 
00139     void recv_message(OArray&& oa) override {}
00140 
00141     void initialize(NodeId self_id, const tls::Pem& network_pkey) override {}
00142 
00143     bool send_encrypted(
00144       const ccf::NodeMsgType& msg_type,
00145       CBuffer cb,
00146       NodeId to,
00147       const std::vector<uint8_t>& data) override
00148     {
00149       return true;
00150     }
00151 
00152     std::vector<uint8_t> recv_encrypted(
00153       NodeId from_node, CBuffer cb, const uint8_t* data, size_t size) override
00154     {
00155       return {};
00156     }
00157 
00158     bool recv_authenticated_with_load(
00159       NodeId from_node, const uint8_t*& data, size_t& size) override
00160     {
00161       return true;
00162     }
00163   };
00164 
00165   class LoggingStubStore
00166   {
00167   private:
00168     aft::NodeId _id;
00169 
00170   public:
00171     LoggingStubStore(aft::NodeId id) : _id(id) {}
00172 
00173     virtual void compact(Index i)
00174     {
00175 
00176 
00177 
00178 
00179     }
00180 
00181     virtual void rollback(Index i, std::optional<Term> t = std::nullopt)
00182     {
00183 
00184 
00185 
00186 
00187 
00188 
00189     }
00190 
00191     virtual void set_term(Term t)
00192     {
00193 
00194 
00195 
00196 
00197     }
00198 
00199     virtual kv::DeserialiseSuccess deserialise(
00200       const std::vector<uint8_t>& data,
00201       bool public_only = false,
00202       Term* term = nullptr)
00203     {
00204       return kv::DeserialiseSuccess::PASS;
00205     }
00206 
00207     kv::Version current_version()
00208     {
00209       return kv::NoVersion;
00210     }
00211 
00212     virtual kv::DeserialiseSuccess deserialise_views(
00213       const std::vector<uint8_t>& data,
00214       bool public_only = false,
00215       kv::Term* term = nullptr,
00216       kv::Version* index = nullptr,
00217       kv::Tx* tx = nullptr,
00218       ccf::PrimarySignature* sig = nullptr)
00219     {
00220       return kv::DeserialiseSuccess::PASS;
00221     }
00222 
00223     std::shared_ptr<ccf::ProgressTracker> get_progress_tracker()
00224     {
00225       return nullptr;
00226     }
00227 
00228     kv::Tx create_tx()
00229     {
00230       return kv::Tx(nullptr, true);
00231     }
00232   };
00233 
00234   class LoggingStubStoreSig : public LoggingStubStore
00235   {
00236   public:
00237     LoggingStubStoreSig(aft::NodeId id) : LoggingStubStore(id) {}
00238 
00239     kv::DeserialiseSuccess deserialise(
00240       const std::vector<uint8_t>& data,
00241       bool public_only = false,
00242       Term* term = nullptr) override
00243     {
00244       return kv::DeserialiseSuccess::PASS_SIGNATURE;
00245     }
00246   };
00247 
00248   class StubSnapshotter
00249   {
00250   public:
00251     void snapshot(Index)
00252     {
00253       // For now, do not test snapshots in unit tests
00254       return;
00255     }
00256 
00257     bool requires_snapshot(Index)
00258     {
00259       // For now, do not test snapshots in unit tests
00260       return false;
00261     }
00262 
00263     void commit(Index)
00264     {
00265       // For now, do not test snapshots in unit tests
00266       return;
00267     }
00268 
00269     void rollback(Index)
00270     {
00271       // For now, do not test snapshots in unit tests
00272       return;
00273     }
00274   };
00275 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/test/logging_stub.h...
Preprocessing /data/git/CCF/src/consensus/aft/test/main.cpp...
#include consensus/aft/raft.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include logging_stub.h: already included! skipping...
#include chrono: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 32626 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 #define DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES
00009 
00010 
00011 
00012 
00013 
00014 using namespace std;
00015 
00016 using ms = std::chrono::milliseconds;
00017 using TRaft =
00018   aft::Aft<aft::LedgerStubProxy, aft::ChannelStubProxy, aft::StubSnapshotter>;
00019 using Store = aft::LoggingStubStore;
00020 using StoreSig = aft::LoggingStubStoreSig;
00021 using Adaptor = aft::Adaptor<Store, kv::DeserialiseSuccess>;
00022 
00023 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00024 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00025 
00026 std::vector<uint8_t> cert;
00027 
00028 
00029 {
00030   auto kv_store = std::make_shared<Store>(0);
00031   aft::NodeId node_id(0);
00032   ms election_timeout(150);
00033 
00034   TRaft r0(
00035     ConsensusType::CFT,
00036     std::make_unique<Adaptor>(kv_store),
00037     std::make_unique<aft::LedgerStubProxy>(node_id),
00038     std::make_shared<aft::ChannelStubProxy>(),
00039     std::make_shared<aft::StubSnapshotter>(),
00040     nullptr,
00041     nullptr,
00042     cert,
00043     std::make_shared<aft::State>(node_id),
00044     nullptr,
00045     nullptr,
00046     nullptr,
00047     ms(10),
00048     election_timeout,
00049     ms(1000));
00050 
00051   kv::Consensus::Configuration::Nodes config;
00052   config.try_emplace(node_id);
00053   r0.add_configuration(0, config);
00054 
00055   DOCTEST_INFO("DOCTEST_REQUIRE Initial State");
00056 
00057   DOCTEST_REQUIRE(!r0.is_primary());
00058   DOCTEST_REQUIRE(r0.leader() == aft::NoNode);
00059   DOCTEST_REQUIRE(r0.get_term() == 0);
00060   DOCTEST_REQUIRE(r0.get_commit_idx() == 0);
00061 
00062   DOCTEST_INFO(
00063     "In the absence of other nodes, become leader after election timeout");
00064 
00065   r0.periodic(ms(0));
00066   DOCTEST_REQUIRE(!r0.is_primary());
00067 
00068   r0.periodic(election_timeout * 2);
00069   DOCTEST_REQUIRE(r0.is_primary());
00070   DOCTEST_REQUIRE(r0.leader() == node_id);
00071 }
00072 
00073 
00074 {
00075   auto kv_store = std::make_shared<Store>(0);
00076   aft::NodeId node_id(0);
00077   ms election_timeout(150);
00078 
00079   TRaft r0(
00080     ConsensusType::CFT,
00081     std::make_unique<Adaptor>(kv_store),
00082     std::make_unique<aft::LedgerStubProxy>(node_id),
00083     std::make_shared<aft::ChannelStubProxy>(),
00084     std::make_shared<aft::StubSnapshotter>(),
00085     nullptr,
00086     nullptr,
00087     cert,
00088     std::make_shared<aft::State>(node_id),
00089     nullptr,
00090     nullptr,
00091     nullptr,
00092     ms(10),
00093     election_timeout,
00094     ms(1000));
00095 
00096   aft::Configuration::Nodes config;
00097   config[node_id] = {};
00098   r0.add_configuration(0, config);
00099 
00100   DOCTEST_INFO("Become leader after election timeout");
00101 
00102   r0.periodic(election_timeout * 2);
00103   DOCTEST_REQUIRE(r0.is_primary());
00104 
00105   DOCTEST_INFO("Observe that data is committed on replicate immediately");
00106 
00107   for (size_t i = 1; i <= 5; ++i)
00108   {
00109     auto entry = std::make_shared<std::vector<uint8_t>>();
00110     entry->push_back(1);
00111     entry->push_back(2);
00112     entry->push_back(3);
00113 
00114     r0.replicate(kv::BatchVector{{i, entry, true}}, 1);
00115     DOCTEST_REQUIRE(r0.get_last_idx() == i);
00116     DOCTEST_REQUIRE(r0.get_commit_idx() == i);
00117   }
00118 }
00119 
00120 DOCTEST_TEST_CASE(
00121   "Multiple nodes startup and election" * doctest::test_suite("multiple"))
00122 {
00123   auto kv_store0 = std::make_shared<Store>(0);
00124   auto kv_store1 = std::make_shared<Store>(1);
00125   auto kv_store2 = std::make_shared<Store>(2);
00126 
00127   aft::NodeId node_id0(0);
00128   aft::NodeId node_id1(1);
00129   aft::NodeId node_id2(2);
00130 
00131   ms request_timeout(10);
00132 
00133   TRaft r0(
00134     ConsensusType::CFT,
00135     std::make_unique<Adaptor>(kv_store0),
00136     std::make_unique<aft::LedgerStubProxy>(node_id0),
00137     std::make_shared<aft::ChannelStubProxy>(),
00138     std::make_shared<aft::StubSnapshotter>(),
00139     nullptr,
00140     nullptr,
00141     cert,
00142     std::make_shared<aft::State>(node_id0),
00143     nullptr,
00144     nullptr,
00145     nullptr,
00146     request_timeout,
00147     ms(20),
00148     ms(1000));
00149   TRaft r1(
00150     ConsensusType::CFT,
00151     std::make_unique<Adaptor>(kv_store1),
00152     std::make_unique<aft::LedgerStubProxy>(node_id1),
00153     std::make_shared<aft::ChannelStubProxy>(),
00154     std::make_shared<aft::StubSnapshotter>(),
00155     nullptr,
00156     nullptr,
00157     cert,
00158     std::make_shared<aft::State>(node_id1),
00159     nullptr,
00160     nullptr,
00161     nullptr,
00162     request_timeout,
00163     ms(100),
00164     ms(1000));
00165   TRaft r2(
00166     ConsensusType::CFT,
00167     std::make_unique<Adaptor>(kv_store2),
00168     std::make_unique<aft::LedgerStubProxy>(node_id2),
00169     std::make_shared<aft::ChannelStubProxy>(),
00170     std::make_shared<aft::StubSnapshotter>(),
00171     nullptr,
00172     nullptr,
00173     cert,
00174     std::make_shared<aft::State>(node_id2),
00175     nullptr,
00176     nullptr,
00177     nullptr,
00178     request_timeout,
00179     ms(50),
00180     ms(1000));
00181 
00182   aft::Configuration::Nodes config;
00183   config[node_id0] = {};
00184   config[node_id1] = {};
00185   config[node_id2] = {};
00186   r0.add_configuration(0, config);
00187   r1.add_configuration(0, config);
00188   r2.add_configuration(0, config);
00189 
00190   auto by_0 = [](auto const& lhs, auto const& rhs) -> bool {
00191     return get<0>(lhs) < get<0>(rhs);
00192   };
00193 
00194   DOCTEST_INFO("Node 0 exceeds its election timeout and starts an election");
00195 
00196   r0.periodic(std::chrono::milliseconds(200));
00197   DOCTEST_REQUIRE(
00198     ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.size() == 2);
00199   ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.sort(by_0);
00200 
00201   DOCTEST_INFO("Node 1 receives the request");
00202 
00203   auto rv =
00204     ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.front();
00205   ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.pop_front();
00206   DOCTEST_REQUIRE(get<0>(rv) == node_id1);
00207   auto rvc = get<1>(rv);
00208   DOCTEST_REQUIRE(rvc.term == 1);
00209   DOCTEST_REQUIRE(rvc.last_committable_idx == 0);
00210   DOCTEST_REQUIRE(
00211     rvc.term_of_last_committable_idx == aft::ViewHistory::InvalidView);
00212 
00213   r1.recv_message(reinterpret_cast<uint8_t*>(&rvc), sizeof(rvc));
00214 
00215   DOCTEST_INFO("Node 2 receives the request");
00216 
00217   rv = ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.front();
00218   ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote.pop_front();
00219   DOCTEST_REQUIRE(get<0>(rv) == node_id2);
00220   rvc = get<1>(rv);
00221   DOCTEST_REQUIRE(rvc.term == 1);
00222   DOCTEST_REQUIRE(rvc.last_committable_idx == 0);
00223   DOCTEST_REQUIRE(
00224     rvc.term_of_last_committable_idx == aft::ViewHistory::InvalidView);
00225 
00226   r2.recv_message(reinterpret_cast<uint8_t*>(&rvc), sizeof(rvc));
00227 
00228   DOCTEST_INFO("Node 1 votes for Node 0");
00229 
00230   DOCTEST_REQUIRE(
00231     ((aft::ChannelStubProxy*)r1.channels.get())
00232       ->sent_request_vote_response.size() == 1);
00233   auto rvr = ((aft::ChannelStubProxy*)r1.channels.get())
00234                ->sent_request_vote_response.front();
00235   ((aft::ChannelStubProxy*)r1.channels.get())
00236     ->sent_request_vote_response.pop_front();
00237 
00238   DOCTEST_REQUIRE(get<0>(rvr) == node_id0);
00239   auto rvrc = get<1>(rvr);
00240   DOCTEST_REQUIRE(rvrc.term == 1);
00241   DOCTEST_REQUIRE(rvrc.vote_granted);
00242 
00243   r0.recv_message(reinterpret_cast<uint8_t*>(&rvrc), sizeof(rvrc));
00244 
00245   DOCTEST_INFO("Node 2 votes for Node 0");
00246 
00247   DOCTEST_REQUIRE(
00248     ((aft::ChannelStubProxy*)r2.channels.get())
00249       ->sent_request_vote_response.size() == 1);
00250   rvr = ((aft::ChannelStubProxy*)r2.channels.get())
00251           ->sent_request_vote_response.front();
00252   ((aft::ChannelStubProxy*)r2.channels.get())
00253     ->sent_request_vote_response.pop_front();
00254 
00255   DOCTEST_REQUIRE(get<0>(rvr) == node_id0);
00256   rvrc = get<1>(rvr);
00257   DOCTEST_REQUIRE(rvrc.term == 1);
00258   DOCTEST_REQUIRE(rvrc.vote_granted);
00259 
00260   r0.recv_message(reinterpret_cast<uint8_t*>(&rvrc), sizeof(rvrc));
00261 
00262   DOCTEST_INFO(
00263     "Node 0 is now leader, and sends empty append entries to other nodes");
00264 
00265   DOCTEST_REQUIRE(r0.is_primary());
00266   DOCTEST_REQUIRE(
00267     ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00268     2);
00269   ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.sort(by_0);
00270 
00271   auto ae =
00272     ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.front();
00273   ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.pop_front();
00274   DOCTEST_REQUIRE(get<0>(ae) == node_id1);
00275   auto aec = get<1>(ae);
00276   DOCTEST_REQUIRE(aec.idx == 0);
00277   DOCTEST_REQUIRE(aec.term == 1);
00278   DOCTEST_REQUIRE(aec.prev_idx == 0);
00279   DOCTEST_REQUIRE(aec.prev_term == aft::ViewHistory::InvalidView);
00280   DOCTEST_REQUIRE(aec.leader_commit_idx == 0);
00281 
00282   ae = ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.front();
00283   ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.pop_front();
00284   DOCTEST_REQUIRE(get<0>(ae) == node_id2);
00285   aec = get<1>(ae);
00286   DOCTEST_REQUIRE(aec.idx == 0);
00287   DOCTEST_REQUIRE(aec.term == 1);
00288   DOCTEST_REQUIRE(aec.prev_idx == 0);
00289   DOCTEST_REQUIRE(aec.prev_term == aft::ViewHistory::InvalidView);
00290   DOCTEST_REQUIRE(aec.leader_commit_idx == 0);
00291 }
00292 
00293 template <class NodeMap, class Messages>
00294 static size_t dispatch_all(NodeMap& nodes, Messages& messages)
00295 {
00296   size_t count = 0;
00297   while (messages.size())
00298   {
00299     auto message = messages.front();
00300     messages.pop_front();
00301     auto tgt_node_id = get<0>(message);
00302     auto contents = get<1>(message);
00303     nodes[tgt_node_id]->recv_message(
00304       reinterpret_cast<uint8_t*>(&contents), sizeof(contents));
00305     count++;
00306   }
00307   return count;
00308 }
00309 
00310 template <class NodeMap, class Messages, class Assertion>
00311 static size_t dispatch_all_and_DOCTEST_CHECK(
00312   NodeMap& nodes, Messages& messages, const Assertion& assertion)
00313 {
00314   size_t count = 0;
00315   while (messages.size())
00316   {
00317     auto message = messages.front();
00318     messages.pop_front();
00319     auto tgt_node_id = get<0>(message);
00320     auto contents = get<1>(message);
00321     assertion(contents);
00322     nodes[tgt_node_id]->recv_message(
00323       reinterpret_cast<uint8_t*>(&contents), sizeof(contents));
00324     count++;
00325   }
00326   return count;
00327 }
00328 
00329 DOCTEST_TEST_CASE(
00330   "Multiple nodes append entries" * doctest::test_suite("multiple"))
00331 {
00332   auto kv_store0 = std::make_shared<Store>(0);
00333   auto kv_store1 = std::make_shared<Store>(1);
00334   auto kv_store2 = std::make_shared<Store>(2);
00335 
00336   aft::NodeId node_id0(0);
00337   aft::NodeId node_id1(1);
00338   aft::NodeId node_id2(2);
00339 
00340   ms request_timeout(10);
00341 
00342   TRaft r0(
00343     ConsensusType::CFT,
00344     std::make_unique<Adaptor>(kv_store0),
00345     std::make_unique<aft::LedgerStubProxy>(node_id0),
00346     std::make_shared<aft::ChannelStubProxy>(),
00347     std::make_shared<aft::StubSnapshotter>(),
00348     nullptr,
00349     nullptr,
00350     cert,
00351     std::make_shared<aft::State>(node_id0),
00352     nullptr,
00353     nullptr,
00354     nullptr,
00355     request_timeout,
00356     ms(20),
00357     ms(1000));
00358   TRaft r1(
00359     ConsensusType::CFT,
00360     std::make_unique<Adaptor>(kv_store1),
00361     std::make_unique<aft::LedgerStubProxy>(node_id1),
00362     std::make_shared<aft::ChannelStubProxy>(),
00363     std::make_shared<aft::StubSnapshotter>(),
00364     nullptr,
00365     nullptr,
00366     cert,
00367 
00368     std::make_shared<aft::State>(node_id1),
00369     nullptr,
00370     nullptr,
00371     nullptr,
00372     request_timeout,
00373     ms(100),
00374     ms(1000));
00375   TRaft r2(
00376     ConsensusType::CFT,
00377     std::make_unique<Adaptor>(kv_store2),
00378     std::make_unique<aft::LedgerStubProxy>(node_id2),
00379     std::make_shared<aft::ChannelStubProxy>(),
00380     std::make_shared<aft::StubSnapshotter>(),
00381     nullptr,
00382     nullptr,
00383     cert,
00384     std::make_shared<aft::State>(node_id2),
00385     nullptr,
00386     nullptr,
00387     nullptr,
00388     request_timeout,
00389     ms(50),
00390     ms(1000));
00391 
00392   aft::Configuration::Nodes config;
00393   config[node_id0] = {};
00394   config[node_id1] = {};
00395   config[node_id2] = {};
00396   r0.add_configuration(0, config);
00397   r1.add_configuration(0, config);
00398   r2.add_configuration(0, config);
00399 
00400   map<aft::NodeId, TRaft*> nodes;
00401   nodes[node_id0] = &r0;
00402   nodes[node_id1] = &r1;
00403   nodes[node_id2] = &r2;
00404 
00405   r0.periodic(std::chrono::milliseconds(200));
00406 
00407   DOCTEST_INFO("Send request_votes to other nodes");
00408   DOCTEST_REQUIRE(
00409     2 ==
00410     dispatch_all(
00411       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote));
00412 
00413   DOCTEST_INFO("Send request_vote_reponses back");
00414   DOCTEST_REQUIRE(
00415     1 ==
00416     dispatch_all(
00417       nodes,
00418       ((aft::ChannelStubProxy*)r1.channels.get())->sent_request_vote_response));
00419   DOCTEST_REQUIRE(
00420     1 ==
00421     dispatch_all(
00422       nodes,
00423       ((aft::ChannelStubProxy*)r2.channels.get())->sent_request_vote_response));
00424 
00425   DOCTEST_INFO("Send empty append_entries to other nodes");
00426   DOCTEST_REQUIRE(
00427     2 ==
00428     dispatch_all(
00429       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00430 
00431   DOCTEST_INFO("Send append_entries_reponses back");
00432   DOCTEST_REQUIRE(
00433     1 ==
00434     dispatch_all_and_DOCTEST_CHECK(
00435       nodes,
00436       ((aft::ChannelStubProxy*)r1.channels.get())->sent_append_entries_response,
00437       [](const auto& msg) {
00438         DOCTEST_REQUIRE(msg.last_log_idx == 0);
00439         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00440       }));
00441   DOCTEST_REQUIRE(
00442     1 ==
00443     dispatch_all_and_DOCTEST_CHECK(
00444       nodes,
00445       ((aft::ChannelStubProxy*)r2.channels.get())->sent_append_entries_response,
00446       [](const auto& msg) {
00447         DOCTEST_REQUIRE(msg.last_log_idx == 0);
00448         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00449       }));
00450 
00451   DOCTEST_INFO("There ought to be no messages pending anywhere now");
00452   DOCTEST_REQUIRE(
00453     ((aft::ChannelStubProxy*)r0.channels.get())->sent_msg_count() == 0);
00454   DOCTEST_REQUIRE(
00455     ((aft::ChannelStubProxy*)r1.channels.get())->sent_msg_count() == 0);
00456   DOCTEST_REQUIRE(
00457     ((aft::ChannelStubProxy*)r2.channels.get())->sent_msg_count() == 0);
00458 
00459   DOCTEST_INFO("Try to replicate on a follower, and fail");
00460   std::vector<uint8_t> entry = {1, 2, 3};
00461   auto data = std::make_shared<std::vector<uint8_t>>(entry);
00462   DOCTEST_REQUIRE_FALSE(r1.replicate(kv::BatchVector{{1, data, true}}, 1));
00463 
00464   DOCTEST_INFO("Tell the leader to replicate a message");
00465   DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{1, data, true}}, 1));
00466   DOCTEST_REQUIRE(r0.ledger->ledger.size() == 1);
00467   DOCTEST_REQUIRE(*r0.ledger->ledger.front() == entry);
00468   DOCTEST_INFO("The other nodes are not told about this yet");
00469   DOCTEST_REQUIRE(
00470     ((aft::ChannelStubProxy*)r0.channels.get())->sent_msg_count() == 0);
00471 
00472   r0.periodic(ms(10));
00473 
00474   DOCTEST_INFO("Now the other nodes are sent append_entries");
00475   DOCTEST_REQUIRE(
00476     2 ==
00477     dispatch_all_and_DOCTEST_CHECK(
00478       nodes,
00479       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries,
00480       [](const auto& msg) {
00481         DOCTEST_REQUIRE(msg.idx == 1);
00482         DOCTEST_REQUIRE(msg.term == 1);
00483         DOCTEST_REQUIRE(msg.prev_idx == 0);
00484         DOCTEST_REQUIRE(msg.prev_term == aft::ViewHistory::InvalidView);
00485         DOCTEST_REQUIRE(msg.leader_commit_idx == 0);
00486       }));
00487 
00488   DOCTEST_INFO("Which they acknowledge correctly");
00489   DOCTEST_REQUIRE(
00490     1 ==
00491     dispatch_all_and_DOCTEST_CHECK(
00492       nodes,
00493       ((aft::ChannelStubProxy*)r1.channels.get())->sent_append_entries_response,
00494       [](const auto& msg) {
00495         DOCTEST_REQUIRE(msg.last_log_idx == 1);
00496         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00497       }));
00498   DOCTEST_REQUIRE(
00499     1 ==
00500     dispatch_all_and_DOCTEST_CHECK(
00501       nodes,
00502       ((aft::ChannelStubProxy*)r2.channels.get())->sent_append_entries_response,
00503       [](const auto& msg) {
00504         DOCTEST_REQUIRE(msg.last_log_idx == 1);
00505         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00506       }));
00507 }
00508 
00509 
00510 {
00511   auto kv_store0 = std::make_shared<Store>(0);
00512   auto kv_store1 = std::make_shared<Store>(1);
00513   auto kv_store2 = std::make_shared<Store>(2);
00514 
00515   aft::NodeId node_id0(0);
00516   aft::NodeId node_id1(1);
00517   aft::NodeId node_id2(2);
00518 
00519   ms request_timeout(10);
00520 
00521   TRaft r0(
00522     ConsensusType::CFT,
00523     std::make_unique<Adaptor>(kv_store0),
00524     std::make_unique<aft::LedgerStubProxy>(node_id0),
00525     std::make_shared<aft::ChannelStubProxy>(),
00526     std::make_shared<aft::StubSnapshotter>(),
00527     nullptr,
00528     nullptr,
00529     cert,
00530 
00531     std::make_shared<aft::State>(node_id0),
00532     nullptr,
00533     nullptr,
00534     nullptr,
00535     request_timeout,
00536     ms(20),
00537     ms(1000));
00538   TRaft r1(
00539     ConsensusType::CFT,
00540     std::make_unique<Adaptor>(kv_store1),
00541     std::make_unique<aft::LedgerStubProxy>(node_id1),
00542     std::make_shared<aft::ChannelStubProxy>(),
00543     std::make_shared<aft::StubSnapshotter>(),
00544     nullptr,
00545     nullptr,
00546     cert,
00547 
00548     std::make_shared<aft::State>(node_id1),
00549     nullptr,
00550     nullptr,
00551     nullptr,
00552     request_timeout,
00553     ms(100),
00554     ms(1000));
00555   TRaft r2(
00556     ConsensusType::CFT,
00557     std::make_unique<Adaptor>(kv_store2),
00558     std::make_unique<aft::LedgerStubProxy>(node_id2),
00559     std::make_shared<aft::ChannelStubProxy>(),
00560     std::make_shared<aft::StubSnapshotter>(),
00561     nullptr,
00562     nullptr,
00563     cert,
00564 
00565     std::make_shared<aft::State>(node_id2),
00566     nullptr,
00567     nullptr,
00568     nullptr,
00569     request_timeout,
00570     ms(50),
00571     ms(1000));
00572 
00573   aft::Configuration::Nodes config;
00574   config[node_id0] = {};
00575   config[node_id1] = {};
00576   r0.add_configuration(0, config);
00577   r1.add_configuration(0, config);
00578 
00579   map<aft::NodeId, TRaft*> nodes;
00580   nodes[node_id0] = &r0;
00581   nodes[node_id1] = &r1;
00582 
00583   r0.periodic(std::chrono::milliseconds(200));
00584 
00585   DOCTEST_REQUIRE(
00586     1 ==
00587     dispatch_all(
00588       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote));
00589   DOCTEST_REQUIRE(
00590     1 ==
00591     dispatch_all(
00592       nodes,
00593       ((aft::ChannelStubProxy*)r1.channels.get())->sent_request_vote_response));
00594   DOCTEST_REQUIRE(
00595     1 ==
00596     dispatch_all(
00597       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00598 
00599   DOCTEST_REQUIRE(
00600     1 ==
00601     dispatch_all_and_DOCTEST_CHECK(
00602       nodes,
00603       ((aft::ChannelStubProxy*)r1.channels.get())->sent_append_entries_response,
00604       [](const auto& msg) {
00605         DOCTEST_REQUIRE(msg.last_log_idx == 0);
00606         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00607       }));
00608 
00609   DOCTEST_REQUIRE(
00610     ((aft::ChannelStubProxy*)r0.channels.get())->sent_msg_count() == 0);
00611   DOCTEST_REQUIRE(
00612     ((aft::ChannelStubProxy*)r1.channels.get())->sent_msg_count() == 0);
00613 
00614   std::vector<uint8_t> first_entry = {1, 2, 3};
00615   auto data = std::make_shared<std::vector<uint8_t>>(first_entry);
00616   DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{1, data, true}}, 1));
00617   r0.periodic(ms(10));
00618 
00619   DOCTEST_REQUIRE(
00620     1 ==
00621     dispatch_all_and_DOCTEST_CHECK(
00622       nodes,
00623       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries,
00624       [](const auto& msg) {
00625         DOCTEST_REQUIRE(msg.idx == 1);
00626         DOCTEST_REQUIRE(msg.term == 1);
00627         DOCTEST_REQUIRE(msg.prev_idx == 0);
00628         DOCTEST_REQUIRE(msg.prev_term == aft::ViewHistory::InvalidView);
00629         DOCTEST_REQUIRE(msg.leader_commit_idx == 0);
00630       }));
00631 
00632   DOCTEST_REQUIRE(
00633     1 ==
00634     dispatch_all_and_DOCTEST_CHECK(
00635       nodes,
00636       ((aft::ChannelStubProxy*)r1.channels.get())->sent_append_entries_response,
00637       [](const auto& msg) {
00638         DOCTEST_REQUIRE(msg.last_log_idx == 1);
00639         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00640       }));
00641 
00642   DOCTEST_INFO("Node 2 joins the ensemble");
00643 
00644   aft::Configuration::Nodes config1;
00645   config1[node_id0] = {};
00646   config1[node_id1] = {};
00647   config1[node_id2] = {};
00648   r0.add_configuration(0, config1);
00649   r1.add_configuration(0, config1);
00650   r2.add_configuration(0, config1);
00651 
00652   nodes[node_id2] = &r2;
00653 
00654   DOCTEST_INFO("Node 0 sends Node 2 what it's missed by joining late");
00655   DOCTEST_REQUIRE(
00656     ((aft::ChannelStubProxy*)r2.channels.get())->sent_msg_count() == 0);
00657   DOCTEST_REQUIRE(
00658     ((aft::ChannelStubProxy*)r1.channels.get())->sent_msg_count() == 0);
00659 
00660   DOCTEST_REQUIRE(
00661     1 ==
00662     dispatch_all_and_DOCTEST_CHECK(
00663       nodes,
00664       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries,
00665       [](const auto& msg) {
00666         DOCTEST_REQUIRE(msg.idx == 1);
00667         DOCTEST_REQUIRE(msg.term == 1);
00668         DOCTEST_REQUIRE(msg.prev_idx == 1);
00669         DOCTEST_REQUIRE(msg.prev_term == 1);
00670         DOCTEST_REQUIRE(msg.leader_commit_idx == 1);
00671       }));
00672 }
00673 
00674 
00675 {
00676   auto kv_store0 = std::make_shared<Store>(0);
00677   auto kv_store1 = std::make_shared<Store>(1);
00678 
00679   aft::NodeId node_id0(0);
00680   aft::NodeId node_id1(1);
00681 
00682   ms request_timeout(10);
00683 
00684   TRaft r0(
00685     ConsensusType::CFT,
00686     std::make_unique<Adaptor>(kv_store0),
00687     std::make_unique<aft::LedgerStubProxy>(node_id0),
00688     std::make_shared<aft::ChannelStubProxy>(),
00689     std::make_shared<aft::StubSnapshotter>(),
00690     nullptr,
00691     nullptr,
00692     cert,
00693 
00694     std::make_shared<aft::State>(node_id0),
00695     nullptr,
00696     nullptr,
00697     nullptr,
00698     request_timeout,
00699     ms(20),
00700     ms(1000));
00701   TRaft r1(
00702     ConsensusType::CFT,
00703     std::make_unique<Adaptor>(kv_store1),
00704     std::make_unique<aft::LedgerStubProxy>(node_id1),
00705     std::make_shared<aft::ChannelStubProxy>(),
00706     std::make_shared<aft::StubSnapshotter>(),
00707     nullptr,
00708     nullptr,
00709     cert,
00710 
00711     std::make_shared<aft::State>(node_id1),
00712     nullptr,
00713     nullptr,
00714     nullptr,
00715     request_timeout,
00716     ms(100),
00717     ms(1000));
00718 
00719   aft::Configuration::Nodes config0;
00720   config0[node_id0] = {};
00721   config0[node_id1] = {};
00722   r0.add_configuration(0, config0);
00723   r1.add_configuration(0, config0);
00724 
00725   map<aft::NodeId, TRaft*> nodes;
00726   nodes[node_id0] = &r0;
00727   nodes[node_id1] = &r1;
00728 
00729   r0.periodic(std::chrono::milliseconds(200));
00730 
00731   DOCTEST_INFO("Initial election");
00732   {
00733     DOCTEST_REQUIRE(
00734       1 ==
00735       dispatch_all(
00736         nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote));
00737     DOCTEST_REQUIRE(
00738       1 ==
00739       dispatch_all(
00740         nodes,
00741         ((aft::ChannelStubProxy*)r1.channels.get())
00742           ->sent_request_vote_response));
00743 
00744     DOCTEST_REQUIRE(r0.is_primary());
00745     DOCTEST_REQUIRE(
00746       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00747       1);
00748     DOCTEST_REQUIRE(
00749       1 ==
00750       dispatch_all(
00751         nodes,
00752         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00753     DOCTEST_REQUIRE(
00754       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00755       0);
00756   }
00757 
00758   aft::AppendEntries ae_idx_2; // To save for later use
00759 
00760   DOCTEST_INFO("Replicate two entries");
00761   {
00762     std::vector<uint8_t> first_entry = {1, 1, 1};
00763     auto data_1 = std::make_shared<std::vector<uint8_t>>(first_entry);
00764     std::vector<uint8_t> second_entry = {2, 2, 2};
00765     auto data_2 = std::make_shared<std::vector<uint8_t>>(second_entry);
00766 
00767     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{1, data_1, true}}, 1));
00768     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{2, data_2, true}}, 1));
00769     DOCTEST_REQUIRE(r0.ledger->ledger.size() == 2);
00770     r0.periodic(ms(10));
00771     DOCTEST_REQUIRE(
00772       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00773       1);
00774 
00775     // Receive append entries (idx: 2, prev_idx: 0)
00776     ae_idx_2 = ((aft::ChannelStubProxy*)r0.channels.get())
00777                  ->sent_append_entries.front()
00778                  .second;
00779     r1.recv_message(reinterpret_cast<uint8_t*>(&ae_idx_2), sizeof(ae_idx_2));
00780     DOCTEST_REQUIRE(r1.ledger->ledger.size() == 2);
00781   }
00782 
00783   DOCTEST_INFO("Receiving same append entries has no effect");
00784   {
00785     DOCTEST_REQUIRE(
00786       1 ==
00787       dispatch_all(
00788         nodes,
00789         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00790     DOCTEST_REQUIRE(r1.ledger->ledger.size() == 2);
00791   }
00792 
00793   DOCTEST_INFO("Replicate one more entry but send AE all entries");
00794   {
00795     std::vector<uint8_t> third_entry = {3, 3, 3};
00796     auto data = std::make_shared<std::vector<uint8_t>>(third_entry);
00797     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{3, data, true}}, 1));
00798     DOCTEST_REQUIRE(r0.ledger->ledger.size() == 3);
00799 
00800     // Simulate that the append entries was not deserialised successfully
00801     // This ensures that r0 re-sends an AE with prev_idx = 0 next time
00802     auto aer = ((aft::ChannelStubProxy*)r1.channels.get())
00803                  ->sent_append_entries_response.front()
00804                  .second;
00805     ((aft::ChannelStubProxy*)r1.channels.get())
00806       ->sent_append_entries_response.pop_front();
00807     aer.success = aft::AppendEntriesResponseType::FAIL;
00808     r0.recv_message(reinterpret_cast<uint8_t*>(&aer), sizeof(aer));
00809     DOCTEST_REQUIRE(
00810       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00811       1);
00812 
00813     // Only the third entry is deserialised
00814     r1.ledger->reset_skip_count();
00815     DOCTEST_REQUIRE(
00816       1 ==
00817       dispatch_all(
00818         nodes,
00819         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00820     DOCTEST_REQUIRE(r0.ledger->ledger.size() == 3);
00821     DOCTEST_REQUIRE(r1.ledger->skip_count == 2);
00822     r1.ledger->reset_skip_count();
00823   }
00824 
00825   DOCTEST_INFO("Receiving stale append entries has no effect");
00826   {
00827     r1.recv_message(reinterpret_cast<uint8_t*>(&ae_idx_2), sizeof(ae_idx_2));
00828     DOCTEST_REQUIRE(r1.ledger->ledger.size() == 3);
00829   }
00830 
00831   DOCTEST_INFO("Replicate one more entry (normal behaviour)");
00832   {
00833     std::vector<uint8_t> fourth_entry = {4, 4, 4};
00834     auto data = std::make_shared<std::vector<uint8_t>>(fourth_entry);
00835     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{4, data, true}}, 1));
00836     DOCTEST_REQUIRE(r0.ledger->ledger.size() == 4);
00837     r0.periodic(ms(10));
00838     DOCTEST_REQUIRE(
00839       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00840       1);
00841     DOCTEST_REQUIRE(
00842       1 ==
00843       dispatch_all(
00844         nodes,
00845         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00846     DOCTEST_REQUIRE(r1.ledger->ledger.size() == 4);
00847   }
00848 
00849   DOCTEST_INFO(
00850     "Replicate one more entry without AE response from previous entry");
00851   {
00852     std::vector<uint8_t> fifth_entry = {5, 5, 5};
00853     auto data = std::make_shared<std::vector<uint8_t>>(fifth_entry);
00854     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{5, data, true}}, 1));
00855     DOCTEST_REQUIRE(r0.ledger->ledger.size() == 5);
00856     r0.periodic(ms(10));
00857     DOCTEST_REQUIRE(
00858       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00859       1);
00860     ((aft::ChannelStubProxy*)r0.channels.get())
00861       ->sent_append_entries.pop_front();
00862 
00863     // Simulate that the append entries was not deserialised successfully
00864     // This ensures that r0 re-sends an AE with prev_idx = 3 next time
00865     auto aer = ((aft::ChannelStubProxy*)r1.channels.get())
00866                  ->sent_append_entries_response.front()
00867                  .second;
00868     ((aft::ChannelStubProxy*)r1.channels.get())
00869       ->sent_append_entries_response.pop_front();
00870     aer.success = aft::AppendEntriesResponseType::FAIL;
00871     r0.recv_message(reinterpret_cast<uint8_t*>(&aer), sizeof(aer));
00872     DOCTEST_REQUIRE(
00873       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() ==
00874       1);
00875 
00876     // Receive append entries (idx: 5, prev_idx: 3)
00877     r1.ledger->reset_skip_count();
00878     DOCTEST_REQUIRE(
00879       1 ==
00880       dispatch_all(
00881         nodes,
00882         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00883     DOCTEST_REQUIRE(r1.ledger->ledger.size() == 5);
00884     DOCTEST_REQUIRE(r1.ledger->skip_count == 2);
00885   }
00886 }
00887 
00888 DOCTEST_TEST_CASE("Exceed append entries limit")
00889 {
00890   logger::config::level() = logger::INFO;
00891 
00892   auto kv_store0 = std::make_shared<Store>(0);
00893   auto kv_store1 = std::make_shared<Store>(1);
00894   auto kv_store2 = std::make_shared<Store>(2);
00895 
00896   aft::NodeId node_id0(0);
00897   aft::NodeId node_id1(1);
00898   aft::NodeId node_id2(2);
00899 
00900   ms request_timeout(10);
00901 
00902   TRaft r0(
00903     ConsensusType::CFT,
00904     std::make_unique<Adaptor>(kv_store0),
00905     std::make_unique<aft::LedgerStubProxy>(node_id0),
00906     std::make_shared<aft::ChannelStubProxy>(),
00907     std::make_shared<aft::StubSnapshotter>(),
00908     nullptr,
00909     nullptr,
00910     cert,
00911 
00912     std::make_shared<aft::State>(node_id0),
00913     nullptr,
00914     nullptr,
00915     nullptr,
00916     request_timeout,
00917     ms(20),
00918     ms(1000));
00919   TRaft r1(
00920     ConsensusType::CFT,
00921     std::make_unique<Adaptor>(kv_store1),
00922     std::make_unique<aft::LedgerStubProxy>(node_id1),
00923     std::make_shared<aft::ChannelStubProxy>(),
00924     std::make_shared<aft::StubSnapshotter>(),
00925     nullptr,
00926     nullptr,
00927     cert,
00928 
00929     std::make_shared<aft::State>(node_id1),
00930     nullptr,
00931     nullptr,
00932     nullptr,
00933     request_timeout,
00934     ms(100),
00935     ms(1000));
00936   TRaft r2(
00937     ConsensusType::CFT,
00938     std::make_unique<Adaptor>(kv_store2),
00939     std::make_unique<aft::LedgerStubProxy>(node_id2),
00940     std::make_shared<aft::ChannelStubProxy>(),
00941     std::make_shared<aft::StubSnapshotter>(),
00942     nullptr,
00943     nullptr,
00944     cert,
00945 
00946     std::make_shared<aft::State>(node_id2),
00947     nullptr,
00948     nullptr,
00949     nullptr,
00950     request_timeout,
00951     ms(50),
00952     ms(1000));
00953 
00954   aft::Configuration::Nodes config0;
00955   config0[node_id0] = {};
00956   config0[node_id1] = {};
00957   r0.add_configuration(0, config0);
00958   r1.add_configuration(0, config0);
00959 
00960   map<aft::NodeId, TRaft*> nodes;
00961   nodes[node_id0] = &r0;
00962   nodes[node_id1] = &r1;
00963 
00964   r0.periodic(std::chrono::milliseconds(200));
00965 
00966   DOCTEST_REQUIRE(
00967     1 ==
00968     dispatch_all(
00969       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_request_vote));
00970   DOCTEST_REQUIRE(
00971     1 ==
00972     dispatch_all(
00973       nodes,
00974       ((aft::ChannelStubProxy*)r1.channels.get())->sent_request_vote_response));
00975   DOCTEST_REQUIRE(
00976     1 ==
00977     dispatch_all(
00978       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries));
00979 
00980   DOCTEST_REQUIRE(
00981     1 ==
00982     dispatch_all_and_DOCTEST_CHECK(
00983       nodes,
00984       ((aft::ChannelStubProxy*)r1.channels.get())->sent_append_entries_response,
00985       [](const auto& msg) {
00986         DOCTEST_REQUIRE(msg.last_log_idx == 0);
00987         DOCTEST_REQUIRE(msg.success == aft::AppendEntriesResponseType::OK);
00988       }));
00989 
00990   DOCTEST_REQUIRE(
00991     ((aft::ChannelStubProxy*)r0.channels.get())->sent_msg_count() == 0);
00992   DOCTEST_REQUIRE(
00993     ((aft::ChannelStubProxy*)r1.channels.get())->sent_msg_count() == 0);
00994 
00995   // large entries of size (append_entries_size_limit / 2), so 2nd and 4th entry
00996   // will exceed append entries limit size which means that 2nd and 4th entries
00997   // will trigger send_append_entries()
00998   auto data =
00999     std::make_shared<::vector<uint8_t>>((r0.append_entries_size_limit / 2), 1);
01000   // I want to get ~500 messages sent over 1mill entries
01001   auto individual_entries = 1000000;
01002   auto num_small_entries_sent = 500;
01003   auto num_big_entries = 4;
01004 
01005   // send_append_entries() triggered or not
01006   bool msg_response = false;
01007 
01008   for (size_t i = 1; i <= num_big_entries; ++i)
01009   {
01010     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{i, data, true}}, 1));
01011     DOCTEST_REQUIRE(
01012       msg_response ==
01013       dispatch_all_and_DOCTEST_CHECK(
01014         nodes,
01015         ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries,
01016         [&i](const auto& msg) {
01017           DOCTEST_REQUIRE(msg.idx == i);
01018           DOCTEST_REQUIRE(msg.term == 1);
01019           DOCTEST_REQUIRE(msg.prev_idx == ((i <= 2) ? 0 : 2));
01020         }));
01021     msg_response = !msg_response;
01022   }
01023 
01024   int data_size = (num_small_entries_sent * r0.append_entries_size_limit) /
01025     (individual_entries - num_big_entries);
01026   auto smaller_data = std::make_shared<std::vector<uint8_t>>(data_size, 1);
01027 
01028   for (size_t i = num_big_entries + 1; i <= individual_entries; ++i)
01029   {
01030     DOCTEST_REQUIRE(r0.replicate(kv::BatchVector{{i, smaller_data, true}}, 1));
01031     dispatch_all(
01032       nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries);
01033   }
01034 
01035   DOCTEST_INFO("Node 2 joins the ensemble");
01036 
01037   aft::Configuration::Nodes config1;
01038   config1[node_id0] = {};
01039   config1[node_id1] = {};
01040   config1[node_id2] = {};
01041   r0.add_configuration(0, config1);
01042   r1.add_configuration(0, config1);
01043   r2.add_configuration(0, config1);
01044 
01045   nodes[node_id2] = &r2;
01046 
01047   DOCTEST_INFO("Node 0 sends Node 2 what it's missed by joining late");
01048   DOCTEST_REQUIRE(
01049     ((aft::ChannelStubProxy*)r2.channels.get())->sent_msg_count() == 0);
01050 
01051   DOCTEST_REQUIRE(
01052     1 ==
01053     dispatch_all_and_DOCTEST_CHECK(
01054       nodes,
01055       ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries,
01056       [&individual_entries](const auto& msg) {
01057         DOCTEST_REQUIRE(msg.idx == individual_entries);
01058         DOCTEST_REQUIRE(msg.term == 1);
01059         DOCTEST_REQUIRE(msg.prev_idx == individual_entries);
01060       }));
01061 
01062   DOCTEST_REQUIRE(r2.ledger->ledger.size() == 0);
01063   DOCTEST_REQUIRE(r0.ledger->ledger.size() == individual_entries);
01064 
01065   DOCTEST_INFO("Node 2 asks for Node 0 to send all the data up to now");
01066   DOCTEST_REQUIRE(
01067     ((aft::ChannelStubProxy*)r2.channels.get())
01068       ->sent_append_entries_response.size() == 1);
01069   auto aer = ((aft::ChannelStubProxy*)r2.channels.get())
01070                ->sent_append_entries_response.front()
01071                .second;
01072   ((aft::ChannelStubProxy*)r2.channels.get())
01073     ->sent_append_entries_response.pop_front();
01074   r0.recv_message(reinterpret_cast<uint8_t*>(&aer), sizeof(aer));
01075 
01076   DOCTEST_REQUIRE(
01077     (((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() >
01078        num_small_entries_sent &&
01079      ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries.size() <=
01080        num_small_entries_sent + num_big_entries));
01081   auto sent_entries = dispatch_all(
01082     nodes, ((aft::ChannelStubProxy*)r0.channels.get())->sent_append_entries);
01083   DOCTEST_REQUIRE(
01084     (sent_entries > num_small_entries_sent &&
01085      sent_entries <= num_small_entries_sent + num_big_entries));
01086   DOCTEST_REQUIRE(r2.ledger->ledger.size() == individual_entries);
01087 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES 
---------
Parsing file /data/git/CCF/src/consensus/aft/test/main.cpp...
Preprocessing /data/git/CCF/src/consensus/aft/test/view_history.cpp...
#include consensus/aft/raft.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 6428 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 using namespace aft;
00009 
00010 
00011 {
00012   ViewHistory history;
00013 
00014   {
00015     INFO("Initial history is completely unknown");
00016     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00017     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00018     CHECK(history.view_at(2) == ViewHistory::InvalidView);
00019     CHECK(history.view_at(3) == ViewHistory::InvalidView);
00020     CHECK(history.view_at(4) == ViewHistory::InvalidView);
00021   }
00022 
00023   {
00024     INFO("Advancing index gives view for current and future indices");
00025     history.update(1, 1);
00026     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00027     CHECK(history.view_at(1) == 1);
00028     CHECK(history.view_at(2) == 1);
00029     CHECK(history.view_at(3) == 1);
00030     CHECK(history.view_at(4) == 1);
00031 
00032     history.update(2, 1);
00033     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00034     CHECK(history.view_at(1) == 1);
00035     CHECK(history.view_at(2) == 1);
00036     CHECK(history.view_at(3) == 1);
00037     CHECK(history.view_at(4) == 1);
00038   }
00039 
00040   {
00041     INFO("Advancing view increases view of affected indices");
00042     history.update(3, 2);
00043     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00044     CHECK(history.view_at(1) == 1);
00045     CHECK(history.view_at(2) == 1);
00046     CHECK(history.view_at(3) == 2);
00047     CHECK(history.view_at(4) == 2);
00048 
00049     history.update(4, 3);
00050     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00051     CHECK(history.view_at(1) == 1);
00052     CHECK(history.view_at(2) == 1);
00053     CHECK(history.view_at(3) == 2);
00054     CHECK(history.view_at(4) == 3);
00055   }
00056 }
00057 
00058 
00059 {
00060   {
00061     INFO("Index skips leave unknown indices");
00062     ViewHistory history;
00063     history.update(3, 1);
00064     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00065     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00066     CHECK(history.view_at(2) == ViewHistory::InvalidView);
00067     CHECK(history.view_at(3) == 1);
00068     CHECK(history.view_at(4) == 1);
00069   }
00070 
00071   {
00072     INFO("View skips advance to given view");
00073     ViewHistory history;
00074     history.update(3, 2);
00075     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00076     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00077     CHECK(history.view_at(2) == ViewHistory::InvalidView);
00078     CHECK(history.view_at(3) == 2);
00079     CHECK(history.view_at(4) == 2);
00080   }
00081 
00082   {
00083     INFO(
00084       "Subsequent calls on same view must not move backward from view start");
00085     ViewHistory history;
00086     history.update(2, 2);
00087     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00088     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00089     CHECK(history.view_at(2) == 2);
00090     CHECK(history.view_at(3) == 2);
00091     CHECK(history.view_at(4) == 2);
00092 
00093     CHECK_NOTHROW(history.update(2, 2));
00094     CHECK_NOTHROW(history.update(3, 2));
00095     CHECK_NOTHROW(history.update(2, 2));
00096     CHECK_NOTHROW(history.update(4, 2));
00097     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00098     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00099     CHECK(history.view_at(2) == 2);
00100     CHECK(history.view_at(3) == 2);
00101     CHECK(history.view_at(4) == 2);
00102 
00103     CHECK_THROWS(history.update(1, 2));
00104   }
00105 
00106   {
00107     INFO("Highest matching view is returned");
00108     ViewHistory history;
00109     history.update(2, 2);
00110     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00111     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00112     CHECK(history.view_at(2) == 2);
00113     CHECK(history.view_at(3) == 2);
00114     CHECK(history.view_at(4) == 2);
00115 
00116     history.update(2, 4);
00117     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00118     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00119     CHECK(history.view_at(2) == 4);
00120     CHECK(history.view_at(3) == 4);
00121     CHECK(history.view_at(4) == 4);
00122 
00123     history.update(2, 3);
00124     CHECK(history.view_at(0) == ViewHistory::InvalidView);
00125     CHECK(history.view_at(1) == ViewHistory::InvalidView);
00126     CHECK(history.view_at(2) == 4);
00127     CHECK(history.view_at(3) == 4);
00128     CHECK(history.view_at(4) == 4);
00129   }
00130 }
00131 
00132 
00133 {
00134   {
00135     INFO("Initialise validates the given view history");
00136     ViewHistory history;
00137     CHECK_NOTHROW(history.initialise({}));
00138     CHECK_NOTHROW(history.initialise({1}));
00139     CHECK_NOTHROW(history.initialise({2}));
00140     CHECK_NOTHROW(history.initialise({1, 2}));
00141     CHECK_NOTHROW(history.initialise({2, 2}));
00142     CHECK_NOTHROW(history.initialise({2, 4, 4, 10}));
00143     CHECK_THROWS(history.initialise({2, 1}));
00144     CHECK_THROWS(history.initialise({1, 2, 1}));
00145     CHECK_THROWS(history.initialise({2, 4, 4, 10, 9}));
00146   }
00147 
00148   {
00149     INFO("Initialise overwrites view history");
00150     ViewHistory history;
00151     history.update(5, 1);
00152     history.update(10, 2);
00153     history.update(20, 3);
00154     CHECK(history.view_at(4) == ViewHistory::InvalidView);
00155     CHECK(history.view_at(8) == 1);
00156     CHECK(history.view_at(19) == 2);
00157     CHECK(history.view_at(20) == 3);
00158 
00159     history.initialise({6});
00160     CHECK(history.view_at(4) == ViewHistory::InvalidView);
00161     CHECK(history.view_at(8) == 1);
00162     CHECK(history.view_at(19) == 1);
00163     CHECK(history.view_at(20) == 1);
00164 
00165     history.initialise({3, 3, 3, 5, 6, 12});
00166     CHECK(history.view_at(4) == 3);
00167     CHECK(history.view_at(8) == 5);
00168     CHECK(history.view_at(19) == 6);
00169     CHECK(history.view_at(20) == 6);
00170   }
00171 }
00172 
00173 TEST_CASE(
00174   "Retrieving view history up to a specific version" *
00175   doctest::test_suite("viewhistory"))
00176 {
00177   ViewHistory history;
00178 
00179   {
00180     INFO("Populate view history");
00181     history.update(1, 1);
00182     history.update(2, 2);
00183     history.update(5, 3);
00184     history.update(5, 4);
00185     history.update(10, 5);
00186   }
00187 
00188   {
00189     INFO("Test that view history is correct");
00190 
00191     REQUIRE(history.get_history_until(kv::NoVersion).size() == 0);
00192     REQUIRE(history.get_history_until(1) == std::vector<kv::Version>({1}));
00193     REQUIRE(history.get_history_until(2) == std::vector<kv::Version>({1, 2}));
00194     REQUIRE(history.get_history_until(3) == std::vector<kv::Version>({1, 2}));
00195     REQUIRE(history.get_history_until(4) == std::vector<kv::Version>({1, 2}));
00196     REQUIRE(
00197       history.get_history_until(5) == std::vector<kv::Version>({1, 2, 5, 5}));
00198     REQUIRE(
00199       history.get_history_until(9) == std::vector<kv::Version>({1, 2, 5, 5}));
00200     REQUIRE(
00201       history.get_history_until(10) ==
00202       std::vector<kv::Version>({1, 2, 5, 5, 10}));
00203     REQUIRE(
00204       history.get_history_until(11) ==
00205       std::vector<kv::Version>({1, 2, 5, 5, 10}));
00206     REQUIRE(
00207       history.get_history_until() ==
00208       std::vector<kv::Version>({1, 2, 5, 5, 10}));
00209   }
00210 }
00211 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/aft/test/view_history.cpp...
Preprocessing /data/git/CCF/src/consensus/consensus_types.h...
#include node/entities.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include stdint.h: not found! skipping...
Preprocessor output (size: 751 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace consensus
00011 {
00012   struct Config
00013   {
00014     size_t raft_request_timeout;
00015     size_t raft_election_timeout;
00016     size_t bft_view_change_timeout;
00017     size_t bft_status_interval;
00018     MSGPACK_DEFINE(
00019       raft_request_timeout,
00020       raft_election_timeout,
00021       bft_view_change_timeout,
00022       bft_status_interval);
00023   };
00024 
00025 
00026   template <typename T>
00027   struct ConsensusHeader
00028   {
00029     ConsensusHeader() = default;
00030     ConsensusHeader(T msg_, ccf::NodeId from_node_) :
00031       msg(msg_),
00032       from_node(from_node_)
00033     {}
00034 
00035     T msg;
00036     ccf::NodeId from_node;
00037   };
00038 
00039   struct AppendEntriesIndex
00040   {
00041     ccf::Index idx;
00042     ccf::Index prev_idx;
00043   };
00044 
00045 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/consensus_types.h...
Preprocessing /data/git/CCF/src/consensus/ledger_enclave.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
Preprocessor output (size: 3394 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace consensus
00010 {
00011   class LedgerEnclave
00012   {
00013   public:
00014     static constexpr size_t FRAME_SIZE = sizeof(uint32_t);
00015 
00016   private:
00017     ringbuffer::WriterPtr to_host;
00018 
00019   public:
00020     LedgerEnclave(ringbuffer::AbstractWriterFactory& writer_factory_) :
00021       to_host(writer_factory_.create_writer_to_outside())
00022     {}
00023 
00024     /**
00025      * Put a single entry to be written the ledger, when primary.
00026      *
00027      * @param entry Serialised entry
00028      * @param globally_committable True is entry is signature transaction
00029      * @param force_chunk Force new ledger chunk to be created after this entry
00030      * (only if globally_committable)
00031      */
00032     void put_entry(
00033       const std::vector<uint8_t>& entry,
00034       bool globally_committable,
00035       bool force_chunk = false)
00036     {
00037       put_entry(entry.data(), entry.size(), globally_committable, force_chunk);
00038     }
00039 
00040     /**
00041      * Put a single entry to be written the ledger, when primary.
00042      *
00043      * @param data Serialised entry start
00044      * @param size Serialised entry size
00045      * @param globally_committable True is entry is signature transaction
00046      * @param force_chunk Force new ledger chunk to be created after this entry
00047      * (only if globally_committable)
00048      */
00049     void put_entry(
00050       const uint8_t* data,
00051       size_t size,
00052       bool globally_committable,
00053       bool force_chunk = false)
00054     {
00055       CCF_ASSERT_FMT(
00056         globally_committable || !force_chunk,
00057         "Only globally committable entries can force new ledger chunk");
00058 
00059       serializer::ByteRange byte_range = {data, size};
00060       RINGBUFFER_WRITE_MESSAGE(
00061         consensus::ledger_append,
00062         to_host,
00063         globally_committable,
00064         force_chunk,
00065         byte_range);
00066     }
00067 
00068     /**
00069      * Skip a single entry, when backup.
00070      *
00071      * Does not write any entry to the legder.
00072      *
00073      * @param data Serialised entries
00074      * @param size Size of overall serialised entries
00075      */
00076     void skip_entry(const uint8_t*& data, size_t& size)
00077     {
00078       auto entry_len = serialized::read<uint32_t>(data, size);
00079       serialized::skip(data, size, entry_len);
00080     }
00081 
00082     /**
00083      * Retrieve a single entry, advancing offset to the next entry.
00084      *
00085      * @param data Serialised entries
00086      * @param size Size of overall serialised entries
00087      *
00088      * @return Raw entry as a vector
00089      */
00090     std::vector<uint8_t> get_entry(const uint8_t*& data, size_t& size)
00091     {
00092       auto entry_len = serialized::read<uint32_t>(data, size);
00093       std::vector<uint8_t> entry(data, data + entry_len);
00094       serialized::skip(data, size, entry_len);
00095       return entry;
00096     }
00097 
00098     /**
00099      * Truncate the ledger at a given index.
00100      *
00101      * @param idx Index to truncate from
00102      */
00103     void truncate(Index idx)
00104     {
00105       RINGBUFFER_WRITE_MESSAGE(consensus::ledger_truncate, to_host, idx);
00106     }
00107 
00108     /**
00109      * Commit the ledger at a given index.
00110      *
00111      * @param idx Index to commit at
00112      */
00113     void commit(Index idx)
00114     {
00115       RINGBUFFER_WRITE_MESSAGE(consensus::ledger_commit, to_host, idx);
00116     }
00117 
00118     /**
00119      * Initialise ledger at a given index (e.g. after a snapshot)
00120      *
00121      * @param idx Index to start ledger from
00122      */
00123     void init(Index idx)
00124     {
00125       RINGBUFFER_WRITE_MESSAGE(consensus::ledger_init, to_host, idx);
00126     }
00127   };
00128 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/ledger_enclave.h...
Preprocessing /data/git/CCF/src/consensus/ledger_enclave_types.h...
#include ds/ring_buffer_types.h: not found! skipping...
Preprocessor output (size: 2030 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace consensus
00008 {
00009   using Index = uint64_t;
00010 
00011   enum LedgerRequestPurpose : uint8_t
00012   {
00013     Recovery,
00014     HistoricalQuery,
00015   };
00016 
00017   /// Consensus-related ringbuffer messages
00018   enum : ringbuffer::Message
00019   {
00020     /// Request individual ledger entries. Enclave -> Host
00021     DEFINE_RINGBUFFER_MSG_TYPE(ledger_get),
00022 
00023     /// Respond to ledger_get. Host -> Enclave
00024     DEFINE_RINGBUFFER_MSG_TYPE(ledger_entry),
00025     DEFINE_RINGBUFFER_MSG_TYPE(ledger_no_entry),
00026 
00027     /// Modify the local ledger. Enclave -> Host
00028     DEFINE_RINGBUFFER_MSG_TYPE(ledger_append),
00029     DEFINE_RINGBUFFER_MSG_TYPE(ledger_truncate),
00030     DEFINE_RINGBUFFER_MSG_TYPE(ledger_commit),
00031     DEFINE_RINGBUFFER_MSG_TYPE(ledger_init),
00032 
00033     /// Create and commit a snapshot. Enclave -> Host
00034     DEFINE_RINGBUFFER_MSG_TYPE(snapshot),
00035     DEFINE_RINGBUFFER_MSG_TYPE(snapshot_commit),
00036   };
00037 }
00038 
00039 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00040   consensus::ledger_get, consensus::Index, consensus::LedgerRequestPurpose);
00041 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00042   consensus::ledger_entry,
00043   consensus::Index,
00044   consensus::LedgerRequestPurpose,
00045   std::vector<uint8_t>);
00046 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00047   consensus::ledger_no_entry,
00048   consensus::Index,
00049   consensus::LedgerRequestPurpose);
00050 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(consensus::ledger_init, consensus::Index);
00051 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00052   consensus::ledger_append,
00053   bool /* committable */,
00054   bool /* force chunk */,
00055   std::vector<uint8_t>);
00056 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00057   consensus::ledger_truncate, consensus::Index);
00058 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(consensus::ledger_commit, consensus::Index);
00059 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00060   consensus::snapshot,
00061   consensus::Index /* snapshot idx */,
00062   consensus::Index /* evidence idx */,
00063   std::vector<uint8_t>);
00064 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00065   consensus::snapshot_commit,
00066   consensus::Index /* snapshot idx */,
00067   consensus::Index /* evidence commit idx */);
00068 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/consensus/ledger_enclave_types.h...
Preprocessing /data/git/CCF/src/crypto/hash.cpp...
#include ds/buffer.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include ostream: not found! skipping...
#include ../tls/mbedtls_wrappers.h: already included! skipping...
#include mbedtls/sha256.h: not found! skipping...
#include stdexcept: not found! skipping...
Preprocessor output (size: 1647 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/crypto/hash.cpp" 2
00004 
00005 
00006 
00007 
00008 
00009 
00010 using namespace std;
00011 
00012 namespace crypto
00013 {
00014   void Sha256Hash::mbedtls_sha256(const CBuffer& data, uint8_t* h)
00015   {
00016     mbedtls_sha256_context ctx;
00017     mbedtls_sha256_init(&ctx);
00018     mbedtls_sha256_starts_ret(&ctx, 0);
00019 
00020     mbedtls_sha256_update_ret(&ctx, data.p, data.rawSize());
00021 
00022     mbedtls_sha256_finish_ret(&ctx, h);
00023     mbedtls_sha256_free(&ctx);
00024   }
00025 
00026   class MBSha256HashImpl
00027   {
00028   public:
00029     MBSha256HashImpl()
00030     {
00031       ctx = std::move(mbedtls::make_unique<mbedtls::SHA256Ctx>());
00032       mbedtls_sha256_starts_ret(ctx.get(), 0);
00033     }
00034 
00035     void finalize(std::array<uint8_t, Sha256Hash::SIZE>& h)
00036     {
00037       mbedtls_sha256_finish_ret(ctx.get(), h.data());
00038     }
00039 
00040     void update(const CBuffer& data)
00041     {
00042       mbedtls_sha256_update_ret(ctx.get(), data.p, data.rawSize());
00043     }
00044 
00045   private:
00046     mbedtls::SHA256Ctx ctx;
00047   };
00048 
00049   Sha256Hash::Sha256Hash() : h{0} {}
00050   Sha256Hash::Sha256Hash(const CBuffer& data) : h{0}
00051   {
00052     mbedtls_sha256(data, h.data());
00053   }
00054 
00055   CSha256Hash::CSha256Hash() : p(std::make_unique<MBSha256HashImpl>()) {}
00056   CSha256Hash::~CSha256Hash() {}
00057 
00058   void CSha256Hash::update_hash(CBuffer data)
00059   {
00060     if (p == nullptr)
00061     {
00062       throw std::logic_error("Attempting to use hash after it was finalized");
00063     }
00064     p->update(data);
00065   }
00066 
00067   Sha256Hash CSha256Hash::finalize()
00068   {
00069     if (p == nullptr)
00070     {
00071       throw std::logic_error("Attempting to use hash after it was finalized");
00072     }
00073 
00074     Sha256Hash h;
00075     p->finalize(h.h);
00076     p = nullptr;
00077     return h;
00078   }
00079 }
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/crypto/hash.cpp...
Preprocessing /data/git/CCF/src/crypto/hash.h...
#include ds/buffer.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include ostream: not found! skipping...
Preprocessor output (size: 2082 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 #define FMT_HEADER_ONLY
00008 
00009 
00010 
00011 
00012 namespace crypto
00013 {
00014   class Sha256Hash
00015   {
00016   public:
00017     static constexpr size_t SIZE = 256 / 8;
00018     Sha256Hash();
00019     Sha256Hash(const CBuffer& data);
00020 
00021     std::array<uint8_t, SIZE> h;
00022 
00023     static void mbedtls_sha256(const CBuffer& data, uint8_t* h);
00024 
00025     friend std::ostream& operator<<(
00026       std::ostream& os, const crypto::Sha256Hash& h)
00027     {
00028       for (unsigned i = 0; i < crypto::Sha256Hash::SIZE; i++)
00029       {
00030         os << std::hex << static_cast<int>(h.h[i]);
00031       }
00032 
00033       return os;
00034     }
00035 
00036     std::string hex_str() const
00037     {
00038       return fmt::format("{:02x}", fmt::join(h, ""));
00039     };
00040 
00041     MSGPACK_DEFINE(h);
00042   };
00043 
00044   DECLARE_JSON_TYPE(Sha256Hash);
00045   DECLARE_JSON_REQUIRED_FIELDS(Sha256Hash, h);
00046 
00047   inline bool operator==(const Sha256Hash& lhs, const Sha256Hash& rhs)
00048   {
00049     for (unsigned i = 0; i < crypto::Sha256Hash::SIZE; i++)
00050     {
00051       if (lhs.h[i] != rhs.h[i])
00052       {
00053         return false;
00054       }
00055     }
00056     return true;
00057   }
00058 
00059   inline bool operator!=(const Sha256Hash& lhs, const Sha256Hash& rhs)
00060   {
00061     return !(lhs == rhs);
00062   }
00063 
00064   class MBSha256HashImpl;
00065   class CSha256Hash
00066   {
00067   public:
00068     CSha256Hash();
00069     ~CSha256Hash();
00070 
00071     void update_hash(CBuffer data);
00072 
00073     template <typename T>
00074     void update(const T& t)
00075     {
00076       update_hash({reinterpret_cast<const uint8_t*>(&t), sizeof(T)});
00077     }
00078 
00079     template <>
00080     void update<std::vector<uint8_t>>(const std::vector<uint8_t>& d)
00081     {
00082       update_hash({d.data(), d.size()});
00083     }
00084 
00085     Sha256Hash finalize();
00086 
00087   private:
00088     std::unique_ptr<MBSha256HashImpl> p;
00089   };
00090 }
00091 
00092 namespace fmt
00093 {
00094   template <>
00095   struct formatter<crypto::Sha256Hash>
00096   {
00097     template <typename ParseContext>
00098     constexpr auto parse(ParseContext& ctx)
00099     {
00100       return ctx.begin();
00101     }
00102 
00103     template <typename FormatContext>
00104     auto format(const crypto::Sha256Hash& p, FormatContext& ctx)
00105     {
00106       return format_to(ctx.out(), "<sha256 {:02x}>", fmt::join(p.h, ""));
00107     }
00108   };
00109 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/crypto/hash.h...
Reading /data/git/CCF/src/crypto/README.md...
Preprocessing /data/git/CCF/src/crypto/symmetric_key.cpp...
#include ds/buffer.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include tls/mbedtls_wrappers.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include tls/error_string.h: not found! skipping...
#include mbedtls/aes.h: not found! skipping...
#include mbedtls/error.h: not found! skipping...
Preprocessor output (size: 1918 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/crypto/symmetric_key.cpp" 2
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace crypto
00013 {
00014   KeyAesGcm::KeyAesGcm(CBuffer rawKey)
00015   {
00016     for (uint32_t i = 0; i < ctxs.size(); ++i)
00017     {
00018       ctxs[i] = mbedtls::make_unique<mbedtls::GcmContext>();
00019 
00020       size_t n_bits;
00021       const auto n = static_cast<unsigned int>(rawKey.rawSize() * 8);
00022       if (n >= 256)
00023       {
00024         n_bits = 256;
00025       }
00026       else if (n >= 192)
00027       {
00028         n_bits = 192;
00029       }
00030       else if (n >= 128)
00031       {
00032         n_bits = 128;
00033       }
00034       else
00035       {
00036         throw std::logic_error(
00037           fmt::format("Need at least {} bits, only have {}", 128, n));
00038       }
00039 
00040       int rc = mbedtls_gcm_setkey(
00041         ctxs[i].get(), MBEDTLS_CIPHER_ID_AES, rawKey.p, n_bits);
00042 
00043       if (rc != 0)
00044       {
00045         throw std::logic_error(tls::error_string(rc));
00046       }
00047     }
00048   }
00049 
00050   KeyAesGcm::KeyAesGcm(KeyAesGcm&& that)
00051   {
00052     ctxs = std::move(that.ctxs);
00053   }
00054 
00055   void KeyAesGcm::encrypt(
00056     CBuffer iv,
00057     CBuffer plain,
00058     CBuffer aad,
00059     uint8_t* cipher,
00060     uint8_t tag[GCM_SIZE_TAG]) const
00061   {
00062     auto ctx = ctxs[threading::get_current_thread_id()].get();
00063     int rc = mbedtls_gcm_crypt_and_tag(
00064       ctx,
00065       MBEDTLS_GCM_ENCRYPT,
00066       plain.n,
00067       iv.p,
00068       iv.n,
00069       aad.p,
00070       aad.n,
00071       plain.p,
00072       cipher,
00073       GCM_SIZE_TAG,
00074       tag);
00075 
00076     if (rc != 0)
00077     {
00078       throw std::logic_error(tls::error_string(rc));
00079     }
00080   }
00081 
00082   bool KeyAesGcm::decrypt(
00083     CBuffer iv,
00084     const uint8_t tag[GCM_SIZE_TAG],
00085     CBuffer cipher,
00086     CBuffer aad,
00087     uint8_t* plain) const
00088   {
00089     auto ctx = ctxs[threading::get_current_thread_id()].get();
00090     return !mbedtls_gcm_auth_decrypt(
00091       ctx,
00092       cipher.n,
00093       iv.p,
00094       iv.n,
00095       aad.p,
00096       aad.n,
00097       tag,
00098       GCM_SIZE_TAG,
00099       cipher.p,
00100       plain);
00101   }
00102 }
00103 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/crypto/symmetric_key.cpp...
Preprocessing /data/git/CCF/src/crypto/symmetric_key.h...
#include ds/buffer.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include tls/mbedtls_wrappers.h: not found! skipping...
Preprocessor output (size: 3877 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace crypto
00010 {
00011   constexpr size_t GCM_SIZE_KEY = 32;
00012   constexpr size_t GCM_SIZE_TAG = 16;
00013   constexpr size_t GCM_SIZE_IV = 12;
00014 
00015   template <size_t SIZE_IV = GCM_SIZE_IV>
00016   struct GcmHeader
00017   {
00018     uint8_t tag[GCM_SIZE_TAG] = {};
00019     uint8_t iv[SIZE_IV] = {};
00020 
00021     // 12 bytes IV with 8 LSB are unique sequence number
00022     // and 4 MSB are 4 LSB of unique id (Node id or View)
00023     constexpr static uint8_t IV_DELIMITER = 8;
00024     constexpr static size_t RAW_DATA_SIZE = sizeof(tag) + sizeof(iv);
00025 
00026     GcmHeader() = default;
00027     GcmHeader(const std::vector<uint8_t>& data)
00028     {
00029       if (data.size() != RAW_DATA_SIZE)
00030       {
00031         throw std::logic_error("Incompatible IV size");
00032       }
00033 
00034       memcpy(tag, data.data(), sizeof(tag));
00035       memcpy(iv, data.data() + sizeof(tag), sizeof(iv));
00036     }
00037 
00038     void set_iv_seq(uint64_t seq)
00039     {
00040       *reinterpret_cast<uint64_t*>(iv) = seq;
00041     }
00042 
00043     void set_iv_id(uint64_t id)
00044     {
00045       if (id > 0x7FFFFFFF)
00046       {
00047         throw std::logic_error(
00048           fmt::format("id should fit in 31 bits of IV. Value is: 0x{0:x}", id));
00049       }
00050 
00051       *reinterpret_cast<uint32_t*>(iv + IV_DELIMITER) =
00052         static_cast<uint32_t>(id);
00053     }
00054 
00055     void set_iv_snapshot(bool is_snapshot)
00056     {
00057       // Set very last bit in IV
00058       iv[SIZE_IV - 1] |= (is_snapshot << ((sizeof(uint8_t) * 8) - 1));
00059     }
00060 
00061     void set_iv(uint8_t* iv_, size_t size)
00062     {
00063       if (size != SIZE_IV)
00064       {
00065         throw std::logic_error(
00066           fmt::format("Specified IV is not of size {}", SIZE_IV));
00067       }
00068 
00069       memcpy(iv, iv_, size);
00070     }
00071 
00072     CBuffer get_iv() const
00073     {
00074       return {iv, SIZE_IV};
00075     }
00076 
00077     uint64_t get_iv_int() const
00078     {
00079       return *reinterpret_cast<const uint64_t*>(iv);
00080     }
00081 
00082     std::vector<uint8_t> serialise()
00083     {
00084       auto space = RAW_DATA_SIZE;
00085       std::vector<uint8_t> serial_hdr(space);
00086 
00087       auto data_ = serial_hdr.data();
00088       serialized::write(data_, space, tag, sizeof(tag));
00089       serialized::write(data_, space, iv, sizeof(iv));
00090 
00091       return serial_hdr;
00092     }
00093 
00094     void deserialise(const std::vector<uint8_t>& serial_hdr)
00095     {
00096       auto data_ = serial_hdr.data();
00097       auto size = serial_hdr.size();
00098 
00099       memcpy(
00100         tag, serialized::read(data_, size, GCM_SIZE_TAG).data(), GCM_SIZE_TAG);
00101       memcpy(iv, serialized::read(data_, size, SIZE_IV).data(), SIZE_IV);
00102     }
00103   };
00104 
00105   struct GcmCipher
00106   {
00107     GcmHeader<> hdr;
00108     std::vector<uint8_t> cipher;
00109 
00110     GcmCipher() {}
00111     GcmCipher(size_t size) : cipher(size) {}
00112 
00113     std::vector<uint8_t> serialise()
00114     {
00115       std::vector<uint8_t> serial;
00116       auto space = GcmHeader<>::RAW_DATA_SIZE + cipher.size();
00117       serial.resize(space);
00118 
00119       auto data_ = serial.data();
00120       serialized::write(data_, space, hdr.tag, sizeof(hdr.tag));
00121       serialized::write(data_, space, hdr.iv, sizeof(hdr.iv));
00122       serialized::write(data_, space, cipher.data(), cipher.size());
00123 
00124       return serial;
00125     }
00126 
00127     void deserialise(const std::vector<uint8_t>& serial)
00128     {
00129       auto size = serial.size();
00130 
00131       auto data_ = serial.data();
00132       hdr = serialized::read(data_, size, GcmHeader<>::RAW_DATA_SIZE);
00133       cipher = serialized::read(data_, size, size);
00134     }
00135   };
00136 
00137   class KeyAesGcm
00138   {
00139   private:
00140     mutable std::
00141       array<mbedtls::GcmContext, threading::ThreadMessaging::max_num_threads>
00142         ctxs;
00143 
00144   public:
00145     KeyAesGcm(CBuffer rawKey);
00146     KeyAesGcm(const KeyAesGcm& that) = delete;
00147     KeyAesGcm(KeyAesGcm&& that);
00148 
00149     void encrypt(
00150       CBuffer iv,
00151       CBuffer plain,
00152       CBuffer aad,
00153       uint8_t* cipher,
00154       uint8_t tag[GCM_SIZE_TAG]) const;
00155 
00156     bool decrypt(
00157       CBuffer iv,
00158       const uint8_t tag[GCM_SIZE_TAG],
00159       CBuffer cipher,
00160       CBuffer aad,
00161       uint8_t* plain) const;
00162   };
00163 }
00164 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/crypto/symmetric_key.h...
Preprocessing /data/git/CCF/src/crypto/test/crypto.cpp...
#include crypto/hash.h: not found! skipping...
#include crypto/symmetric_key.h: not found! skipping...
#include tls/base64.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include mbedtls/pem.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 649 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 using namespace crypto;
00014 using namespace std;
00015 
00016 static const vector<uint8_t>& getRawKey()
00017 {
00018   static const vector<uint8_t> v(16, '$');
00019   return v;
00020 }
00021 
00022 TEST_CASE("ExtendedIv0")
00023 {
00024   KeyAesGcm k(getRawKey());
00025   // setup plain text
00026   unsigned char rawP[100];
00027   memset(rawP, 'x', sizeof(rawP));
00028   Buffer p{rawP, sizeof(rawP)};
00029   // test large IV
00030   GcmHeader<1234> h;
00031   k.encrypt(h.get_iv(), p, nullb, p.p, h.tag);
00032 
00033   KeyAesGcm k2(getRawKey());
00034   REQUIRE(k2.decrypt(h.get_iv(), h.tag, p, nullb, p.p));
00035 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/crypto/test/crypto.cpp...
Preprocessing /data/git/CCF/src/crypto/test/digest_bench.cpp...
#include crypto/hash.h: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 827 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 enum HashImpl
00010 {
00011   mbedtls
00012 };
00013 
00014 template <HashImpl IMPL>
00015 static void sha256_bench(picobench::state& s)
00016 {
00017   std::vector<uint8_t> v(s.iterations());
00018   for (size_t i = 0; i < v.size(); ++i)
00019   {
00020     v.data()[i] = rand();
00021   }
00022 
00023   crypto::Sha256Hash h;
00024 
00025   s.start_timer();
00026   for (size_t i = 0; i < 10; ++i)
00027   {
00028     if constexpr (IMPL == HashImpl::mbedtls)
00029     {
00030       crypto::Sha256Hash::mbedtls_sha256(v, h.h.data());
00031     }
00032   }
00033   s.stop_timer();
00034 }
00035 
00036 const std::vector<int> hash_sizes = {2 << 6, 2 << 8, 2 << 12, 2 << 16, 2 << 18};
00037 
00038 PICOBENCH_SUITE("SHA-256");
00039 
00040 auto mbedtls_digest_sha256 = sha256_bench<HashImpl::mbedtls>;
00041 PICOBENCH(mbedtls_digest_sha256).iterations(hash_sizes).baseline();
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/crypto/test/digest_bench.cpp...
Preprocessing /data/git/CCF/src/ds/buffer.h...
#include assert.h: not found! skipping...
#include atomic: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include type_traits: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2628 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 // The OArray (Owning Array) owns a buffer and provides a projection onto said
00013 // buffer via a pointer and a length.
00014 class OArray
00015 {
00016 public:
00017   OArray(const std::vector<uint8_t>& d_) : d(std::move(d_))
00018   {
00019     data_ = d.data();
00020     size_ = d.size();
00021 
00022     check_invariants();
00023   }
00024 
00025   OArray(const OArray& other) = delete;
00026   OArray(OArray& other) = delete;
00027   OArray& operator=(const OArray& rhs) = delete;
00028   OArray& operator=(OArray& rhs) = delete;
00029 
00030   OArray(OArray&& other)
00031   {
00032     other.check_invariants();
00033     data_ = other.data_;
00034     size_ = other.size_;
00035     d = std::move(other.d);
00036     check_invariants();
00037   }
00038   OArray& operator=(OArray&& other)
00039   {
00040     other.check_invariants();
00041     data_ = other.data_;
00042     size_ = other.size_;
00043     d = std::move(other.d);
00044     check_invariants();
00045 
00046     return *this;
00047   }
00048 
00049   const uint8_t*& data()
00050   {
00051     check_invariants();
00052     return data_;
00053   }
00054 
00055   size_t& size()
00056   {
00057     check_invariants();
00058     return size_;
00059   }
00060 
00061 private:
00062   const uint8_t* data_;
00063   size_t size_;
00064 
00065   void check_invariants()
00066   {
00067     assert((uint64_t)data_ >= (uint64_t)d.data());
00068     assert(d.size() >= size_);
00069     assert((uint64_t)data_ + size_ <= (uint64_t)d.data() + d.size());
00070   }
00071 
00072   std::vector<uint8_t> d;
00073 };
00074 
00075 template <typename T>
00076 struct Array
00077 {
00078   // pointer to the buffer
00079   T* p;
00080   // number of elements
00081   size_t n;
00082   auto rawSize() const
00083   {
00084     return n * sizeof(T);
00085   }
00086 
00087   constexpr Array() : p(nullptr), n(0) {}
00088   constexpr Array(T* p, size_t n) : p(p), n(n) {}
00089 
00090   Array(const std::string& s) :
00091     p(reinterpret_cast<decltype(p)>(s.data())),
00092     n(s.size())
00093   {}
00094 
00095   using T_NON_CONST = std::remove_const_t<T>;
00096   Array(std::vector<T_NON_CONST>& v) : p(v.data()), n(v.size()) {}
00097   Array(const std::vector<T_NON_CONST>& v) : p(v.data()), n(v.size()) {}
00098 
00099   template <typename U, typename V = void>
00100   using ENABLE_CTOR = std::enable_if_t<std::is_convertible<U*, T*>::value, V>;
00101   template <typename U, typename = ENABLE_CTOR<U>>
00102   Array(const Array<U>& b) : p(b.p), n(b.n)
00103   {}
00104 
00105   bool operator==(const Array<T>& that) const
00106   {
00107     return (that.n == n) && (that.p == p);
00108   }
00109 
00110   bool operator!=(const Array<T>& that) const
00111   {
00112     return !(*this == that);
00113   }
00114 
00115   explicit operator std::vector<T_NON_CONST>() const
00116   {
00117     return {p, p + n};
00118   }
00119 };
00120 
00121 template <typename T>
00122 using CArray = Array<const T>;
00123 using Buffer = Array<uint8_t>;
00124 using CBuffer = Array<const uint8_t>;
00125 constexpr CBuffer nullb;
00126 
00127 template <typename T>
00128 CBuffer asCb(const T& o)
00129 {
00130   return {reinterpret_cast<const uint8_t*>(&o), sizeof(T)};
00131 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/buffer.h...
Preprocessing /data/git/CCF/src/ds/ccf_assert.h...
#include ds/logger.h: not found! skipping...
      #include fmt/format.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include sstream: not found! skipping...
          #include ds/nonstd.h: not found! skipping...
                  #include cstddef: not found! skipping...
#include cstdint: not found! skipping...
#include vector: not found! skipping...
#include array: not found! skipping...
#include cstdint: not found! skipping...
#include small_vector/SmallVector.h: not found! skipping...
#include vector: not found! skipping...
        #include ds/nonstd.h: not found! skipping...
          #include cstdint: not found! skipping...
#include cstring: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include memory: not found! skipping...
#include tuple: not found! skipping...
#include type_traits: not found! skipping...
#include vector: not found! skipping...
#include atomic: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include cstring: not found! skipping...
#include functional: not found! skipping...
    #include fmt/format.h: not found! skipping...
#include fmt/ostream.h: not found! skipping...
#include limits: not found! skipping...
#include map: not found! skipping...
#include thread: not found! skipping...
#include chrono: not found! skipping...
#include cstring: not found! skipping...
#include ctime: not found! skipping...
#include fmt/chrono.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include fstream: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include memory: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include optional: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include thread: not found! skipping...
#include backward-cpp/backward.hpp: not found! skipping...
#include iostream: not found! skipping...
Preprocessor output (size: 279 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/ds/ccf_assert.h" 2
00007 
00008 #define CCF_ASSERT_FMT_FAIL(...) 
00009 
00010 
00011 #define CCF_ASSERT_FMT(expr, ...) 
00012 
00013 
00014 
00015 #define CCF_ASSERT(expr, msg) 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027  /* NDEBUG */
00028 
---------
Macros accessible in this file:
---------
LOG_DEBUG CCF_ASSERT_FMT_FAIL LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL_FMT LOG_FAIL LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE CCF_ASSERT_FMT LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE CCF_ASSERT LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/ccf_assert.h...
Preprocessing /data/git/CCF/src/ds/ccf_deprecated.h...
Preprocessor output (size: 137 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define CCF_DEPRECATED(reason) 
00006 
---------
Macros accessible in this file:
---------
CCF_DEPRECATED 
---------
Parsing file /data/git/CCF/src/ds/ccf_deprecated.h...
Preprocessing /data/git/CCF/src/ds/ccf_exception.h...
#include logger.h: already included! skipping...
#include exception: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 560 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   class ccf_logic_error : public std::exception
00019   {
00020   public:
00021     ccf_logic_error(const std::string& what_arg)
00022     {
00023       if (!what_arg.empty())
00024       {
00025         result.append(what_arg.c_str());
00026         result.append("\n");
00027       }
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038     }
00039 
00040     ccf_logic_error() : ccf_logic_error("") {}
00041 
00042     const char* what() const throw() override
00043     {
00044       return result.c_str();
00045     }
00046 
00047   private:
00048     std::string result;
00049   };
00050 };
00051 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/ccf_exception.h...
Preprocessing /data/git/CCF/src/ds/champ_map.h...
#include ds/buffer.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/champ_map_serializers.h: not found! skipping...
#include algorithm: not found! skipping...
#include array: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 15372 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 namespace champ
00016 {
00017   // A persistent hash map based on the Compressed Hash-Array Mapped Preﬁx-tree
00018   // from 'Fast and Lean Immutable Multi-Maps on the JVM based on Heterogeneous
00019   // Hash-Array Mapped Tries' by Michael J. Steindorfer and Jurgen J. Vinju
00020   // (https://arxiv.org/pdf/1608.01036.pdf).
00021 
00022   static constexpr size_t index_mask_bits = 5;
00023   static constexpr size_t index_mask = (1 << index_mask_bits) - 1;
00024 
00025   using Hash = uint32_t;
00026   static constexpr size_t hash_bits = sizeof(Hash) * 8;
00027 
00028   using SmallIndex = uint8_t;
00029   static constexpr size_t small_index_bits = sizeof(SmallIndex) * 8;
00030   static_assert(small_index_bits > index_mask_bits);
00031 
00032   static constexpr size_t collision_node_bits = hash_bits % index_mask_bits;
00033   static_assert(collision_node_bits > 0);
00034   static constexpr SmallIndex collision_depth = hash_bits / index_mask_bits;
00035   static constexpr size_t collision_bins = 1 << collision_node_bits;
00036 
00037   static constexpr SmallIndex mask(Hash hash, SmallIndex depth)
00038   {
00039     return (hash >> ((Hash)depth * index_mask_bits)) & index_mask;
00040   }
00041 
00042   class Bitmap
00043   {
00044     uint32_t _bits;
00045 
00046   public:
00047     constexpr Bitmap() : _bits(0) {}
00048 
00049     constexpr Bitmap(uint32_t bits) : _bits(bits) {}
00050 
00051     constexpr Bitmap operator&(const Bitmap& other) const
00052     {
00053       return Bitmap(_bits & other._bits);
00054     }
00055 
00056     constexpr SmallIndex pop() const
00057     {
00058       return __builtin_popcount(_bits);
00059     }
00060 
00061     constexpr Bitmap set(SmallIndex idx) const
00062     {
00063       return Bitmap(_bits | ((uint32_t)1 << idx));
00064     }
00065 
00066     constexpr Bitmap clear(SmallIndex idx) const
00067     {
00068       return Bitmap(_bits & ~((uint32_t)1 << idx));
00069     }
00070 
00071     constexpr bool check(SmallIndex idx) const
00072     {
00073       return (_bits & ((uint32_t)1 << idx)) != 0;
00074     }
00075   };
00076 
00077   template <class K, class V, class H>
00078   struct SubNodes;
00079 
00080   template <class K, class V>
00081   struct Entry
00082   {
00083     K key;
00084     V value;
00085 
00086     Entry(K k, V v) : key(k), value(v) {}
00087 
00088     const V* getp(const K& k) const
00089     {
00090       if (k == key)
00091         return &value;
00092       else
00093         return nullptr;
00094     }
00095   };
00096 
00097   uint32_t static get_padding(uint32_t size)
00098   {
00099     uint32_t padding = size % sizeof(uintptr_t);
00100     if (padding != 0)
00101     {
00102       padding = sizeof(uintptr_t) - padding;
00103     }
00104     return padding;
00105   }
00106 
00107   template <class K, class V>
00108   size_t static get_size_with_padding(const K& k, const V& v)
00109   {
00110     uint32_t size_k = champ::get_size(k);
00111     uint32_t size_v = champ::get_size(v);
00112     return size_k + get_padding(size_k) + size_v + get_padding(size_v);
00113   }
00114 
00115   template <class K, class V, class H>
00116   using Node = std::shared_ptr<void>;
00117 
00118   template <class K, class V, class H>
00119   struct Collisions
00120   {
00121     std::array<std::vector<std::shared_ptr<Entry<K, V>>>, collision_bins> bins;
00122 
00123     const V* getp(Hash hash, const K& k) const
00124     {
00125       const auto idx = mask(hash, collision_depth);
00126       const auto& bin = bins[idx];
00127       for (const auto& node : bin)
00128       {
00129         if (k == node->key)
00130           return &node->value;
00131       }
00132       return nullptr;
00133     }
00134 
00135     size_t put_mut(Hash hash, const K& k, const V& v)
00136     {
00137       const auto idx = mask(hash, collision_depth);
00138       auto& bin = bins[idx];
00139       for (size_t i = 0; i < bin.size(); ++i)
00140       {
00141         const auto& entry = bin[i];
00142         if (k == entry->key)
00143         {
00144           bin[i] = std::make_shared<Entry<K, V>>(k, v);
00145           return champ::get_size<K>(k) + champ::get_size<V>(v);
00146         }
00147       }
00148       bin.push_back(std::make_shared<Entry<K, V>>(k, v));
00149       return 0;
00150     }
00151 
00152     size_t remove_mut(Hash hash, const K& k)
00153     {
00154       const auto idx = mask(hash, collision_depth);
00155       auto& bin = bins[idx];
00156       for (size_t i = 0; i < bin.size(); ++i)
00157       {
00158         const auto& entry = bin[i];
00159         if (k == entry->key)
00160         {
00161           const auto diff =
00162             champ::get_size<K>(entry->key) + champ::get_size<V>(entry->value);
00163           bin.erase(bin.begin() + i);
00164           return diff;
00165         }
00166       }
00167       return 0;
00168     }
00169 
00170     template <class F>
00171     bool foreach(F&& f) const
00172     {
00173       for (const auto& bin : bins)
00174       {
00175         for (const auto& entry : bin)
00176           if (!f(entry->key, entry->value))
00177             return false;
00178       }
00179       return true;
00180     }
00181   };
00182 
00183   template <class K, class V, class H>
00184   struct SubNodes
00185   {
00186     std::vector<Node<K, V, H>> nodes;
00187     Bitmap node_map;
00188     Bitmap data_map;
00189 
00190     SubNodes() {}
00191 
00192     SubNodes(std::vector<Node<K, V, H>>&& ns) : nodes(std::move(ns)) {}
00193 
00194     SubNodes(std::vector<Node<K, V, H>>&& ns, Bitmap nm, Bitmap dm) :
00195       nodes(std::move(ns)),
00196       node_map(nm),
00197       data_map(dm)
00198     {}
00199 
00200     SmallIndex compressed_idx(SmallIndex idx) const
00201     {
00202       if (!node_map.check(idx) && !data_map.check(idx))
00203         return (SmallIndex)-1;
00204 
00205       const auto mask = Bitmap(~((uint32_t)-1 << idx));
00206       if (data_map.check(idx))
00207         return (data_map & mask).pop();
00208 
00209       return data_map.pop() + (node_map & mask).pop();
00210     }
00211 
00212     const V* getp(SmallIndex depth, Hash hash, const K& k) const
00213     {
00214       const auto idx = mask(hash, depth);
00215       const auto c_idx = compressed_idx(idx);
00216 
00217       if (c_idx == (SmallIndex)-1)
00218         return nullptr;
00219 
00220       if (data_map.check(idx))
00221         return node_as<Entry<K, V>>(c_idx)->getp(k);
00222 
00223       if (depth == (collision_depth - 1))
00224         return node_as<Collisions<K, V, H>>(c_idx)->getp(hash, k);
00225 
00226       return node_as<SubNodes<K, V, H>>(c_idx)->getp(depth + 1, hash, k);
00227     }
00228 
00229     size_t put_mut(SmallIndex depth, Hash hash, const K& k, const V& v)
00230     {
00231       const auto idx = mask(hash, depth);
00232       auto c_idx = compressed_idx(idx);
00233 
00234       if (c_idx == (SmallIndex)-1)
00235       {
00236         data_map = data_map.set(idx);
00237         c_idx = compressed_idx(idx);
00238         nodes.insert(
00239           nodes.begin() + c_idx, std::make_shared<Entry<K, V>>(k, v));
00240         return 0;
00241       }
00242 
00243       if (node_map.check(idx))
00244       {
00245         size_t insert;
00246         if (depth < (collision_depth - 1))
00247         {
00248           auto sn = *node_as<SubNodes<K, V, H>>(c_idx);
00249           insert = sn.put_mut(depth + 1, hash, k, v);
00250           nodes[c_idx] = std::make_shared<SubNodes<K, V, H>>(std::move(sn));
00251         }
00252         else
00253         {
00254           auto sn = *node_as<Collisions<K, V, H>>(c_idx);
00255           insert = sn.put_mut(hash, k, v);
00256           nodes[c_idx] = std::make_shared<Collisions<K, V, H>>(std::move(sn));
00257         }
00258         return insert;
00259       }
00260 
00261       const auto& entry0 = node_as<Entry<K, V>>(c_idx);
00262       if (k == entry0->key)
00263       {
00264         auto current_size =
00265           get_size_with_padding<K, V>(entry0->key, entry0->value);
00266         nodes[c_idx] = std::make_shared<Entry<K, V>>(k, v);
00267         return current_size;
00268       }
00269 
00270       if (depth < (collision_depth - 1))
00271       {
00272         const auto hash0 = H()(entry0->key);
00273         const auto idx0 = mask(hash0, depth + 1);
00274         auto sub_node =
00275           SubNodes<K, V, H>({entry0}, Bitmap(0), Bitmap(0).set(idx0));
00276         sub_node.put_mut(depth + 1, hash, k, v);
00277 
00278         nodes.erase(nodes.begin() + c_idx);
00279         data_map = data_map.clear(idx);
00280         node_map = node_map.set(idx);
00281         c_idx = compressed_idx(idx);
00282         nodes.insert(
00283           nodes.begin() + c_idx,
00284           std::make_shared<SubNodes<K, V, H>>(std::move(sub_node)));
00285       }
00286       else
00287       {
00288         auto sub_node = Collisions<K, V, H>();
00289         const auto hash0 = H()(entry0->key);
00290         const auto idx0 = mask(hash0, collision_depth);
00291         sub_node.bins[idx0].push_back(entry0);
00292         const auto idx1 = mask(hash, collision_depth);
00293         sub_node.bins[idx1].push_back(std::make_shared<Entry<K, V>>(k, v));
00294 
00295         nodes.erase(nodes.begin() + c_idx);
00296         data_map = data_map.clear(idx);
00297         node_map = node_map.set(idx);
00298         c_idx = compressed_idx(idx);
00299         nodes.insert(
00300           nodes.begin() + c_idx,
00301           std::make_shared<Collisions<K, V, H>>(std::move(sub_node)));
00302       }
00303       return 0;
00304     }
00305 
00306     std::pair<std::shared_ptr<SubNodes<K, V, H>>, size_t> put(
00307       SmallIndex depth, Hash hash, const K& k, const V& v) const
00308     {
00309       auto node = *this;
00310       auto r = node.put_mut(depth, hash, k, v);
00311       return std::make_pair(
00312         std::make_shared<SubNodes<K, V, H>>(std::move(node)), r);
00313     }
00314 
00315     size_t remove_mut(SmallIndex depth, Hash hash, const K& k)
00316     {
00317       const auto idx = mask(hash, depth);
00318       const auto c_idx = compressed_idx(idx);
00319 
00320       if (c_idx == (SmallIndex)-1)
00321         return 0;
00322 
00323       if (data_map.check(idx))
00324       {
00325         const auto& entry = node_as<Entry<K, V>>(c_idx);
00326         if (entry->key != k)
00327           return 0;
00328 
00329         const auto diff = get_size_with_padding<K, V>(entry->key, entry->value);
00330         nodes.erase(nodes.begin() + c_idx);
00331         data_map = data_map.clear(idx);
00332         return diff;
00333       }
00334 
00335       if (depth == (collision_depth - 1))
00336       {
00337         auto sn = *node_as<Collisions<K, V, H>>(c_idx);
00338         const auto diff = sn.remove_mut(hash, k);
00339         nodes[c_idx] = std::make_shared<Collisions<K, V, H>>(std::move(sn));
00340         return diff;
00341       }
00342 
00343       auto sn = *node_as<SubNodes<K, V, H>>(c_idx);
00344       const auto diff = sn.remove_mut(depth + 1, hash, k);
00345       nodes[c_idx] = std::make_shared<SubNodes<K, V, H>>(std::move(sn));
00346       return diff;
00347     }
00348 
00349     std::pair<std::shared_ptr<SubNodes<K, V, H>>, size_t> remove(
00350       SmallIndex depth, Hash hash, const K& k) const
00351     {
00352       auto node = *this;
00353       auto r = node.remove_mut(depth, hash, k);
00354       return std::make_pair(
00355         std::make_shared<SubNodes<K, V, H>>(std::move(node)), r);
00356     }
00357 
00358     template <class F>
00359     bool foreach(SmallIndex depth, F&& f) const
00360     {
00361       const auto entries = data_map.pop();
00362       for (SmallIndex i = 0; i < entries; ++i)
00363       {
00364         const auto& entry = node_as<Entry<K, V>>(i);
00365         if (!f(entry->key, entry->value))
00366           return false;
00367       }
00368       for (size_t i = entries; i < nodes.size(); ++i)
00369       {
00370         if (depth == (collision_depth - 1))
00371         {
00372           if (!node_as<Collisions<K, V, H>>(i)->foreach(std::forward<F>(f)))
00373             return false;
00374         }
00375         else
00376         {
00377           if (!node_as<SubNodes<K, V, H>>(i)->foreach(
00378                 depth + 1, std::forward<F>(f)))
00379             return false;
00380         }
00381       }
00382       return true;
00383     }
00384 
00385   private:
00386     template <class A>
00387     const std::shared_ptr<A>& node_as(SmallIndex c_idx) const
00388     {
00389       return reinterpret_cast<const std::shared_ptr<A>&>(nodes[c_idx]);
00390     }
00391   };
00392 
00393   template <class K, class V, class H = std::hash<K>>
00394   class Map
00395   {
00396   private:
00397     std::shared_ptr<SubNodes<K, V, H>> root;
00398     size_t map_size = 0;
00399     size_t serialized_size = 0;
00400 
00401     Map(
00402       std::shared_ptr<SubNodes<K, V, H>>&& root_,
00403       size_t size_,
00404       size_t serialized_size_) :
00405       root(std::move(root_)),
00406       map_size(size_),
00407       serialized_size(serialized_size_)
00408     {}
00409 
00410   public:
00411     Map() : root(std::make_shared<SubNodes<K, V, H>>()) {}
00412 
00413     static Map<K, V, H> deserialize_map(CBuffer serialized_state)
00414     {
00415       Map<K, V, H> map;
00416       const uint8_t* data = serialized_state.p;
00417       size_t size = serialized_state.rawSize();
00418 
00419       while (size != 0)
00420       {
00421         // Deserialize the key
00422         size_t key_size = size;
00423         K key = champ::deserialize<K>(data, size);
00424         key_size -= size;
00425         serialized::skip(data, size, get_padding(key_size));
00426 
00427         // Deserialize the value
00428         size_t value_size = size;
00429         V value = champ::deserialize<V>(data, size);
00430         value_size -= size;
00431         serialized::skip(data, size, get_padding(value_size));
00432         map = map.put(key, value);
00433       }
00434       return map;
00435     }
00436 
00437     size_t size() const
00438     {
00439       return map_size;
00440     }
00441 
00442     size_t get_serialized_size() const
00443     {
00444       return serialized_size;
00445     }
00446 
00447     bool empty() const
00448     {
00449       return map_size == 0;
00450     }
00451 
00452     std::optional<V> get(const K& key) const
00453     {
00454       auto v = root->getp(0, H()(key), key);
00455 
00456       if (v)
00457         return *v;
00458       else
00459         return {};
00460     }
00461 
00462     const V* getp(const K& key) const
00463     {
00464       return root->getp(0, H()(key), key);
00465     }
00466 
00467     const Map<K, V, H> put(const K& key, const V& value) const
00468     {
00469       auto r = root->put(0, H()(key), key, value);
00470       auto size_ = map_size;
00471       if (r.second == 0)
00472         size_++;
00473 
00474       int64_t size_change = get_size_with_padding<K, V>(key, value) - r.second;
00475       return Map(std::move(r.first), size_, size_change + serialized_size);
00476     }
00477 
00478     const Map<K, V, H> remove(const K& key) const
00479     {
00480       auto r = root->remove(0, H()(key), key);
00481       auto size_ = map_size;
00482       if (r.second > 0)
00483         size_--;
00484 
00485       return Map(std::move(r.first), size_, serialized_size - r.second);
00486     }
00487 
00488     template <class F>
00489     bool foreach(F&& f) const
00490     {
00491       return root->foreach(0, std::forward<F>(f));
00492     }
00493   };
00494 
00495   template <class K, class V, class H = std::hash<K>>
00496   class Snapshot
00497   {
00498   private:
00499     Map<K, V, H> map;
00500     CBuffer serialized_buffer;
00501 
00502     struct KVTuple
00503     {
00504       K* k;
00505       Hash h_k;
00506       V* v;
00507 
00508       KVTuple(K* k_, Hash h_k_, V* v_) : k(k_), h_k(h_k_), v(v_) {}
00509     };
00510     const uintptr_t padding = 0;
00511 
00512     uint32_t add_padding(uint32_t data_size, uint8_t*& data, size_t& size) const
00513     {
00514       uint32_t padding_size = get_padding(data_size);
00515       if (padding_size != 0)
00516       {
00517         serialized::write(
00518           data, size, reinterpret_cast<const uint8_t*>(&padding), padding_size);
00519       }
00520       return padding_size;
00521     }
00522 
00523   public:
00524     Snapshot(Map<K, V, H>& map_)
00525     {
00526       map = map_;
00527     }
00528 
00529     size_t get_serialized_size()
00530     {
00531       return map.get_serialized_size();
00532     }
00533 
00534     CBuffer& get_serialized_buffer()
00535     {
00536       return serialized_buffer;
00537     }
00538 
00539     void serialize(uint8_t* data)
00540     {
00541       std::vector<KVTuple> ordered_state;
00542       ordered_state.reserve(map.size());
00543       size_t size = 0;
00544 
00545       map.foreach([&](auto& key, auto& value) {
00546         K* k = &key;
00547         V* v = &value;
00548         uint32_t ks = champ::get_size(key);
00549         uint32_t vs = champ::get_size(value);
00550         uint32_t key_size = ks + get_padding(ks);
00551         uint32_t value_size = vs + get_padding(vs);
00552 
00553         size += (key_size + value_size);
00554 
00555         ordered_state.emplace_back(k, static_cast<Hash>(H()(key)), v);
00556 
00557         return true;
00558       });
00559 
00560       // Sort keys to be able to generate byte-for-byte serialised snapshot from
00561       // the same state
00562       std::sort(
00563         ordered_state.begin(), ordered_state.end(), [](KVTuple& i, KVTuple& j) {
00564           return i.h_k < j.h_k;
00565         });
00566 
00567       CCF_ASSERT_FMT(
00568         size == map.get_serialized_size(),
00569         "size:{}, map->size:{} ==> count:{}, vect:{}",
00570         size,
00571         map.get_serialized_size(),
00572         map.size(),
00573         ordered_state.size());
00574 
00575       serialized_buffer = CBuffer(data, map.get_serialized_size());
00576 
00577       for (const auto& p : ordered_state)
00578       {
00579         // Serialize the key
00580         uint32_t key_size = champ::serialize(*p.k, data, size);
00581         add_padding(key_size, data, size);
00582 
00583         // Serialize the value
00584         uint32_t value_size = champ::serialize(*p.v, data, size);
00585         add_padding(value_size, data, size);
00586       }
00587 
00588       CCF_ASSERT_FMT(size == 0, "buffer not filled, remaining:{}", size);
00589     }
00590   };
00591 }
00592 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/champ_map.h...
Preprocessing /data/git/CCF/src/ds/champ_map_serializers.h...
#include ds/logger.h: not found! skipping...
#include stacktrace_utils.h: already included! skipping...
#include serialized.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include small_vector/SmallVector.h: not found! skipping...
Preprocessor output (size: 3753 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/ds/champ_map_serializers.h" 2
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace champ
00013 {
00014   using Version = int64_t;
00015 
00016   template <typename V>
00017   struct VersionV
00018   {
00019     Version version;
00020     V value;
00021 
00022     VersionV() = default;
00023     VersionV(Version ver, V val) : version(ver), value(val) {}
00024   };
00025 
00026   namespace serialisers
00027   {
00028     using SerialisedEntry = llvm_vecsmall::SmallVector<uint8_t, 8>;
00029   }
00030 
00031   namespace untyped
00032   {
00033     using SerialisedEntry = champ::serialisers::SerialisedEntry;
00034     using VersionV = champ::VersionV<SerialisedEntry>;
00035   }
00036 
00037   template <class T>
00038   inline size_t get_size(const T& data)
00039   {
00040     return sizeof(uint64_t) + sizeof(data);
00041   }
00042 
00043   template <>
00044   inline size_t get_size<champ::untyped::SerialisedEntry>(
00045     const champ::untyped::SerialisedEntry& data)
00046   {
00047     return sizeof(uint64_t) + data.size();
00048   }
00049 
00050   template <>
00051   inline size_t get_size<champ::untyped::VersionV>(
00052     const champ::untyped::VersionV& data)
00053   {
00054     return sizeof(uint64_t) + sizeof(data.version) + data.value.size();
00055   }
00056 
00057   template <class T>
00058   inline size_t serialize(const T& t, uint8_t*& data, size_t& size)
00059   {
00060     uint64_t data_size = sizeof(T);
00061     serialized::write(
00062       data,
00063       size,
00064       reinterpret_cast<const uint8_t*>(&data_size),
00065       sizeof(uint64_t));
00066     serialized::write(
00067       data, size, reinterpret_cast<const uint8_t*>(&t), sizeof(T));
00068     return sizeof(uint64_t) + sizeof(T);
00069   }
00070 
00071   template <>
00072   inline size_t serialize<champ::untyped::SerialisedEntry>(
00073     const champ::untyped::SerialisedEntry& t, uint8_t*& data, size_t& size)
00074   {
00075     uint64_t data_size = t.size();
00076     serialized::write(
00077       data,
00078       size,
00079       reinterpret_cast<const uint8_t*>(&data_size),
00080       sizeof(uint64_t));
00081     serialized::write(
00082       data, size, reinterpret_cast<const uint8_t*>(t.data()), data_size);
00083     return sizeof(uint64_t) + data_size;
00084   }
00085 
00086   template <>
00087   inline size_t serialize<champ::untyped::VersionV>(
00088     const champ::untyped::VersionV& t, uint8_t*& data, size_t& size)
00089   {
00090     uint64_t data_size = sizeof(t.version) + t.value.size();
00091     serialized::write(
00092       data,
00093       size,
00094       reinterpret_cast<const uint8_t*>(&data_size),
00095       sizeof(uint64_t));
00096     serialized::write(
00097       data,
00098       size,
00099       reinterpret_cast<const uint8_t*>(&t.version),
00100       sizeof(t.version));
00101     serialized::write(
00102       data,
00103       size,
00104       reinterpret_cast<const uint8_t*>(t.value.data()),
00105       t.value.size());
00106     return sizeof(uint64_t) + sizeof(t.version) + t.value.size();
00107   }
00108 
00109   template <class T>
00110   inline T deserialize(const uint8_t*& data, size_t& size)
00111   {
00112     size_t result = serialized::read<size_t>(data, size);
00113     (void)result;
00114     CCF_ASSERT_FMT(
00115       result == sizeof(T), "result:{} == sizeof(T):{}", result, sizeof(T));
00116     return serialized::read<T>(data, size);
00117   }
00118 
00119   template <>
00120   inline champ::untyped::SerialisedEntry deserialize<
00121     champ::untyped::SerialisedEntry>(const uint8_t*& data, size_t& size)
00122   {
00123     uint64_t data_size = serialized::read<uint64_t>(data, size);
00124     champ::untyped::SerialisedEntry ret;
00125     ret.append(data, data + data_size);
00126     serialized::skip(data, size, data_size);
00127     return ret;
00128   }
00129 
00130   template <>
00131   inline champ::untyped::VersionV deserialize<champ::untyped::VersionV>(
00132     const uint8_t*& data, size_t& size)
00133   {
00134     champ::untyped::VersionV ret;
00135     uint64_t data_size = serialized::read<uint64_t>(data, size);
00136     champ::Version version = serialized::read<champ::Version>(data, size);
00137     ret.version = version;
00138     data_size -= sizeof(champ::Version);
00139     ret.value.append(data, data + data_size);
00140     serialized::skip(data, size, data_size);
00141     return ret;
00142   }
00143 }
---------
Macros accessible in this file:
---------
LOG_DEBUG CCF_ASSERT_FMT_FAIL LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE CCF_ASSERT_FMT LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE CCF_ASSERT LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/champ_map_serializers.h...
Preprocessing /data/git/CCF/src/ds/cli_helper.h...
#include ds/nonstd.h: not found! skipping...
#include tls/san.h: not found! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
#include optional: not found! skipping...
#include fmt/format.h: not found! skipping...
Preprocessor output (size: 5258 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define FMT_HEADER_ONLY
00012 
00013 
00014 namespace cli
00015 {
00016   struct ParsedAddress
00017   {
00018     std::string hostname = {};
00019     std::string port = {};
00020   };
00021 
00022   CLI::Option* add_address_option(
00023     CLI::App& app,
00024     ParsedAddress& parsed,
00025     const std::string& option_name,
00026     const std::string& option_desc,
00027     const std::string& default_port = "0")
00028   {
00029     CLI::callback_t fun = [&parsed, option_name, default_port](
00030                             CLI::results_t results) {
00031       if (results.size() != 1)
00032       {
00033         throw CLI::ValidationError(option_name, "Address could not be parsed");
00034       }
00035 
00036       auto addr = results[0];
00037       auto found = addr.find_last_of(":");
00038       auto hostname = addr.substr(0, found);
00039 
00040       const auto port =
00041         found == std::string::npos ? default_port : addr.substr(found + 1);
00042 
00043       // Check if port is in valid range
00044       int port_int;
00045       try
00046       {
00047         port_int = std::stoi(port);
00048       }
00049       catch (const std::exception&)
00050       {
00051         throw CLI::ValidationError(option_name, "Port is not a number");
00052       }
00053       if (port_int < 0 || port_int > 65535)
00054       {
00055         throw CLI::ValidationError(
00056           option_name, "Port number is not in range 0-65535");
00057       }
00058 
00059       parsed.hostname = hostname;
00060       parsed.port = port;
00061 
00062       return true;
00063     };
00064 
00065     auto* option = app.add_option(option_name, fun, option_desc, true);
00066     option->type_name("HOST:PORT");
00067 
00068     return option;
00069   }
00070 
00071   struct ParsedMemberInfo
00072   {
00073     std::string cert_file;
00074     std::optional<std::string> enc_pubk_file;
00075     std::optional<std::string> member_data_file;
00076   };
00077 
00078   CLI::Option* add_member_info_option(
00079     CLI::App& app,
00080     std::vector<ParsedMemberInfo>& parsed,
00081     const std::string& option_name,
00082     const std::string& option_desc)
00083   {
00084     CLI::callback_t fun = [&option_name, &parsed](CLI::results_t res) {
00085       parsed.clear();
00086       for (const auto& r : res)
00087       {
00088         std::stringstream ss(r);
00089         std::string chunk;
00090         std::vector<std::string> chunks;
00091 
00092         while (std::getline(ss, chunk, ','))
00093         {
00094           chunks.emplace_back(chunk);
00095         }
00096 
00097         if (chunks.empty() || chunks.size() > 3)
00098         {
00099           throw CLI::ValidationError(
00100             option_name,
00101             "Member info is not in expected format: "
00102             "member_cert.pem[,member_enc_pubk.pem[,member_data.json]]");
00103         }
00104 
00105         ParsedMemberInfo member_info;
00106         member_info.cert_file = chunks.at(0);
00107         if (chunks.size() == 2)
00108         {
00109           member_info.enc_pubk_file = chunks.at(1);
00110         }
00111         else if (chunks.size() == 3)
00112         {
00113           // Only read encryption public key if there is something between two
00114           // commas
00115           if (!chunks.at(1).empty())
00116           {
00117             member_info.enc_pubk_file = chunks.at(1);
00118           }
00119           member_info.member_data_file = chunks.at(2);
00120         }
00121 
00122         // Validate that member info files exist, when specified
00123         auto validator = CLI::detail::ExistingFileValidator();
00124         auto err_str = validator(member_info.cert_file);
00125         if (!err_str.empty())
00126         {
00127           throw CLI::ValidationError(option_name, err_str);
00128         }
00129 
00130         if (member_info.enc_pubk_file.has_value())
00131         {
00132           err_str = validator(member_info.enc_pubk_file.value());
00133           if (!err_str.empty())
00134           {
00135             throw CLI::ValidationError(option_name, err_str);
00136           }
00137         }
00138 
00139         if (member_info.member_data_file.has_value())
00140         {
00141           err_str = validator(member_info.member_data_file.value());
00142           if (!err_str.empty())
00143           {
00144             throw CLI::ValidationError(option_name, err_str);
00145           }
00146         }
00147 
00148         parsed.emplace_back(member_info);
00149       }
00150       return true;
00151     };
00152 
00153     auto* option = app.add_option(option_name, fun, option_desc, true);
00154     option
00155       ->type_name("member_cert.pem[,member_enc_pubk.pem[,member_data.json]]")
00156       ->type_size(-1);
00157 
00158     return option;
00159   }
00160 
00161   static const std::string IP_ADDRESS_PREFIX("iPAddress:");
00162   static const std::string DNS_NAME_PREFIX("dNSName:");
00163 
00164   CLI::Option* add_subject_alternative_name_option(
00165     CLI::App& app,
00166     std::vector<tls::SubjectAltName>& parsed,
00167     const std::string& option_name,
00168     const std::string& option_desc)
00169   {
00170     CLI::callback_t fun = [&parsed, option_name](CLI::results_t results) {
00171       for (auto& result : results)
00172       {
00173         if (nonstd::starts_with(result, IP_ADDRESS_PREFIX))
00174         {
00175           parsed.push_back({result.substr(IP_ADDRESS_PREFIX.size()), true});
00176         }
00177         else if (nonstd::starts_with(result, DNS_NAME_PREFIX))
00178         {
00179           parsed.push_back({result.substr(DNS_NAME_PREFIX.size()), false});
00180         }
00181         else
00182         {
00183           throw CLI::ValidationError(
00184             option_name,
00185             fmt::format(
00186               "SAN could not be parsed: {}, must be (iPAddress|dNSName):VALUE",
00187               result));
00188         }
00189       }
00190 
00191       return true;
00192     };
00193 
00194     auto* option = app.add_option(option_name, fun, option_desc, true);
00195     option->type_name("(iPAddress|dNSName):VALUE")->type_size(-1);
00196 
00197     return option;
00198   }
00199 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/ds/cli_helper.h...
Preprocessing /data/git/CCF/src/ds/dl_list.h...
#include cassert: not found! skipping...
#include cstdint: not found! skipping...
#include snmalloc/src/ds/dllist.h: not found! skipping...
#include assert.h: not found! skipping...
Preprocessor output (size: 238 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 #define SNMALLOC_ASSERT
00009 #define ALWAYSINLINE
00010 #define SNMALLOC_FAST_PATH
00011 
00012 namespace snmalloc
00013 {
00014   using address_t = uintptr_t;
00015 }
00016 
00017 
00018 
00019 
---------
Macros accessible in this file:
---------
ALWAYSINLINE SNMALLOC_ASSERT SNMALLOC_FAST_PATH 
---------
Parsing file /data/git/CCF/src/ds/dl_list.h...
Preprocessing /data/git/CCF/src/ds/files.h...
#include cstring: not found! skipping...
#include fstream: not found! skipping...
#include glob.h: not found! skipping...
#include iostream: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include optional: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2944 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 namespace files
00016 {
00017   /**
00018    * @brief Checks if a path exists
00019    *
00020    * @param path path to check
00021    * @return true if the file exists.
00022    */
00023   bool exists(const std::string& file)
00024   {
00025     std::ifstream f(file.c_str());
00026     return f.good();
00027   }
00028 
00029   /**
00030    * @brief Tries to read a file as byte vector.
00031    *
00032    * @param file the path
00033    * @param optional determines behaviour in the case where the file does not
00034    * exist. If true, an empty vector is returned. If false, the process exits
00035    * @return vector<uint8_t> the file contents as bytes.
00036    */
00037   std::vector<uint8_t> slurp(const std::string& file, bool optional = false)
00038   {
00039     std::ifstream f(file, std::ios::binary | std::ios::ate);
00040 
00041     if (!f)
00042     {
00043       if (optional)
00044       {
00045         return {};
00046       }
00047       else
00048       {
00049         std::cerr << "Could not open file " << file << std::endl;
00050         exit(-1);
00051       }
00052     }
00053 
00054     auto size = f.tellg();
00055     f.seekg(0, std::ios::beg);
00056 
00057     std::vector<uint8_t> data(size);
00058     f.read((char*)data.data(), size);
00059 
00060     if (!optional && !f)
00061     {
00062       std::cerr << "Could not read file " << file << std::endl;
00063       exit(-1);
00064     }
00065     return data;
00066   }
00067 
00068   /**
00069    * @brief Tries to read a file as string
00070    *
00071    * @param file the path
00072    * @param optional determines behaviour in the case where the file does not
00073    * exist. If true, an empty vector is returned. If false, the process exits
00074    * @return std::string the file contents as a string.
00075    */
00076   std::string slurp_string(const std::string& file, bool optional = false)
00077   {
00078     auto v = slurp(file, optional);
00079     return {v.begin(), v.end()};
00080   }
00081 
00082   /**
00083    * @brief Tries to read a file as JSON.
00084    *
00085    * @param file the path
00086    * @param optional determines behaviour in the case where the file does not
00087    * exist. If true, an empty JSON object is returned. If false, the process
00088    * exits
00089    * @return nlohmann::json JSON object containing the parsed file
00090    */
00091   nlohmann::json slurp_json(const std::string& file, bool optional = false)
00092   {
00093     auto v = slurp(file, optional);
00094     if (v.size() == 0)
00095       return nlohmann::json();
00096 
00097     return nlohmann::json::parse(v.begin(), v.end());
00098   }
00099 
00100   /**
00101    * @brief Writes the content of a vector to a file
00102    *
00103    * @param data vector to write
00104    * @param file the path
00105    */
00106   void dump(const std::vector<uint8_t>& data, const std::string& file)
00107   {
00108     using namespace std;
00109     ofstream f(file, ios::binary | ios::trunc);
00110     f.write((char*)data.data(), data.size());
00111     if (!f)
00112       throw logic_error("Failed to write to file: " + file);
00113   }
00114 
00115   /**
00116    * @brief Writes the content of a string to a file
00117    *
00118    * @param data string to write
00119    * @param file the path
00120    */
00121   void dump(const std::string& data, const std::string& file)
00122   {
00123     return dump(std::vector<uint8_t>(data.begin(), data.end()), file);
00124   }
00125 }
00126 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/files.h...
Preprocessing /data/git/CCF/src/ds/hash.h...
#include siphash.h: already included! skipping...
#include array: not found! skipping...
#include cstdint: not found! skipping...
#include small_vector/SmallVector.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2842 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ds::hashutils
00013 {
00014   template <typename T>
00015   inline void hash_combine(size_t& n, const T& v, std::hash<T>& h)
00016   {
00017     n ^= h(v) + (n << 6) + (n >> 2);
00018   }
00019 
00020   template <typename T>
00021   inline size_t hash_container(const T& v)
00022   {
00023     size_t n = 0x444e414c544f4353;
00024     std::hash<typename T::value_type> h{};
00025 
00026     for (const auto& e : v)
00027     {
00028       hash_combine(n, e, h);
00029     }
00030 
00031     return n;
00032   }
00033 }
00034 
00035 namespace std
00036 {
00037   template <>
00038   struct hash<std::vector<uint8_t>>
00039   {
00040     size_t operator()(const std::vector<uint8_t>& v) const
00041     {
00042       // For cryptographically secure hashing, use SipHash directly with a
00043       // secret key. For std::hash, we use this fixed key
00044       static constexpr siphash::SipKey k{0x7720796f726c694b,
00045                                          0x2165726568207361};
00046       return siphash::siphash<2, 4>(v, k);
00047     }
00048   };
00049 
00050   template <typename T>
00051   struct hash<std::vector<T>>
00052   {
00053     size_t operator()(const std::vector<T>& v) const
00054     {
00055       return ds::hashutils::hash_container(v);
00056     }
00057   };
00058 
00059   template <typename T, size_t N>
00060   struct hash<std::array<T, N>>
00061   {
00062     size_t operator()(const std::array<T, N>& v) const
00063     {
00064       return ds::hashutils::hash_container(v);
00065     }
00066   };
00067 
00068   template <typename A, typename B>
00069   struct hash<std::pair<A, B>>
00070   {
00071     size_t operator()(const std::pair<A, B>& v) const
00072     {
00073       size_t n = 0x444e414c544f4353;
00074 
00075       std::hash<A> h_a{};
00076       ds::hashutils::hash_combine(n, v.first, h_a);
00077 
00078       std::hash<B> h_b{};
00079       ds::hashutils::hash_combine(n, v.second, h_b);
00080 
00081       return n;
00082     }
00083   };
00084 
00085   template <typename T, unsigned N>
00086   struct hash<llvm_vecsmall::SmallVector<T, N>>
00087   {
00088     size_t operator()(const llvm_vecsmall::SmallVector<T, N>& v) const
00089     {
00090       static constexpr siphash::SipKey k{0x7720796f726c694b,
00091                                          0x2165726568207361};
00092       return siphash::siphash<2, 4>(v.data(), v.size(), k);
00093     }
00094   };
00095 }
00096 
00097 namespace ds
00098 {
00099   /// Simple, fast constexpr hash function (NOT cryptographically sound)
00100   namespace
00101   {
00102     template <typename T>
00103     struct fnv_parameters
00104     {};
00105 
00106     template <>
00107     struct fnv_parameters<uint32_t>
00108     {
00109       static constexpr uint32_t offset_basis = 0x811c9dc5;
00110       static constexpr uint32_t prime = 16777619;
00111     };
00112 
00113     template <>
00114     struct fnv_parameters<uint64_t>
00115     {
00116       static constexpr uint64_t offset_basis = 0xcbf29ce484222325;
00117       static constexpr uint64_t prime = 1099511628211;
00118     };
00119   }
00120 
00121   template <typename T>
00122   static constexpr T fnv_1a(char const* s)
00123   {
00124     using params = fnv_parameters<T>;
00125 
00126     T hash = params::offset_basis;
00127     T c = 0;
00128 
00129     while ((c = *s++))
00130     {
00131       hash ^= c;
00132       hash *= params::prime;
00133     }
00134 
00135     return hash;
00136   }
00137 }
00138 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/hash.h...
Preprocessing /data/git/CCF/src/ds/histogram.h...
#include cassert: not found! skipping...
#include chrono: not found! skipping...
#include limits: not found! skipping...
#include map: not found! skipping...
#include mutex: not found! skipping...
#include utility: not found! skipping...
Preprocessor output (size: 6659 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace histogram
00017 {
00018   static constexpr size_t bits = sizeof(size_t) * 8;
00019 
00020   constexpr bool bits64()
00021   {
00022     return bits == 64;
00023   }
00024 
00025   inline size_t clz(size_t x)
00026   {
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037     return __builtin_clzl(x);
00038 
00039   }
00040 
00041   constexpr size_t clz_const(size_t x)
00042   {
00043     size_t n = 0;
00044 
00045     for (int i = bits - 1; i >= 0; i--)
00046     {
00047       size_t mask = (size_t)1 << i;
00048 
00049       if ((x & mask) == mask)
00050         return n;
00051 
00052       n++;
00053     }
00054 
00055     return n;
00056   }
00057 
00058   inline size_t next_pow2(size_t x)
00059   {
00060     // Correct for numbers [0..MAX_SIZE >> 1).
00061     // Returns 1 for x > (MAX_SIZE >> 1).
00062     if (x <= 2)
00063       return x;
00064 
00065     return (size_t)1 << (bits - clz(x - 1));
00066   }
00067 
00068   inline size_t next_pow2_bits(size_t x)
00069   {
00070     // Correct for numbers [1..MAX_SIZE].
00071     // Returns -1 for 0. Approximately 7 cycles.
00072     return bits - clz(x) - (!(x & (x - 1)));
00073   }
00074 
00075   constexpr size_t next_pow2_const(size_t x)
00076   {
00077     if (x <= 2)
00078       return x;
00079 
00080     return (size_t)1 << (bits - clz_const(x - 1));
00081   }
00082 
00083   constexpr size_t next_pow2_bits_const(size_t x)
00084   {
00085     return bits - clz_const(x) - (!(x & (x - 1)));
00086   }
00087 
00088   template <class H>
00089   class Global;
00090 
00091   template <class V, V LOW, V HIGH, size_t SIGNIFICANT_BITS = 3>
00092   class Histogram
00093   {
00094   public:
00095     using Value = V;
00096     using This = Histogram<V, LOW, HIGH, SIGNIFICANT_BITS>;
00097 
00098   private:
00099     friend Global<This>;
00100 
00101     static_assert(LOW >= 1, "LOW must be at least 1");
00102     static_assert(LOW < HIGH, "LOW must be less than HIGH");
00103     static_assert(LOW == next_pow2_const(LOW), "LOW must be a power of 2");
00104     static_assert(HIGH == next_pow2_const(HIGH), "HIGH must be a power of 2");
00105     static_assert(
00106       (SIGNIFICANT_BITS >= 1) && (SIGNIFICANT_BITS <= 6),
00107       "SIGNIFICANT_BITS must be from 1 to 6");
00108 
00109     static constexpr size_t LOW_BITS = next_pow2_bits_const(LOW);
00110     static constexpr size_t HIGH_BITS = next_pow2_bits_const(HIGH);
00111     static constexpr size_t BUCKETS = (HIGH_BITS - LOW_BITS - 1)
00112       << (SIGNIFICANT_BITS - 1);
00113     static constexpr size_t SIGNIFICANT = (size_t)1 << SIGNIFICANT_BITS;
00114     static constexpr size_t SIGNIFICANT_MASK = (SIGNIFICANT >> 1) - 1;
00115 
00116     V low;
00117     V high;
00118 
00119     size_t underflow = 0;
00120     size_t overflow = 0;
00121     size_t count[BUCKETS];
00122 
00123     This* next;
00124 
00125   public:
00126     Histogram(Global<This>& g) :
00127       low((std::numeric_limits<V>::max)()),
00128       high((std::numeric_limits<V>::min)()),
00129       next(nullptr)
00130     {
00131       g.add(*this);
00132     }
00133 
00134     void record(V value)
00135     {
00136       if (value < low)
00137         low = value;
00138 
00139       if (value > high)
00140         high = value;
00141 
00142       if (value < LOW)
00143       {
00144         underflow++;
00145       }
00146       else if (value >= HIGH)
00147       {
00148         overflow++;
00149       }
00150       else
00151       {
00152         auto i = get_index(value);
00153         assert(i < BUCKETS);
00154         count[i]++;
00155       }
00156     }
00157 
00158     V get_low()
00159     {
00160       return low;
00161     }
00162 
00163     V get_high()
00164     {
00165       return high;
00166     }
00167 
00168     size_t get_underflow()
00169     {
00170       return underflow;
00171     }
00172 
00173     size_t get_overflow()
00174     {
00175       return overflow;
00176     }
00177 
00178     size_t get_buckets()
00179     {
00180       return BUCKETS;
00181     }
00182 
00183     size_t get_count(size_t index)
00184     {
00185       if (index >= BUCKETS)
00186         return 0;
00187 
00188       return count[index];
00189     }
00190 
00191     std::pair<V, V> get_range(size_t index)
00192     {
00193       if (index >= BUCKETS)
00194         return std::make_pair(HIGH, HIGH);
00195 
00196       return std::make_pair(get_value(index), get_value(index + 1) - 1);
00197     }
00198 
00199     void add(Histogram<V, LOW, HIGH, SIGNIFICANT_BITS>& that)
00200     {
00201       low = std::min(low, that.low);
00202       high = std::max(high, that.high);
00203       underflow += that.underflow;
00204       overflow += that.overflow;
00205 
00206       for (size_t i = 0; i < BUCKETS; i++)
00207         count[i] += that.count[i];
00208     }
00209 
00210     void print(std::stringstream& ss)
00211     {
00212       ss << "\tLow: " << low << std::endl
00213          << "\tHigh: " << high << std::endl
00214          << "\tUnderflow: " << underflow << std::endl
00215          << "\tOverflow: " << underflow << std::endl;
00216 
00217       for (size_t i = 0; i < BUCKETS; i++)
00218       {
00219         auto r = get_range(i);
00220         ss << "\t" << std::get<0>(r) << ".." << std::get<1>(r) << ": "
00221            << count[i] << std::endl;
00222       }
00223     }
00224 
00225     std::map<std::pair<size_t, size_t>, size_t> get_range_count()
00226     {
00227       std::map<std::pair<size_t, size_t>, size_t> range_counts;
00228 
00229       for (size_t i = 0; i < BUCKETS; i++)
00230       {
00231         auto r = get_range(i);
00232         range_counts.insert({{std::get<0>(r), std::get<1>(r)}, count[i]});
00233       }
00234       return range_counts;
00235     }
00236 
00237   private:
00238     size_t get_index(V value)
00239     {
00240       auto v = value >> LOW_BITS;
00241       auto s = bits - clz(v);
00242 
00243       if (s <= SIGNIFICANT_BITS)
00244         return v - 1;
00245 
00246       auto shift = s - SIGNIFICANT_BITS;
00247       auto m1 = (v >> shift) & SIGNIFICANT_MASK;
00248       auto m2 = (shift + 1) << (SIGNIFICANT_BITS - 1);
00249       return m1 + m2 - 1;
00250     }
00251 
00252     V get_value(size_t index)
00253     {
00254       auto i = index + 1;
00255 
00256       if (i < SIGNIFICANT)
00257         return (V)i;
00258 
00259       auto shift = (i >> (SIGNIFICANT_BITS - 1)) - 1;
00260       auto m1 = (i & SIGNIFICANT_MASK) << shift;
00261       auto m2 = (size_t)1 << (shift + SIGNIFICANT_BITS - 1);
00262       return (m1 + m2) << LOW_BITS;
00263     }
00264   };
00265 
00266   template <class H>
00267   class Global
00268   {
00269   private:
00270     std::mutex m;
00271     std::string name;
00272     std::string file;
00273     size_t line;
00274     H* head;
00275 
00276   public:
00277     Global(const std::string& name_, const std::string& file_, size_t line_) :
00278       name(name_),
00279       file(file_),
00280       line(line_),
00281       head(nullptr)
00282     {}
00283 
00284     ~Global() {}
00285 
00286     void add(H& histogram)
00287     {
00288       std::lock_guard<std::mutex> lock(m);
00289       histogram.next = head;
00290       head = &histogram;
00291     }
00292 
00293     void print()
00294     {
00295       std::lock_guard<std::mutex> lock(m);
00296       std::stringstream ss;
00297       H* p = head;
00298 
00299       ss << name << ": " << file << ":" << line << ":" << std::endl;
00300 
00301       while (p != nullptr)
00302       {
00303         p->print(ss);
00304         p = p->next;
00305       }
00306       std::cout << ss.str() << std::endl;
00307     }
00308   };
00309 
00310   template <class H>
00311   class Measure
00312   {
00313   private:
00314     H& histogram;
00315     std::chrono::high_resolution_clock::time_point t;
00316     bool stopped;
00317 
00318   public:
00319     Measure(H& histogram_) : histogram(histogram_), stopped(false)
00320     {
00321       t = std::chrono::high_resolution_clock::now();
00322     }
00323 
00324     virtual ~Measure()
00325     {
00326       stop();
00327     }
00328 
00329     void stop()
00330     {
00331       auto e = std::chrono::high_resolution_clock::now() - t;
00332 
00333       if (!stopped)
00334       {
00335         histogram.record((H::Value)(e.count()));
00336         stopped = true;
00337       }
00338     }
00339   };
00340 
00341 
00342 
00343 
00344 
00345 
00346 
00347 
00348 
00349 
00350 
00351 
00352 #define MEASURE(id)
00353 #define STOP_MEASURE(id)
00354 
00355 }
00356 
---------
Macros accessible in this file:
---------
MEASURE STOP_MEASURE 
---------
Parsing file /data/git/CCF/src/ds/histogram.h...
Preprocessing /data/git/CCF/src/ds/json.h...
#include ds/nonstd.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include fmt/format.h: not found! skipping...
#include sstream: not found! skipping...
Preprocessor output (size: 11543 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 # 4 "/data/git/CCF/src/ds/json.h" 2
00005 
00006 #define FMT_HEADER_ONLY
00007 
00008 
00009 
00010 template <typename T>
00011 void assign_j(T& o, const nlohmann::json& j)
00012 {
00013   o = std::move(j.get<T>());
00014 }
00015 
00016 /** Represents a field within a JSON object. Tuples of these can be used in
00017  * schema generation.
00018  */
00019 template <typename T>
00020 struct JsonField
00021 {
00022   using Target = T;
00023   char const* name;
00024 };
00025 
00026 class JsonParseError : public std::invalid_argument
00027 {
00028 public:
00029   std::vector<std::string> pointer_elements = {};
00030 
00031   using std::invalid_argument::invalid_argument;
00032 
00033   std::string pointer() const
00034   {
00035     return fmt::format(
00036       "#/{}",
00037       fmt::join(pointer_elements.crbegin(), pointer_elements.crend(), "/"));
00038   }
00039 };
00040 
00041 namespace std
00042 {
00043   template <typename T>
00044   inline void to_json(nlohmann::json& j, const std::optional<T>& t)
00045   {
00046     if (t.has_value())
00047     {
00048       j = t.value();
00049     }
00050   }
00051 
00052   template <typename T>
00053   inline void from_json(const nlohmann::json& j, std::optional<T>& t)
00054   {
00055     if (!j.is_null())
00056     {
00057       t = j.get<T>();
00058     }
00059   }
00060 
00061   template <typename T>
00062   inline void to_json(nlohmann::json& j, const std::vector<T>& t)
00063   {
00064     j = nlohmann::json::array();
00065     for (const auto& e : t)
00066     {
00067       j.push_back(e);
00068     }
00069   }
00070 
00071   template <typename T>
00072   inline void from_json(const nlohmann::json& j, std::vector<T>& t)
00073   {
00074     if (!j.is_array())
00075     {
00076       throw JsonParseError("Expected array, found: " + j.dump());
00077     }
00078 
00079     for (auto i = 0u; i < j.size(); ++i)
00080     {
00081       try
00082       {
00083         t.push_back(j.at(i).template get<T>());
00084       }
00085       catch (JsonParseError& jpe)
00086       {
00087         jpe.pointer_elements.push_back(std::to_string(i));
00088         throw;
00089       }
00090     }
00091   }
00092 }
00093 
00094 // FOREACH macro machinery for counting args
00095 
00096 // -Wpedantic flags token pasting of __VA_ARGS__
00097 
00098 
00099 
00100                                               #define __FOR_JSON_COUNT_NN( _0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19, _20, N, ...) 
00101 
00102 
00103 
00104 
00105 
00106 
00107 
00108 
00109 
00110 
00111 
00112 
00113 
00114 
00115 
00116 
00117 
00118 
00119 
00120 
00121 
00122 
00123 
00124 
00125 #define _FOR_JSON_COUNT_NN_WITH_0(...) 
00126 
00127 
00128 
00129 
00130 
00131 
00132 
00133 
00134 
00135 
00136 
00137 
00138 
00139 
00140 
00141 
00142 
00143 
00144 
00145 
00146 
00147 
00148 
00149 #define _FOR_JSON_COUNT_NN(...) 
00150 
00151 #define _FOR_JSON_0(POP_N) 
00152 #define _FOR_JSON_1(POP_N) 
00153 #define _FOR_JSON_2(POP_N) 
00154 #define _FOR_JSON_3(POP_N) 
00155 #define _FOR_JSON_4(POP_N) 
00156 #define _FOR_JSON_5(POP_N) 
00157 #define _FOR_JSON_6(POP_N) 
00158 #define _FOR_JSON_7(POP_N) 
00159 #define _FOR_JSON_8(POP_N) 
00160 #define _FOR_JSON_9(POP_N) 
00161 #define _FOR_JSON_10(POP_N) 
00162 #define _FOR_JSON_11(POP_N) 
00163 #define _FOR_JSON_12(POP_N) 
00164 #define _FOR_JSON_13(POP_N) 
00165 #define _FOR_JSON_14(POP_N) 
00166 #define _FOR_JSON_15(POP_N) 
00167 #define _FOR_JSON_16(POP_N) 
00168 #define _FOR_JSON_17(POP_N) 
00169 #define _FOR_JSON_18(POP_N) 
00170 #define _FOR_JSON_19(POP_N) 
00171 #define _FOR_JSON_20(POP_N) 
00172 
00173 // FOREACH macro machinery for forwarding to single arg macros
00174 #define _FOR_JSON_0_POP1(FUNC, TYPE)
00175 #define _FOR_JSON_1_POP1(FUNC, TYPE, ARG1) 
00176 #define _FOR_JSON_2_POP1(FUNC, TYPE, ARG1, ...) 
00177 
00178 
00179 #define _FOR_JSON_3_POP1(FUNC, TYPE, ARG1, ...) 
00180 
00181 
00182 #define _FOR_JSON_4_POP1(FUNC, TYPE, ARG1, ...) 
00183 
00184 
00185 #define _FOR_JSON_5_POP1(FUNC, TYPE, ARG1, ...) 
00186 
00187 
00188 #define _FOR_JSON_6_POP1(FUNC, TYPE, ARG1, ...) 
00189 
00190 
00191 #define _FOR_JSON_7_POP1(FUNC, TYPE, ARG1, ...) 
00192 
00193 
00194 #define _FOR_JSON_8_POP1(FUNC, TYPE, ARG1, ...) 
00195 
00196 
00197 #define _FOR_JSON_9_POP1(FUNC, TYPE, ARG1, ...) 
00198 
00199 
00200 #define _FOR_JSON_10_POP1(FUNC, TYPE, ARG1, ...) 
00201 
00202 
00203 #define _FOR_JSON_11_POP1(FUNC, TYPE, ARG1, ...) 
00204 
00205 
00206 #define _FOR_JSON_12_POP1(FUNC, TYPE, ARG1, ...) 
00207 
00208 
00209 #define _FOR_JSON_13_POP1(FUNC, TYPE, ARG1, ...) 
00210 
00211 
00212 #define _FOR_JSON_14_POP1(FUNC, TYPE, ARG1, ...) 
00213 
00214 
00215 #define _FOR_JSON_15_POP1(FUNC, TYPE, ARG1, ...) 
00216 
00217 
00218 #define _FOR_JSON_16_POP1(FUNC, TYPE, ARG1, ...) 
00219 
00220 
00221 #define _FOR_JSON_17_POP1(FUNC, TYPE, ARG1, ...) 
00222 
00223 
00224 #define _FOR_JSON_18_POP1(FUNC, TYPE, ARG1, ...) 
00225 
00226 
00227 #define _FOR_JSON_19_POP1(FUNC, TYPE, ARG1, ...) 
00228 
00229 
00230 #define _FOR_JSON_20_POP1(FUNC, TYPE, ARG1, ...) 
00231 
00232 
00233 
00234 // FOREACH macro machinery for forwarding to double arg macros
00235 #define _FOR_JSON_0_POP2(FUNC, TYPE)
00236 #define _FOR_JSON_1_POP2(FUNC, TYPE, ARG1) 
00237 #define _FOR_JSON_2_POP2(FUNC, TYPE, ARG1, ARG2) 
00238 
00239 #define _FOR_JSON_3_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00240 #define _FOR_JSON_4_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00241 
00242 
00243 #define _FOR_JSON_5_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00244 #define _FOR_JSON_6_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00245 
00246 
00247 #define _FOR_JSON_7_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00248 #define _FOR_JSON_8_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00249 
00250 
00251 #define _FOR_JSON_9_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00252 #define _FOR_JSON_10_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00253 
00254 
00255 #define _FOR_JSON_11_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00256 #define _FOR_JSON_12_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00257 
00258 
00259 #define _FOR_JSON_13_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00260 #define _FOR_JSON_14_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00261 
00262 
00263 #define _FOR_JSON_15_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00264 #define _FOR_JSON_16_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00265 
00266 
00267 #define _FOR_JSON_17_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00268 #define _FOR_JSON_18_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00269 
00270 
00271 #define _FOR_JSON_19_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00272 #define _FOR_JSON_20_POP2(FUNC, TYPE, ARG1, ARG2, ...) 
00273 
00274 
00275 
00276 // Forwarders for macros produced by the machinery above
00277 #define _FOR_JSON_NEXT(FUNC, ...) 
00278 #define _FOR_JSON_FINAL(FUNC, ...) 
00279 
00280 #define WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT(TYPE, C_FIELD, JSON_FIELD) 
00281 
00282 
00283 
00284 #define WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL(TYPE, C_FIELD, JSON_FIELD) 
00285 
00286 
00287 #define WRITE_REQUIRED_FOR_JSON_NEXT(TYPE, FIELD) 
00288 
00289 #define WRITE_REQUIRED_FOR_JSON_FINAL(TYPE, FIELD) 
00290 
00291 
00292 #define WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT(TYPE, C_FIELD, JSON_FIELD) 
00293 
00294 
00295 
00296 
00297 
00298 
00299 #define WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL(TYPE, C_FIELD, JSON_FIELD) 
00300 
00301 
00302 #define WRITE_OPTIONAL_FOR_JSON_NEXT(TYPE, FIELD) 
00303 
00304 #define WRITE_OPTIONAL_FOR_JSON_FINAL(TYPE, FIELD) 
00305 
00306 
00307 #define READ_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT(TYPE, C_FIELD, JSON_FIELD) 
00308 
00309 
00310 
00311 
00312 
00313 
00314 
00315 
00316 
00317 
00318 
00319 
00320 
00321 
00322 
00323 
00324 
00325 #define READ_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL(TYPE, C_FIELD, JSON_FIELD) 
00326 
00327 
00328 #define READ_REQUIRED_FOR_JSON_NEXT(TYPE, FIELD) 
00329 
00330 #define READ_REQUIRED_FOR_JSON_FINAL(TYPE, FIELD) 
00331 
00332 
00333 #define READ_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT(TYPE, C_FIELD, JSON_FIELD) 
00334 
00335 
00336 
00337 
00338 
00339 
00340 
00341 #define READ_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL(TYPE, C_FIELD, JSON_FIELD) 
00342 
00343 
00344 #define READ_OPTIONAL_FOR_JSON_NEXT(TYPE, FIELD) 
00345 
00346 #define READ_OPTIONAL_FOR_JSON_FINAL(TYPE, FIELD) 
00347 
00348 
00349   #define FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT( TYPE, C_FIELD, JSON_FIELD) 
00350 
00351 
00352 
00353 
00354   #define FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL( TYPE, C_FIELD, JSON_FIELD) 
00355 
00356 
00357 
00358 #define FILL_SCHEMA_REQUIRED_FOR_JSON_NEXT(TYPE, FIELD) 
00359 
00360 #define FILL_SCHEMA_REQUIRED_FOR_JSON_FINAL(TYPE, FIELD) 
00361 
00362 
00363   #define FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT( TYPE, C_FIELD, JSON_FIELD) 
00364 
00365 
00366 
00367   #define FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL( TYPE, C_FIELD, JSON_FIELD) 
00368 
00369 
00370 
00371 #define FILL_SCHEMA_OPTIONAL_FOR_JSON_NEXT(TYPE, FIELD) 
00372 
00373 #define FILL_SCHEMA_OPTIONAL_FOR_JSON_FINAL(TYPE, FIELD) 
00374 
00375 
00376   #define ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT( TYPE, C_FIELD, JSON_FIELD) 
00377 
00378 
00379 
00380 
00381   #define ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL( TYPE, C_FIELD, JSON_FIELD) 
00382 
00383 
00384 
00385 
00386 #define ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_NEXT(TYPE, FIELD) 
00387 
00388 #define ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_FINAL(TYPE, FIELD) 
00389 
00390 
00391   #define ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT( TYPE, C_FIELD, JSON_FIELD) 
00392 
00393 
00394 
00395   #define ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL( TYPE, C_FIELD, JSON_FIELD) 
00396 
00397 
00398 
00399 
00400 #define ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_NEXT(TYPE, FIELD) 
00401 
00402 #define ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_FINAL(TYPE, FIELD) 
00403 
00404 
00405 #define JSON_FIELD_FOR_JSON_NEXT(TYPE, FIELD) 
00406 
00407 #define JSON_FIELD_FOR_JSON_FINAL(TYPE, FIELD) 
00408 
00409 
00410 
00411 
00412 
00413 /** Defines from_json, to_json, fill_json_schema, schema_name, fill_json_schema,
00414  * and add_schema_components functions for struct/class types, converting member
00415  * fields to JSON elements and populating schema documents describing this
00416  * transformation. Missing elements will cause errors to be raised. This assumes
00417  * that from_json, to_json, are implemented for each member
00418  * field type, either manually or through these macros. Additionally, you will
00419  * schema_name, fill_json_schema, and add_schema_components to be defined for
00420  * OpenAPI schema generation.
00421  * // clang-format off
00422  *  ie, the following must compile, for each foo in T:
00423  *    T t; nlohmann::json j, schema;
00424  *    j["foo"] = t.foo;
00425  *    t.foo = j["foo"].get<decltype(T::foo)>();
00426  *    fill_json_schema(schema, t);
00427  *    std::string s = schema_name(t.foo);
00428  * // clang-format on
00429  *
00430  * Optional fields will be inserted into the JSON object iff their value differs
00431  * from the value in a default-constructed instance of T. So if optional fields
00432  * are present, then T must be default-constructible and the optional fields
00433  * must be distinguishable (have operator!= defined)
00434  *
00435  * To use:
00436  *  - Declare struct as normal
00437  *  - Add DELARE_JSON_TYPE, or WITH_BASE or WITH_OPTIONAL variants as required
00438  *  - Add DECLARE_JSON_REQUIRED_FIELDS listing fields which must be present
00439  *  - If there are optional fields, add DECLARE_JSON_OPTIONAL_FIELDS
00440  *  - If the json and struct fields have different names, use WITH_RENAMES
00441  *
00442  * Examples:
00443  *  struct X
00444  *  {
00445  *   int a, b;
00446  *  };
00447  *  DECLARE_JSON_TYPE(X)
00448  *  DECLARE_JSON_REQUIRED_FIELDS(X, a, b)
00449  *
00450  *  Valid JSON:
00451  *   { "a": 42, "b": 100 }
00452  *   { "a": 42, "b": 100, "Unused": ["Anything"] }
00453  *  Invalid JSON:
00454  *   {}
00455  *   { "a": 42 }
00456  *   { "a": 42, "b": "Hello world" }
00457  *
00458  *  struct Y
00459  *  {
00460  *   bool c;
00461  *   std::string d;
00462  *  };
00463  *  DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(Y)
00464  *  DECLARE_JSON_REQUIRED_FIELDS(Y, c)
00465  *  DECLARE_JSON_OPTIONAL_FIELDS(Y, d)
00466  *
00467  *  Valid JSON:
00468  *   { "c": true }
00469  *   { "c": false, "d": "Hello" }
00470  *  Invalid JSON:
00471  *   { "d": "Hello" }
00472  *
00473  *  struct X_A : X
00474  *  {
00475  *   int m;
00476  *  };
00477  *  DECLARE_JSON_TYPE_WITH_BASE(X_A, X)
00478  *  DECLARE_JSON_REQUIRED_FIELDS(X_A, m)
00479  *
00480  *  Valid JSON:
00481  *   { "a": 42, "b": 100, "m": 101 }
00482  *  Invalid JSON:
00483  *   { "a": 42, "b": 100 }
00484  *   { "m": 101 }
00485  *
00486  *  struct X_B : X
00487  *  {
00488  *   int n;
00489  *  };
00490  *  DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(X_B, X)
00491  *  DECLARE_JSON_REQUIRED_FIELDS(X_B) // NO additional required fields
00492  *  DECLARE_JSON_OPTIONAL_FIELDS(X_B, n)
00493  *
00494  *  Valid JSON:
00495  *   { "a": 42, "b": 100 }
00496  *   { "a": 42, "b": 100, "n": 101 }
00497  *  Invalid JSON:
00498  *   { "n": 101 }
00499  *
00500  *  struct Z
00501  *  {
00502  *   int snake_case;
00503  *   std::string s;
00504  *  };
00505  *  DECLARE_JSON_TYPE(Z);
00506  *  DECLARE_JSON_REQUIRE_FIELDS_WITH_RENAMES(
00507  *    Z, snake_case, camelCase, s, msg);
00508  *
00509  *  Valid JSON:
00510  *   { "camelCase": 42, "msg": "Hello" }
00511  *   (converts to and from struct {snake_case: 42, s: "Hello"})
00512  *
00513  */
00514 
00515                   #define DECLARE_JSON_TYPE_IMPL( TYPE, PRE_TO_JSON, POST_TO_JSON, PRE_FROM_JSON, POST_FROM_JSON, PRE_FILL_SCHEMA, POST_FILL_SCHEMA, PRE_ADD_SCHEMA, POST_ADD_SCHEMA) 
00516 
00517 
00518 
00519 
00520 
00521 
00522 
00523 
00524 
00525 
00526 
00527 
00528 
00529 
00530 
00531 
00532 
00533 
00534 
00535 
00536 
00537 
00538 
00539 
00540 
00541 
00542 
00543 
00544 
00545 
00546 
00547 
00548 
00549 
00550 
00551 
00552 
00553 
00554 
00555 
00556 
00557 
00558 
00559 
00560 
00561 
00562 
00563 
00564 
00565 
00566 
00567 #define DECLARE_JSON_TYPE(TYPE) 
00568 
00569 #define DECLARE_JSON_TYPE_WITH_BASE(TYPE, BASE) 
00570 
00571 
00572 
00573 
00574 
00575 
00576 
00577 
00578 
00579 
00580 #define DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(TYPE) 
00581 
00582 
00583 
00584 
00585 
00586 
00587 
00588 
00589 
00590 
00591 
00592 #define DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(TYPE, BASE) 
00593 
00594 
00595 
00596 
00597 
00598 
00599 
00600 
00601 
00602 
00603 
00604 #define DECLARE_JSON_REQUIRED_FIELDS(TYPE, ...) 
00605 
00606 
00607 
00608 
00609 
00610 
00611 
00612 
00613 
00614 
00615 
00616 
00617 
00618 
00619 
00620 
00621 
00622 
00623 
00624 
00625 
00626 
00627 
00628 
00629 
00630 
00631 
00632 
00633 
00634 
00635 
00636 
00637 
00638 
00639 
00640 
00641 #define DECLARE_JSON_REQUIRED_FIELDS_WITH_RENAMES(TYPE, ...) 
00642 
00643 
00644 
00645 
00646 
00647 
00648 
00649 
00650 
00651 
00652 
00653 
00654 
00655 
00656 
00657 
00658 
00659 
00660 
00661 
00662 
00663 
00664 
00665 
00666 
00667 
00668 
00669 
00670 
00671 
00672 
00673 
00674 
00675 #define DECLARE_JSON_OPTIONAL_FIELDS(TYPE, ...) 
00676 
00677 
00678 
00679 
00680 
00681 
00682 
00683 
00684 
00685 
00686 
00687 
00688 
00689 
00690 
00691 
00692 
00693 
00694 
00695 
00696 
00697 
00698 #define DECLARE_JSON_OPTIONAL_FIELDS_WITH_RENAMES(TYPE, ...) 
00699 
00700 
00701 
00702 
00703 
00704 
00705 
00706 
00707 
00708 
00709 
00710 
00711 
00712 
00713 
00714 
00715 
00716 
00717 
00718 
00719 
00720 
00721 
00722 
00723 
00724 #define DECLARE_JSON_ENUM(TYPE, ...) 
00725 
00726 
00727 
00728 
00729 
00730 
00731 
00732 
00733 
00734 
00735 
00736 
00737 
00738 
00739 
00740 
00741 
---------
Macros accessible in this file:
---------
READ_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_FOR_JSON_NEXT DECLARE_JSON_TYPE_WITH_BASE DECLARE_JSON_REQUIRED_FIELDS_WITH_RENAMES _FOR_JSON_18_POP1 _FOR_JSON_18_POP2 WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_4_POP1 _FOR_JSON_4_POP2 FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_FINAL READ_REQUIRED_FOR_JSON_FINAL DECLARE_JSON_ENUM DECLARE_JSON_TYPE _FOR_JSON_14_POP1 _FOR_JSON_14_POP2 _FOR_JSON_0 _FOR_JSON_1 JSON_FIELD_FOR_JSON_NEXT _FOR_JSON_2 _FOR_JSON_3 _FOR_JSON_4 _FOR_JSON_5 _FOR_JSON_6 _FOR_JSON_7 _FOR_JSON_8 _FOR_JSON_9 _FOR_JSON_0_POP1 _FOR_JSON_0_POP2 DECLARE_JSON_OPTIONAL_FIELDS_WITH_RENAMES WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_7_POP1 _FOR_JSON_7_POP2 DECLARE_JSON_OPTIONAL_FIELDS READ_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL JSON_FIELD_FOR_JSON_FINAL _FOR_JSON_NEXT _FOR_JSON_20_POP1 _FOR_JSON_20_POP2 _FOR_JSON_17_POP1 _FOR_JSON_17_POP2 _FOR_JSON_12_POP1 _FOR_JSON_12_POP2 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS _FOR_JSON_3_POP1 _FOR_JSON_3_POP2 FILL_SCHEMA_REQUIRED_FOR_JSON_FINAL _FOR_JSON_COUNT_NN ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_FINAL _FOR_JSON_13_POP1 _FOR_JSON_13_POP2 WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_REQUIRED_FIELDS WRITE_OPTIONAL_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_NEXT WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT READ_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_11_POP1 _FOR_JSON_11_POP2 _FOR_JSON_COUNT_NN_WITH_0 FILL_SCHEMA_OPTIONAL_FOR_JSON_FINAL DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS READ_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_16_POP1 _FOR_JSON_16_POP2 ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_6_POP1 _FOR_JSON_6_POP2 ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_FINAL FMT_HEADER_ONLY WRITE_OPTIONAL_FOR_JSON_FINAL _FOR_JSON_19_POP1 _FOR_JSON_19_POP2 _FOR_JSON_2_POP1 _FOR_JSON_2_POP2 _FOR_JSON_9_POP1 _FOR_JSON_9_POP2 FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_TYPE_IMPL __FOR_JSON_COUNT_NN _FOR_JSON_FINAL _FOR_JSON_15_POP1 _FOR_JSON_15_POP2 READ_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_10_POP1 _FOR_JSON_10_POP2 _FOR_JSON_5_POP1 _FOR_JSON_5_POP2 READ_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_20 _FOR_JSON_10 _FOR_JSON_11 _FOR_JSON_12 ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_NEXT _FOR_JSON_13 _FOR_JSON_14 _FOR_JSON_15 _FOR_JSON_16 _FOR_JSON_17 _FOR_JSON_18 _FOR_JSON_19 READ_OPTIONAL_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_1_POP1 _FOR_JSON_1_POP2 _FOR_JSON_8_POP1 _FOR_JSON_8_POP2 
---------
Parsing file /data/git/CCF/src/ds/json.h...
Preprocessing /data/git/CCF/src/ds/json_schema.h...
#include ds/nonstd.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 7214 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 #define FMT_HEADER_ONLY
00008 
00009 
00010 
00011 namespace ds
00012 {
00013   namespace json
00014   {
00015     struct JsonSchema
00016     {
00017       static constexpr auto hyperschema =
00018         "http://json-schema.org/draft-07/schema#";
00019 
00020       nlohmann::json schema;
00021     };
00022 
00023     inline void to_json(nlohmann::json& j, const JsonSchema& s)
00024     {
00025       j = s.schema;
00026     }
00027 
00028     inline void from_json(const nlohmann::json& j, JsonSchema& s)
00029     {
00030       s.schema = j;
00031     }
00032 
00033     template <typename T>
00034     inline void fill_number_schema(nlohmann::json& schema)
00035     {
00036       schema["type"] = "integer";
00037       schema["minimum"] = std::numeric_limits<T>::min();
00038       schema["maximum"] = std::numeric_limits<T>::max();
00039     }
00040 
00041     template <typename T>
00042     std::string schema_name();
00043 
00044     template <typename T>
00045     void fill_schema(nlohmann::json& schema);
00046 
00047     template <typename T>
00048     void fill_json_schema(nlohmann::json& j, const T& t);
00049 
00050     template <typename T>
00051     nlohmann::json schema_element()
00052     {
00053       auto element = nlohmann::json::object();
00054       fill_schema<T>(element);
00055       return element;
00056     }
00057 
00058     template <typename T, typename Doc>
00059     nlohmann::json schema_element()
00060     {
00061       auto element = nlohmann::json::object();
00062       fill_schema<T>(element);
00063       return element;
00064     }
00065 
00066     namespace adl
00067     {
00068       template <typename T>
00069       std::string schema_name()
00070       {
00071         T t;
00072         return schema_name(t);
00073       }
00074 
00075       template <typename T>
00076       void fill_schema(nlohmann::json& schema)
00077       {
00078         T t;
00079         if constexpr (std::is_enum<T>::value)
00080         {
00081           fill_enum_schema(schema, t);
00082         }
00083         else
00084         {
00085           fill_json_schema(schema, t);
00086         }
00087       }
00088     }
00089 
00090     template <typename T>
00091     inline std::string schema_name()
00092     {
00093       if constexpr (nonstd::is_specialization<T, std::optional>::value)
00094       {
00095         return schema_name<typename T::value_type>();
00096       }
00097       else if constexpr (nonstd::is_specialization<T, std::vector>::value)
00098       {
00099         return fmt::format("{}_array", schema_name<typename T::value_type>());
00100       }
00101       else if constexpr (
00102         nonstd::is_specialization<T, std::map>::value ||
00103         nonstd::is_specialization<T, std::unordered_map>::value)
00104       {
00105         if (std::is_same<typename T::key_type, std::string>::value)
00106         {
00107           return fmt::format(
00108             "named_{}", schema_name<typename T::mapped_type>());
00109         }
00110         else
00111         {
00112           return fmt::format(
00113             "{}_to_{}",
00114             schema_name<typename T::key_type>(),
00115             schema_name<typename T::mapped_type>());
00116         }
00117       }
00118       else if constexpr (nonstd::is_specialization<T, std::pair>::value)
00119       {
00120         return fmt::format(
00121           "{}_and_{}",
00122           schema_name<typename T::first_type>(),
00123           schema_name<typename T::second_type>());
00124       }
00125       else if constexpr (std::is_same<T, std::string>::value)
00126       {
00127         return "string";
00128       }
00129       else if constexpr (std::is_same<T, bool>::value)
00130       {
00131         return "boolean";
00132       }
00133       else if constexpr (std::is_same<T, uint8_t>::value)
00134       {
00135         return "uint8";
00136       }
00137       else if constexpr (std::is_same<T, uint16_t>::value)
00138       {
00139         return "uint16";
00140       }
00141       else if constexpr (std::is_same<T, uint32_t>::value)
00142       {
00143         return "uint32";
00144       }
00145       else if constexpr (std::is_same<T, uint64_t>::value)
00146       {
00147         return "uint64";
00148       }
00149       else if constexpr (std::is_same<T, int8_t>::value)
00150       {
00151         return "int8";
00152       }
00153       else if constexpr (std::is_same<T, int16_t>::value)
00154       {
00155         return "int16";
00156       }
00157       else if constexpr (std::is_same<T, int32_t>::value)
00158       {
00159         return "int32";
00160       }
00161       else if constexpr (std::is_same<T, int64_t>::value)
00162       {
00163         return "int64";
00164       }
00165       else if constexpr (std::is_same<T, float>::value)
00166       {
00167         return "float";
00168       }
00169       else if constexpr (std::is_same<T, double>::value)
00170       {
00171         return "double";
00172       }
00173       else if constexpr (std::is_same<T, nlohmann::json>::value)
00174       {
00175         return "json";
00176       }
00177       else if constexpr (std::is_same<T, JsonSchema>::value)
00178       {
00179         return "json_schema";
00180       }
00181       else
00182       {
00183         return adl::schema_name<T>();
00184       }
00185     }
00186 
00187     template <typename T>
00188     inline void fill_schema(nlohmann::json& schema)
00189     {
00190       if constexpr (nonstd::is_specialization<T, std::optional>::value)
00191       {
00192         fill_schema<typename T::value_type>(schema);
00193       }
00194       else if constexpr (nonstd::is_specialization<T, std::vector>::value)
00195       {
00196         schema["type"] = "array";
00197         schema["items"] = schema_element<typename T::value_type>();
00198       }
00199       else if constexpr (
00200         nonstd::is_specialization<T, std::map>::value ||
00201         nonstd::is_specialization<T, std::unordered_map>::value)
00202       {
00203         // Nlohmann serialises maps to an array of (K, V) pairs...
00204         if (std::is_same<typename T::key_type, std::string>::value)
00205         {
00206           // ...unless the keys are strings!
00207           schema["type"] = "object";
00208           schema["additionalProperties"] =
00209             schema_element<typename T::mapped_type>();
00210         }
00211         else
00212         {
00213           schema["type"] = "array";
00214           auto items = nlohmann::json::object();
00215           {
00216             items["type"] = "array";
00217 
00218             auto sub_items = nlohmann::json::array();
00219             sub_items.push_back(schema_element<typename T::key_type>());
00220             sub_items.push_back(schema_element<typename T::mapped_type>());
00221             items["items"] = sub_items;
00222           }
00223           schema["items"] = items;
00224         }
00225       }
00226       else if constexpr (nonstd::is_specialization<T, std::pair>::value)
00227       {
00228         schema["type"] = "array";
00229         auto items = nlohmann::json::array();
00230         items.push_back(schema_element<typename T::first_type>());
00231         items.push_back(schema_element<typename T::second_type>());
00232         schema["items"] = items;
00233       }
00234       else if constexpr (std::is_same<T, std::string>::value)
00235       {
00236         schema["type"] = "string";
00237       }
00238       else if constexpr (std::is_same<T, bool>::value)
00239       {
00240         schema["type"] = "boolean";
00241       }
00242       else if constexpr (std::is_same<T, nlohmann::json>::value)
00243       {
00244         // Any field that contains more json is completely unconstrained, so we
00245         // do not add a type or any other fields
00246         schema = nlohmann::json::object();
00247       }
00248       else if constexpr (std::is_integral<T>::value)
00249       {
00250         fill_number_schema<T>(schema);
00251       }
00252       else if constexpr (std::is_floating_point<T>::value)
00253       {
00254         schema["type"] = "number";
00255       }
00256       else if constexpr (std::is_same<T, JsonSchema>::value)
00257       {
00258         schema["type"] = "object";
00259       }
00260       else
00261       {
00262         adl::fill_schema<T>(schema);
00263       }
00264     }
00265 
00266     template <typename T>
00267     inline nlohmann::json build_schema(const std::string& title)
00268     {
00269       nlohmann::json schema;
00270       schema["title"] = title;
00271 
00272       fill_schema<T>(schema);
00273 
00274       return schema;
00275     }
00276   }
00277 }
00278 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/ds/json_schema.h...
Preprocessing /data/git/CCF/src/ds/logger.h...
#include logger_formatters.h: already included! skipping...
#include ring_buffer.h: already included! skipping...
#include thread_ids.h: already included! skipping...
#include chrono: not found! skipping...
#include cstring: not found! skipping...
#include ctime: not found! skipping...
#include fmt/chrono.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include fstream: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include memory: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include optional: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include thread: not found! skipping...
Preprocessor output (size: 11944 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 #define FMT_HEADER_ONLY
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 namespace logger
00026 {
00027   enum Level
00028   {
00029     TRACE = 0,
00030     DEBUG, // events useful for debugging
00031     INFO, // important events that should be logged even in release mode
00032     FAIL, // important failures that should always be logged
00033     FATAL, // fatal errors that lead to a termination of the program/enclave
00034     MAX_LOG_LEVEL
00035   };
00036 
00037   static constexpr long int ns_per_s = 1'000'000'000;
00038 
00039   class AbstractLogger
00040   {
00041   protected:
00042     std::string log_path;
00043     std::ofstream f;
00044 
00045   public:
00046     AbstractLogger() = default;
00047     AbstractLogger(std::string log_path_) : log_path(log_path_)
00048     {
00049       f.open(log_path, std::ios_base::app);
00050     }
00051     virtual ~AbstractLogger() = default;
00052 
00053     std::string get_timestamp(const std::tm& tm, const ::timespec& ts)
00054     {
00055       // Sample: "2019-07-19 18:53:25.690267"
00056       return fmt::format("{:%Y-%m-%dT%H:%M:%S}.{:0>6}Z", tm, ts.tv_nsec / 1000);
00057     }
00058 
00059     virtual std::string format(
00060       const std::string& file_name,
00061       size_t line_number,
00062       const std::string& log_level,
00063       const std::string& msg,
00064       const std::tm& host_tm,
00065       const ::timespec& host_ts,
00066       uint16_t thread_id,
00067       const std::optional<::timespec>& enclave_ts = std::nullopt) = 0;
00068 
00069     virtual void write(const std::string& log_line) = 0;
00070 
00071     void dump(const std::string& msg)
00072     {
00073       f << msg << std::endl;
00074     }
00075 
00076     virtual std::ostream& get_stream()
00077     {
00078       return f;
00079     }
00080   };
00081 
00082   class JsonConsoleLogger : public AbstractLogger
00083   {
00084   public:
00085     std::string format(
00086       const std::string& file_name,
00087       size_t line_number,
00088       const std::string& log_level,
00089       const std::string& msg,
00090       const std::tm& host_tm,
00091       const ::timespec& host_ts,
00092       uint16_t thread_id,
00093       const std::optional<::timespec>& enclave_ts = std::nullopt) override
00094     {
00095       nlohmann::json j;
00096       j["m"] = msg;
00097 
00098       if (enclave_ts.has_value())
00099       {
00100         std::tm enclave_tm;
00101         auto enc_ts = enclave_ts.value();
00102         ::timespec_get(&enc_ts, TIME_UTC);
00103         ::gmtime_r(&enc_ts.tv_sec, &enclave_tm);
00104 
00105         return fmt::format(
00106           "{{\"h_ts\":\"{}\",\"e_ts\":\"{}\",\"thread_id\":\"{}\",\"level\":\"{"
00107           "}\",\"file\":\"{}\","
00108           "\"number\":\"{}\","
00109           "\"msg\":{}}}",
00110           get_timestamp(host_tm, host_ts),
00111           get_timestamp(enclave_tm, enc_ts),
00112           thread_id,
00113           log_level,
00114           file_name,
00115           line_number,
00116           j["m"].dump());
00117       }
00118 
00119       return fmt::format(
00120         "{{\"h_ts\":\"{}\",\"thread_id\":\"{}\",\"level\":\"{}\",\"file\":\"{}"
00121         "\",\"number\":\"{}\","
00122         "\"msg\":{}}}",
00123         get_timestamp(host_tm, host_ts),
00124         thread_id,
00125         log_level,
00126         file_name,
00127         line_number,
00128         j["m"].dump());
00129     }
00130 
00131     virtual void write(const std::string& log_line) override
00132     {
00133       std::cout << log_line;
00134     }
00135 
00136     std::ostream& get_stream() override
00137     {
00138       return std::cout;
00139     }
00140   };
00141 
00142   class ConsoleLogger : public AbstractLogger
00143   {
00144   public:
00145     std::string format(
00146       const std::string& file_name,
00147       size_t line_number,
00148       const std::string& log_level,
00149       const std::string& msg,
00150       const std::tm& host_tm,
00151       const ::timespec& host_ts,
00152       uint16_t thread_id,
00153       const std::optional<::timespec>& enclave_ts = std::nullopt) override
00154     {
00155       auto file_line = fmt::format("{}:{}", file_name, line_number);
00156       auto file_line_data = file_line.data();
00157 
00158       // Truncate to final characters - if too long, advance char*
00159       constexpr auto max_len = 36u;
00160 
00161       const auto len = file_line.size();
00162       if (len > max_len)
00163         file_line_data += len - max_len;
00164 
00165       if (enclave_ts.has_value())
00166       {
00167         // Sample: "2019-07-19 18:53:25.690183 -0.130 " where -0.130 indicates
00168         // that the time inside the enclave was 130 milliseconds earlier than
00169         // the host timestamp printed on the line
00170         return fmt::format(
00171           "{} -{}.{:0>3} {:<3} [{:<5}] {:<36} | {}",
00172           get_timestamp(host_tm, host_ts),
00173           enclave_ts.value().tv_sec,
00174           enclave_ts.value().tv_nsec / 1000000,
00175           thread_id,
00176           log_level,
00177           file_line_data,
00178           msg);
00179       }
00180       else
00181       {
00182         // Padding on the right to align the rest of the message
00183         // with lines that contain enclave time offsets
00184         return fmt::format(
00185           "{}        {:<3} [{:<5}] {:<36} | {}",
00186           get_timestamp(host_tm, host_ts),
00187           thread_id,
00188           log_level,
00189           file_line_data,
00190           msg);
00191       }
00192     }
00193 
00194     void write(const std::string& log_line) override
00195     {
00196       std::cout << log_line << std::flush;
00197     }
00198 
00199     std::ostream& get_stream() override
00200     {
00201       return std::cout;
00202     }
00203   };
00204 
00205   class config
00206   {
00207   public:
00208     static constexpr const char* LevelNames[] = {
00209       "trace", "debug", "info", "fail", "fatal"};
00210 
00211     static const char* to_string(Level l)
00212     {
00213       return LevelNames[static_cast<int>(l)];
00214     }
00215 
00216     static std::optional<Level> to_level(const char* s)
00217     {
00218       for (int i = TRACE; i < MAX_LOG_LEVEL; i++)
00219       {
00220         if (std::strcmp(s, LevelNames[i]) == 0)
00221           return (Level)i;
00222       }
00223 
00224       return {};
00225     }
00226 
00227     static inline std::vector<std::unique_ptr<AbstractLogger>>& loggers()
00228     {
00229       std::vector<std::unique_ptr<AbstractLogger>>& the_loggers = get_loggers();
00230       try_initialize();
00231       return the_loggers;
00232     }
00233 
00234     static inline void initialize_with_json_console()
00235     {
00236       std::vector<std::unique_ptr<AbstractLogger>>& the_loggers = get_loggers();
00237       if (the_loggers.size() > 0)
00238       {
00239         the_loggers.front() = std::make_unique<JsonConsoleLogger>();
00240       }
00241       else
00242       {
00243         the_loggers.emplace_back(std::make_unique<JsonConsoleLogger>());
00244       }
00245     }
00246 
00247     static inline Level& level()
00248     {
00249       static Level the_level =
00250 
00251 
00252 
00253         Level::INFO
00254 
00255         ;
00256 
00257       return the_level;
00258     }
00259 
00260 
00261 
00262 
00263 
00264 
00265 
00266 
00267 
00268 
00269 
00270 
00271 
00272 
00273 
00274 
00275 
00276 
00277 
00278 
00279 
00280 
00281 
00282 
00283 
00284 
00285 
00286 
00287     // Timestamp of first tick. Used by the host when receiving log messages
00288     // from the enclave. Combined with the elapsed ms reported by the enclave,
00289     // and used to compute the offset between time inside the enclave, and time
00290     // on the host when the log message is received.
00291     static ::timespec start;
00292 
00293     static void set_start(
00294       const std::chrono::time_point<std::chrono::system_clock>& start_)
00295     {
00296       start.tv_sec = std::chrono::time_point_cast<std::chrono::seconds>(start_)
00297                        .time_since_epoch()
00298                        .count();
00299       start.tv_nsec =
00300         std::chrono::time_point_cast<std::chrono::nanoseconds>(start_)
00301           .time_since_epoch()
00302           .count() -
00303         start.tv_sec * ns_per_s;
00304     }
00305 
00306 
00307     static inline bool ok(Level l)
00308     {
00309       return l >= level();
00310     }
00311 
00312   private:
00313     static inline void try_initialize()
00314     {
00315       std::vector<std::unique_ptr<AbstractLogger>>& the_loggers = get_loggers();
00316       if (the_loggers.size() == 0)
00317       {
00318         the_loggers.emplace_back(std::make_unique<ConsoleLogger>());
00319       }
00320     }
00321 
00322     static inline std::vector<std::unique_ptr<AbstractLogger>>& get_loggers()
00323     {
00324       static std::vector<std::unique_ptr<AbstractLogger>> the_loggers;
00325       return the_loggers;
00326     }
00327   };
00328 
00329   class LogLine
00330   {
00331   private:
00332     friend struct Out;
00333     std::ostringstream ss;
00334     Level log_level;
00335     std::string file_name;
00336     size_t line_number;
00337     std::string ll_str;
00338     std::string msg;
00339     uint16_t thread_id;
00340 
00341   public:
00342     LogLine(Level ll, const char* file_name, size_t line_number) :
00343       log_level(ll),
00344       file_name(file_name),
00345       line_number(line_number),
00346 
00347 
00348 
00349       thread_id(100)
00350 
00351     {}
00352 
00353     template <typename T>
00354     LogLine& operator<<(const T& item)
00355     {
00356       ss << item;
00357       return *this;
00358     }
00359 
00360     LogLine& operator<<(std::ostream& (*f)(std::ostream&))
00361     {
00362       ss << f;
00363       return *this;
00364     }
00365 
00366     void finalize()
00367     {
00368       msg = ss.str();
00369     }
00370   };
00371 
00372 
00373 
00374 
00375 
00376 
00377 
00378 
00379 
00380 
00381 
00382 
00383 
00384 
00385 
00386 
00387 
00388 
00389 
00390 
00391   struct Out
00392   {
00393     bool operator==(LogLine& line)
00394     {
00395       line.finalize();
00396       write(
00397         line.file_name,
00398         line.line_number,
00399         line.log_level,
00400         line.thread_id,
00401         line.msg);
00402 
00403       return true;
00404     }
00405 
00406     static void write(
00407       const std::string& file_name,
00408       size_t line_number,
00409       const Level& log_level,
00410       uint16_t thread_id,
00411       const std::string& msg)
00412     {
00413       // When logging from host code, print local time.
00414       ::timespec ts;
00415       ::timespec_get(&ts, TIME_UTC);
00416       std::tm now;
00417       ::gmtime_r(&ts.tv_sec, &now);
00418 
00419       for (auto const& logger : config::loggers())
00420       {
00421         logger->write(logger->format(
00422           file_name,
00423           line_number,
00424           config::to_string(log_level),
00425           msg,
00426           now,
00427           ts,
00428           thread_id));
00429       }
00430     }
00431 
00432     static void write(
00433       const std::string& file_name,
00434       size_t line_number,
00435       const Level& log_level,
00436       uint16_t thread_id,
00437       const std::string& msg,
00438       size_t ms_offset_from_start)
00439     {
00440       // When logging messages received from the enclave, print local time,
00441       // and the offset to time inside the enclave at the time the message
00442       // was logged there.
00443       // Not thread-safe (uses std::localtime)
00444       ::timespec ts;
00445       ::timespec_get(&ts, TIME_UTC);
00446       std::tm now;
00447       ::gmtime_r(&ts.tv_sec, &now);
00448       time_t elapsed_s = ms_offset_from_start / 1000;
00449       ssize_t elapsed_ns = (ms_offset_from_start % 1000) * 1000000;
00450 
00451       // Enclave time is recomputed every time. If multiple threads
00452       // log inside the enclave, offsets may not always increase
00453       ::timespec enclave_ts{logger::config::start.tv_sec + elapsed_s,
00454                             logger::config::start.tv_nsec + elapsed_ns};
00455 
00456       if (enclave_ts.tv_nsec > ns_per_s)
00457       {
00458         enclave_ts.tv_sec++;
00459         enclave_ts.tv_nsec -= ns_per_s;
00460       }
00461 
00462       // We assume time in the enclave is behind (less than) time on the host.
00463       // This would reliably be the case if we used a monotonic clock,
00464       // but we want human-readable wall-clock time. Inaccurate offsets may
00465       // occasionally occur as a result.
00466       enclave_ts.tv_sec = ts.tv_sec - enclave_ts.tv_sec;
00467       enclave_ts.tv_nsec = ts.tv_nsec - enclave_ts.tv_nsec;
00468       if (enclave_ts.tv_nsec < 0)
00469       {
00470         enclave_ts.tv_sec--;
00471         enclave_ts.tv_nsec += ns_per_s;
00472       }
00473 
00474       for (auto const& logger : config::loggers())
00475       {
00476         logger->write(logger->format(
00477           file_name,
00478           line_number,
00479           config::to_string(log_level),
00480           msg,
00481           now,
00482           ts,
00483           thread_id,
00484           enclave_ts));
00485       }
00486 
00487       if (log_level == Level::FATAL)
00488         throw std::logic_error(
00489           "Fatal: " +
00490           config::loggers().front()->format(
00491             file_name,
00492             line_number,
00493             config::to_string(log_level),
00494             msg,
00495             now,
00496             ts,
00497             thread_id,
00498             enclave_ts));
00499     }
00500   };
00501 
00502 
00503   // The == operator is being used to:
00504   // 1. Be a lower precedence than <<, such that using << on the LogLine will
00505   // happen before the LogLine is "equalitied" with the Out.
00506   // 2. Be a higher precedence than &&, such that the log statement is bound
00507   // more tightly than the short-circuiting.
00508   // This allows:
00509   // LOG_DEBUG << "info" << std::endl;
00510 
00511 
00512 
00513 
00514 #define LOG_TRACE
00515 
00516 
00517 #define LOG_TRACE_FMT(s, ...) 
00518 
00519 
00520 #define LOG_DEBUG
00521 
00522 
00523 #define LOG_DEBUG_FMT(s, ...) 
00524 
00525 
00526 #define LOG_INFO
00527 
00528 
00529 #define LOG_INFO_FMT(s, ...) 
00530 
00531 
00532 #define LOG_FAIL
00533 
00534 
00535 #define LOG_FAIL_FMT(s, ...) 
00536 
00537 
00538 #define LOG_FATAL
00539 
00540 
00541 #define LOG_FATAL_FMT(s, ...) 
00542 
00543 
00544 // Convenient wrapper to report exception errors. Exception message is only
00545 // displayed in debug mode
00546 #define LOG_FAIL_EXC(msg) 
00547 
00548 
00549 
00550 
00551 
00552 
00553 
00554 }
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL_FMT LOG_FAIL LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/logger.h...
Preprocessing /data/git/CCF/src/ds/logger_formatters.h...
#include fmt/format.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include sstream: not found! skipping...
Preprocessor output (size: 1171 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define FMT_HEADER_ONLY
00006 
00007 
00008 
00009 
00010 namespace fmt
00011 {
00012   inline std::string uint8_vector_to_hex_string(const std::vector<uint8_t>& v)
00013   {
00014     std::stringstream ss;
00015     for (auto it = v.begin(); it != v.end(); it++)
00016     {
00017       ss << std::hex << static_cast<unsigned>(*it);
00018     }
00019 
00020     return ss.str();
00021   }
00022 
00023   template <>
00024   struct formatter<std::vector<uint8_t>>
00025   {
00026     template <typename ParseContext>
00027     constexpr auto parse(ParseContext& ctx)
00028     {
00029       return ctx.begin();
00030     }
00031 
00032     template <typename FormatContext>
00033     auto format(const std::vector<uint8_t>& p, FormatContext& ctx)
00034     {
00035       return format_to(ctx.out(), uint8_vector_to_hex_string(p));
00036     }
00037   };
00038 
00039   template <>
00040   struct formatter<std::array<uint8_t, 32>>
00041   {
00042     template <typename ParseContext>
00043     constexpr auto parse(ParseContext& ctx)
00044     {
00045       return ctx.begin();
00046     }
00047 
00048     template <typename FormatContext>
00049     auto format(const std::array<uint8_t, 32>& p, FormatContext& ctx)
00050     {
00051       return format_to(
00052         ctx.out(), uint8_vector_to_hex_string({p.begin(), p.end()}));
00053     }
00054   };
00055 }
00056 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/ds/logger_formatters.h...
Preprocessing /data/git/CCF/src/ds/messaging.h...
#include logger.h: already included! skipping...
#include ring_buffer.h: already included! skipping...
#include mutex: not found! skipping...
#include atomic: not found! skipping...
#include condition_variable: not found! skipping...
#include map: not found! skipping...
#include stdexcept: not found! skipping...
Preprocessor output (size: 7141 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 # 7 "/data/git/CCF/src/ds/messaging.h" 2
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace messaging
00015 {
00016   using Handler = std::function<void(const uint8_t*, size_t)>;
00017 
00018   class no_handler : public std::logic_error
00019   {
00020     using logic_error::logic_error;
00021   };
00022 
00023   class already_handled : public std::logic_error
00024   {
00025     using logic_error::logic_error;
00026   };
00027 
00028   struct Counts
00029   {
00030     size_t messages;
00031     size_t bytes;
00032   };
00033 
00034   template <typename MessageType>
00035   using MessageCounts = std::unordered_map<MessageType, Counts>;
00036 
00037   template <typename MessageType>
00038   class Dispatcher
00039   {
00040   public:
00041     using MessageCounts = MessageCounts<MessageType>;
00042 
00043   private:
00044     // Store a name to distinguish error messages
00045     char const* const name;
00046 
00047     std::map<MessageType, Handler> handlers;
00048     std::map<MessageType, char const*> message_labels;
00049 
00050     MessageCounts message_counts;
00051 
00052     std::string get_error_prefix()
00053     {
00054       return std::string("[") + std::string(name) + std::string("] ");
00055     }
00056 
00057     char const* get_message_name(MessageType m)
00058     {
00059       const auto it = message_labels.find(m);
00060       if (it == message_labels.end())
00061       {
00062         return "unknown";
00063       }
00064 
00065       return it->second;
00066     }
00067 
00068     static std::string decorate_message_name(MessageType m, char const* s)
00069     {
00070       return fmt::format("<{}:{}>", s, m);
00071     }
00072 
00073     std::string get_decorated_message_name(MessageType m)
00074     {
00075       return decorate_message_name(m, get_message_name(m));
00076     }
00077 
00078   public:
00079     Dispatcher(char const* name) : name(name), handlers() {}
00080 
00081     /** Set a callback for this message type
00082      *
00083      * Each message type may have a single handler registered at a time. Every
00084      * time a message with this type is encountered, the handler will receive a
00085      * callback with the raw message data.
00086      *
00087      * The handler will remain registered and continue to receive messages until
00088      * it is explicitly removed by a call to remove_message_handler.
00089      *
00090      * @throws already_handled if a handler is already registered for
00091      * this type.
00092      */
00093     void set_message_handler(
00094       MessageType m, char const* message_label, Handler h)
00095     {
00096       // Check for presence first, so we only copy if we're actually inserting
00097       auto it = handlers.find(m);
00098       if (it != handlers.end())
00099       {
00100         throw already_handled(
00101           get_error_prefix() + "MessageType " + std::to_string(m) +
00102           " already handled by " + get_decorated_message_name(m) +
00103           ", cannot set handler for " +
00104           decorate_message_name(m, message_label));
00105       }
00106 
00107       LOG_DEBUG_FMT("Setting handler for {} ({})", message_label, m);
00108       handlers.insert(it, {m, h});
00109 
00110       if (message_label != nullptr)
00111       {
00112         message_labels.emplace(m, message_label);
00113       }
00114     }
00115 
00116     /** Remove the callback for this message type
00117      *
00118      * The handler will be erased and will not receive any future messages
00119      * from this Dispatcher.
00120      *
00121      * @throws no_handler if no handler is registered for this type.
00122      */
00123     void remove_message_handler(MessageType m)
00124     {
00125       auto it = handlers.find(m);
00126       if (it == handlers.end())
00127       {
00128         throw no_handler(
00129           get_error_prefix() +
00130           "Can't remove non-existent handler for this message: " +
00131           get_decorated_message_name(m));
00132       }
00133 
00134       handlers.erase(it);
00135     }
00136 
00137     /** Is handler already registered for this message type
00138      *
00139      * @returns true iff there is an active handler for type, which has not
00140      * been removed.
00141      */
00142     bool has_handler(MessageType m)
00143     {
00144       return handlers.find(m) != handlers.end();
00145     }
00146 
00147     /** Dispatch a single message
00148      *
00149      * If there is a handler registered for this type, it will be called with
00150      * the given message body.
00151      *
00152      * @throws no_handler if no handler is registered for this type.
00153      */
00154     void dispatch(MessageType m, const uint8_t* data, size_t size)
00155     {
00156       auto it = handlers.find(m);
00157       if (it == handlers.end())
00158       {
00159         throw no_handler(
00160           get_error_prefix() +
00161           "No handler for this message: " + get_decorated_message_name(m));
00162       }
00163 
00164       // Handlers may register or remove handlers, so iterator is invalidated
00165       it->second(data, size);
00166 
00167       auto& counts = message_counts[m];
00168       counts.messages++;
00169       counts.bytes += size;
00170     }
00171 
00172     MessageCounts retrieve_message_counts()
00173     {
00174       MessageCounts current;
00175       std::swap(message_counts, current);
00176       return current;
00177     }
00178 
00179     nlohmann::json convert_message_counts(const MessageCounts& mc)
00180     {
00181       auto j = nlohmann::json::object();
00182       for (const auto& it : mc)
00183       {
00184         j[get_message_name(it.first)] = {{"count", it.second.messages},
00185                                          {"bytes", it.second.bytes}};
00186       }
00187       return j;
00188     }
00189   };
00190 
00191   using RingbufferDispatcher = Dispatcher<ringbuffer::Message>;
00192 
00193   using IdleBehaviour = std::function<void(size_t num_consecutive_idles)>;
00194   static inline void default_idle_behaviour(size_t)
00195   {
00196     CCF_PAUSE();
00197   }
00198 
00199   class BufferProcessor
00200   {
00201     RingbufferDispatcher dispatcher;
00202     std::atomic<bool> finished;
00203 
00204   public:
00205     BufferProcessor(char const* name = "") : dispatcher(name), finished(false)
00206     {}
00207 
00208     RingbufferDispatcher& get_dispatcher()
00209     {
00210       return dispatcher;
00211     }
00212 
00213     template <typename... Ts>
00214     void set_message_handler(Ts&&... ts)
00215     {
00216       dispatcher.set_message_handler(std::forward<Ts>(ts)...);
00217     }
00218 
00219     void set_finished(bool v = true)
00220     {
00221       finished.store(v);
00222     }
00223 
00224     bool get_finished()
00225     {
00226       return finished.load();
00227     }
00228 
00229     size_t read_n(size_t max_messages, ringbuffer::Reader& r)
00230     {
00231       size_t total_read = 0;
00232 
00233       while (!finished.load() && total_read < max_messages)
00234       {
00235         // Read one at a time so we don't process any after being told to stop
00236         auto read = r.read(
00237           1,
00238           [& d = dispatcher](
00239             ringbuffer::Message m, const uint8_t* data, size_t size) {
00240             d.dispatch(m, data, size);
00241           });
00242 
00243         total_read += read;
00244 
00245         if (read == 0)
00246         {
00247           break;
00248         }
00249       }
00250 
00251       return total_read;
00252     };
00253 
00254     size_t run(
00255       ringbuffer::Reader& r, IdleBehaviour idler = default_idle_behaviour)
00256     {
00257       size_t total_read = 0;
00258       size_t consecutive_idles = 0u;
00259 
00260       while (!finished.load())
00261       {
00262         auto num_read = read_n(-1, r);
00263         total_read += num_read;
00264 
00265         if (num_read == 0)
00266         {
00267           idler(consecutive_idles++);
00268         }
00269         else
00270         {
00271           consecutive_idles = 0;
00272         }
00273       }
00274 
00275       return total_read;
00276     }
00277   };
00278 
00279   // The last variadic argument is expected to be the handler itself. It is
00280   // variadic so that you can use an inline lambda, _with commas_. The
00281   // preprocessor will blindly paste this as (what it thinks are) multiple
00282   // arguments to set_message_handler, and the real processor will recognise
00283   // will read it as the original lambda.
00284 #define DISPATCHER_SET_MESSAGE_HANDLER(DISP, MSG, ...) 
00285 
00286 }
00287 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE DISPATCHER_SET_MESSAGE_HANDLER LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/messaging.h...
Preprocessing /data/git/CCF/src/ds/msgpack_adaptor_nlohmann.h...
#include msgpack/msgpack.hpp: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 1415 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace msgpack
00009 {
00010   MSGPACK_API_VERSION_NAMESPACE(MSGPACK_DEFAULT_API_NS)
00011   {
00012     namespace adaptor
00013     {
00014       // Both pack and convert involve unnecessary copies. If this
00015       // nlohmann::json issue is accepted, we can write custom input_adapter and
00016       // output_adapter to read/write directly from msgpack objects.
00017       // https://github.com/nlohmann/json/issues/1534
00018       template <>
00019       struct pack<nlohmann::json>
00020       {
00021         template <typename Stream>
00022         msgpack::packer<Stream>& operator()(
00023           msgpack::packer<Stream>& o, const nlohmann::json& j) const
00024         {
00025           const auto packed = nlohmann::json::to_msgpack(j);
00026 
00027           o.pack_bin(packed.size());
00028           o.pack_bin_body(
00029             reinterpret_cast<const char*>(packed.data()), packed.size());
00030 
00031           return o;
00032         }
00033       };
00034 
00035       template <>
00036       struct convert<nlohmann::json>
00037       {
00038         const msgpack::object& operator()(
00039           const msgpack::object& o, nlohmann::json& j) const
00040         {
00041           if ((o.type) != msgpack::type::BIN)
00042           {
00043             throw msgpack::type_error();
00044           }
00045 
00046           std::vector<uint8_t> v(o.via.bin.ptr, o.via.bin.ptr + o.via.bin.size);
00047           j = nlohmann::json::from_msgpack(v);
00048 
00049           return o;
00050         }
00051       };
00052     }
00053   }
00054 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/msgpack_adaptor_nlohmann.h...
Preprocessing /data/git/CCF/src/ds/net.h...
#include arpa/inet.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 828 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006  // For inet_addr()
00007 #define FMT_HEADER_ONLY
00008 
00009 
00010 
00011 namespace ds
00012 {
00013   static constexpr size_t ipv4_binary_size = 4;
00014   static constexpr size_t ipv6_binary_size = 16;
00015 
00016   struct IPAddr
00017   {
00018     char buf[ipv6_binary_size]; // Large enough buffer to hold IPv6
00019     size_t size;
00020   };
00021 
00022   inline std::optional<IPAddr> ip_to_binary(const char* hostname)
00023   {
00024     IPAddr ip_bin;
00025     ip_bin.size = ipv4_binary_size;
00026     if (inet_pton(AF_INET, hostname, ip_bin.buf) != 1)
00027     {
00028       ip_bin.size = ipv6_binary_size;
00029       if (inet_pton(AF_INET6, hostname, ip_bin.buf) != 1)
00030       {
00031         return {};
00032       }
00033     }
00034     return ip_bin;
00035   }
00036 
00037   inline bool is_valid_ip(const char* hostname)
00038   {
00039     return ip_to_binary(hostname).has_value();
00040   }
00041 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/ds/net.h...
Preprocessing /data/git/CCF/src/ds/non_blocking.h...
#include ring_buffer.h: already included! skipping...
#include deque: not found! skipping...
#include fmt/format.h: not found! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 7200 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 #define FMT_HEADER_ONLY
00009 
00010 
00011 
00012 
00013 namespace ringbuffer
00014 {
00015   // This wraps an underlying Writer implementation and ensure calls to write()
00016   // will not block indefinitely. This never calls the blocking write()
00017   // implementation. Instead it calls try_write(), and in the case that a write
00018   // fails (because the target ringbuffer is full), the message is placed in a
00019   // pending queue. These pending message must be flushed regularly, attempting
00020   // again to write to the ringbuffer.
00021 
00022   class NonBlockingWriter : public AbstractWriter
00023   {
00024   private:
00025     WriterPtr underlying_writer;
00026 
00027     struct PendingMessage
00028     {
00029       Message m;
00030       size_t marker;
00031       bool finished;
00032       std::vector<uint8_t> buffer;
00033 
00034       PendingMessage(Message m_, std::vector<uint8_t>&& buffer_) :
00035         m(m_),
00036         marker(0),
00037         finished(false),
00038         buffer(buffer_)
00039       {}
00040     };
00041 
00042     std::deque<PendingMessage> pending;
00043 
00044   public:
00045     NonBlockingWriter(const WriterPtr& writer) : underlying_writer(writer) {}
00046 
00047     virtual WriteMarker prepare(
00048       ringbuffer::Message m,
00049       size_t total_size,
00050       bool,
00051       size_t* identifier = nullptr) override
00052     {
00053       if (pending.empty())
00054       {
00055         // No currently pending messages - try to write to underlying buffer
00056         const auto marker =
00057           underlying_writer->prepare(m, total_size, false, identifier);
00058 
00059         if (marker.has_value())
00060         {
00061           return marker;
00062         }
00063 
00064         // Prepare failed, no space in buffer - so add to queue
00065       }
00066 
00067       pending.emplace_back(m, std::vector<uint8_t>(total_size));
00068 
00069       auto& msg = pending.back();
00070       msg.marker = (size_t)msg.buffer.data();
00071 
00072       // NB: There is an assumption that these markers will never conflict with
00073       // the markers produced by the underlying writer impl
00074       return msg.marker;
00075     }
00076 
00077     virtual void finish(const WriteMarker& marker) override
00078     {
00079       if (marker.has_value())
00080       {
00081         for (auto& it : pending)
00082         {
00083           // NB: finish is passed the _initial_ WriteMarker, so we compare
00084           // against it.buffer.data() rather than it.marker
00085           if ((size_t)it.buffer.data() == marker.value())
00086           {
00087             // This is a pending write. Mark as completed, so we can later flush
00088             // it
00089             it.finished = true;
00090             return;
00091           }
00092         }
00093       }
00094 
00095       underlying_writer->finish(marker);
00096     }
00097 
00098     virtual WriteMarker write_bytes(
00099       const WriteMarker& marker, const uint8_t* bytes, size_t size) override
00100     {
00101       if (marker.has_value())
00102       {
00103         for (auto& it : pending)
00104         {
00105           const auto buffer_end = it.buffer.data() + it.buffer.size();
00106           if (
00107             it.marker == marker.value() &&
00108             marker.value() != reinterpret_cast<uint64_t>(buffer_end))
00109           {
00110             // This is a pending write - dump data directly to write marker,
00111             // which should be within the appropriate buffer
00112             auto dest = (uint8_t*)marker.value();
00113             if (dest < it.buffer.data())
00114             {
00115               throw std::runtime_error(fmt::format(
00116                 "Invalid pending marker - writing before buffer: {} < {}",
00117                 (size_t)dest,
00118                 (size_t)it.buffer.data()));
00119             }
00120 
00121             if (dest + size > buffer_end)
00122             {
00123               throw std::runtime_error(fmt::format(
00124                 "Invalid pending marker - write extends beyond buffer: {} + {} "
00125                 "> {}",
00126                 (size_t)dest,
00127                 (size_t)size,
00128                 (size_t)buffer_end));
00129             }
00130 
00131             std::memcpy(dest, bytes, size);
00132             dest += size;
00133             it.marker = (size_t)dest;
00134             return {it.marker};
00135           }
00136         }
00137       }
00138 
00139       // Otherwise, this was successfully prepared on the underlying
00140       // implementation - delegate to it for remaining writes
00141       return underlying_writer->write_bytes(marker, bytes, size);
00142     }
00143 
00144     // Returns true if flush completed and there are no more pending messages.
00145     // False means 0 or more pending messages were written, but some remain
00146     bool try_flush_pending()
00147     {
00148       while (!pending.empty())
00149       {
00150         const auto& next = pending.front();
00151         if (!next.finished)
00152         {
00153           // If we reached an in-progress pending message, stop - we can't flush
00154           // this or anything after it
00155           break;
00156         }
00157 
00158         // Try to write this pending message to the underlying writer
00159         const auto marker = underlying_writer->prepare(
00160           next.m, next.buffer.size(), false, nullptr);
00161 
00162         if (!marker.has_value())
00163         {
00164           // No space - stop flushing
00165           break;
00166         }
00167 
00168         underlying_writer->write_bytes(
00169           marker, next.buffer.data(), next.buffer.size());
00170         underlying_writer->finish(marker);
00171 
00172         // This pending message was successfully written - pop it and continue
00173         pending.pop_front();
00174       }
00175 
00176       return pending.empty();
00177     }
00178   };
00179 
00180   class NonBlockingWriterFactory : public AbstractWriterFactory
00181   {
00182     AbstractWriterFactory& factory_impl;
00183 
00184     // Could be set, but needs custom hash() + operator<, so vector is simpler
00185     using WriterSet = std::vector<std::weak_ptr<ringbuffer::NonBlockingWriter>>;
00186 
00187     WriterSet writers_to_outside;
00188     WriterSet writers_to_inside;
00189 
00190     std::shared_ptr<ringbuffer::NonBlockingWriter> add_writer(
00191       const std::shared_ptr<ringbuffer::AbstractWriter>& underlying,
00192       WriterSet& writers)
00193     {
00194       auto new_writer = std::make_shared<NonBlockingWriter>(underlying);
00195       writers.emplace_back(new_writer);
00196       return new_writer;
00197     }
00198 
00199     bool flush_all(WriterSet& writers)
00200     {
00201       bool all_empty = true;
00202 
00203       auto it = writers.begin();
00204       while (it != writers.end())
00205       {
00206         auto shared_ptr = it->lock();
00207         if (shared_ptr)
00208         {
00209           all_empty &= shared_ptr->try_flush_pending();
00210           ++it;
00211         }
00212         else
00213         {
00214           it = writers.erase(it);
00215         }
00216       }
00217 
00218       return all_empty;
00219     }
00220 
00221   public:
00222     NonBlockingWriterFactory(AbstractWriterFactory& impl) : factory_impl(impl)
00223     {}
00224 
00225     std::shared_ptr<ringbuffer::NonBlockingWriter>
00226     create_non_blocking_writer_to_outside()
00227     {
00228       return add_writer(
00229         factory_impl.create_writer_to_outside(), writers_to_outside);
00230     }
00231 
00232     bool flush_all_outbound()
00233     {
00234       return flush_all(writers_to_outside);
00235     }
00236 
00237     std::shared_ptr<ringbuffer::NonBlockingWriter>
00238     create_non_blocking_writer_to_inside()
00239     {
00240       return add_writer(
00241         factory_impl.create_writer_to_inside(), writers_to_inside);
00242     }
00243 
00244     bool flush_all_inbound()
00245     {
00246       return flush_all(writers_to_inside);
00247     }
00248 
00249     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_outside()
00250       override
00251     {
00252       return create_non_blocking_writer_to_outside();
00253     }
00254 
00255     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_inside()
00256       override
00257     {
00258       return create_non_blocking_writer_to_inside();
00259     }
00260   };
00261 }
---------
Macros accessible in this file:
---------
RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD CCF_PAUSE 
---------
Parsing file /data/git/CCF/src/ds/non_blocking.h...
Preprocessing /data/git/CCF/src/ds/nonstd.h...
#include algorithm: not found! skipping...
#include array: not found! skipping...
#include cctype: not found! skipping...
#include string: not found! skipping...
#include string_view: not found! skipping...
#include type_traits: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2562 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 /**
00014  * This file defines various type traits and utils that are not available in the
00015  * standard library. Some are added in C++20, some are proposed, some are purely
00016  * custom. They are defined here to avoid repetition in other locations
00017  */
00018 namespace nonstd
00019 {
00020   /** is_specialization detects type-specialized templates. This does not work
00021    * for value-dependent types (eg - std::array)
00022    */
00023   template <typename T, template <typename...> class U>
00024   struct is_specialization : std::false_type
00025   {};
00026 
00027   template <template <typename...> class T, typename... Args>
00028   struct is_specialization<T<Args...>, T> : std::true_type
00029   {};
00030 
00031   /** Similar to is_specialization, but for detecting std::array specifically
00032    */
00033   template <typename T>
00034   struct is_std_array : std::false_type
00035   {};
00036 
00037   template <typename T, size_t N>
00038   struct is_std_array<std::array<T, N>> : public std::true_type
00039   {};
00040 
00041   /** dependent_false produces a static, compile-time false, dependent on a
00042    * specific type or value instantiation. This is useful for producing a
00043    * static_assert which will fail only when invalid paths are called, but
00044    * allows compilation otherwise
00045    */
00046   template <typename T, T = T{}>
00047   struct dependent_false : public std::false_type
00048   {};
00049 
00050   template <typename T, T t = T{}>
00051   static constexpr bool dependent_false_v = dependent_false<T, t>::value;
00052 
00053   /** remove_cvref combines remove_cv and remove_reference - this is present in
00054    * C++20
00055    */
00056   template <class T>
00057   struct remove_cvref
00058   {
00059     typedef std::remove_cv_t<std::remove_reference_t<T>> type;
00060   };
00061 
00062   template <class T>
00063   using remove_cvref_t = typename remove_cvref<T>::type;
00064 
00065   /** a more generic std::string member function is present in C++20
00066    */
00067   static inline bool starts_with(
00068     const std::string& s, const std::string& prefix)
00069   {
00070     return s.rfind(prefix, 0) == 0;
00071   }
00072 
00073   /** converts strings to upper or lower case, in-place
00074    */
00075   static inline void to_upper(std::string& s)
00076   {
00077     std::transform(s.begin(), s.end(), s.begin(), [](unsigned char c) {
00078       return std::toupper(c);
00079     });
00080   }
00081 
00082   static inline void to_lower(std::string& s)
00083   {
00084     std::transform(s.begin(), s.end(), s.begin(), [](unsigned char c) {
00085       return std::tolower(c);
00086     });
00087   }
00088 
00089   static inline std::string remove_prefix(
00090     const std::string& s, const std::string& prefix)
00091   {
00092     if (starts_with(s, prefix))
00093     {
00094       return s.substr(prefix.size());
00095     }
00096 
00097     return s;
00098   }
00099 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/nonstd.h...
Preprocessing /data/git/CCF/src/ds/openapi.h...
#include ds/json.h: not found! skipping...
#include ds/nonstd.h: not found! skipping...
#include http/http_status.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 11843 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ds
00017 {
00018   /**
00019    * This namespace contains helper functions, structs, and templates for
00020    * modifying an OpenAPI JSON document. They do not set every field, but should
00021    * fill every _required_ field, and the resulting object can be further
00022    * modified by hand as required.
00023    */
00024   namespace openapi
00025   {
00026     namespace access
00027     {
00028       static inline nlohmann::json& get_object(
00029         nlohmann::json& j, const std::string& k)
00030       {
00031         const auto ib = j.emplace(k, nlohmann::json::object());
00032         return ib.first.value();
00033       }
00034 
00035       static inline nlohmann::json& get_array(
00036         nlohmann::json& j, const std::string& k)
00037       {
00038         const auto ib = j.emplace(k, nlohmann::json::array());
00039         return ib.first.value();
00040       }
00041     }
00042 
00043     static inline void check_path_valid(const std::string& s)
00044     {
00045       if (!nonstd::starts_with(s, "/"))
00046       {
00047         throw std::logic_error(
00048           fmt::format("'{}' is not a valid path - must begin with '/'", s));
00049       }
00050     }
00051 
00052     static inline std::string remove_invalid_chars(const std::string_view& s_)
00053     {
00054       std::string s(s_);
00055 
00056       for (auto& c : s)
00057       {
00058         if (c == ':')
00059         {
00060           c = '_';
00061         }
00062       }
00063 
00064       return s;
00065     }
00066 
00067     static inline nlohmann::json create_document(
00068       const std::string& title,
00069       const std::string& description,
00070       const std::string& document_version)
00071     {
00072       return nlohmann::json{{"openapi", "3.0.0"},
00073                             {"info",
00074                              {{"title", title},
00075                               {"description", description},
00076                               {"version", document_version}}},
00077                             {"servers", nlohmann::json::array()},
00078                             {"paths", nlohmann::json::object()}};
00079     }
00080 
00081     static inline nlohmann::json& server(
00082       nlohmann::json& document, const std::string& url)
00083     {
00084       auto& servers = access::get_object(document, "servers");
00085       servers.push_back({{"url", url}});
00086       return servers.back();
00087     }
00088 
00089     static inline nlohmann::json& path(
00090       nlohmann::json& document, const std::string& path)
00091     {
00092       auto p = remove_invalid_chars(path);
00093       if (p.find("/") != 0)
00094       {
00095         p = fmt::format("/{}", p);
00096       }
00097 
00098       auto& paths = access::get_object(document, "paths");
00099       return access::get_object(paths, p);
00100     }
00101 
00102     static inline nlohmann::json& path_operation(
00103       nlohmann::json& path, llhttp_method verb)
00104     {
00105       // HTTP_GET becomes the string "get"
00106       std::string s = llhttp_method_name(verb);
00107       nonstd::to_lower(s);
00108       auto& po = access::get_object(path, s);
00109       // responses is required field in a path_operation
00110       access::get_object(po, "responses");
00111       return po;
00112     }
00113 
00114     static inline nlohmann::json& parameters(nlohmann::json& path_operation)
00115     {
00116       return access::get_array(path_operation, "parameters");
00117     }
00118 
00119     static inline nlohmann::json& response(
00120       nlohmann::json& path_operation,
00121       http_status status,
00122       const std::string& description = "Default response description")
00123     {
00124       auto& responses = access::get_object(path_operation, "responses");
00125       // HTTP_STATUS_OK (aka an int-enum with value 200) becomes the string
00126       // "200"
00127       const auto s = std::to_string(status);
00128       auto& response = access::get_object(responses, s);
00129       response["description"] = description;
00130       return response;
00131     }
00132 
00133     static inline nlohmann::json& request_body(nlohmann::json& path_operation)
00134     {
00135       auto& request_body = access::get_object(path_operation, "requestBody");
00136       access::get_object(request_body, "content");
00137       return request_body;
00138     }
00139 
00140     static inline nlohmann::json& media_type(
00141       nlohmann::json& j, const std::string& mt)
00142     {
00143       auto& content = access::get_object(j, "content");
00144       return access::get_object(content, mt);
00145     }
00146 
00147     static inline nlohmann::json& schema(nlohmann::json& media_type_object)
00148     {
00149       return access::get_object(media_type_object, "schema");
00150     }
00151 
00152     //
00153     // Helper functions for auto-inserting schema into components
00154     //
00155 
00156     static inline nlohmann::json components_ref_object(
00157       const std::string& element_name)
00158     {
00159       auto schema_ref_object = nlohmann::json::object();
00160       schema_ref_object["$ref"] =
00161         fmt::format("#/components/schemas/{}", element_name);
00162       return schema_ref_object;
00163     }
00164 
00165     // Returns a ref object pointing to the item inserted into the components
00166     static inline nlohmann::json add_schema_to_components(
00167       nlohmann::json& document,
00168       const std::string& element_name,
00169       const nlohmann::json& schema_)
00170     {
00171       const auto name = remove_invalid_chars(element_name);
00172 
00173       auto& components = access::get_object(document, "components");
00174       auto& schemas = access::get_object(components, "schemas");
00175 
00176       const auto schema_it = schemas.find(name);
00177       if (schema_it != schemas.end())
00178       {
00179         // Check that the existing schema matches the new one being added with
00180         // the same name
00181         const auto& existing_schema = schema_it.value();
00182         if (schema_ != existing_schema)
00183         {
00184           throw std::logic_error(fmt::format(
00185             "Adding schema with name '{}'. Does not match previous schema "
00186             "registered with this name: {} vs {}",
00187             name,
00188             schema_.dump(),
00189             existing_schema.dump()));
00190         }
00191       }
00192       else
00193       {
00194         schemas.emplace(name, schema_);
00195       }
00196 
00197       return components_ref_object(name);
00198     }
00199 
00200     struct SchemaHelper
00201     {
00202       nlohmann::json& document;
00203 
00204       template <typename T>
00205       nlohmann::json add_schema_component()
00206       {
00207         nlohmann::json schema;
00208         if constexpr (nonstd::is_specialization<T, std::optional>::value)
00209         {
00210           return add_schema_component<typename T::value_type>();
00211         }
00212         else if constexpr (nonstd::is_specialization<T, std::vector>::value)
00213         {
00214           schema["type"] = "array";
00215           schema["items"] = add_schema_component<typename T::value_type>();
00216 
00217           return add_schema_to_components(
00218             document, ds::json::schema_name<T>(), schema);
00219         }
00220         else if constexpr (
00221           nonstd::is_specialization<T, std::map>::value ||
00222           nonstd::is_specialization<T, std::unordered_map>::value)
00223         {
00224           // Nlohmann serialises maps to an array of (K, V) pairs
00225           if (std::is_same<typename T::key_type, std::string>::value)
00226           {
00227             // ...unless the keys are strings!
00228             schema["type"] = "object";
00229             schema["additionalProperties"] =
00230               add_schema_component<typename T::mapped_type>();
00231           }
00232           else
00233           {
00234             schema["type"] = "array";
00235             auto items = nlohmann::json::object();
00236             {
00237               items["type"] = "array";
00238 
00239               auto sub_items = nlohmann::json::array();
00240               sub_items.push_back(add_schema_component<typename T::key_type>());
00241               sub_items.push_back(
00242                 add_schema_component<typename T::mapped_type>());
00243 
00244               items["items"]["oneOf"] = sub_items;
00245               items["minItems"] = 2;
00246               items["maxItems"] = 2;
00247             }
00248             schema["items"] = items;
00249           }
00250           return add_schema_to_components(
00251             document, ds::json::schema_name<T>(), schema);
00252         }
00253         else if constexpr (nonstd::is_specialization<T, std::pair>::value)
00254         {
00255           schema["type"] = "array";
00256           auto items = nlohmann::json::array();
00257           items.push_back(add_schema_component<typename T::first_type>());
00258           items.push_back(add_schema_component<typename T::second_type>());
00259           schema["items"] = items;
00260           return add_schema_to_components(
00261             document, ds::json::schema_name<T>(), schema);
00262         }
00263         else if constexpr (
00264           std::is_same<T, std::string>::value || std::is_arithmetic_v<T> ||
00265           std::is_same<T, nlohmann::json>::value ||
00266           std::is_same<T, ds::json::JsonSchema>::value)
00267         {
00268           ds::json::fill_schema<T>(schema);
00269           return add_schema_to_components(
00270             document, ds::json::schema_name<T>(), schema);
00271         }
00272         else
00273         {
00274           const auto name = remove_invalid_chars(ds::json::schema_name<T>());
00275 
00276           auto& components = access::get_object(document, "components");
00277           auto& schemas = access::get_object(components, "schemas");
00278 
00279           const auto ib = schemas.emplace(name, nlohmann::json::object());
00280           if (ib.second)
00281           {
00282             auto& j = ib.first.value();
00283 
00284             // Use argument-dependent-lookup to call correct functions
00285             T t;
00286             if constexpr (std::is_enum<T>::value)
00287             {
00288               fill_enum_schema(j, t);
00289             }
00290             else
00291             {
00292               add_schema_components(*this, j, t);
00293             }
00294           }
00295 
00296           return components_ref_object(name);
00297         }
00298       }
00299     };
00300 
00301     static inline void add_request_body_schema(
00302       nlohmann::json& document,
00303       const std::string& uri,
00304       llhttp_method verb,
00305       const std::string& content_type,
00306       const std::string& schema_name,
00307       const nlohmann::json& schema_)
00308     {
00309       auto& rb = request_body(path_operation(path(document, uri), verb));
00310       rb["description"] = "Auto-generated request body schema";
00311 
00312       schema(media_type(rb, content_type)) =
00313         add_schema_to_components(document, schema_name, schema_);
00314     }
00315 
00316     template <typename T>
00317     static inline void add_request_body_schema(
00318       nlohmann::json& document,
00319       const std::string& uri,
00320       llhttp_method verb,
00321       const std::string& content_type)
00322     {
00323       auto& rb = request_body(path_operation(path(document, uri), verb));
00324       rb["description"] = "Auto-generated request body schema";
00325 
00326       SchemaHelper sh{document};
00327       const auto schema_comp = sh.add_schema_component<T>();
00328       if (schema_comp != nullptr)
00329       {
00330         schema(media_type(rb, content_type)) = sh.add_schema_component<T>();
00331       }
00332     }
00333 
00334     static inline void add_path_parameter_schema(
00335       nlohmann::json& document,
00336       const std::string& uri,
00337       const nlohmann::json& param)
00338     {
00339       auto& params = parameters(path(document, uri));
00340       params.push_back(param);
00341     }
00342 
00343     static inline void add_request_parameter_schema(
00344       nlohmann::json& document,
00345       const std::string& uri,
00346       llhttp_method verb,
00347       const nlohmann::json& param)
00348     {
00349       auto& params = parameters(path_operation(path(document, uri), verb));
00350       params.push_back(param);
00351     }
00352 
00353     static inline void add_response_schema(
00354       nlohmann::json& document,
00355       const std::string& uri,
00356       llhttp_method verb,
00357       http_status status,
00358       const std::string& content_type,
00359       const std::string& schema_name,
00360       const nlohmann::json& schema_)
00361     {
00362       auto& r = response(path_operation(path(document, uri), verb), status);
00363 
00364       schema(media_type(r, content_type)) =
00365         add_schema_to_components(document, schema_name, schema_);
00366     }
00367 
00368     template <typename T>
00369     static inline void add_response_schema(
00370       nlohmann::json& document,
00371       const std::string& uri,
00372       llhttp_method verb,
00373       http_status status,
00374       const std::string& content_type)
00375     {
00376       auto& r = response(path_operation(path(document, uri), verb), status);
00377 
00378       SchemaHelper sh{document};
00379       const auto schema_comp = sh.add_schema_component<T>();
00380       if (schema_comp != nullptr)
00381       {
00382         schema(media_type(r, content_type)) = sh.add_schema_component<T>();
00383       }
00384     }
00385   }
00386 }
00387 
00388 
00389 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/openapi.h...
Preprocessing /data/git/CCF/src/ds/oversized.h...
#include logger.h: already included! skipping...
#include ring_buffer.h: already included! skipping...
#include spin_lock.h: already included! skipping...
#include atomic: not found! skipping...
#include condition_variable: not found! skipping...
#include map: not found! skipping...
#include stdexcept: not found! skipping...
#include ring_buffer.h: already included! skipping...
#include serialized.h: already included! skipping...
#include fmt/format.h: not found! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 11132 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/ds/oversized.h" 2
00006 
00007 
00008 
00009 #define FMT_HEADER_ONLY
00010 
00011 
00012 
00013 namespace oversized
00014 {
00015   enum OversizedMessage : ringbuffer::Message
00016   {
00017     /// Part of a larger message. Can be sent both ways
00018     DEFINE_RINGBUFFER_MSG_TYPE(fragment),
00019   };
00020 
00021   class FragmentReconstructor
00022   {
00023     messaging::RingbufferDispatcher& dispatcher;
00024 
00025     struct PartialMessage
00026     {
00027       const ringbuffer::Message m;
00028       const size_t total_size;
00029 
00030       size_t received;
00031       uint8_t* data;
00032     };
00033 
00034     std::unordered_map<size_t, PartialMessage> partial_messages;
00035 
00036   public:
00037     FragmentReconstructor(messaging::RingbufferDispatcher& d) : dispatcher(d)
00038     {
00039       DISPATCHER_SET_MESSAGE_HANDLER(
00040         d,
00041         OversizedMessage::fragment,
00042         [this](const uint8_t* data, size_t size) {
00043           auto message_id = serialized::read<size_t>(data, size);
00044 
00045           auto it = partial_messages.find(message_id);
00046           if (it == partial_messages.end())
00047           {
00048             // First reference to this oversized message - should contain a
00049             // header. Read its type, size, then allocate space for it
00050             auto m = serialized::read<ringbuffer::Message>(data, size);
00051             auto total_size = serialized::read<size_t>(data, size);
00052 
00053             // No safety checks on the size - trust that in normal operation the
00054             // Writer has set sensible limits, don't duplicate here
00055             uint8_t* dest = new uint8_t[total_size];
00056 
00057             auto ib =
00058               partial_messages.insert({message_id, {m, total_size, 0, dest}});
00059 
00060             it = ib.first;
00061           }
00062 
00063           auto& partial = it->second;
00064           if (size + partial.received > partial.total_size)
00065           {
00066             throw ringbuffer::message_error(
00067               message_id,
00068               fmt::format(
00069                 "Too much data for oversized fragmented message. Message {} "
00070                 "asked for {} bytes, has already written {}, but has sent a "
00071                 "further {}",
00072                 message_id,
00073                 partial.total_size,
00074                 partial.received,
00075                 size));
00076           }
00077 
00078           ::memcpy(partial.data + partial.received, data, size);
00079           partial.received += size;
00080           data += size;
00081           size -= size;
00082 
00083           if (partial.received == partial.total_size)
00084           {
00085             // Entire message received - dispatch it then free buffer
00086             dispatcher.dispatch(partial.m, partial.data, partial.total_size);
00087 
00088             delete[] partial.data;
00089 
00090             // Erase by key - dispatch may have invalidated previous iterator
00091             // (nested fragmented messages - odd, but no reason to disallow)
00092             partial_messages.erase(message_id);
00093           }
00094         });
00095     }
00096 
00097     ~FragmentReconstructor()
00098     {
00099       dispatcher.remove_message_handler(OversizedMessage::fragment);
00100 
00101       for (const auto& [_, partial] : partial_messages)
00102       {
00103         delete[] partial.data;
00104       }
00105     }
00106   };
00107 
00108 
00109   struct InitialFragmentHeader
00110   {
00111     size_t identifier;
00112     ringbuffer::Message contained;
00113     size_t total_size;
00114   };
00115 
00116 
00117   class Writer : public ringbuffer::AbstractWriter
00118   {
00119   private:
00120     ringbuffer::WriterPtr underlying_writer;
00121 
00122     const size_t max_fragment_size;
00123     const size_t max_total_size;
00124 
00125     struct FragmentProgress
00126     {
00127       WriteMarker marker; // Track this so a later call can finish this fragment
00128       size_t identifier; // Identifier for all fragments of oversized message
00129       size_t remainder; // Remaining space in currently prepared fragment buffer
00130     };
00131 
00132     // None iff the message is small enough to fit in a single fragment, or
00133     // we're not currently within a [prepare, write_bytes*, finish] loop
00134     std::optional<FragmentProgress> fragment_progress;
00135 
00136   public:
00137     Writer(const ringbuffer::WriterPtr& writer, size_t f, size_t t = -1) :
00138       underlying_writer(writer),
00139       max_fragment_size(f),
00140       max_total_size(t),
00141       fragment_progress({})
00142     {
00143       if (max_fragment_size >= max_total_size)
00144         throw std::logic_error(fmt::format(
00145           "Fragment sizes must be smaller than total max: {} >= {}",
00146           max_fragment_size,
00147           max_total_size));
00148 
00149       constexpr auto header_size = sizeof(InitialFragmentHeader);
00150       if (max_fragment_size <= header_size)
00151         throw std::logic_error(fmt::format(
00152           "Fragment size must be large enough to contain the header for the "
00153           "initial fragment, and some additional payload data: {} <= {}",
00154           max_fragment_size,
00155           header_size));
00156     }
00157 
00158     virtual WriteMarker prepare(
00159       ringbuffer::Message m,
00160       size_t total_size,
00161       bool wait = true,
00162       size_t* identifier = nullptr) override
00163     {
00164       // Ensure this is not called out of order
00165       if (fragment_progress.has_value())
00166       {
00167         throw std::logic_error("This Writer is already preparing a message");
00168       }
00169 
00170       // Small enough to be handled directly by underlying writer
00171       if (total_size <= max_fragment_size)
00172       {
00173         return underlying_writer->prepare(m, total_size, wait, identifier);
00174       }
00175 
00176       if (total_size > max_total_size)
00177       {
00178         throw std::logic_error(fmt::format(
00179           "Requested a write of {} bytes, max allowed is {}",
00180           total_size,
00181           max_total_size));
00182       }
00183 
00184       // Need to split this message into multiple fragments
00185 
00186       if (!wait)
00187       {
00188         throw std::logic_error(fmt::format(
00189           "Requested write of {} bytes will be split into multiple fragments: "
00190           "caller must wait for these to complete as fragment writes will be "
00191           "blocking",
00192           total_size));
00193       }
00194 
00195       // Prepare space for the first fragment, getting an id for all related
00196       // fragments
00197       size_t outer_id;
00198       const auto marker = underlying_writer->prepare(
00199         OversizedMessage::fragment, max_fragment_size, wait, &outer_id);
00200       if (!marker.has_value())
00201       {
00202         return {};
00203       }
00204 
00205       // Write the header
00206       InitialFragmentHeader header = {outer_id, m, total_size};
00207       auto next = underlying_writer->write_bytes(
00208         marker, (const uint8_t*)&header, sizeof(header));
00209 
00210       // Track progress in current oversized message
00211       fragment_progress = {
00212         marker, outer_id, max_fragment_size - sizeof(header)};
00213 
00214       if (identifier != nullptr)
00215         *identifier = outer_id;
00216 
00217       // Don't need to store next - it will be an argument of the next call to
00218       // write_bytes
00219       return next;
00220     }
00221 
00222     virtual void finish(const WriteMarker& marker) override
00223     {
00224       if (fragment_progress.has_value())
00225       {
00226         // We were writing an oversized message, the given marker means nothing
00227         // to us
00228         if (fragment_progress->remainder != 0)
00229         {
00230           throw std::logic_error(
00231             "Attempting to finish an oversized message before the entire "
00232             "requested payload has been written");
00233         }
00234 
00235         // Finish the final fragment message
00236         underlying_writer->finish(fragment_progress->marker);
00237 
00238         // Clean up, ready for next call to prepare
00239         fragment_progress = {};
00240       }
00241       else
00242       {
00243         // We were writing a small message - get underlying writer to finish it
00244         underlying_writer->finish(marker);
00245       }
00246     }
00247 
00248     virtual WriteMarker write_bytes(
00249       const WriteMarker& marker, const uint8_t* bytes, size_t size) override
00250     {
00251       if (!marker.has_value())
00252       {
00253         return {};
00254       }
00255 
00256       if (!fragment_progress.has_value())
00257       {
00258         // Writing a small message - nothing to do here
00259         return underlying_writer->write_bytes(marker, bytes, size);
00260       }
00261 
00262       // Append as much as possible into the current prepared buffer
00263       auto write_size = std::min(size, fragment_progress->remainder);
00264       auto next = underlying_writer->write_bytes(marker, bytes, write_size);
00265       bytes += write_size;
00266       size -= write_size;
00267       fragment_progress->remainder -= write_size;
00268 
00269       // While there is more to write...
00270       while (size > 0)
00271       {
00272         // Prepare a new fragment
00273         const auto id = fragment_progress->identifier;
00274         const auto frag_size = std::min(size + sizeof(id), max_fragment_size);
00275         next = underlying_writer->prepare(
00276           OversizedMessage::fragment, frag_size, true);
00277 
00278         if (!next.has_value())
00279         {
00280           // Intermediate fragment failed - this is unexpected
00281           throw std::logic_error(
00282             "Failed to create fragment for oversized message");
00283 
00284           // If this path is hit it is likely because we have allowed oversized
00285           // writes to write without waiting. Some initial fragments were
00286           // written, but there is insufficient space to write this fragment.
00287           // In this case we can either cancel the entire oversized message, or
00288           // retry. In either case we should send a message to inform the
00289           // reader.
00290           fragment_progress->remainder = 0;
00291           break;
00292         }
00293 
00294         // Finish the previous fragment
00295         underlying_writer->finish(fragment_progress->marker);
00296 
00297         // Update progress tracking to reference the new fragment
00298         write_size = frag_size - sizeof(id);
00299         fragment_progress->marker = next;
00300         fragment_progress->remainder = write_size;
00301 
00302         // Write the id of the oversized message
00303         next =
00304           underlying_writer->write_bytes(next, (const uint8_t*)&id, sizeof(id));
00305 
00306         // Write some fragment payload
00307         next = underlying_writer->write_bytes(next, bytes, write_size);
00308         bytes += write_size;
00309         size -= write_size;
00310         fragment_progress->remainder -= write_size;
00311       }
00312 
00313       return next;
00314     }
00315   };
00316 
00317   struct WriterConfig
00318   {
00319     size_t max_fragment_size;
00320     size_t max_total_size;
00321   };
00322 
00323   // Wrap ringbuffer::Circuit to provide the same fragment/total maximum sizes
00324   // for every Writer
00325   class WriterFactory : public ringbuffer::AbstractWriterFactory
00326   {
00327     AbstractWriterFactory& factory_impl;
00328 
00329     const WriterConfig config;
00330 
00331   public:
00332     WriterFactory(AbstractWriterFactory& impl, const WriterConfig& config_) :
00333       factory_impl(impl),
00334       config(config_)
00335     {}
00336 
00337     std::shared_ptr<oversized::Writer> create_oversized_writer_to_outside()
00338     {
00339       return std::make_shared<oversized::Writer>(
00340         factory_impl.create_writer_to_outside(),
00341         config.max_fragment_size,
00342         config.max_total_size);
00343     }
00344 
00345     std::shared_ptr<oversized::Writer> create_oversized_writer_to_inside()
00346     {
00347       return std::make_shared<oversized::Writer>(
00348         factory_impl.create_writer_to_inside(),
00349         config.max_fragment_size,
00350         config.max_total_size);
00351     }
00352 
00353     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_outside()
00354       override
00355     {
00356       return create_oversized_writer_to_outside();
00357     }
00358 
00359     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_inside()
00360       override
00361     {
00362       return create_oversized_writer_to_inside();
00363     }
00364   };
00365 }
00366 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE DISPATCHER_SET_MESSAGE_HANDLER LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/oversized.h...
Preprocessing /data/git/CCF/src/ds/rb_map.h...
#include cassert: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 4247 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 template <class K, class V>
00010 class RBMap
00011 {
00012 private:
00013   enum Color
00014   {
00015     R,
00016     B
00017   };
00018 
00019   struct Node
00020   {
00021     Node(
00022       Color c,
00023       const std::shared_ptr<const Node>& lft,
00024       const K& key,
00025       const V& val,
00026       const std::shared_ptr<const Node>& rgt) :
00027       _c(c),
00028       _lft(lft),
00029       _key(key),
00030       _val(val),
00031       _rgt(rgt)
00032     {}
00033 
00034     Color _c;
00035     std::shared_ptr<const Node> _lft;
00036     K _key;
00037     V _val;
00038     std::shared_ptr<const Node> _rgt;
00039   };
00040 
00041   explicit RBMap(std::shared_ptr<const Node> const& node) : _root(node) {}
00042 
00043   RBMap(
00044     Color c, const RBMap& lft, const K& key, const V& val, const RBMap& rgt) :
00045     _root(std::make_shared<const Node>(c, lft._root, key, val, rgt._root))
00046   {
00047     assert(lft.empty() || lft.rootKey() < key);
00048     assert(rgt.empty() || key < rgt.rootKey());
00049   }
00050 
00051 public:
00052   RBMap() {}
00053 
00054   bool empty() const
00055   {
00056     return !_root;
00057   }
00058 
00059   std::optional<V> get(const K& key) const
00060   {
00061     auto v = getp(key);
00062 
00063     if (v)
00064       return *v;
00065     else
00066       return {};
00067   }
00068 
00069   const V* getp(const K& key) const
00070   {
00071     if (empty())
00072       return nullptr;
00073 
00074     auto& y = rootKey();
00075 
00076     if (key < y)
00077       return left().getp(key);
00078     else if (y < key)
00079       return right().getp(key);
00080     else
00081       return &rootValue();
00082   }
00083 
00084   RBMap put(const K& key, const V& value) const
00085   {
00086     RBMap t = insert(key, value);
00087     return RBMap(B, t.left(), t.rootKey(), t.rootValue(), t.right());
00088   }
00089 
00090   template <class F>
00091   void foreach(F&& f) const
00092   {
00093     if (!empty())
00094     {
00095       left().foreach(std::forward<F>(f));
00096       f(rootKey(), rootValue());
00097       right().foreach(std::forward<F>(f));
00098     }
00099   }
00100 
00101 private:
00102   std::shared_ptr<const Node> _root;
00103 
00104   Color rootColor() const
00105   {
00106     return _root->_c;
00107   }
00108 
00109   const K& rootKey() const
00110   {
00111     return _root->_key;
00112   }
00113 
00114   const V& rootValue() const
00115   {
00116     return _root->_val;
00117   }
00118 
00119   RBMap left() const
00120   {
00121     return RBMap(_root->_lft);
00122   }
00123 
00124   RBMap right() const
00125   {
00126     return RBMap(_root->_rgt);
00127   }
00128 
00129   RBMap insert(const K& x, const V& v) const
00130   {
00131     if (empty())
00132       return RBMap(R, RBMap(), x, v, RBMap());
00133 
00134     const K& y = rootKey();
00135     const V& yv = rootValue();
00136     Color c = rootColor();
00137 
00138     if (rootColor() == B)
00139     {
00140       if (x < y)
00141         return balance(left().insert(x, v), y, yv, right());
00142       else if (y < x)
00143         return balance(left(), y, yv, right().insert(x, v));
00144       else
00145         return RBMap(c, left(), y, v, right());
00146     }
00147     else
00148     {
00149       if (x < y)
00150         return RBMap(c, left().insert(x, v), y, yv, right());
00151       else if (y < x)
00152         return RBMap(c, left(), y, yv, right().insert(x, v));
00153       else
00154         return RBMap(c, left(), y, v, right());
00155     }
00156   }
00157 
00158   // Called only when parent is black
00159   static RBMap balance(
00160     const RBMap& lft, const K& x, const V& v, const RBMap& rgt)
00161   {
00162     if (lft.doubledLeft())
00163       return RBMap(
00164         R,
00165         lft.left().paint(B),
00166         lft.rootKey(),
00167         lft.rootValue(),
00168         RBMap(B, lft.right(), x, v, rgt));
00169     else if (lft.doubledRight())
00170       return RBMap(
00171         R,
00172         RBMap(
00173           B, lft.left(), lft.rootKey(), lft.rootValue(), lft.right().left()),
00174         lft.right().rootKey(),
00175         lft.right().rootValue(),
00176         RBMap(B, lft.right().right(), x, v, rgt));
00177     else if (rgt.doubledLeft())
00178       return RBMap(
00179         R,
00180         RBMap(B, lft, x, v, rgt.left().left()),
00181         rgt.left().rootKey(),
00182         rgt.left().rootValue(),
00183         RBMap(
00184           B, rgt.left().right(), rgt.rootKey(), rgt.rootValue(), rgt.right()));
00185     else if (rgt.doubledRight())
00186       return RBMap(
00187         R,
00188         RBMap(B, lft, x, v, rgt.left()),
00189         rgt.rootKey(),
00190         rgt.rootValue(),
00191         rgt.right().paint(B));
00192     else
00193       return RBMap(B, lft, x, v, rgt);
00194   }
00195 
00196   bool doubledLeft() const
00197   {
00198     return !empty() && rootColor() == R && !left().empty() &&
00199       left().rootColor() == R;
00200   }
00201 
00202   bool doubledRight() const
00203   {
00204     return !empty() && rootColor() == R && !right().empty() &&
00205       right().rootColor() == R;
00206   }
00207 
00208   RBMap paint(Color c) const
00209   {
00210     return RBMap(c, left(), rootKey(), rootValue(), right());
00211   }
00212 };
00213 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/rb_map.h...
Reading /data/git/CCF/src/ds/README.md...
Preprocessing /data/git/CCF/src/ds/ring_buffer.h...
#include ring_buffer_types.h: already included! skipping...
#include cstring: not found! skipping...
#include functional: not found! skipping...
Preprocessor output (size: 13319 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 // Ideally this would be _mm_pause or similar, but finding cross-platform
00011 // headers that expose this neatly through OE (ie - non-standard std libs) is
00012 // awkward. Instead we resort to copying OE, and implementing this directly
00013 // ourselves.
00014 #define CCF_PAUSE() 
00015 
00016 // This file implements a Multiple-Producer Single-Consumer ringbuffer.
00017 
00018 // A single Reader instance owns an underlying memory buffer, and a single
00019 // thread should process message written to it. Any number of other threads and
00020 // Writers may write to it, and the messages will be distinct, correct, and
00021 // ordered.
00022 
00023 // A Circuit wraps a pair of ringbuffers to allow 2-way communication - messages
00024 // are written to the inbound buffer, processed inside an enclave, and responses
00025 // written back to the outbound.
00026 
00027 namespace ringbuffer
00028 {
00029   using Handler = std::function<void(Message, const uint8_t*, size_t)>;
00030 
00031   // High bit of message size is used to indicate a pending message
00032   static constexpr uint32_t pending_write_flag = 1 << 31;
00033   static constexpr uint32_t length_mask = ~pending_write_flag;
00034 
00035   struct Const
00036   {
00037     enum : Message
00038     {
00039       msg_max = std::numeric_limits<Message>::max() - 1,
00040       msg_min = 1,
00041       msg_none = 0,
00042       msg_pad = std::numeric_limits<Message>::max()
00043     };
00044 
00045     static constexpr bool is_power_of_2(size_t n)
00046     {
00047       return n && ((n & (~n + 1)) == n);
00048     }
00049 
00050     static constexpr size_t header_size()
00051     {
00052       // The header is a 32 bit length and a 32 bit message ID.
00053       return sizeof(int32_t) + sizeof(uint32_t);
00054     }
00055 
00056     static constexpr size_t align_size(size_t n)
00057     {
00058       // Make sure the header is aligned in memory.
00059       return (n + (header_size() - 1)) & ~(header_size() - 1);
00060     }
00061 
00062     static constexpr size_t entry_size(size_t n)
00063     {
00064       return Const::align_size(n + header_size());
00065     }
00066 
00067     static constexpr size_t max_size()
00068     {
00069       // The length of a message plus its header must be encodable in the
00070       // header. High bit of lengths indicate pending writes.
00071       return std::numeric_limits<int32_t>::max() - header_size();
00072     }
00073 
00074     static constexpr size_t max_reservation_size(size_t buffer_size)
00075     {
00076       // This guarantees that in an empty buffer, we can always make this
00077       // reservation in a single contiguous region (either before or after the
00078       // current tail). If we allow larger reservations then we may need to
00079       // artificially advance the tail (writing padding then clearing it) to
00080       // create a sufficiently large region.
00081       return buffer_size / 2;
00082     }
00083 
00084     Const(uint8_t* const buffer, size_t size) : buffer(buffer), size(size)
00085     {
00086       if (!is_power_of_2(size))
00087         throw std::logic_error("Buffer size must be a power of 2");
00088     }
00089 
00090     uint8_t* const buffer;
00091     const size_t size;
00092   };
00093 
00094   struct BufferDef
00095   {
00096     uint8_t* data;
00097     size_t size;
00098 
00099     Offsets* offsets;
00100   };
00101 
00102   class Reader
00103   {
00104     friend class Writer;
00105 
00106     BufferDef bd;
00107 
00108   public:
00109     Reader(const BufferDef& bd_) : bd(bd_) {}
00110 
00111     size_t read(size_t limit, Handler f)
00112     {
00113       auto mask = bd.size - 1;
00114       auto hd = bd.offsets->head.load(std::memory_order_acquire);
00115       auto hd_index = hd & mask;
00116       auto block = bd.size - hd_index;
00117       size_t advance = 0;
00118       size_t count = 0;
00119 
00120       while ((advance < block) && (count < limit))
00121       {
00122         auto msg_index = hd_index + advance;
00123         auto header = read64(msg_index);
00124         auto size = length(header);
00125 
00126         // If we see a pending write, we're done.
00127         if ((size & pending_write_flag) != 0u)
00128           break;
00129 
00130         auto m = message(header);
00131 
00132         if (m == Const::msg_none)
00133         {
00134           // There is no message here, we're done.
00135           break;
00136         }
00137         else if (m == Const::msg_pad)
00138         {
00139           // If we see padding, skip it.
00140           advance += size;
00141           continue;
00142         }
00143 
00144         advance += Const::entry_size(size);
00145         ++count;
00146 
00147         // Call the handler function for this message.
00148         f(m, bd.data + msg_index + Const::header_size(), (size_t)size);
00149       }
00150 
00151       if (advance > 0)
00152       {
00153         // Zero the buffer and advance the head.
00154         ::memset(bd.data + hd_index, 0, advance);
00155         bd.offsets->head.store(hd + advance, std::memory_order_release);
00156       }
00157 
00158       return count;
00159     }
00160 
00161   private:
00162     uint64_t read64(size_t index)
00163     {
00164       uint64_t r = *reinterpret_cast<volatile uint64_t*>(bd.data + index);
00165       atomic_thread_fence(std::memory_order_acq_rel);
00166       return r;
00167     }
00168 
00169     static Message message(uint64_t header)
00170     {
00171       return (Message)(header >> 32);
00172     }
00173 
00174     static uint32_t length(uint64_t header)
00175     {
00176       return header & std::numeric_limits<uint32_t>::max();
00177     }
00178   };
00179 
00180   class Writer : public AbstractWriter
00181   {
00182   protected:
00183     BufferDef bd; // copy of reader's buffer definition
00184 
00185     virtual void checkAccess(size_t, size_t) {}
00186 
00187     struct Reservation
00188     {
00189       // Index within buffer of reservation start
00190       size_t index;
00191 
00192       // Individual identifier for this reservation. Should be unique across
00193       // buffer lifetime, amongst all writers
00194       size_t identifier;
00195     };
00196 
00197   public:
00198     Writer(const Reader& r) : bd(r.bd) {}
00199 
00200     Writer(const Writer& that) : bd(that.bd) {}
00201 
00202     virtual ~Writer() {}
00203 
00204     virtual std::optional<size_t> prepare(
00205       Message m,
00206       size_t size,
00207       bool wait = true,
00208       size_t* identifier = nullptr) override
00209     {
00210       // Make sure we aren't using a reserved message.
00211       if ((m < Const::msg_min) || (m > Const::msg_max))
00212         throw message_error(
00213           m, "Cannot use a reserved message (" + std::to_string(m) + ")");
00214 
00215       // Make sure the message fits.
00216       if (size > Const::max_size())
00217         throw message_error(
00218           m,
00219           "Message (" + std::to_string(m) + ") is too long for any writer (" +
00220             std::to_string(size) + " > " + std::to_string(Const::max_size()) +
00221             ")");
00222 
00223       auto rsize = Const::entry_size(size);
00224       auto rmax = Const::max_reservation_size(bd.size);
00225       if (rsize > rmax)
00226       {
00227         throw message_error(
00228           m,
00229           "Message (" + std::to_string(m) +
00230             ") with header is too long for this writer (" +
00231             std::to_string(rsize) + " > " + std::to_string(rmax) + ")");
00232       }
00233 
00234       auto r = reserve(rsize);
00235 
00236       if (!r.has_value())
00237       {
00238         if (wait)
00239         {
00240           // Retry until there is sufficient space.
00241           do
00242           {
00243             CCF_PAUSE();
00244             r = reserve(rsize);
00245           } while (!r.has_value());
00246         }
00247         else
00248         {
00249           // Fail if there is insufficient space.
00250           return {};
00251         }
00252       }
00253 
00254       // Write the preliminary header and return the buffer pointer.
00255       // The initial header length has high bit set to indicate a pending
00256       // message. We rewrite the real length after the message data.
00257       write64(r.value().index, make_header(m, size));
00258 
00259       if (identifier != nullptr)
00260         *identifier = r.value().identifier;
00261 
00262       return {r.value().index + Const::header_size()};
00263     }
00264 
00265     virtual void finish(const WriteMarker& marker) override
00266     {
00267       if (marker.has_value())
00268       {
00269         // Fix up the size to indicate we're done writing - unset pending bit.
00270         const auto index = marker.value() - Const::header_size();
00271         auto size = read32(index);
00272         write32(index, size & length_mask);
00273       }
00274     }
00275 
00276   protected:
00277     virtual WriteMarker write_bytes(
00278       const WriteMarker& marker, const uint8_t* bytes, size_t size) override
00279     {
00280       if (!marker.has_value())
00281       {
00282         return {};
00283       }
00284 
00285       const auto index = marker.value();
00286 
00287       checkAccess(index, size);
00288 
00289       // Standard says memcpy(x, null, 0) is undefined, so avoid it
00290       if (size > 0)
00291         ::memcpy(bd.data + index, bytes, size);
00292 
00293       return {index + size};
00294     }
00295 
00296   private:
00297     uint32_t read32(size_t index)
00298     {
00299       uint32_t r;
00300       checkAccess(index, sizeof(r));
00301       r = *reinterpret_cast<volatile uint32_t*>(bd.data + index);
00302       atomic_thread_fence(std::memory_order_acq_rel);
00303       return r;
00304     }
00305 
00306     void write32(size_t index, uint32_t value)
00307     {
00308       atomic_thread_fence(std::memory_order_acq_rel);
00309       checkAccess(index, sizeof(value));
00310       *reinterpret_cast<volatile uint32_t*>(bd.data + index) = value;
00311     }
00312 
00313     void write64(size_t index, uint64_t value)
00314     {
00315       atomic_thread_fence(std::memory_order_acq_rel);
00316       checkAccess(index, sizeof(value));
00317       *reinterpret_cast<volatile uint64_t*>(bd.data + index) = value;
00318     }
00319 
00320     uint64_t make_header(Message m, size_t size, bool pending = true)
00321     {
00322       return (((uint64_t)m) << 32) |
00323         ((size & length_mask) | (pending ? pending_write_flag : 0u));
00324     }
00325 
00326     std::optional<Reservation> reserve(size_t size)
00327     {
00328       auto mask = bd.size - 1;
00329       auto hd = bd.offsets->head_cache.load(std::memory_order_relaxed);
00330       auto tl = bd.offsets->tail.load(std::memory_order_relaxed);
00331 
00332       // NB: These will be always be set on the first loop, before they are
00333       // read, so this initialisation is unnecessary. It is added to placate
00334       // static analyzers.
00335       size_t padding = 0u;
00336       size_t tl_index = 0u;
00337 
00338       do
00339       {
00340         auto gap = tl - hd;
00341         auto avail = bd.size - gap;
00342 
00343         // If the head cache is too far behind the tail, or if the message does
00344         // not fit in the available space, get an accurate head and try again.
00345         if ((gap > bd.size) || (size > avail))
00346         {
00347           // If the message does not fit in the sum of front-space and
00348           // back-space, see if head has moved to give us enough space.
00349           hd = bd.offsets->head.load(std::memory_order_relaxed);
00350 
00351           // This happens if the head has passed the tail we previously loaded.
00352           // It is safe to continue here, as the compare_exchange_weak is
00353           // guaranteed to fail and update tl.
00354           if (hd > tl)
00355             continue;
00356 
00357           avail = bd.size - (tl - hd);
00358 
00359           // If it still doesn't fit, fail.
00360           if (size > avail)
00361             return {};
00362 
00363           // This may move the head cache backwards, but if so, that is safe and
00364           // will be corrected later.
00365           bd.offsets->head_cache.store(hd, std::memory_order_relaxed);
00366         }
00367 
00368         padding = 0;
00369         tl_index = tl & mask;
00370         auto block = bd.size - tl_index;
00371 
00372         if (size > block)
00373         {
00374           // If the message doesn't fit in back-space...
00375           auto hd_index = hd & mask;
00376 
00377           if (size > hd_index)
00378           {
00379             // If message doesn't fit in front-space, see if the head has moved
00380             hd = bd.offsets->head.load(std::memory_order_relaxed);
00381             hd_index = hd & mask;
00382 
00383             // If it still doesn't fit, fail - there is not a contiguous region
00384             // large enough for this reservation
00385             if (size > hd_index)
00386               return {};
00387 
00388             // This may move the head cache backwards, but if so, that is safe
00389             // and will be corrected later.
00390             bd.offsets->head_cache.store(hd, std::memory_order_relaxed);
00391           }
00392 
00393           // Pad the back-space and reserve front-space for our message in a
00394           // single tail update.
00395           padding = block;
00396         }
00397       } while (!bd.offsets->tail.compare_exchange_weak(
00398         tl, tl + size + padding, std::memory_order_seq_cst));
00399 
00400       if (padding != 0)
00401       {
00402         write64(tl_index, make_header(Const::msg_pad, padding, false));
00403         tl_index = 0;
00404       }
00405 
00406       return {{tl_index, tl}};
00407     }
00408   };
00409 
00410   // This is entirely non-virtual so can be safely passed to the enclave
00411   class Circuit
00412   {
00413   private:
00414     ringbuffer::Reader from_outside;
00415     ringbuffer::Reader from_inside;
00416 
00417   public:
00418     Circuit(
00419       const BufferDef& from_outside_buffer,
00420       const BufferDef& from_inside_buffer) :
00421       from_outside(from_outside_buffer),
00422       from_inside(from_inside_buffer)
00423     {}
00424 
00425     ringbuffer::Reader& read_from_outside()
00426     {
00427       return from_outside;
00428     }
00429 
00430     ringbuffer::Reader& read_from_inside()
00431     {
00432       return from_inside;
00433     }
00434 
00435     ringbuffer::Writer write_to_outside()
00436     {
00437       return ringbuffer::Writer(from_inside);
00438     }
00439 
00440     ringbuffer::Writer write_to_inside()
00441     {
00442       return ringbuffer::Writer(from_outside);
00443     }
00444   };
00445 
00446   class WriterFactory : public AbstractWriterFactory
00447   {
00448     ringbuffer::Circuit& raw_circuit;
00449 
00450   public:
00451     WriterFactory(ringbuffer::Circuit& c) : raw_circuit(c) {}
00452 
00453     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_outside()
00454       override
00455     {
00456       return std::make_shared<Writer>(raw_circuit.read_from_inside());
00457     }
00458 
00459     std::shared_ptr<ringbuffer::AbstractWriter> create_writer_to_inside()
00460       override
00461     {
00462       return std::make_shared<Writer>(raw_circuit.read_from_outside());
00463     }
00464   };
00465 
00466   // This struct wraps buffer management to simplify testing
00467   struct TestBuffer
00468   {
00469     std::vector<uint8_t> storage;
00470     Offsets offsets;
00471 
00472     BufferDef bd;
00473 
00474     TestBuffer(size_t size) : storage(size, 0), offsets()
00475     {
00476       bd.data = storage.data();
00477       bd.size = storage.size();
00478       bd.offsets = &offsets;
00479     }
00480   };
00481 }
00482 
---------
Macros accessible in this file:
---------
RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD CCF_PAUSE 
---------
Parsing file /data/git/CCF/src/ds/ring_buffer.h...
Preprocessing /data/git/CCF/src/ds/ring_buffer_types.h...
#include ds/nonstd.h: not found! skipping...
#include hash.h: already included! skipping...
#include serializer.h: already included! skipping...
#include atomic: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 6061 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ringbuffer
00015 {
00016   using Message = uint32_t;
00017 
00018   // Align by cacheline to avoid false sharing
00019   static constexpr size_t CACHELINE_SIZE = 64;
00020 
00021   struct alignas(CACHELINE_SIZE) Offsets
00022   {
00023     std::atomic<size_t> head_cache = {0};
00024     std::atomic<size_t> tail = {0};
00025     alignas(CACHELINE_SIZE) std::atomic<size_t> head = {0};
00026   };
00027 
00028   class message_error : public std::logic_error
00029   {
00030   public:
00031     Message ringbuffer_message_type;
00032 
00033     template <typename... Ts>
00034     message_error(Message m, Ts&&... ts) :
00035       std::logic_error(std::forward<Ts>(ts)...),
00036       ringbuffer_message_type(m)
00037     {}
00038   };
00039 
00040   class AbstractWriter
00041   {
00042   public:
00043     virtual ~AbstractWriter() = default;
00044 
00045     /// Write a message of the given type, containing serialized representation
00046     /// of each of the args, in order. Blocks until the entire message is
00047     /// written.
00048     template <typename Serializer, typename... Ts>
00049     void write_with(Message m, Ts&&... ts)
00050     {
00051       write_multiple<Serializer>(m, true, std::forward<Ts>(ts)...);
00052     }
00053 
00054     /// Try to write a message, but fail (and write nothing) if there is not
00055     /// currently sufficient space to write completely.
00056     template <typename Serializer, typename... Ts>
00057     bool try_write_with(Message m, Ts&&... ts)
00058     {
00059       return write_multiple<Serializer>(m, false, std::forward<Ts>(ts)...);
00060     }
00061 
00062     template <typename... Ts>
00063     void write(Message m, Ts&&... ts)
00064     {
00065       write_with<serializer::CommonSerializer>(m, std::forward<Ts>(ts)...);
00066     }
00067 
00068     template <typename... Ts>
00069     bool try_write(Message m, Ts&&... ts)
00070     {
00071       return try_write_with<serializer::CommonSerializer>(
00072         m, std::forward<Ts>(ts)...);
00073     }
00074 
00075     // If a call to prepare or write_bytes fails, this returned value will be
00076     // empty. Otherwise it is an opaque marker that the implementation can use
00077     // to track progress between writes in the same message.
00078     using WriteMarker = std::optional<size_t>;
00079 
00080     /// Implementation requires 3 methods - prepare, finish, and write_bytes.
00081     /// For each message, prepare will be called with the total message size. It
00082     /// should return a WriteMarker for this reservation. That WriteMarker will
00083     /// be passed to write_bytes, which may be called repeatedly for each part
00084     /// of the message. write_bytes returns an opaque WriteMarker which will be
00085     /// passed to the next invocation of write_bytes, to track progress.
00086     /// Finally, finish will be called with the WriteMarker initially returned
00087     /// from prepare.
00088     ///@{
00089     virtual WriteMarker prepare(
00090       Message m,
00091       size_t size,
00092       bool wait = true,
00093       size_t* identifier = nullptr) = 0;
00094 
00095     virtual void finish(const WriteMarker& marker) = 0;
00096 
00097     virtual WriteMarker write_bytes(
00098       const WriteMarker& marker, const uint8_t* bytes, size_t size) = 0;
00099     ///@}
00100 
00101   private:
00102     template <typename Serializer, typename... Ts>
00103     bool write_multiple(Message m, bool wait, Ts&&... ts)
00104     {
00105       auto sections = Serializer::serialize(std::forward<Ts>(ts)...);
00106 
00107       // Fold section->sizes over the + operator, with initial value 0
00108       size_t total_size = std::apply(
00109         [](const auto&... section) { return (section->size() + ... + 0); },
00110         sections);
00111 
00112       const auto initial_marker = prepare(m, total_size, wait);
00113 
00114       if (!initial_marker.has_value())
00115         return false;
00116 
00117       auto next = initial_marker;
00118       serializer::details::tuple_for_each(sections, [&](const auto& s) {
00119         next = write_bytes(next, s->data(), s->size());
00120       });
00121 
00122       finish(initial_marker);
00123 
00124       return next.has_value();
00125     }
00126   };
00127 
00128   using WriterPtr = std::shared_ptr<AbstractWriter>;
00129 
00130   class AbstractWriterFactory
00131   {
00132   public:
00133     virtual ~AbstractWriterFactory() = default;
00134 
00135     virtual WriterPtr create_writer_to_outside() = 0;
00136     virtual WriterPtr create_writer_to_inside() = 0;
00137   };
00138 
00139   /// Useful machinery
00140 #define DEFINE_RINGBUFFER_MSG_TYPE(NAME) 
00141 
00142 
00143   template <ringbuffer::Message m>
00144   struct MessageSerializers
00145   {
00146     static_assert(
00147       nonstd::dependent_false<ringbuffer::Message, m>::value,
00148       "No payload specialization for this Message");
00149   };
00150 
00151 #define DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD(MTYPE) 
00152 
00153 
00154 
00155 
00156 
00157 #define DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(MTYPE, ...) 
00158 
00159 
00160 
00161 
00162 
00163   // Helper functions to write/read with serializer determined by message
00164   template <ringbuffer::Message m, typename WriterPtr, typename... Ts>
00165   inline void write_message(const WriterPtr& w, Ts&&... ts)
00166   {
00167     using S = MessageSerializers<m>;
00168 
00169     w->template write_with<S>(m, std::forward<Ts>(ts)...);
00170   }
00171 
00172   template <ringbuffer::Message m, typename WriterPtr, typename... Ts>
00173   inline bool try_write_message(const WriterPtr& w, Ts&&... ts)
00174   {
00175     using S = MessageSerializers<m>;
00176 
00177     return w->template try_write_with<S>(m, std::forward<Ts>(ts)...);
00178   }
00179 
00180   template <ringbuffer::Message m>
00181   inline auto read_message(const uint8_t*& data, size_t& size)
00182   {
00183     using S = MessageSerializers<m>;
00184 
00185     return S::deserialize(data, size);
00186   }
00187 
00188   template <ringbuffer::Message m, typename... Ts>
00189   inline void write_message_with_error_wrapper(char const* prefix, Ts&&... ts)
00190   {
00191     try
00192     {
00193       write_message<m>(std::forward<Ts>(ts)...);
00194     }
00195     catch (const ringbuffer::message_error& ex)
00196     {
00197       throw std::logic_error(std::string("[") + prefix + "] " + ex.what());
00198     }
00199   }
00200 
00201   template <ringbuffer::Message m, typename... Ts>
00202   inline bool try_write_message_with_error_wrapper(
00203     char const* prefix, Ts&&... ts)
00204   {
00205     try
00206     {
00207       return try_write_message<m>(std::forward<Ts>(ts)...);
00208     }
00209     catch (const ringbuffer::message_error& ex)
00210     {
00211       throw std::logic_error(std::string("[") + prefix + "] " + ex.what());
00212     }
00213 
00214     return false;
00215   }
00216 
00217   /// Macros to catch message-related errors and translate to a human-readable
00218   /// message name
00219 #define RINGBUFFER_WRITE_MESSAGE(MSG, ...) 
00220 
00221 
00222 #define RINGBUFFER_TRY_WRITE_MESSAGE(MSG, ...) 
00223 
00224 }
---------
Macros accessible in this file:
---------
RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD 
---------
Parsing file /data/git/CCF/src/ds/ring_buffer_types.h...
Preprocessing /data/git/CCF/src/ds/serialized.h...
#include cstdint: not found! skipping...
#include cstring: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 3830 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace serialized
00012 {
00013   template <class T>
00014   T peek(const uint8_t*& data, size_t& size)
00015   {
00016     if (size < sizeof(T))
00017       throw std::logic_error(
00018         "Insufficient space (peek<T>: " + std::to_string(size) + " < " +
00019         std::to_string(sizeof(T)) + ")");
00020 
00021     return *(T*)data;
00022   }
00023 
00024   template <class T>
00025   T read(const uint8_t*& data, size_t& size)
00026   {
00027     if (size < sizeof(T))
00028       throw std::logic_error(
00029         "Insufficient space (read<T>: " + std::to_string(size) + " < " +
00030         std::to_string(sizeof(T)) + ")");
00031 
00032     T v;
00033     std::memcpy(reinterpret_cast<uint8_t*>(&v), data, sizeof(T));
00034     data += sizeof(T);
00035     size -= sizeof(T);
00036     return v;
00037   }
00038 
00039   template <>
00040   inline std::string read(const uint8_t*& data, size_t& size)
00041   {
00042     size_t len = read<size_t>(data, size);
00043     std::string v(data, data + len);
00044     data += len;
00045     size -= len;
00046     return v;
00047   }
00048 
00049   inline std::vector<uint8_t> read(
00050     const uint8_t*& data, size_t& size, size_t block_size)
00051   {
00052     if (size < block_size)
00053       throw std::logic_error(
00054         "Insufficient space (read block: " + std::to_string(size) + " < " +
00055         std::to_string(block_size) + ")");
00056 
00057     std::vector<uint8_t> v(data, data + block_size);
00058     data += block_size;
00059     size -= block_size;
00060     return v;
00061   }
00062 
00063   // Read a length-prefixed (uint16_t) buffer into a string view
00064   inline std::string_view read_lpsv(const uint8_t*& data, size_t& size)
00065   {
00066     auto len = read<uint16_t>(data, size);
00067     if (size < len)
00068       throw std::logic_error(
00069         "Insufficient space (read block: " + std::to_string(size) + " < " +
00070         std::to_string(len) + ")");
00071     std::string_view v((char*)data, len);
00072     data += len;
00073     size -= len;
00074     return v;
00075   };
00076 
00077   template <class T>
00078   void write(uint8_t*& data, size_t& size, const T& v)
00079   {
00080     if (size < sizeof(T))
00081       throw std::logic_error(
00082         "Insufficient space (write<T>: " + std::to_string(size) + " < " +
00083         std::to_string(sizeof(T)) + ")");
00084 
00085     const auto src = reinterpret_cast<const uint8_t*>(&v);
00086     std::memcpy(data, src, sizeof(T));
00087     data += sizeof(T);
00088     size -= sizeof(T);
00089   }
00090 
00091   inline void write(
00092     uint8_t*& data, size_t& size, const uint8_t* block, size_t block_size)
00093   {
00094     if (size < block_size)
00095       throw std::logic_error(
00096         "Insufficient space (write block: " + std::to_string(size) + " < " +
00097         std::to_string(block_size) + ")");
00098 
00099     if (block_size > 0)
00100     {
00101       std::memcpy(data, block, block_size);
00102     }
00103 
00104     data += block_size;
00105     size -= block_size;
00106   }
00107 
00108   inline void write(uint8_t*& data, size_t& size, const std::string& v)
00109   {
00110     if (size < (sizeof(size_t) + v.size()))
00111       throw std::logic_error(
00112         "Insufficient space (write string: " + std::to_string(size) + " < " +
00113         std::to_string(sizeof(size_t) + v.size()) + ")");
00114 
00115     write(data, size, v.size());
00116     write(data, size, (const uint8_t*)v.data(), v.size());
00117   }
00118 
00119   inline void write_lps(uint8_t*& data, size_t& size, const std::string& v)
00120   {
00121     write<uint16_t>(data, size, v.size());
00122     write(data, size, (const uint8_t*)v.data(), v.size());
00123   }
00124 
00125   template <class T>
00126   T& overlay(const uint8_t*& data, size_t& size)
00127   {
00128     if (size < sizeof(T))
00129       throw std::logic_error(
00130         "Insufficient space (overlay<T>: " + std::to_string(size) + " < " +
00131         std::to_string(sizeof(T)) + ")");
00132 
00133     T* v = (T*)data;
00134     data += sizeof(T);
00135     size -= sizeof(T);
00136     return *v;
00137   }
00138 
00139   inline void skip(const uint8_t*& data, size_t& size, size_t skip)
00140   {
00141     if (size < skip)
00142       throw std::logic_error(
00143         "Insufficient space (skip: " + std::to_string(size) + " < " +
00144         std::to_string(skip) + ")");
00145 
00146     data += skip;
00147     size -= skip;
00148   }
00149 }
00150 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/serialized.h...
Preprocessing /data/git/CCF/src/ds/serializer.h...
#include ds/nonstd.h: not found! skipping...
#include serialized.h: already included! skipping...
#include memory: not found! skipping...
#include tuple: not found! skipping...
#include type_traits: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 13256 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace serializer
00014 {
00015   // A Serializer is generally used as a template argument. It should provide:
00016   // - serialize(...): returning a tuple of PartialSerializations representing
00017   //   all passed args. It may be templated and variadic or accept only precise
00018   //   argument types. Ideally it should give a useful error message at compile
00019   //   time when called with argument types it doesn't support.
00020   // - deserialize(const uint8_t* data, size_t size): returning a tuple of
00021   //   elements parsed from byte buffer, potentially throwing logic errors if
00022   //   anything is missing/malformed. May need to be templated on expected
00023   //   types.
00024 
00025   struct ByteRange
00026   {
00027     const uint8_t* data;
00028     const size_t size;
00029   };
00030 
00031   namespace details
00032   {
00033     /// Iterate through tuple, calling functor on each element
00034     template <size_t I = 0, typename F, typename... Ts>
00035     static void tuple_for_each(const std::tuple<Ts...>& t, const F& f)
00036     {
00037       if constexpr (I < sizeof...(Ts))
00038       {
00039         f(std::get<I>(t));
00040         tuple_for_each<I + 1>(t, f);
00041       }
00042     }
00043 
00044     /// Call functor on each element, cat all results. f takes a tuple-element,
00045     /// returns a tuple of results
00046     template <size_t I = 0, typename F, typename... Ts>
00047     static auto tuple_apply(const std::tuple<Ts...>& t, const F& f)
00048     {
00049       if constexpr (sizeof...(Ts) == 1)
00050       {
00051         return std::make_tuple();
00052       }
00053       else if constexpr (I == sizeof...(Ts) - 1)
00054       {
00055         return f(std::get<I>(t));
00056       }
00057       else
00058       {
00059         return std::tuple_cat(f(std::get<I>(t)), tuple_apply<I + 1>(t, f));
00060       }
00061     }
00062 
00063     template <typename Tup>
00064     struct TupMatcher
00065     {
00066       static constexpr size_t TupSize = std::tuple_size_v<Tup>;
00067 
00068       template <typename... Ts>
00069       struct correct_size
00070       {
00071         static constexpr bool value = TupSize == sizeof...(Ts);
00072       };
00073 
00074       template <typename... Ts>
00075       static constexpr bool correct_size_v = correct_size<Ts...>::value;
00076 
00077       template <size_t I, typename T>
00078       struct close_enough_at
00079       {
00080         using CanonTarget =
00081           nonstd::remove_cvref_t<typename std::tuple_element_t<I, Tup>>;
00082         using CanonArgument = nonstd::remove_cvref_t<T>;
00083 
00084         // This determines what types a Serializer will accept as arguments to
00085         // serialize(...), relative to the declared param types.
00086         // The main feature is the removal of const, volatile, and references
00087         // from the type so that a Serializer<int> will accept an argument of
00088         // type const int&.
00089         // Additionally, this will accept ByteRange arguments for parameters
00090         // declared as std::vector<uint8_t> - when serializing we can copy bytes
00091         // from either in the same way, but there is a distinction in the
00092         // deserialized type of whether we are copying (to a byte vector) or
00093         // referring to an existing byte range.
00094         // It may be possible to generalise this further and replace with
00095         // std::is_constructible, but these restrictions are sufficient for the
00096         // current uses.
00097         static constexpr bool value =
00098           std::is_same_v<CanonTarget, CanonArgument> ||
00099           (std::is_same_v<CanonTarget, std::vector<uint8_t>> &&
00100            std::is_same_v<CanonArgument, ByteRange>);
00101       };
00102 
00103       // Only reached when Ts is empty
00104       template <size_t I, typename... Ts>
00105       struct close_enough_from
00106       {
00107         static constexpr bool value = I == TupSize;
00108       };
00109 
00110       template <size_t I, typename T, typename... Ts>
00111       struct close_enough_from<I, T, Ts...>
00112       {
00113         static constexpr bool value = close_enough_at<I, T>::value &&
00114           close_enough_from<I + 1, Ts...>::value;
00115       };
00116 
00117       template <typename... Ts>
00118       struct close_enough
00119       {
00120         static constexpr bool value = close_enough_from<0, Ts...>::value;
00121       };
00122 
00123       template <typename... Ts>
00124       static constexpr bool close_enough_v = close_enough<Ts...>::value;
00125     };
00126 
00127     template <typename... Ts>
00128     struct TypeMatcher : public TupMatcher<std::tuple<Ts...>>
00129     {};
00130   }
00131 
00132   struct AbstractSerializedSection
00133   {
00134     virtual ~AbstractSerializedSection() = default;
00135     virtual const uint8_t* data() const = 0;
00136     virtual size_t size() const = 0;
00137   };
00138 
00139   using PartialSerialization = std::shared_ptr<AbstractSerializedSection>;
00140 
00141   template <typename T>
00142   struct CopiedSection : public AbstractSerializedSection
00143   {
00144     const T t;
00145 
00146     CopiedSection(const T& t_) : t(t_) {}
00147 
00148     virtual const uint8_t* data() const override
00149     {
00150       return reinterpret_cast<const uint8_t*>(&t);
00151     }
00152 
00153     virtual size_t size() const override
00154     {
00155       return sizeof(T);
00156     }
00157   };
00158 
00159   template <typename T>
00160   struct RawSection : public AbstractSerializedSection
00161   {
00162     const T& t;
00163 
00164     RawSection(const T& t_) : t(t_) {}
00165 
00166     virtual const uint8_t* data() const override
00167     {
00168       return reinterpret_cast<const uint8_t*>(&t);
00169     }
00170 
00171     virtual size_t size() const override
00172     {
00173       return sizeof(T);
00174     }
00175   };
00176 
00177   struct MemoryRegionSection : public AbstractSerializedSection
00178   {
00179     const uint8_t* const d;
00180     const size_t s;
00181 
00182     MemoryRegionSection(const uint8_t* data_, size_t size_) : d(data_), s(size_)
00183     {}
00184 
00185     virtual const uint8_t* data() const override
00186     {
00187       return d;
00188     }
00189 
00190     virtual size_t size() const override
00191     {
00192       return s;
00193     }
00194   };
00195 
00196   class EmptySerializer
00197   {
00198   public:
00199     /// Can serialize empty messages, but nothing else
00200     template <typename... Ts>
00201     static std::tuple<> serialize(const Ts&... ts)
00202     {
00203       static_assert(
00204         sizeof...(ts) == 0,
00205         "EmptySerializer was given message payload to serialize - can only "
00206         "serialize empty "
00207         "messages");
00208       return std::make_tuple();
00209     }
00210 
00211     template <typename... Ts>
00212     static std::tuple<> deserialize(const uint8_t*, size_t size)
00213     {
00214       if constexpr (sizeof...(Ts) == 0)
00215       {
00216         if (size > 0)
00217           throw std::logic_error(
00218             "EmptySerializer asked to deserialize buffer of size " +
00219             std::to_string(size) + ", should be empty");
00220       }
00221       return std::make_tuple();
00222     }
00223   };
00224 
00225   class CommonSerializer : public EmptySerializer
00226   {
00227     /// Overloads of serialize_value - return a tuple of PartialSerializations
00228     ///@{
00229     /// Overload for ByteRanges (no length-prefix)
00230     static auto serialize_value(const ByteRange& br)
00231     {
00232       auto bfs = std::make_shared<MemoryRegionSection>(br.data, br.size);
00233       return std::make_tuple(bfs);
00234     }
00235 
00236     /// Overload for std::vectors of bytes (no length-prefix)
00237     static auto serialize_value(const std::vector<uint8_t>& vec)
00238     {
00239       auto bfs = std::make_shared<MemoryRegionSection>(vec.data(), vec.size());
00240       return std::make_tuple(bfs);
00241     }
00242 
00243     /// Overload for strings (length-prefixed)
00244     static auto serialize_value(const std::string& s)
00245     {
00246       auto cs = std::make_shared<CopiedSection<size_t>>(s.size());
00247       auto bfs = std::make_shared<MemoryRegionSection>(
00248         reinterpret_cast<const uint8_t*>(s.data()), s.size());
00249       return std::tuple_cat(std::make_tuple(cs), std::make_tuple(bfs));
00250     }
00251 
00252     /// Generic case - use raw byte representation
00253     template <typename T>
00254     static auto serialize_value(const T& t)
00255     {
00256       auto rs = std::make_shared<RawSection<T>>(t);
00257       return std::make_tuple(rs);
00258     }
00259     ///@}
00260 
00261     /// Tag type to distinguish deserialize overloads by return type
00262     template <typename T>
00263     struct Tag
00264     {
00265       using type = T;
00266     };
00267 
00268     /// Overloads of deserialize_value
00269     ///@{
00270     /// Overload for ByteRange (refers to data in-place)
00271     static ByteRange deserialize_value(
00272       const uint8_t*& data, size_t& size, const Tag<ByteRange>&)
00273     {
00274       ByteRange br{data, size};
00275       data += size;
00276       size -= size;
00277       return br;
00278     }
00279 
00280     /// Overload for std::vectors of bytes (copied)
00281     static std::vector<uint8_t> deserialize_value(
00282       const uint8_t*& data, size_t& size, const Tag<std::vector<uint8_t>>&)
00283     {
00284       return serialized::read(data, size, size);
00285     }
00286 
00287     /// Overload for strings
00288     static std::string deserialize_value(
00289       const uint8_t*& data, size_t& size, const Tag<std::string>&)
00290     {
00291       return serialized::read<std::string>(data, size);
00292     }
00293 
00294     /// Generic case
00295     template <typename T>
00296     static T deserialize_value(
00297       const uint8_t*& data, size_t& size, const Tag<T>&)
00298     {
00299       return serialized::read<T>(data, size);
00300     }
00301     ///@}
00302 
00303     template <typename T, typename... Ts>
00304     static auto deserialize_impl(const uint8_t* data, size_t size)
00305     {
00306       using StrippedT = nonstd::remove_cvref_t<T>;
00307 
00308       if constexpr (
00309         std::is_same_v<StrippedT, std::vector<uint8_t>> ||
00310         std::is_same_v<StrippedT, ByteRange>)
00311       {
00312         static_assert(
00313           sizeof...(Ts) == 0,
00314           "Byte vectors must be the final element in message");
00315       }
00316 
00317       const auto next =
00318         std::make_tuple(deserialize_value(data, size, Tag<StrippedT>{}));
00319 
00320       if constexpr (sizeof...(Ts) == 0)
00321       {
00322         return next;
00323       }
00324       else
00325       {
00326         return std::tuple_cat(next, deserialize_impl<Ts...>(data, size));
00327       }
00328     }
00329 
00330   public:
00331     // Can also serialize empty messages
00332     using EmptySerializer::serialize;
00333 
00334     /// General serialize call - convert each argument to a tuple, cat those
00335     /// tuples
00336     template <typename T, typename... Ts>
00337     static auto serialize(T&& t, Ts&&... ts)
00338     {
00339       const auto next = serialize_value(std::forward<T>(t));
00340       return std::tuple_cat(next, serialize(std::forward<Ts>(ts)...));
00341     }
00342 
00343     template <typename... Ts>
00344     static auto deserialize(const uint8_t* data, size_t size)
00345     {
00346       if constexpr (sizeof...(Ts) == 0)
00347       {
00348         return EmptySerializer::deserialize(data, size);
00349       }
00350       else
00351       {
00352         return deserialize_impl<Ts...>(data, size);
00353       }
00354     }
00355   };
00356 
00357   // Serializes a list of exactly these argument types, and nothing else
00358   template <typename... Us>
00359   class PreciseSerializer : private CommonSerializer
00360   {
00361     using Matcher = details::TypeMatcher<Us...>;
00362 
00363   public:
00364     template <typename... Ts>
00365     static auto serialize(Ts&&... ts)
00366     {
00367       static_assert(
00368         Matcher::template correct_size_v<Ts...>,
00369         "Incorrect number of arguments for PreciseSerializer");
00370       static_assert(
00371         Matcher::template close_enough_v<Ts...>,
00372         "Incorrect type of arguments for PreciseSerializer");
00373 
00374       return CommonSerializer::serialize(std::forward<Ts>(ts)...);
00375     }
00376 
00377     template <typename... Ts>
00378     static auto deserialize(const uint8_t* data, size_t size)
00379     {
00380       static_assert(
00381         Matcher::template correct_size_v<Ts...>,
00382         "Incorrect number of results for PreciseSerializer");
00383       static_assert(
00384         Matcher::template close_enough_v<Ts...>,
00385         "Incorrect type of results for PreciseSerializer");
00386 
00387       return CommonSerializer::deserialize<Us...>(data, size);
00388     }
00389 
00390     static auto deserialize(const uint8_t* data, size_t size)
00391     {
00392       return CommonSerializer::deserialize<Us...>(data, size);
00393     }
00394   };
00395 
00396   template <typename>
00397   class TupleSerializer;
00398 
00399   // Specializes a specific tuple-type only. Removes ref and const when
00400   // comparing types, ie tuple<int, const float&> will be accepted by
00401   // TupleSerializers specialized at tuple<int, float>, tuple<const int&, const
00402   // float&> etc
00403   template <typename... Us>
00404   class TupleSerializer<std::tuple<Us...>> : private CommonSerializer
00405   {
00406     using Tup = std::tuple<Us...>;
00407     using Matcher = details::TupMatcher<Tup>;
00408 
00409   public:
00410     template <typename... Ts>
00411     static auto serialize(std::tuple<Ts...>&& t)
00412     {
00413       static_assert(
00414         Matcher::template correct_size_v<Ts...>,
00415         "Incorrect tuple size for TupleSerializer");
00416       static_assert(
00417         Matcher::template close_enough_v<Ts...>,
00418         "Incorrect tuple type for TupleSerializer");
00419 
00420       return details::tuple_apply(
00421         t, [](const auto& e) { return CommonSerializer::serialize(e); });
00422     }
00423 
00424     // Takes variadic arguments list, they don't need to be packed in tuple
00425     template <typename... Ts>
00426     static auto serialize(Ts&&... ts)
00427     {
00428       static_assert(
00429         Matcher::template correct_size_v<Ts...>,
00430         "Incorrect number of args for unpacked TupleSerializer");
00431       static_assert(
00432         Matcher::template close_enough_v<Ts...>,
00433         "Incorrect arg types for unpacked TupleSerializer");
00434 
00435       return CommonSerializer::serialize(std::forward<Ts>(ts)...);
00436     }
00437 
00438     template <typename... Ts>
00439     static auto deserialize(const uint8_t* data, size_t size)
00440     {
00441       static_assert(
00442         Matcher::template correct_size_v<Ts...>,
00443         "Incorrect number of results for TupleSerializer");
00444       static_assert(
00445         Matcher::template close_enough_v<Ts...>,
00446         "Incorrect type of results for TupleSerializer");
00447 
00448       return CommonSerializer::deserialize<Ts...>(data, size);
00449     }
00450 
00451     static auto deserialize(const uint8_t* data, size_t size)
00452     {
00453       return CommonSerializer::deserialize<Us...>(data, size);
00454     }
00455   };
00456 } // namespace serializer
00457 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/serializer.h...
Preprocessing /data/git/CCF/src/ds/siphash.h...
#include cstddef: not found! skipping...
#include cstdint: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 3938 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 // C++ port of reference implementation
00010 namespace siphash
00011 {
00012   using SipState = uint64_t[4];
00013   using SipKey = uint64_t[2];
00014 
00015   constexpr uint64_t rotl(uint64_t x, size_t b)
00016   {
00017     return (x << b) | (x >> (64 - b));
00018   }
00019 
00020   inline void u32_to_bytes_le(uint32_t v, uint8_t* out)
00021   {
00022     out[0] = (uint8_t)(v);
00023     out[1] = (uint8_t)(v >> 8);
00024     out[2] = (uint8_t)(v >> 16);
00025     out[3] = (uint8_t)(v >> 24);
00026   }
00027 
00028   inline void u64_to_bytes_le(uint64_t v, uint8_t* out)
00029   {
00030     u32_to_bytes_le((uint32_t)v, out);
00031     u32_to_bytes_le((uint32_t)(v >> 32), out + 4);
00032   }
00033 
00034   template <typename ConstRandomIterator>
00035   constexpr uint64_t bytes_to_64_le(const ConstRandomIterator in)
00036   {
00037     return ((uint64_t)in[0]) | ((uint64_t)in[1] << 8) |
00038       ((uint64_t)in[2] << 16) | ((uint64_t)in[3] << 24) |
00039       ((uint64_t)in[4] << 32) | ((uint64_t)in[5] << 40) |
00040       ((uint64_t)in[6] << 48) | ((uint64_t)in[7] << 56);
00041   }
00042 
00043   inline void sip_rounds(SipState& s, size_t rounds)
00044   {
00045     for (size_t i = 0; i < rounds; ++i)
00046     {
00047       s[0] += s[1];
00048       s[1] = rotl(s[1], 13);
00049       s[1] ^= s[0];
00050       s[0] = rotl(s[0], 32);
00051       s[2] += s[3];
00052       s[3] = rotl(s[3], 16);
00053       s[3] ^= s[2];
00054       s[0] += s[3];
00055       s[3] = rotl(s[3], 21);
00056       s[3] ^= s[0];
00057       s[2] += s[1];
00058       s[1] = rotl(s[1], 17);
00059       s[1] ^= s[2];
00060       s[2] = rotl(s[2], 32);
00061     }
00062   }
00063 
00064   enum class OutputLength
00065   {
00066     EightBytes = 8,
00067     SixteenBytes = 16,
00068   };
00069 
00070   template <
00071     size_t CompressionRounds,
00072     size_t FinalizationRounds,
00073     OutputLength out_size>
00074   void siphash_raw(
00075     const uint8_t* in, size_t in_len, const SipKey& key, uint8_t* out)
00076   {
00077     SipState s{0x736f6d6570736575ULL,
00078                0x646f72616e646f6dULL,
00079                0x6c7967656e657261ULL,
00080                0x7465646279746573ULL};
00081 
00082     SipKey k{key[0], key[1]};
00083 
00084     s[0] ^= k[0];
00085     s[1] ^= k[1];
00086     s[2] ^= k[0];
00087     s[3] ^= k[1];
00088 
00089     const uint8_t* end = in + in_len - (in_len % 8);
00090     const size_t left = in_len & 7;
00091 
00092     if constexpr (out_size == OutputLength::SixteenBytes)
00093     {
00094       s[1] ^= 0xee;
00095     }
00096 
00097     uint64_t m;
00098     for (; in != end; in += 8)
00099     {
00100       m = bytes_to_64_le(in);
00101       s[3] ^= m;
00102 
00103       sip_rounds(s, CompressionRounds);
00104 
00105       s[0] ^= m;
00106     }
00107 
00108     uint64_t b = (uint64_t)in_len << 56;
00109 
00110     // Deliberate fall through
00111     switch (left)
00112     {
00113       case 7:
00114         b |= (uint64_t)in[6] << 48;
00115       case 6:
00116         b |= (uint64_t)in[5] << 40;
00117       case 5:
00118         b |= (uint64_t)in[4] << 32;
00119       case 4:
00120         b |= (uint64_t)in[3] << 24;
00121       case 3:
00122         b |= (uint64_t)in[2] << 16;
00123       case 2:
00124         b |= (uint64_t)in[1] << 8;
00125       case 1:
00126         b |= (uint64_t)in[0];
00127       case 0:
00128         break;
00129     }
00130 
00131     s[3] ^= b;
00132 
00133     sip_rounds(s, CompressionRounds);
00134 
00135     s[0] ^= b;
00136 
00137     if constexpr (out_size == OutputLength::SixteenBytes)
00138     {
00139       s[2] ^= 0xee;
00140     }
00141     else
00142     {
00143       s[2] ^= 0xff;
00144     }
00145 
00146     sip_rounds(s, FinalizationRounds);
00147 
00148     b = s[0] ^ s[1] ^ s[2] ^ s[3];
00149     u64_to_bytes_le(b, out);
00150 
00151     if constexpr (out_size == OutputLength::EightBytes)
00152     {
00153       return;
00154     }
00155 
00156     s[1] ^= 0xdd;
00157 
00158     sip_rounds(s, FinalizationRounds);
00159 
00160     b = s[0] ^ s[1] ^ s[2] ^ s[3];
00161     u64_to_bytes_le(b, out + 8);
00162 
00163     return;
00164   }
00165 
00166   template <size_t CompressionRounds, size_t FinalizationRounds>
00167   uint64_t siphash(const uint8_t* data, size_t size, const SipKey& key)
00168   {
00169     uint64_t out;
00170 
00171     siphash_raw<
00172       CompressionRounds,
00173       FinalizationRounds,
00174       OutputLength::EightBytes>(
00175       data, size, key, reinterpret_cast<uint8_t*>(&out));
00176 
00177     return out;
00178   }
00179 
00180   template <size_t CompressionRounds, size_t FinalizationRounds>
00181   uint64_t siphash(const std::vector<uint8_t>& in, const SipKey& key)
00182   {
00183     return siphash<CompressionRounds, FinalizationRounds>(
00184       in.data(), in.size(), key);
00185   }
00186 }
00187 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/siphash.h...
Preprocessing /data/git/CCF/src/ds/spin_lock.h...
#include mutex: not found! skipping...
Preprocessor output (size: 194 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 using SpinLock = std::mutex;
00065 
00066 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/spin_lock.h...
Preprocessing /data/git/CCF/src/ds/stacktrace_utils.h...
#include logger.h: already included! skipping...
#include backward-cpp/backward.hpp: not found! skipping...
#include iostream: not found! skipping...
Preprocessor output (size: 2611 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 // #  pragma clang diagnostic push
00008 // #  pragma clang diagnostic ignored "-Wundef"
00009 
00010 // #  pragma clang diagnostic pop
00011 
00012 
00013 
00014 
00015 
00016 
00017 namespace stacktrace
00018 {
00019   /** Print a stack backtrace of the caller function to std out.
00020    * In-enclave version will contain mangled names, and uses the standard
00021    * ringbuffer logging mechanism.
00022    */
00023   static inline void print_stacktrace()
00024   {
00025 
00026     backward::StackTrace st;
00027     st.load_here();
00028     backward::Printer p;
00029     p.print(st, std::cout);
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047   }
00048 
00049 
00050   static void sig_handler(int signo, siginfo_t* info, void* _ctx)
00051   {
00052     backward::SignalHandling::handleSignal(signo, info, _ctx);
00053     LOG_FATAL_FMT("Handled fatal signal {}", signo);
00054 
00055     // SA_RESETHAND seems to be insufficient, so we manually reset the handler
00056     // before re-raising
00057     signal(signo, SIG_DFL);
00058     raise(signo);
00059   }
00060 
00061   static inline void init_sig_handlers()
00062   {
00063     // This is based on the constructor of backward::SignalHandling, but avoids
00064     // infinitely recursing stacktraces
00065     constexpr size_t stack_size = 1024 * 1024 * 8;
00066     static std::unique_ptr<char[]> stack_content = nullptr;
00067 
00068     stack_content.reset(new char[stack_size]);
00069 
00070     stack_t ss;
00071     ss.ss_sp = stack_content.get();
00072     ss.ss_size = stack_size;
00073     ss.ss_flags = 0;
00074     const auto ret = sigaltstack(&ss, nullptr);
00075     if (ret < 0)
00076     {
00077       LOG_FATAL_FMT("sigalstack returned error");
00078     }
00079 
00080     const int posix_signals[] = {
00081       // Signals for which the default action is "Core".
00082       SIGABRT, // Abort signal from abort(3)
00083       SIGBUS, // Bus error (bad memory access)
00084       SIGFPE, // Floating point exception
00085       SIGILL, // Illegal Instruction
00086       SIGIOT, // IOT trap. A synonym for SIGABRT
00087       SIGQUIT, // Quit from keyboard
00088       SIGSEGV, // Invalid memory reference
00089       SIGSYS, // Bad argument to routine (SVr4)
00090       SIGTRAP, // Trace/breakpoint trap
00091       SIGXCPU, // CPU time limit exceeded (4.2BSD)
00092       SIGXFSZ, // File size limit exceeded (4.2BSD)
00093 
00094 
00095 
00096     };
00097 
00098     for (const int signal : posix_signals)
00099     {
00100       struct sigaction action;
00101       memset(&action, 0, sizeof action);
00102       action.sa_flags =
00103         static_cast<int>(SA_SIGINFO | SA_ONSTACK | SA_NODEFER | SA_RESETHAND);
00104       sigfillset(&action.sa_mask);
00105       sigdelset(&action.sa_mask, signal);
00106 
00107 
00108 
00109 
00110       action.sa_sigaction = &sig_handler;
00111 
00112 
00113 
00114 
00115       int r = sigaction(signal, &action, nullptr);
00116       if (r < 0)
00117       {
00118         LOG_FATAL_FMT("Error installing signal {} ({})", signal, r);
00119       }
00120     }
00121   }
00122 
00123 }
00124 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/stacktrace_utils.h...
Preprocessing /data/git/CCF/src/ds/test/hash.cpp...
#include ../hash.h: already included! skipping...
#include ../siphash.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include iostream: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 4606 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/ds/test/hash.cpp" 2
00007 
00008 
00009 
00010 
00011 
00012 
00013 {
00014   siphash::SipKey key{
00015     siphash::bytes_to_64_le("\000\001\002\003\004\005\006\007"),
00016     siphash::bytes_to_64_le("\010\011\012\013\014\015\016\017")};
00017 
00018   std::vector<uint8_t> in;
00019 
00020   for (auto i = 0; i < 64; ++i)
00021   {
00022     const auto& expected = siphash_2_4_vectors[i];
00023 
00024     auto out = siphash::siphash<2, 4>(in, key);
00025     uint8_t actual[8];
00026 
00027     siphash::u64_to_bytes_le(out, actual);
00028 
00029     for (auto j = 0; j < 8; ++j)
00030     {
00031       REQUIRE(actual[j] == expected[j]);
00032     }
00033 
00034     in.push_back(i);
00035   }
00036 }
00037 
00038 template <typename T>
00039 void check_hash_uniqueness()
00040 {
00041   std::hash<std::vector<T>> h{};
00042 
00043   std::set<size_t> taken;
00044 
00045   std::vector<T> identical;
00046   std::vector<T> different;
00047   for (size_t i = 0; i < 1024; ++i)
00048   {
00049     identical.push_back(1);
00050     different.push_back((T)i);
00051 
00052     REQUIRE(taken.insert(h(identical)).second);
00053     REQUIRE(taken.insert(h(different)).second);
00054   }
00055 
00056   REQUIRE(taken.insert(h({2, 4})).second);
00057   REQUIRE(taken.insert(h({4, 2})).second);
00058 }
00059 
00060 
00061 {
00062   check_hash_uniqueness<uint8_t>();
00063   check_hash_uniqueness<size_t>();
00064   check_hash_uniqueness<int>();
00065 
00066   {
00067     std::set<size_t> taken;
00068     using T = std::vector<std::string>;
00069     std::hash<T> h{};
00070 
00071     REQUIRE(taken.insert(h({})).second);
00072     REQUIRE(taken.insert(h({""})).second);
00073     REQUIRE(taken.insert(h({"hello world"})).second);
00074     REQUIRE(taken.insert(h({"hello", "world"})).second);
00075     REQUIRE(taken.insert(h({"world", "hello"})).second);
00076     REQUIRE(taken.insert(h({"hello", "hello"})).second);
00077     REQUIRE(taken.insert(h({"world", "world"})).second);
00078   }
00079 }
00080 
00081 
00082 {
00083   std::set<size_t> taken;
00084 
00085   {
00086     using UU = std::pair<size_t, size_t>;
00087     std::hash<UU> h{};
00088     REQUIRE(taken.insert(h({0, 0})).second);
00089     REQUIRE(taken.insert(h({0, 1})).second);
00090     REQUIRE(taken.insert(h({1, 0})).second);
00091     REQUIRE(taken.insert(h({1, 1})).second);
00092   }
00093 
00094   {
00095     using II = std::pair<int, int>;
00096     std::hash<II> h{};
00097     REQUIRE(taken.insert(h({2, 2})).second);
00098     REQUIRE(taken.insert(h({2, 3})).second);
00099     REQUIRE(taken.insert(h({3, 2})).second);
00100     REQUIRE(taken.insert(h({3, 3})).second);
00101   }
00102 
00103   {
00104     using SU = std::pair<std::string, size_t>;
00105     std::hash<SU> h{};
00106     REQUIRE(taken.insert(h({"A", 0})).second);
00107     REQUIRE(taken.insert(h({"A", 1})).second);
00108     REQUIRE(taken.insert(h({"B", 0})).second);
00109     REQUIRE(taken.insert(h({"B", 1})).second);
00110   }
00111 
00112   {
00113     using US = std::pair<size_t, std::string>;
00114     std::hash<US> h{};
00115     REQUIRE(taken.insert(h({0, "A"})).second);
00116     REQUIRE(taken.insert(h({1, "A"})).second);
00117     REQUIRE(taken.insert(h({0, "B"})).second);
00118     REQUIRE(taken.insert(h({1, "B"})).second);
00119   }
00120 }
00121 
00122 constexpr auto fnv_1a_32 = ds::fnv_1a<uint32_t>;
00123 constexpr auto fnv_1a_64 = ds::fnv_1a<uint64_t>;
00124 
00125 
00126 {
00127   INFO("Comparing against known values from external calculators");
00128   REQUIRE(fnv_1a_32("") == 0x811c9dc5);
00129   REQUIRE(fnv_1a_64("") == 0xcbf29ce484222325);
00130 
00131   REQUIRE(fnv_1a_32("0") == 0x350ca8af);
00132   REQUIRE(fnv_1a_64("0") == 0xaf63ad4c86019caf);
00133 
00134   REQUIRE(fnv_1a_32("Hello world") == 0x594d29c7);
00135   REQUIRE(fnv_1a_64("Hello world") == 0x2713f785a33764c7);
00136 }
00137 
00138 
00139 {
00140   // Build some hashes, check we have no collisions
00141   std::set<uint32_t> taken_32;
00142   std::set<uint64_t> taken_64;
00143 
00144   char cc[4] = {0};
00145 
00146   // Hash every single byte
00147   for (size_t i = 0; i < 256; ++i)
00148   {
00149     cc[0] = i;
00150     REQUIRE(taken_32.insert(fnv_1a_32(cc)).second);
00151     REQUIRE(taken_64.insert(fnv_1a_64(cc)).second);
00152   }
00153 
00154   // Hash every pair of lower-case characters
00155   for (char a = 'a'; a <= 'z'; ++a)
00156   {
00157     cc[0] = a;
00158     for (char b = 'a'; b <= 'z'; ++b)
00159     {
00160       cc[1] = b;
00161       REQUIRE(taken_32.insert(fnv_1a_32(cc)).second);
00162       REQUIRE(taken_64.insert(fnv_1a_64(cc)).second);
00163     }
00164   }
00165 
00166   // Hash every triple of lower-case characters
00167   for (char a = 'a'; a <= 'z'; ++a)
00168   {
00169     cc[0] = a;
00170     for (char b = 'a'; b <= 'z'; ++b)
00171     {
00172       cc[1] = b;
00173       for (char c = 'a'; c <= 'z'; ++c)
00174       {
00175         cc[2] = c;
00176         REQUIRE(taken_32.insert(fnv_1a_32(cc)).second);
00177         REQUIRE(taken_64.insert(fnv_1a_64(cc)).second);
00178       }
00179     }
00180   }
00181 
00182   cc[0] = 0;
00183   cc[1] = 0;
00184   cc[2] = 0;
00185 
00186   // And just for good measure, do upper-case as well
00187   for (char a = 'A'; a <= 'Z'; ++a)
00188   {
00189     cc[0] = a;
00190     for (char b = 'A'; b <= 'Z'; ++b)
00191     {
00192       cc[1] = b;
00193       for (char c = 'A'; c <= 'Z'; ++c)
00194       {
00195         cc[2] = c;
00196         REQUIRE(taken_32.insert(fnv_1a_32(cc)).second);
00197         REQUIRE(taken_64.insert(fnv_1a_64(cc)).second);
00198       }
00199     }
00200   }
00201 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/test/hash.cpp...
Preprocessing /data/git/CCF/src/ds/test/hash_bench.cpp...
#include ds/hash.h: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 925 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 template <typename T>
00010 static void hash(picobench::state& s)
00011 {
00012   T v(s.iterations());
00013   auto* d = v.data();
00014   for (size_t i = 0; i < v.size(); ++i)
00015   {
00016     d[i] = rand();
00017   }
00018 
00019   std::hash<T> hasher;
00020 
00021   s.start_timer();
00022   for (size_t i = 0; i < 1000; ++i)
00023   {
00024     volatile auto n = hasher(v);
00025     s.stop_timer();
00026   }
00027 }
00028 
00029 const std::vector<int> hash_sizes = {1, 8, 64, 1024, 16536};
00030 
00031 PICOBENCH_SUITE("hash");
00032 auto hash_vec = hash<std::vector<uint8_t>>;
00033 PICOBENCH(hash_vec).iterations(hash_sizes).baseline();
00034 auto hash_small_vec_16 = hash<llvm_vecsmall::SmallVector<uint8_t, 16>>;
00035 PICOBENCH(hash_small_vec_16).iterations(hash_sizes).baseline();
00036 auto hash_small_vec_128 = hash<llvm_vecsmall::SmallVector<uint8_t, 128>>;
00037 PICOBENCH(hash_small_vec_128).iterations(hash_sizes).baseline();
00038 
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/ds/test/hash_bench.cpp...
Preprocessing /data/git/CCF/src/ds/test/json_bench.cpp...
#include json_schema.h: already included! skipping...
#include fmt/format.h: not found! skipping...
#include sstream: not found! skipping...
#include ../json_schema.h: already included! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 3551 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/ds/test/json_bench.cpp" 2
00004 
00005 
00006 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 template <class A>
00010 inline void do_not_optimize(A const& value)
00011 {
00012   asm volatile("" : : "r,m"(value) : "memory");
00013 }
00014 
00015 inline void clobber_memory()
00016 {
00017   asm volatile("" : : : "memory");
00018 }
00019 
00020 void randomise(std::string& s)
00021 {
00022   s.resize(rand() % 20);
00023   for (auto& c : s)
00024   {
00025     c = 'a' + rand() % 26;
00026   }
00027 }
00028 
00029 void randomise(size_t& n)
00030 {
00031   n = rand();
00032 }
00033 
00034 void randomise(int& n)
00035 {
00036   n = rand();
00037 }
00038 
00039 void randomise(bool& b)
00040 {
00041   b = rand() % 2;
00042 }
00043 
00044 #define DECLARE_SIMPLE_STRUCT(PREFIX) 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 #define DECLARE_COMPLEX_STRUCT(PREFIX) 
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 
00065 
00066 
00067 
00068 
00069 
00070 
00071 
00072 
00073 
00074 
00075 
00076 
00077 
00078 
00079 
00080 
00081 
00082 
00083 
00084 
00085 
00086 
00087 
00088 
00089 
00090 
00091 
00092 
00093 
00094 
00095 
00096 
00097 
00098 
00099 
00100 
00101 
00102 
00103 
00104 void to_json(nlohmann::json& j, const Simple_manual& s)
00105 {
00106   j["x"] = s.x;
00107   j["y"] = s.y;
00108 }
00109 
00110 void from_json(const nlohmann::json& j, Simple_manual& s)
00111 {
00112   s.x = j["x"];
00113   s.y = j["y"];
00114 }
00115 
00116 
00117 
00118 void to_json(nlohmann::json& j, const Complex_manual::Foo& f)
00119 {
00120   j["n"] = f.n;
00121   j["s"] = f.s;
00122 }
00123 
00124 void to_json(nlohmann::json& j, const Complex_manual::Bar& b)
00125 {
00126   j["a"] = b.a;
00127   j["b"] = b.b;
00128   j["foos"] = b.foos;
00129 }
00130 
00131 void to_json(nlohmann::json& j, const Complex_manual& c)
00132 {
00133   j["b"] = c.b;
00134   j["i"] = c.i;
00135   j["s"] = c.s;
00136   j["bars"] = c.bars;
00137 }
00138 
00139 void from_json(const nlohmann::json& j, Complex_manual::Foo& f)
00140 {
00141   f.n = j["n"];
00142   f.s = j["s"];
00143 }
00144 
00145 void from_json(const nlohmann::json& j, Complex_manual::Bar& b)
00146 {
00147   b.a = j["a"];
00148   b.b = j["b"];
00149   b.foos = j["foos"].get<decltype(b.foos)>();
00150 }
00151 
00152 void from_json(const nlohmann::json& j, Complex_manual& c)
00153 {
00154   c.b = j["b"];
00155   c.i = j["i"];
00156   c.s = j["s"];
00157   c.bars = j["bars"].get<decltype(c.bars)>();
00158 }
00159 
00160 
00161 DECLARE_JSON_TYPE(Simple_macros);
00162 DECLARE_JSON_REQUIRED_FIELDS(Simple_macros, x, y);
00163 
00164 
00165 DECLARE_JSON_TYPE(Complex_macros::Foo);
00166 DECLARE_JSON_REQUIRED_FIELDS(Complex_macros::Foo, n, s);
00167 DECLARE_JSON_TYPE(Complex_macros::Bar);
00168 DECLARE_JSON_REQUIRED_FIELDS(Complex_macros::Bar, a, b, foos);
00169 DECLARE_JSON_TYPE(Complex_macros);
00170 DECLARE_JSON_REQUIRED_FIELDS(Complex_macros, b, i, s, bars);
00171 
00172 template <typename T, typename R = T>
00173 std::vector<R> build_entries(picobench::state& s)
00174 {
00175   std::vector<R> entries(s.iterations());
00176 
00177   for (auto& e : entries)
00178   {
00179     T t;
00180     t.randomise();
00181     e = t;
00182   }
00183 
00184   return entries;
00185 }
00186 
00187 template <typename T>
00188 static void conv(picobench::state& s)
00189 {
00190   std::vector<T> entries = build_entries<T>(s);
00191 
00192   clobber_memory();
00193   picobench::scope scope(s);
00194 
00195   for (size_t i = 0; i < s.iterations(); ++i)
00196   {
00197     nlohmann::json j = entries[i];
00198     const auto b = j.get<T>();
00199     do_not_optimize(b);
00200     clobber_memory();
00201   }
00202 }
00203 
00204 template <typename T>
00205 void valmacro(picobench::state& s)
00206 {
00207   std::vector<nlohmann::json> entries = build_entries<T, nlohmann::json>(s);
00208 
00209   clobber_memory();
00210   picobench::scope scope(s);
00211 
00212   for (size_t i = 0; i < s.iterations(); ++i)
00213   {
00214     const auto b = entries[i].get<T>();
00215     do_not_optimize(b);
00216     clobber_memory();
00217   }
00218 }
00219 
00220 const std::vector<int> sizes = {200, 2'000};
00221 
00222 PICOBENCH_SUITE("simple");
00223 PICOBENCH(conv<Simple_manual>).iterations(sizes).samples(10);
00224 PICOBENCH(conv<Simple_macros>).iterations(sizes).samples(10);
00225 
00226 PICOBENCH_SUITE("complex");
00227 PICOBENCH(conv<Complex_manual>).iterations(sizes).samples(10);
00228 PICOBENCH(conv<Complex_macros>).iterations(sizes).samples(10);
00229 
00230 PICOBENCH_SUITE("validation simple");
00231 PICOBENCH(valmacro<Simple_macros>).iterations(sizes).samples(10);
00232 
00233 PICOBENCH_SUITE("validation complex");
00234 PICOBENCH(valmacro<Complex_macros>).iterations(sizes).samples(10);
00235 
---------
Macros accessible in this file:
---------
READ_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_FOR_JSON_NEXT DECLARE_JSON_TYPE_WITH_BASE DECLARE_JSON_REQUIRED_FIELDS_WITH_RENAMES _FOR_JSON_18_POP1 _FOR_JSON_18_POP2 WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_4_POP1 _FOR_JSON_4_POP2 FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_FINAL READ_REQUIRED_FOR_JSON_FINAL DECLARE_JSON_ENUM _FOR_JSON_14_POP1 DECLARE_JSON_TYPE _FOR_JSON_14_POP2 _FOR_JSON_0 _FOR_JSON_1 _FOR_JSON_2 JSON_FIELD_FOR_JSON_NEXT _FOR_JSON_3 _FOR_JSON_4 _FOR_JSON_5 _FOR_JSON_6 _FOR_JSON_7 _FOR_JSON_8 _FOR_JSON_9 _FOR_JSON_0_POP1 _FOR_JSON_0_POP2 DECLARE_JSON_OPTIONAL_FIELDS_WITH_RENAMES WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_7_POP1 _FOR_JSON_7_POP2 DECLARE_JSON_OPTIONAL_FIELDS READ_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL JSON_FIELD_FOR_JSON_FINAL _FOR_JSON_NEXT _FOR_JSON_20_POP1 _FOR_JSON_20_POP2 _FOR_JSON_17_POP1 _FOR_JSON_17_POP2 _FOR_JSON_12_POP1 _FOR_JSON_12_POP2 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS _FOR_JSON_3_POP1 _FOR_JSON_3_POP2 FILL_SCHEMA_REQUIRED_FOR_JSON_FINAL _FOR_JSON_COUNT_NN ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT DECLARE_COMPLEX_STRUCT FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_FINAL PICOBENCH_IMPLEMENT_WITH_MAIN _FOR_JSON_13_POP1 _FOR_JSON_13_POP2 WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_REQUIRED_FIELDS WRITE_OPTIONAL_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_NEXT DECLARE_SIMPLE_STRUCT WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT READ_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_11_POP1 _FOR_JSON_11_POP2 _FOR_JSON_COUNT_NN_WITH_0 FILL_SCHEMA_OPTIONAL_FOR_JSON_FINAL DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS READ_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_16_POP1 _FOR_JSON_16_POP2 ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_6_POP1 _FOR_JSON_6_POP2 ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_FINAL FMT_HEADER_ONLY WRITE_OPTIONAL_FOR_JSON_FINAL _FOR_JSON_19_POP1 _FOR_JSON_19_POP2 _FOR_JSON_2_POP1 _FOR_JSON_2_POP2 _FOR_JSON_9_POP1 _FOR_JSON_9_POP2 FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_TYPE_IMPL __FOR_JSON_COUNT_NN _FOR_JSON_FINAL _FOR_JSON_15_POP1 _FOR_JSON_15_POP2 READ_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_10_POP1 _FOR_JSON_10_POP2 _FOR_JSON_5_POP1 _FOR_JSON_5_POP2 READ_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_20 _FOR_JSON_10 _FOR_JSON_11 _FOR_JSON_12 ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_NEXT _FOR_JSON_13 _FOR_JSON_14 _FOR_JSON_15 _FOR_JSON_16 _FOR_JSON_17 _FOR_JSON_18 _FOR_JSON_19 READ_OPTIONAL_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_1_POP1 _FOR_JSON_1_POP2 _FOR_JSON_8_POP1 _FOR_JSON_8_POP2 
---------
Parsing file /data/git/CCF/src/ds/test/json_bench.cpp...
Preprocessing /data/git/CCF/src/ds/test/json_schema.cpp...
#include ../json.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 11632 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00006 
00007 
00008 
00009 
00010 struct Bar
00011 {
00012   size_t a = {};
00013   std::string b = {};
00014   size_t c = {};
00015 };
00016 DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(Bar);
00017 DECLARE_JSON_REQUIRED_FIELDS(Bar, a);
00018 DECLARE_JSON_OPTIONAL_FIELDS(Bar, b, c);
00019 
00020 TEST_CASE("basic macro parser generation")
00021 {
00022   const Bar default_bar = {};
00023   nlohmann::json j;
00024 
00025   REQUIRE_THROWS_AS(j.get<Bar>(), std::invalid_argument);
00026 
00027   j["a"] = 42;
00028 
00029   const Bar bar_0 = j;
00030   REQUIRE(bar_0.a == j["a"]);
00031   REQUIRE(bar_0.b == default_bar.b);
00032   REQUIRE(bar_0.c == default_bar.c);
00033 
00034   j["b"] = "Test";
00035   j["c"] = 100;
00036   const Bar bar_1 = j;
00037   REQUIRE(bar_1.a == j["a"]);
00038   REQUIRE(bar_1.b == j["b"]);
00039   REQUIRE(bar_1.c == j["c"]);
00040 }
00041 
00042 struct Biz : public Bar
00043 {
00044   size_t f = {};
00045 };
00046 DECLARE_JSON_TYPE_WITH_BASE(Biz, Bar);
00047 DECLARE_JSON_REQUIRED_FIELDS(Biz, f);
00048 
00049 struct Baz : public Bar
00050 {
00051   size_t d = {};
00052   size_t e = {};
00053 };
00054 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(Baz, Bar);
00055 DECLARE_JSON_REQUIRED_FIELDS(Baz, d);
00056 DECLARE_JSON_OPTIONAL_FIELDS(Baz, e);
00057 
00058 TEST_CASE("macro parser generation with base classes")
00059 {
00060   const Biz default_biz = {};
00061   const Baz default_baz = {};
00062   nlohmann::json j;
00063 
00064   REQUIRE_THROWS_AS(j.get<Biz>(), std::invalid_argument);
00065   REQUIRE_THROWS_AS(j.get<Baz>(), std::invalid_argument);
00066 
00067   j["a"] = 42;
00068 
00069   REQUIRE_THROWS_AS(j.get<Biz>(), std::invalid_argument);
00070   REQUIRE_THROWS_AS(j.get<Baz>(), std::invalid_argument);
00071 
00072   j["f"] = 44;
00073   const Biz biz_0 = j;
00074   REQUIRE(biz_0.a == j["a"]);
00075   REQUIRE(biz_0.b == default_biz.b);
00076   REQUIRE(biz_0.c == default_biz.c);
00077   REQUIRE(biz_0.f == j["f"]);
00078 
00079   j["d"] = 43;
00080   const Baz baz_0 = j;
00081   REQUIRE(baz_0.a == j["a"]);
00082   REQUIRE(baz_0.b == default_baz.b);
00083   REQUIRE(baz_0.c == default_baz.c);
00084   REQUIRE(baz_0.d == j["d"]);
00085   REQUIRE(baz_0.e == default_baz.e);
00086 
00087   j["b"] = "Test";
00088   j["c"] = 100;
00089   j["e"] = 101;
00090   const Baz baz_1 = j;
00091   REQUIRE(baz_1.a == j["a"]);
00092   REQUIRE(baz_1.b == j["b"]);
00093   REQUIRE(baz_1.c == j["c"]);
00094   REQUIRE(baz_1.d == j["d"]);
00095   REQUIRE(baz_1.e == j["e"]);
00096 }
00097 
00098 struct Foo
00099 {
00100   size_t n_0 = 42;
00101   size_t n_1 = 43;
00102   int i_0 = -1;
00103   int64_t i64_0 = -2;
00104   std::string s_0 = "Default value";
00105   std::string s_1 = "Other default value";
00106   std::optional<size_t> opt = std::nullopt;
00107   std::vector<std::string> vec_s = {};
00108   size_t ignored;
00109 };
00110 DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(Foo);
00111 DECLARE_JSON_REQUIRED_FIELDS(Foo, n_0, i_0, i64_0, s_0);
00112 DECLARE_JSON_OPTIONAL_FIELDS(Foo, n_1, s_1, opt, vec_s);
00113 
00114 TEST_CASE("schema generation")
00115 {
00116   const auto schema = ds::json::build_schema<Foo>("Foo");
00117 
00118   const auto properties_it = schema.find("properties");
00119   REQUIRE(properties_it != schema.end());
00120 
00121   const auto required_it = schema.find("required");
00122   REQUIRE(required_it != schema.end());
00123 
00124   REQUIRE(required_it->is_array());
00125   REQUIRE(required_it->size() == 4);
00126 
00127   // Check limits are actually achievable
00128   {
00129     auto j_max = nlohmann::json::object();
00130     auto j_min = nlohmann::json::object();
00131     for (const std::string& required : *required_it)
00132     {
00133       const auto property_it = properties_it->find(required);
00134       REQUIRE(property_it != properties_it->end());
00135 
00136       const auto type = property_it->at("type");
00137       if (type == "integer")
00138       {
00139         j_min[required] = property_it->at("minimum");
00140         j_max[required] = property_it->at("maximum");
00141       }
00142       else if (type == "string")
00143       {
00144         j_min[required] = "Hello world";
00145         j_max[required] = "Hello world";
00146       }
00147       else
00148       {
00149         throw std::logic_error("Unsupported type");
00150       }
00151     }
00152 
00153     const auto foo_min = j_min.get<Foo>();
00154     const auto foo_max = j_max.get<Foo>();
00155 
00156     using size_limits = std::numeric_limits<size_t>;
00157 
00158     REQUIRE(foo_min.n_0 == size_limits::min());
00159     REQUIRE(foo_max.n_0 == size_limits::max());
00160 
00161     using int_limits = std::numeric_limits<int>;
00162     REQUIRE(foo_min.i_0 == int_limits::min());
00163     REQUIRE(foo_max.i_0 == int_limits::max());
00164 
00165     using int64_limits = std::numeric_limits<int64_t>;
00166     REQUIRE(foo_min.i64_0 == int64_limits::min());
00167     REQUIRE(foo_max.i64_0 == int64_limits::max());
00168   }
00169 }
00170 
00171 TEST_CASE_TEMPLATE("schema types, integer", T, size_t, ssize_t)
00172 {
00173   std::map<T, std::string> m;
00174   const auto schema = ds::json::build_schema<decltype(m)>("Map");
00175 
00176   REQUIRE(schema["type"] == "array");
00177   REQUIRE(schema["items"].is_object());
00178 
00179   REQUIRE(schema["items"]["type"] == "array");
00180   REQUIRE(schema["items"]["items"].is_array());
00181   REQUIRE(schema["items"]["items"].size() == 2);
00182   REQUIRE(schema["items"]["items"][0]["type"] == "integer");
00183   REQUIRE(schema["items"]["items"][1]["type"] == "string");
00184 }
00185 
00186 TEST_CASE_TEMPLATE("schema types, floating point", T, float, double)
00187 {
00188   std::map<size_t, T> m;
00189   const auto schema = ds::json::build_schema<decltype(m)>("Map");
00190 
00191   REQUIRE(schema["type"] == "array");
00192   REQUIRE(schema["items"].is_object());
00193 
00194   REQUIRE(schema["items"]["type"] == "array");
00195   REQUIRE(schema["items"]["items"].is_array());
00196   REQUIRE(schema["items"]["items"].size() == 2);
00197   REQUIRE(schema["items"]["items"][0]["type"] == "integer");
00198   REQUIRE(schema["items"]["items"][1]["type"] == "number");
00199 }
00200 
00201 namespace custom
00202 {
00203   namespace user
00204   {
00205     namespace defined
00206     {
00207       struct X
00208       {
00209         std::string email;
00210       };
00211 
00212       void fill_json_schema(nlohmann::json& schema, const X&)
00213       {
00214         schema["type"] = "string";
00215         schema["format"] = "email";
00216       }
00217 
00218       struct Y
00219       {
00220         size_t a;
00221         int b;
00222       };
00223       DECLARE_JSON_TYPE(Y);
00224       DECLARE_JSON_REQUIRED_FIELDS(Y, a, b);
00225     }
00226   }
00227 }
00228 
00229 TEST_CASE("custom elements")
00230 {
00231   const auto x_schema =
00232     ds::json::build_schema<custom::user::defined::X>("custom-x");
00233   REQUIRE(x_schema["format"] == "email");
00234 
00235   const auto y_schema =
00236     ds::json::build_schema<custom::user::defined::Y>("custom-y");
00237   REQUIRE(y_schema["required"].size() == 2);
00238 }
00239 
00240 struct Nest0
00241 {
00242   size_t n = {};
00243 };
00244 DECLARE_JSON_TYPE(Nest0);
00245 DECLARE_JSON_REQUIRED_FIELDS(Nest0, n);
00246 
00247 bool operator==(const Nest0& l, const Nest0& r)
00248 {
00249   return l.n == r.n;
00250 }
00251 
00252 struct Nest1
00253 {
00254   Nest0 a = {};
00255   Nest0 b = {};
00256 };
00257 DECLARE_JSON_TYPE(Nest1);
00258 DECLARE_JSON_REQUIRED_FIELDS(Nest1, a, b);
00259 
00260 bool operator==(const Nest1& l, const Nest1& r)
00261 {
00262   return l.a == r.a && l.b == r.b;
00263 }
00264 
00265 struct Nest2
00266 {
00267   Nest1 x;
00268   std::vector<Nest1> xs;
00269 };
00270 DECLARE_JSON_TYPE(Nest2);
00271 DECLARE_JSON_REQUIRED_FIELDS(Nest2, x, xs);
00272 
00273 bool operator==(const Nest2& l, const Nest2& r)
00274 {
00275   return l.x == r.x && l.xs == r.xs;
00276 }
00277 
00278 struct Nest3
00279 {
00280   Nest2 v;
00281 };
00282 DECLARE_JSON_TYPE(Nest3);
00283 DECLARE_JSON_REQUIRED_FIELDS(Nest3, v);
00284 
00285 bool operator==(const Nest3& l, const Nest3& r)
00286 {
00287   return l.v == r.v;
00288 }
00289 
00290 TEST_CASE("nested")
00291 {
00292   const Nest0 n0_1{10};
00293   const Nest0 n0_2{20};
00294   const Nest0 n0_3{30};
00295   const Nest0 n0_4{40};
00296 
00297   const Nest1 n1_1{n0_1, n0_2};
00298   const Nest1 n1_2{n0_1, n0_3};
00299   const Nest1 n1_3{n0_1, n0_4};
00300   const Nest1 n1_4{n0_2, n0_3};
00301   const Nest1 n1_5{n0_3, n0_4};
00302   const Nest1 n1_6{n0_4, n0_4};
00303 
00304   const Nest2 n2_1{n1_1, {n1_6, n1_5, n1_4, n1_3, n1_2}};
00305 
00306   Nest3 n3{n2_1};
00307 
00308   nlohmann::json j = n3;
00309   const auto r0 = j.get<Nest3>();
00310 
00311   REQUIRE(n3 == r0);
00312 
00313   {
00314     auto invalid_json = j;
00315     invalid_json["v"]["xs"][3]["a"].erase("n");
00316     try
00317     {
00318       invalid_json.get<Nest3>();
00319     }
00320     catch (JsonParseError& jpe)
00321     {
00322       REQUIRE(jpe.pointer() == "#/v/xs/3/a");
00323     }
00324 
00325     invalid_json["v"]["xs"][3].erase("a");
00326     try
00327     {
00328       invalid_json.get<Nest3>();
00329     }
00330     catch (JsonParseError& jpe)
00331     {
00332       REQUIRE(jpe.pointer() == "#/v/xs/3");
00333     }
00334 
00335     invalid_json["v"]["xs"][3] = "Broken";
00336     try
00337     {
00338       invalid_json.get<Nest3>();
00339     }
00340     catch (JsonParseError& jpe)
00341     {
00342       REQUIRE(jpe.pointer() == "#/v/xs/3");
00343     }
00344 
00345     invalid_json["v"]["xs"] = "Broken";
00346     try
00347     {
00348       invalid_json.get<Nest3>();
00349     }
00350     catch (JsonParseError& jpe)
00351     {
00352       REQUIRE(jpe.pointer() == "#/v/xs");
00353     }
00354 
00355     invalid_json["v"].erase("xs");
00356     try
00357     {
00358       invalid_json.get<Nest3>();
00359     }
00360     catch (JsonParseError& jpe)
00361     {
00362       REQUIRE(jpe.pointer() == "#/v");
00363     }
00364   }
00365 }
00366 
00367 struct EnumStruct
00368 {
00369   enum class SampleEnum
00370   {
00371     One,
00372     Two,
00373     Three
00374   };
00375 
00376   SampleEnum se;
00377 };
00378 
00379 DECLARE_JSON_ENUM(
00380   EnumStruct::SampleEnum,
00381   {{EnumStruct::SampleEnum::One, "one"},
00382    {EnumStruct::SampleEnum::Two, "two"},
00383    {EnumStruct::SampleEnum::Three, "three"}})
00384 DECLARE_JSON_TYPE(EnumStruct);
00385 DECLARE_JSON_REQUIRED_FIELDS(EnumStruct, se);
00386 
00387 TEST_CASE("enum")
00388 {
00389   EnumStruct es;
00390   es.se = EnumStruct::SampleEnum::Two;
00391 
00392   nlohmann::json j = es;
00393 
00394   REQUIRE(j["se"] == "two");
00395 
00396   const auto schema = ds::json::build_schema<EnumStruct>("EnumStruct");
00397 
00398   const nlohmann::json expected{"one", "two", "three"};
00399   REQUIRE(schema["properties"]["se"]["enum"] == expected);
00400 }
00401 
00402 namespace examples
00403 {
00404   struct X
00405   {
00406     int a, b;
00407   };
00408 
00409 
00410 
00411   struct Y
00412   {
00413     bool c;
00414     std::string d;
00415   };
00416 
00417 
00418 
00419 
00420   struct X_A : X
00421   {
00422     int m;
00423   };
00424 
00425 
00426 
00427   struct X_B : X
00428   {
00429     int n;
00430   };
00431 
00432 
00433 
00434 }
00435 
00436 namespace renamed
00437 {
00438   struct Foo
00439   {
00440     size_t x;
00441     size_t y;
00442     size_t z;
00443 
00444     size_t a;
00445     size_t b;
00446     size_t c;
00447   };
00448 
00449 
00450 
00451 }
00452 
00453 TEST_CASE("JSON with different field names")
00454 {
00455   const auto schema = ds::json::build_schema<renamed::Foo>("renamed::Foo");
00456 
00457   const auto& properties = schema["properties"];
00458   const auto& required = schema["required"];
00459 
00460   std::vector<char const*> required_json_fields{"X", "SOMETHING_ELSE", "z"};
00461   for (const auto s : required_json_fields)
00462   {
00463     REQUIRE(properties.find(s) != properties.end());
00464     REQUIRE(std::find(required.begin(), required.end(), s) != required.end());
00465   }
00466 
00467   std::vector<char const*> optional_json_fields{"A", "OTHER_NAME", "c"};
00468   for (const auto s : optional_json_fields)
00469   {
00470     REQUIRE(properties.find(s) != properties.end());
00471     REQUIRE(std::find(required.begin(), required.end(), s) == required.end());
00472   }
00473 
00474   renamed::Foo foo;
00475   foo.x = 1;
00476   foo.y = 2;
00477   foo.z = 3;
00478   foo.a = 4;
00479   foo.b = 5;
00480   foo.c = 6;
00481 
00482   const nlohmann::json j = foo;
00483   REQUIRE(j["X"] == foo.x);
00484   REQUIRE(j["SOMETHING_ELSE"] == foo.y);
00485   REQUIRE(j["z"] == foo.z);
00486   REQUIRE(j["A"] == foo.a);
00487   REQUIRE(j["OTHER_NAME"] == foo.b);
00488   REQUIRE(j["c"] == foo.c);
00489 
00490   const auto foo2 = j.get<renamed::Foo>();
00491   REQUIRE(foo2.x == foo.x);
00492   REQUIRE(foo2.y == foo.y);
00493   REQUIRE(foo2.z == foo.z);
00494   REQUIRE(foo2.a == foo.a);
00495   REQUIRE(foo2.b == foo.b);
00496   REQUIRE(foo2.c == foo.c);
00497 }
00498 
00499 TEST_CASE("example validation")
00500 {
00501   using namespace examples;
00502 
00503   // struct X
00504   {
00505     // Valid JSON
00506     REQUIRE_NOTHROW("{ \"a\": 42, \"b\": 100 }"_json.get<X>());
00507     REQUIRE_NOTHROW(
00508       "{ \"a\": 42, \"b\": 100, \"Unused\": [\"Anything\"] }"_json.get<X>());
00509 
00510     // Invalid JSON
00511     REQUIRE_THROWS("{}"_json.get<X>());
00512     REQUIRE_THROWS("{ \"a\": 42 }"_json.get<X>());
00513     REQUIRE_THROWS("{ \"a\": 42, \"b\": \"Hello world\" }"_json.get<X>());
00514   }
00515 
00516   // struct Y
00517   {
00518     // Valid JSON
00519     REQUIRE_NOTHROW("{ \"c\": true }"_json.get<Y>());
00520     REQUIRE_NOTHROW("{ \"c\": false, \"d\": \"Hello\" }"_json.get<Y>());
00521 
00522     // Invalid JSON
00523     REQUIRE_THROWS("{ \"d\": \"Hello\" }"_json.get<Y>());
00524   }
00525 
00526   // struct X_A
00527   {
00528     // Valid JSON
00529     REQUIRE_NOTHROW("{ \"a\": 42, \"b\": 100, \"m\": 101 }"_json.get<X_A>());
00530 
00531     // Invalid JSON
00532     REQUIRE_THROWS("{ \"a\": 42, \"b\": 100 }"_json.get<X_A>());
00533     REQUIRE_THROWS("{ \"m\": 101 }"_json.get<X_A>());
00534   }
00535 
00536   // struct X_B
00537   {
00538     // Valid JSON
00539     REQUIRE_NOTHROW("{ \"a\": 42, \"b\": 100 }"_json.get<X_B>());
00540     REQUIRE_NOTHROW("{ \"a\": 42, \"b\": 100, \"n\": 101 }"_json.get<X_B>());
00541 
00542     // Invalid JSON
00543     REQUIRE_THROWS("{ \"n\": 101 }"_json.get<X_B>());
00544   }
00545 }
00546 
---------
Macros accessible in this file:
---------
READ_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_FOR_JSON_NEXT DECLARE_JSON_TYPE_WITH_BASE DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN DECLARE_JSON_REQUIRED_FIELDS_WITH_RENAMES _FOR_JSON_18_POP1 _FOR_JSON_18_POP2 WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_4_POP1 _FOR_JSON_4_POP2 FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_FINAL READ_REQUIRED_FOR_JSON_FINAL DECLARE_JSON_ENUM _FOR_JSON_14_POP1 DECLARE_JSON_TYPE _FOR_JSON_14_POP2 _FOR_JSON_0 _FOR_JSON_1 _FOR_JSON_2 JSON_FIELD_FOR_JSON_NEXT _FOR_JSON_3 _FOR_JSON_4 _FOR_JSON_5 _FOR_JSON_6 _FOR_JSON_7 _FOR_JSON_8 _FOR_JSON_9 _FOR_JSON_0_POP1 _FOR_JSON_0_POP2 DECLARE_JSON_OPTIONAL_FIELDS_WITH_RENAMES WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_7_POP1 _FOR_JSON_7_POP2 DECLARE_JSON_OPTIONAL_FIELDS READ_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL JSON_FIELD_FOR_JSON_FINAL _FOR_JSON_NEXT _FOR_JSON_20_POP1 _FOR_JSON_20_POP2 _FOR_JSON_17_POP1 _FOR_JSON_17_POP2 _FOR_JSON_12_POP1 _FOR_JSON_12_POP2 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS _FOR_JSON_3_POP1 _FOR_JSON_3_POP2 FILL_SCHEMA_REQUIRED_FOR_JSON_FINAL _FOR_JSON_COUNT_NN ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_FINAL _FOR_JSON_13_POP1 _FOR_JSON_13_POP2 WRITE_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_REQUIRED_FIELDS WRITE_OPTIONAL_FOR_JSON_NEXT WRITE_REQUIRED_FOR_JSON_NEXT WRITE_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT READ_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_11_POP1 _FOR_JSON_11_POP2 _FOR_JSON_COUNT_NN_WITH_0 FILL_SCHEMA_OPTIONAL_FOR_JSON_FINAL DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS READ_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_16_POP1 _FOR_JSON_16_POP2 ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_NEXT _FOR_JSON_6_POP1 _FOR_JSON_6_POP2 ADD_SCHEMA_COMPONENTS_OPTIONAL_FOR_JSON_FINAL FMT_HEADER_ONLY WRITE_OPTIONAL_FOR_JSON_FINAL _FOR_JSON_19_POP1 _FOR_JSON_19_POP2 _FOR_JSON_2_POP1 _FOR_JSON_2_POP2 _FOR_JSON_9_POP1 _FOR_JSON_9_POP2 FILL_SCHEMA_REQUIRED_WITH_RENAMES_FOR_JSON_FINAL DECLARE_JSON_TYPE_IMPL __FOR_JSON_COUNT_NN _FOR_JSON_FINAL _FOR_JSON_15_POP1 _FOR_JSON_15_POP2 READ_OPTIONAL_WITH_RENAMES_FOR_JSON_NEXT ADD_SCHEMA_COMPONENTS_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_10_POP1 _FOR_JSON_10_POP2 _FOR_JSON_5_POP1 _FOR_JSON_5_POP2 READ_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_REQUIRED_FOR_JSON_NEXT FILL_SCHEMA_OPTIONAL_WITH_RENAMES_FOR_JSON_FINAL _FOR_JSON_20 _FOR_JSON_10 _FOR_JSON_11 _FOR_JSON_12 ADD_SCHEMA_COMPONENTS_REQUIRED_FOR_JSON_NEXT _FOR_JSON_13 _FOR_JSON_14 _FOR_JSON_15 _FOR_JSON_16 _FOR_JSON_17 _FOR_JSON_18 _FOR_JSON_19 READ_OPTIONAL_FOR_JSON_FINAL ADD_SCHEMA_COMPONENTS_REQUIRED_WITH_RENAMES_FOR_JSON_NEXT _FOR_JSON_1_POP1 _FOR_JSON_1_POP2 _FOR_JSON_8_POP1 _FOR_JSON_8_POP2 
---------
Parsing file /data/git/CCF/src/ds/test/json_schema.cpp...
Preprocessing /data/git/CCF/src/ds/test/logger_bench.cpp...
#include ../logger.h: already included! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 3898 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 enum LoggerKind
00009 {
00010   None = 0x0,
00011 
00012   Console = 0x1,
00013   JSON = 0x2,
00014 
00015   All = 0xffff,
00016 };
00017 
00018 template <LoggerKind LK, bool Absorb = true>
00019 static void prepare_loggers()
00020 {
00021   logger::config::loggers().clear();
00022 
00023   if constexpr ((LK & LoggerKind::Console) != 0)
00024   {
00025     logger::config::loggers().emplace_back(
00026       std::make_unique<logger::ConsoleLogger>());
00027   }
00028 
00029   if constexpr ((LK & LoggerKind::JSON) != 0)
00030   {
00031     logger::config::loggers().emplace_back(
00032       std::make_unique<logger::JsonConsoleLogger>());
00033   }
00034 
00035   if constexpr (Absorb)
00036   {
00037     // Swallow all output for duration of benchmarks
00038     for (auto& logger : logger::config::loggers())
00039     {
00040       logger->get_stream().setstate(std::ios_base::badbit);
00041     }
00042   }
00043 }
00044 
00045 static void reset_loggers()
00046 {
00047   logger::config::loggers().clear();
00048 
00049   logger::config::loggers().emplace_back(
00050     std::make_unique<logger::ConsoleLogger>());
00051 
00052   std::cout.clear();
00053 }
00054 
00055 template <LoggerKind LK, bool Absorb = true>
00056 static void log_accepted(picobench::state& s)
00057 {
00058   prepare_loggers<LK, Absorb>();
00059 
00060   logger::config::level() = logger::DEBUG;
00061   {
00062     picobench::scope scope(s);
00063 
00064     for (size_t i = 0; i < s.iterations(); ++i)
00065     {
00066       LOG_DEBUG << "test" << std::endl;
00067     }
00068   }
00069 
00070   reset_loggers();
00071 }
00072 
00073 template <LoggerKind LK, bool Absorb = true>
00074 static void log_accepted_fmt(picobench::state& s)
00075 {
00076   prepare_loggers<LK, Absorb>();
00077 
00078   logger::config::level() = logger::DEBUG;
00079   {
00080     picobench::scope scope(s);
00081 
00082     for (size_t i = 0; i < s.iterations(); ++i)
00083     {
00084       LOG_DEBUG_FMT("test");
00085     }
00086   }
00087 
00088   reset_loggers();
00089 }
00090 
00091 template <LoggerKind LK, bool Absorb = true>
00092 static void log_rejected(picobench::state& s)
00093 {
00094   prepare_loggers<LK, Absorb>();
00095 
00096   logger::config::level() = logger::FAIL;
00097   {
00098     picobench::scope scope(s);
00099 
00100     for (size_t i = 0; i < s.iterations(); ++i)
00101     {
00102       LOG_DEBUG << "test" << std::endl;
00103     }
00104   }
00105 
00106   reset_loggers();
00107 }
00108 
00109 template <LoggerKind LK, bool Absorb = true>
00110 static void log_rejected_fmt(picobench::state& s)
00111 {
00112   prepare_loggers<LK, Absorb>();
00113 
00114   logger::config::level() = logger::FAIL;
00115   {
00116     picobench::scope scope(s);
00117 
00118     for (size_t i = 0; i < s.iterations(); ++i)
00119     {
00120       LOG_DEBUG_FMT("test");
00121     }
00122   }
00123 
00124   reset_loggers();
00125 }
00126 
00127 const std::vector<int> sizes = {1000};
00128 
00129 PICOBENCH_SUITE("logger");
00130 auto console_accept = log_accepted<LoggerKind::Console>;
00131 PICOBENCH(console_accept).iterations(sizes).samples(10);
00132 auto console_accept_fmt = log_accepted_fmt<LoggerKind::Console>;
00133 PICOBENCH(console_accept_fmt).iterations(sizes).samples(10);
00134 auto console_reject = log_rejected<LoggerKind::Console>;
00135 PICOBENCH(console_reject).iterations(sizes).samples(10);
00136 auto console_reject_fmt = log_rejected_fmt<LoggerKind::Console>;
00137 PICOBENCH(console_reject_fmt).iterations(sizes).samples(10);
00138 
00139 auto json_accept = log_accepted<LoggerKind::JSON>;
00140 PICOBENCH(json_accept).iterations(sizes).samples(10);
00141 auto json_accept_fmt = log_accepted_fmt<LoggerKind::JSON>;
00142 PICOBENCH(json_accept_fmt).iterations(sizes).samples(10);
00143 auto json_reject = log_rejected<LoggerKind::JSON>;
00144 PICOBENCH(json_reject).iterations(sizes).samples(10);
00145 auto json_reject_fmt = log_rejected_fmt<LoggerKind::JSON>;
00146 PICOBENCH(json_reject_fmt).iterations(sizes).samples(10);
00147 
00148 // The enabled benchmarks are artifically cheap since they talk to a broken
00149 // stream, skipping the cost of _actually writing something_. To compare this,
00150 // uncomment the lines below (~3x slower)
00151 // auto console_loud = log_accepted<LoggerKind::Console, false>;
00152 // PICOBENCH(console_loud).iterations(sizes).samples(10);
00153 // auto json_loud = log_accepted<LoggerKind::JSON, false>;
00154 // PICOBENCH(json_loud).iterations(sizes).samples(10);
00155 // auto all_loud = log_accepted<LoggerKind::All, false>;
00156 // PICOBENCH(all_loud).iterations(sizes).samples(10);
00157 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE PICOBENCH_IMPLEMENT_WITH_MAIN LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/test/logger_bench.cpp...
Preprocessing /data/git/CCF/src/ds/test/logger_json_test.cpp...
#include ../logger.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include fstream: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 1191 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00006 
00007 
00008 
00009 
00010 TEST_CASE("Test custom log format")
00011 {
00012   std::string test_log_file = "./test_json_logger.txt";
00013   remove(test_log_file.c_str());
00014   logger::config::initialize_with_json_console();
00015   logger::config::level() = logger::DEBUG;
00016   std::string log_msg_dbg = "log_msg_dbg";
00017   std::string log_msg_fail = "log_msg_fail";
00018 
00019   std::ofstream out(test_log_file.c_str());
00020   std::streambuf* coutbuf = std::cout.rdbuf();
00021   std::cout.rdbuf(out.rdbuf());
00022 
00023   LOG_DEBUG_FMT("{}", log_msg_dbg);
00024   LOG_TRACE_FMT("{}", log_msg_fail);
00025 
00026   out.flush();
00027   out.close();
00028 
00029   std::cout.rdbuf(coutbuf);
00030 
00031   std::ifstream f(test_log_file);
00032   std::string line;
00033   size_t line_count = 0;
00034   while (std::getline(f, line))
00035   {
00036     line_count++;
00037     auto j = nlohmann::json::parse(line);
00038     auto host_ts = j.find("h_ts");
00039     REQUIRE(host_ts != j.end());
00040     REQUIRE(j["msg"] == log_msg_dbg + "\n");
00041     REQUIRE(j["file"] == __FILE__);
00042     auto line_number = j.find("number");
00043     REQUIRE(line_number != j.end());
00044     REQUIRE(j["level"] == "debug");
00045   }
00046   REQUIRE(line_count == 1);
00047 }
00048 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/test/logger_json_test.cpp...
Preprocessing /data/git/CCF/src/ds/test/map_bench.cpp...
#include ds/buffer.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/champ_map_serializers.h: not found! skipping...
#include algorithm: not found! skipping...
#include array: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
#include cassert: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 3321 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00004 # 4 "/data/git/CCF/src/ds/test/map_bench.cpp" 2
00005 # 5 "/data/git/CCF/src/ds/test/map_bench.cpp" 2
00006 
00007 
00008 
00009 using namespace std;
00010 
00011 using K = uint64_t;
00012 using V = std::vector<uint64_t>;
00013 
00014 static size_t val_size = 32;
00015 
00016 static V gen_val(size_t size)
00017 {
00018   V v;
00019 
00020   for (uint64_t i = 0; i < size; ++i)
00021   {
00022     v.push_back(i);
00023   }
00024 
00025   return v;
00026 }
00027 
00028 template <class M>
00029 static const M gen_map(size_t size)
00030 {
00031   auto v = gen_val(val_size);
00032 
00033   M map;
00034   for (uint64_t i = 0; i < size; ++i)
00035   {
00036     map = map.put(i, v);
00037   }
00038   return map;
00039 }
00040 
00041 template <class A>
00042 inline void do_not_optimize(A const& value)
00043 {
00044   asm volatile("" : : "r,m"(value) : "memory");
00045 }
00046 
00047 inline void clobber_memory()
00048 {
00049   asm volatile("" : : : "memory");
00050 }
00051 
00052 template <class M>
00053 static void benchmark_put(picobench::state& s)
00054 {
00055   size_t size = s.iterations();
00056   auto v = gen_val(val_size);
00057   auto map = gen_map<M>(size);
00058   s.start_timer();
00059   for (auto _ : s)
00060   {
00061     (void)_;
00062     auto res = map.put(size, v);
00063     do_not_optimize(res);
00064     clobber_memory();
00065   }
00066   s.stop_timer();
00067 }
00068 
00069 template <class M>
00070 static void benchmark_get(picobench::state& s)
00071 {
00072   size_t size = s.iterations();
00073   auto map = gen_map<M>(size);
00074   s.start_timer();
00075   for (auto _ : s)
00076   {
00077     (void)_;
00078     auto res = map.get(0);
00079     do_not_optimize(res);
00080     clobber_memory();
00081   }
00082   s.stop_timer();
00083 }
00084 
00085 template <class M>
00086 static void benchmark_getp(picobench::state& s)
00087 {
00088   size_t size = s.iterations();
00089   auto map = gen_map<M>(size);
00090   s.start_timer();
00091   for (auto _ : s)
00092   {
00093     (void)_;
00094     auto res = map.getp(0);
00095     do_not_optimize(res);
00096     clobber_memory();
00097   }
00098   s.stop_timer();
00099 }
00100 
00101 template <class M>
00102 static void benchmark_foreach(picobench::state& s)
00103 {
00104   size_t size = s.iterations();
00105   auto map = gen_map<M>(size);
00106   size_t count = 0;
00107   s.start_timer();
00108   for (auto _ : s)
00109   {
00110     (void)_;
00111     map.foreach([&count, map](const auto& key, const auto& value) {
00112       count++;
00113       return true;
00114     });
00115     clobber_memory();
00116   }
00117   s.stop_timer();
00118 }
00119 
00120 const std::vector<int> sizes = {32, 32 << 2, 32 << 4, 32 << 6, 32 << 8};
00121 
00122 PICOBENCH_SUITE("put");
00123 auto bench_rb_map_put = benchmark_put<RBMap<K, V>>;
00124 PICOBENCH(bench_rb_map_put).iterations(sizes).samples(10).baseline();
00125 auto bench_champ_map_put = benchmark_put<champ::Map<K, V>>;
00126 PICOBENCH(bench_champ_map_put).iterations(sizes).samples(10);
00127 
00128 PICOBENCH_SUITE("get");
00129 auto bench_rb_map_get = benchmark_get<RBMap<K, V>>;
00130 PICOBENCH(bench_rb_map_get).iterations(sizes).samples(10).baseline();
00131 auto bench_rb_map_getp = benchmark_getp<RBMap<K, V>>;
00132 PICOBENCH(bench_rb_map_getp).iterations(sizes).samples(10);
00133 auto bench_champ_map_get = benchmark_get<champ::Map<K, V>>;
00134 PICOBENCH(bench_champ_map_get).iterations(sizes).samples(10);
00135 auto bench_champ_map_getp = benchmark_getp<champ::Map<K, V>>;
00136 PICOBENCH(bench_champ_map_getp).iterations(sizes).samples(10);
00137 
00138 const std::vector<int> for_sizes = {32 << 4, 32 << 5, 32 << 6};
00139 
00140 PICOBENCH_SUITE("foreach");
00141 auto bench_rb_map_foreach = benchmark_foreach<RBMap<K, V>>;
00142 PICOBENCH(bench_rb_map_foreach).iterations(for_sizes).samples(10).baseline();
00143 auto bench_champ_map_foreach = benchmark_foreach<champ::Map<K, V>>;
00144 PICOBENCH(bench_champ_map_foreach).iterations(for_sizes).samples(10);
00145 
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/ds/test/map_bench.cpp...
Preprocessing /data/git/CCF/src/ds/test/map_test.cpp...
#include ../champ_map.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include random: not found! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 6602 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 using namespace std;
00011 
00012 template <class K>
00013 struct CollisionHash
00014 {
00015   size_t operator()(const K& k) const noexcept
00016   {
00017     return std::hash<K>()(k) % 100;
00018   }
00019 };
00020 
00021 using K = uint64_t;
00022 using V = uint64_t;
00023 
00024 // using H = std::hash<K>;
00025 using H = CollisionHash<K>;
00026 
00027 class Model
00028 {
00029   unordered_map<K, V> internal;
00030 
00031 public:
00032   optional<V> get(const K& key) const
00033   {
00034     auto it = internal.find(key);
00035     if (it == internal.end())
00036       return {};
00037 
00038     return it->second;
00039   }
00040 
00041   Model put(const K& key, const V& value) const
00042   {
00043     auto next = *this;
00044     next.internal[key] = value;
00045     return next;
00046   }
00047 
00048   Model remove(const K& key) const
00049   {
00050     auto next = *this;
00051     next.internal.erase(key);
00052     return next;
00053   }
00054 };
00055 
00056 struct Op
00057 {
00058   virtual ~Op() = default;
00059   virtual pair<const Model, const champ::Map<K, V, H>> apply(
00060     const Model& a, const champ::Map<K, V, H>& b) = 0;
00061   virtual string str() = 0;
00062 };
00063 
00064 struct Put : public Op
00065 {
00066   K k;
00067   V v;
00068 
00069   Put(K k_, V v_) : k(k_), v(v_) {}
00070 
00071   pair<const Model, const champ::Map<K, V, H>> apply(
00072     const Model& a, const champ::Map<K, V, H>& b)
00073   {
00074     return make_pair(a.put(k, v), b.put(k, v));
00075   }
00076 
00077   string str()
00078   {
00079     auto ss = stringstream();
00080     ss << "Put(" << H()(k) << ", " << v << ")";
00081     return ss.str();
00082   }
00083 };
00084 
00085 struct Remove : public Op
00086 {
00087   K k;
00088 
00089   Remove(K k_) : k(k_) {}
00090 
00091   pair<const Model, const champ::Map<K, V, H>> apply(
00092     const Model& a, const champ::Map<K, V, H>& b)
00093   {
00094     return make_pair(a.remove(k), b.remove(k));
00095   }
00096 
00097   string str()
00098   {
00099     auto ss = stringstream();
00100     ss << "Remove(" << H()(k) << ")";
00101     return ss.str();
00102   }
00103 };
00104 
00105 vector<unique_ptr<Op>> gen_ops(size_t n)
00106 {
00107   random_device rand_dev;
00108   auto seed = rand_dev();
00109   std::cout << "seed: " << seed << std::endl;
00110   mt19937 gen(seed);
00111   uniform_int_distribution<> gen_op(0, 3);
00112 
00113   vector<unique_ptr<Op>> ops;
00114   vector<K> keys;
00115   for (V v = 0; v < n; ++v)
00116   {
00117     unique_ptr<Op> op;
00118     auto op_i = keys.empty() ? 0 : gen_op(gen);
00119     switch (op_i)
00120     {
00121       case 0:
00122       case 1: // insert
00123       {
00124         auto k = gen();
00125         keys.push_back(k);
00126         op = make_unique<Put>(k, v);
00127 
00128         break;
00129       }
00130       case 2: // update
00131       {
00132         uniform_int_distribution<> gen_idx(0, keys.size() - 1);
00133         auto k = keys[gen_idx(gen)];
00134         op = make_unique<Put>(k, v);
00135 
00136         break;
00137       }
00138       case 3: // remove
00139       {
00140         uniform_int_distribution<> gen_idx(0, keys.size() - 1);
00141         auto i = gen_idx(gen);
00142         auto k = keys[i];
00143         keys.erase(keys.begin() + i);
00144         op = make_unique<Remove>(k);
00145 
00146         break;
00147       }
00148       default:
00149         throw logic_error("bad op number");
00150     }
00151     ops.push_back(move(op));
00152   }
00153 
00154   return ops;
00155 }
00156 
00157 TEST_CASE("persistent map operations")
00158 {
00159   Model model;
00160   champ::Map<K, V, H> champ;
00161 
00162   auto ops = gen_ops(500);
00163   for (auto& op : ops)
00164   {
00165     std::cout << op->str() << std::endl;
00166     auto r = op->apply(model, champ);
00167     auto model_new = r.first;
00168     auto champ_new = r.second;
00169 
00170     INFO("check consistency of persistent maps");
00171     {
00172       size_t n = 0;
00173       champ_new.foreach([&](const auto& k, const auto& v) {
00174         n++;
00175         auto model_value = model_new.get(k);
00176         REQUIRE(model_value.has_value());
00177         REQUIRE(model_value.value() == v);
00178         return true;
00179       });
00180       REQUIRE(n == champ_new.size());
00181     }
00182 
00183     INFO("check persistence of previous versions");
00184     {
00185       size_t n = 0;
00186       champ.foreach([&](const auto& k, const auto& v) {
00187         n++;
00188         auto model_value = model.get(k);
00189         REQUIRE(model_value.has_value());
00190         REQUIRE(model_value.value() == v);
00191         return true;
00192       });
00193       REQUIRE(n == champ.size());
00194     }
00195 
00196     model = model_new;
00197     champ = champ_new;
00198   }
00199 }
00200 
00201 static const champ::Map<K, V, H> gen_map(size_t size)
00202 {
00203   champ::Map<K, V, H> map;
00204   for (size_t i = 0; i < size; ++i)
00205   {
00206     map = map.put(i, i);
00207   }
00208   return map;
00209 }
00210 
00211 TEST_CASE("serialize map")
00212 {
00213   struct pair
00214   {
00215     K k;
00216     V v;
00217   };
00218 
00219   std::vector<pair> results;
00220   uint32_t num_elements = 100;
00221   auto map = gen_map(num_elements);
00222 
00223   INFO("make sure we can serialize a map");
00224   {
00225     map.foreach([&results](const auto& key, const auto& value) {
00226       results.push_back({key, value});
00227       return true;
00228     });
00229     REQUIRE_EQ(num_elements, results.size());
00230   }
00231 
00232   INFO("make sure we can deserialize a map");
00233   {
00234     std::set<K> keys;
00235     champ::Map<K, V, H> new_map;
00236     for (const auto& p : results)
00237     {
00238       REQUIRE_LT(p.k, num_elements);
00239       keys.insert(p.k);
00240       new_map = new_map.put(p.k, p.v);
00241     }
00242     REQUIRE_EQ(num_elements, new_map.size());
00243     REQUIRE_EQ(num_elements, keys.size());
00244   }
00245 
00246   INFO("Serialize map to array");
00247   {
00248     champ::Snapshot<K, V, H> snapshot(map);
00249     std::vector<uint8_t> s(map.get_serialized_size());
00250     snapshot.serialize(s.data());
00251 
00252     champ::Map<K, V, H> new_map = champ::Map<K, V, H>::deserialize_map(s);
00253 
00254     std::set<K> keys;
00255     new_map.foreach([&keys](const auto& key, const auto& value) {
00256       keys.insert(key);
00257       REQUIRE_EQ(key, value);
00258       return true;
00259     });
00260     REQUIRE_EQ(map.size(), new_map.size());
00261     REQUIRE_EQ(map.size(), keys.size());
00262 
00263     uint32_t offset = 1000;
00264     for (uint32_t i = offset; i < offset + num_elements; ++i)
00265     {
00266       new_map = new_map.put(i, i);
00267     }
00268     REQUIRE_EQ(new_map.size(), map.size() + num_elements);
00269     for (uint32_t i = offset; i < offset + num_elements; ++i)
00270     {
00271       auto p = new_map.get(i);
00272       REQUIRE(p.has_value());
00273       REQUIRE(p.value() == i);
00274     }
00275   }
00276 
00277   INFO("Ensure serialized state is byte identical");
00278   {
00279     champ::Snapshot<K, V, H> snapshot_1(map);
00280     std::vector<uint8_t> s_1(map.get_serialized_size());
00281     snapshot_1.serialize(s_1.data());
00282 
00283     champ::Snapshot<K, V, H> snapshot_2(map);
00284     std::vector<uint8_t> s_2(map.get_serialized_size());
00285     snapshot_2.serialize(s_2.data());
00286 
00287     REQUIRE_EQ(s_1, s_2);
00288   }
00289 
00290   INFO("Serialize map with different key sizes");
00291   {
00292     using SerialisedKey = champ::serialisers::SerialisedEntry;
00293     using SerialisedValue = champ::serialisers::SerialisedEntry;
00294 
00295     champ::Map<SerialisedKey, SerialisedValue> map;
00296     SerialisedKey key(16);
00297     SerialisedValue value(8);
00298     SerialisedValue long_value(256);
00299 
00300     map = map.put(key, value);
00301     map = map.put(key, long_value);
00302 
00303     champ::Snapshot<SerialisedKey, SerialisedValue> snapshot(map);
00304     std::vector<uint8_t> s(map.get_serialized_size());
00305     snapshot.serialize(s.data());
00306   }
00307 }
00308 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/ds/test/map_test.cpp...
Preprocessing /data/git/CCF/src/ds/test/messaging.cpp...
#include ../messaging.h: already included! skipping...
#include ring_buffer.h: already included! skipping...
#include deque: not found! skipping...
#include fmt/format.h: not found! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
#include ../ring_buffer.h: already included! skipping...
#include ../serialized.h: already included! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/thread_ids.h: not found! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include cstddef: not found! skipping...
#include array: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include iomanip: not found! skipping...
#include iostream: not found! skipping...
#include numeric: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 16468 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/ds/test/messaging.cpp" 2
00006 
00007 
00008 # 8 "/data/git/CCF/src/ds/test/messaging.cpp" 2
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 using namespace messaging;
00019 using namespace ringbuffer;
00020 
00021 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 1;
00022 
00023 template <typename Ex, typename F>
00024 void require_throws_with(
00025   F&& f,
00026   const std::vector<std::string>& includes,
00027   const std::vector<std::string>& excludes = {})
00028 {
00029   bool threw = false;
00030   try
00031   {
00032     f();
00033   }
00034   catch (const Ex& ex)
00035   {
00036     threw = true;
00037     const std::string what = ex.what();
00038 
00039     for (const auto& s : includes)
00040     {
00041       REQUIRE(what.find(s) != std::string::npos);
00042     }
00043 
00044     for (const auto& s : excludes)
00045     {
00046       REQUIRE(what.find(s) == std::string::npos);
00047     }
00048   }
00049   REQUIRE(true);
00050 }
00051 
00052 
00053 {
00054   using MType = size_t;
00055   constexpr MType m0 = 0;
00056   constexpr MType m1 = 1;
00057   constexpr MType m2 = 2;
00058 
00059   size_t x = 0;
00060   constexpr size_t a = 0xcafe;
00061   constexpr size_t b = 0xbeef;
00062 
00063   auto set_a = [&x](const uint8_t*, size_t) { x = a; };
00064 
00065   auto set_b = [&x](const uint8_t*, size_t) { x = b; };
00066 
00067   auto set_arg = [&x](const uint8_t* data, size_t size) {
00068     x = serialized::read<size_t>(data, size);
00069   };
00070 
00071   auto unregister = [](const uint8_t*, size_t) { return false; };
00072 
00073   Dispatcher<MType> d("Test");
00074 
00075   INFO("Handlers can be registered");
00076   {
00077     REQUIRE_NOTHROW(DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_a));
00078     REQUIRE_NOTHROW(DISPATCHER_SET_MESSAGE_HANDLER(d, m1, set_b));
00079   }
00080 
00081   INFO("Only unregistered IDs can be registered");
00082   {
00083     REQUIRE_THROWS_AS(
00084       DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_a), already_handled);
00085     REQUIRE_THROWS_AS(
00086       DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_b), already_handled);
00087     REQUIRE_THROWS_AS(
00088       DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_arg), already_handled);
00089     REQUIRE_THROWS_AS(
00090       DISPATCHER_SET_MESSAGE_HANDLER(d, m1, set_a), already_handled);
00091     REQUIRE_THROWS_AS(
00092       DISPATCHER_SET_MESSAGE_HANDLER(d, m1, set_b), already_handled);
00093     REQUIRE_THROWS_AS(
00094       DISPATCHER_SET_MESSAGE_HANDLER(d, m1, set_arg), already_handled);
00095   }
00096 
00097   INFO("Error messages are informative");
00098   {
00099     require_throws_with<already_handled>(
00100       [&] { DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_a); }, {"m0"}, {"m1"});
00101     require_throws_with<already_handled>(
00102       [&] { DISPATCHER_SET_MESSAGE_HANDLER(d, m1, set_a); }, {"m1"}, {"m0"});
00103 
00104     constexpr MType duplicate = m0;
00105     require_throws_with<already_handled>(
00106       [&] { DISPATCHER_SET_MESSAGE_HANDLER(d, duplicate, set_a); },
00107       {"m0", "duplicate"},
00108       {"m1"});
00109   }
00110 
00111   INFO("Handlers can be called");
00112   {
00113     REQUIRE_NOTHROW(d.dispatch(m0, nullptr, 0));
00114     REQUIRE(x == a);
00115 
00116     REQUIRE_NOTHROW(d.dispatch(m1, nullptr, 0));
00117     REQUIRE(x == b);
00118   }
00119 
00120   INFO("Dispatching an unhandled message will throw");
00121   {
00122     REQUIRE_THROWS_AS(d.dispatch(m2, nullptr, 0), no_handler);
00123     REQUIRE(x == b);
00124   }
00125 
00126   INFO("Handlers can be unregistered");
00127   {
00128     REQUIRE_NOTHROW(d.remove_message_handler(m0));
00129     REQUIRE_NOTHROW(d.remove_message_handler(m1));
00130   }
00131 
00132   INFO("Only registered IDs can be unregistered");
00133   {
00134     REQUIRE_THROWS_AS(d.remove_message_handler(m0), no_handler);
00135     REQUIRE_THROWS_AS(d.remove_message_handler(m1), no_handler);
00136   }
00137 
00138   INFO("IDs can be re-registered and called");
00139   {
00140     REQUIRE_NOTHROW(DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_arg));
00141     REQUIRE_THROWS_AS(
00142       DISPATCHER_SET_MESSAGE_HANDLER(d, m0, set_arg), already_handled);
00143 
00144     const size_t arg = 0xdead;
00145     REQUIRE_NOTHROW(d.dispatch(m0, (const uint8_t*)&arg, sizeof(arg)));
00146     REQUIRE(x == arg);
00147 
00148     REQUIRE_NOTHROW(d.remove_message_handler(m0));
00149     REQUIRE_THROWS_AS(d.remove_message_handler(m0), no_handler);
00150   }
00151 }
00152 
00153 
00154 {
00155   enum : Message
00156   {
00157     set_x = Const::msg_min,
00158     echo,
00159     echo_out,
00160     finish
00161   };
00162 
00163   BufferProcessor bp;
00164 
00165   constexpr auto buffer_size = 1 << 10;
00166 
00167   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00168   Reader loop_src(in_buffer->bd);
00169   Writer test_filler(loop_src);
00170 
00171   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00172   Reader out_reader(out_buffer->bd);
00173   Writer out_writer(out_reader);
00174 
00175   size_t x = 0;
00176 
00177   auto set_x_handler = [&](const uint8_t* data, size_t size) {
00178     x = serialized::read<uint8_t>(data, size);
00179   };
00180 
00181   auto echo_handler = [&](const uint8_t* data, size_t size) {
00182     out_writer.write(echo_out, serializer::ByteRange{data, size});
00183   };
00184 
00185   auto finish_handler = [&](const uint8_t* data, size_t size) {
00186     bp.set_finished();
00187   };
00188 
00189   DISPATCHER_SET_MESSAGE_HANDLER(bp, set_x, set_x_handler);
00190   DISPATCHER_SET_MESSAGE_HANDLER(bp, echo, echo_handler);
00191   DISPATCHER_SET_MESSAGE_HANDLER(bp, finish, finish_handler);
00192 
00193   SUBCASE("Duplicate calls to set handler will throw")
00194   {
00195     REQUIRE_THROWS_AS(
00196       DISPATCHER_SET_MESSAGE_HANDLER(bp, finish, finish_handler),
00197       messaging::already_handled);
00198   }
00199 
00200   SUBCASE("Unhandled messages will throw")
00201   {
00202     test_filler.write(echo_out);
00203     REQUIRE_THROWS_AS(bp.run(loop_src), messaging::no_handler);
00204 
00205     const auto counts = bp.get_dispatcher().retrieve_message_counts();
00206     REQUIRE(counts.empty());
00207   }
00208 
00209   SUBCASE("Message handlers can finish the loop")
00210   {
00211     test_filler.write(finish);
00212     REQUIRE(bp.run(loop_src) == 1);
00213 
00214     const auto counts = bp.get_dispatcher().retrieve_message_counts();
00215     REQUIRE(counts.size() == 1);
00216     REQUIRE(counts.find(finish) != counts.end());
00217     REQUIRE(counts.at(finish).messages == 1);
00218     REQUIRE(counts.at(finish).bytes == 0);
00219   }
00220 
00221   SUBCASE("Message handlers can affect external state")
00222   {
00223     const uint8_t new_x = 42;
00224     test_filler.write(set_x, new_x);
00225     test_filler.write(finish);
00226     REQUIRE(bp.run(loop_src) == 2);
00227     REQUIRE(x == new_x);
00228 
00229     const auto counts = bp.get_dispatcher().retrieve_message_counts();
00230     REQUIRE(counts.size() == 2);
00231     REQUIRE(counts.find(set_x) != counts.end());
00232     REQUIRE(counts.at(set_x).messages == 1);
00233     REQUIRE(counts.at(set_x).bytes == sizeof(new_x));
00234     REQUIRE(counts.find(finish) != counts.end());
00235     REQUIRE(counts.at(finish).messages == 1);
00236     REQUIRE(counts.at(finish).bytes == 0);
00237   }
00238 
00239   SUBCASE("Message handlers can communicate through the writer")
00240   {
00241     const std::vector<uint8_t> actual = {0, 13, 42, 100, 100, 10, 1};
00242     test_filler.write(echo, actual);
00243     test_filler.write(finish);
00244     REQUIRE(bp.run(loop_src) == 2);
00245 
00246     REQUIRE(
00247       out_reader.read(
00248         1, [&actual](Message m, const uint8_t* data, size_t size) {
00249           REQUIRE(m == echo_out);
00250           REQUIRE(size == actual.size());
00251           for (size_t i = 0; i < size; ++i)
00252           {
00253             REQUIRE(data[i] == actual[i]);
00254           }
00255         }) == 1);
00256 
00257     const auto counts = bp.get_dispatcher().retrieve_message_counts();
00258     REQUIRE(counts.size() == 2);
00259     REQUIRE(counts.find(echo) != counts.end());
00260     REQUIRE(counts.at(echo).messages == 1);
00261     REQUIRE(counts.at(echo).bytes == actual.size());
00262     REQUIRE(counts.find(finish) != counts.end());
00263     REQUIRE(counts.at(finish).messages == 1);
00264     REQUIRE(counts.at(finish).bytes == 0);
00265   }
00266 
00267   SUBCASE("Dispatcher can be accessed directly")
00268   {
00269     auto& dispatcher = bp.get_dispatcher();
00270     dispatcher.remove_message_handler(set_x);
00271 
00272     const auto old_x = x;
00273     const auto new_x = old_x + 1;
00274     DISPATCHER_SET_MESSAGE_HANDLER(
00275       dispatcher, set_x, [&](const uint8_t* data, size_t size) { x = new_x; });
00276 
00277     REQUIRE(x == old_x);
00278     dispatcher.dispatch(set_x, nullptr, 0);
00279     REQUIRE(x == new_x);
00280 
00281     REQUIRE_NOTHROW(dispatcher.remove_message_handler(set_x));
00282     REQUIRE_THROWS_AS(
00283       dispatcher.remove_message_handler(set_x), messaging::no_handler);
00284     REQUIRE_THROWS_AS(
00285       dispatcher.dispatch(set_x, nullptr, 0), messaging::no_handler);
00286 
00287     const auto counts = bp.get_dispatcher().retrieve_message_counts();
00288     REQUIRE(counts.size() == 1);
00289     REQUIRE(counts.find(set_x) != counts.end());
00290     REQUIRE(counts.at(set_x).messages == 1);
00291     REQUIRE(counts.at(set_x).bytes == 0);
00292   }
00293 }
00294 
00295 
00296 {
00297   enum : Message
00298   {
00299     empty = Const::msg_min,
00300     ping,
00301     pong,
00302     finish
00303   };
00304 
00305   struct ThreadArgs
00306   {
00307     Reader& r;
00308     Writer w;
00309     size_t& read_count;
00310   };
00311 
00312   auto run_threads =
00313     [](Circuit& circuit, size_t& reads_inside, size_t& reads_outside) {
00314       std::atomic<bool> first_finished(false);
00315 
00316       auto thread_fn = [&](ThreadArgs* ta) {
00317         BufferProcessor bp;
00318 
00319         auto finish_handler = [&bp, &ta](const uint8_t* data, size_t size) {
00320           // If they tell us to stop, we tell them to stop as well
00321           ta->w.write(finish);
00322           bp.set_finished();
00323         };
00324         DISPATCHER_SET_MESSAGE_HANDLER(bp, finish, finish_handler);
00325 
00326         auto empty_handler = [](const uint8_t* data, size_t size) {};
00327         DISPATCHER_SET_MESSAGE_HANDLER(bp, empty, empty_handler);
00328 
00329         // Read [count, tail...], write pong(count, tail...)
00330         auto ping_handler = [&ta](const uint8_t* data, size_t size) {
00331           const auto count = serialized::read<uint8_t>(data, size);
00332           ta->w.write(pong, count, serializer::ByteRange{data, size});
00333         };
00334         DISPATCHER_SET_MESSAGE_HANDLER(bp, ping, ping_handler);
00335 
00336         // Read [count, tail...], if positive write ping(count - 1)
00337         // else if tail, write ping(tail...)
00338         // else if we're the second finisher, write finish
00339         auto pong_handler = [&ta, &first_finished](
00340                               const uint8_t* data, size_t size) {
00341           const auto count = serialized::read<uint8_t>(data, size);
00342           if (count > 0)
00343           {
00344             ta->w.write(
00345               ping, (uint8_t)(count - 1), serializer::ByteRange{data, size});
00346           }
00347           else if (size > 0)
00348           {
00349             const auto next = serialized::read<uint8_t>(data, size);
00350             ta->w.write(ping, (uint8_t)next, serializer::ByteRange{data, size});
00351           }
00352           else
00353           {
00354             bool was = false;
00355             const bool done = !first_finished.compare_exchange_weak(was, true);
00356             if (done)
00357             {
00358               ta->w.write(finish);
00359             }
00360           }
00361         };
00362         DISPATCHER_SET_MESSAGE_HANDLER(bp, pong, pong_handler);
00363 
00364         ta->read_count += bp.run(ta->r);
00365       };
00366 
00367       ThreadArgs insideArgs = {
00368         circuit.read_from_outside(), circuit.write_to_outside(), reads_inside};
00369       std::thread inside_thread(thread_fn, &insideArgs);
00370 
00371       ThreadArgs outsideArgs = {
00372         circuit.read_from_inside(), circuit.write_to_inside(), reads_outside};
00373       std::thread outside_thread(thread_fn, &outsideArgs);
00374 
00375       inside_thread.join();
00376       outside_thread.join();
00377     };
00378 
00379   SUBCASE("Message loops run until stopped")
00380   {
00381     constexpr auto buffer_size = 1 << 10;
00382 
00383     auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00384     auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00385 
00386     ringbuffer::Circuit circuit(in_buffer->bd, out_buffer->bd);
00387 
00388     size_t reads_inside = 0;
00389     size_t reads_outside = 0;
00390 
00391     // Prepare a single message from outside to inside, telling it to finish
00392     circuit.write_to_inside().write(finish);
00393     run_threads(circuit, reads_inside, reads_outside);
00394 
00395     REQUIRE(reads_inside == 1);
00396     REQUIRE(reads_outside == 1);
00397   }
00398 
00399   SUBCASE("Both loops can send data")
00400   {
00401     constexpr auto buffer_size = 1 << 10;
00402 
00403     auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00404     auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00405 
00406     ringbuffer::Circuit circuit(in_buffer->bd, out_buffer->bd);
00407 
00408     size_t reads_inside = 0;
00409     size_t reads_outside = 0;
00410 
00411     // Both sides send some empty messages
00412     constexpr auto count_inbound = 2u;
00413     constexpr auto count_outbound = 5u;
00414 
00415     for (auto i = 0u; i < count_inbound; ++i)
00416     {
00417       circuit.write_to_inside().write(empty);
00418     }
00419 
00420     for (auto i = 0u; i < count_outbound; ++i)
00421     {
00422       circuit.write_to_outside().write(empty);
00423     }
00424 
00425     circuit.write_to_inside().write(finish);
00426 
00427     run_threads(circuit, reads_inside, reads_outside);
00428 
00429     REQUIRE(reads_inside == count_inbound + 1);
00430     REQUIRE(reads_outside == count_outbound + 1);
00431   }
00432 
00433   SUBCASE("Messages can cause repeated nested responses")
00434   {
00435     struct PingCounts
00436     {
00437       const std::vector<uint8_t> in;
00438       const std::vector<uint8_t> out;
00439     };
00440 
00441     for (const auto& pc : {PingCounts{{5}, {5}},
00442                            {{3, 4, 5}, {2}},
00443                            {{2}, {3, 4, 5}},
00444                            {{3, 4, 2, 8}, {100, 10}},
00445                            {{100, 10}, {3, 4, 2, 8}}})
00446     {
00447       const auto& pings_in = pc.in;
00448       const auto& pings_out = pc.out;
00449 
00450       constexpr auto buffer_size = 1 << 10;
00451 
00452       auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00453       auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00454 
00455       ringbuffer::Circuit circuit(in_buffer->bd, out_buffer->bd);
00456 
00457       size_t reads_inside = 0;
00458       size_t reads_outside = 0;
00459 
00460       circuit.write_to_inside().write(ping, pings_in);
00461       circuit.write_to_outside().write(ping, pings_out);
00462 
00463       run_threads(circuit, reads_inside, reads_outside);
00464 
00465       // There's a pong for every ping, so both sides read the same number of
00466       // messages
00467       const size_t total_piongs = pings_in.size() +
00468         std::accumulate(pings_in.begin(), pings_in.end(), 0u) +
00469         pings_out.size() +
00470         std::accumulate(pings_out.begin(), pings_out.end(), 0u);
00471       CHECK(reads_inside == total_piongs + 1);
00472       CHECK(reads_outside == total_piongs + 1);
00473     }
00474   }
00475 }
00476 
00477 
00478 {
00479   enum : Message
00480   {
00481     big_message = Const::msg_min,
00482     finish
00483   };
00484 
00485   constexpr auto circuit_size = 1 << 6;
00486 
00487   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(circuit_size);
00488   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(circuit_size);
00489 
00490   ringbuffer::Circuit circuit(in_buffer->bd, out_buffer->bd);
00491 
00492   BufferProcessor processor_inside;
00493 
00494   auto finish_handler = [&processor_inside](const uint8_t* data, size_t size) {
00495     processor_inside.set_finished();
00496   };
00497   DISPATCHER_SET_MESSAGE_HANDLER(processor_inside, finish, finish_handler);
00498 
00499   auto big_message_handler = [](const uint8_t* data, size_t size) {};
00500   DISPATCHER_SET_MESSAGE_HANDLER(
00501     processor_inside, big_message, big_message_handler);
00502 
00503   auto write_to_inside = circuit.write_to_inside();
00504 
00505   std::vector<uint8_t> message_body(circuit_size / 3);
00506   std::iota(message_body.begin(), message_body.end(), 0);
00507 
00508   // If we continually write to a ringbuffer which is not being read, it will
00509   // eventually fill up and writes will fail
00510   constexpr size_t target_writes = circuit_size * 2;
00511   size_t i = 0;
00512   for (; i <= target_writes; ++i)
00513   {
00514     const bool succeeded = write_to_inside.try_write(big_message, message_body);
00515     if (!succeeded)
00516     {
00517       break;
00518     }
00519   }
00520 
00521   REQUIRE(i < target_writes);
00522 
00523   // Read progress enables write progress
00524   size_t last_progress = i;
00525   while (i < target_writes)
00526   {
00527     REQUIRE(
00528       processor_inside.read_n(target_writes, circuit.read_from_outside()) > 0);
00529 
00530     while (write_to_inside.try_write(big_message, message_body))
00531     {
00532       ++i;
00533     }
00534 
00535     REQUIRE(i > last_progress);
00536     last_progress = i;
00537   }
00538 
00539   // Read remaining messages
00540   REQUIRE(
00541     processor_inside.read_n(target_writes, circuit.read_from_outside()) > 0);
00542 
00543   // NonBlockingWriter also avoids deadlock
00544   ringbuffer::WriterFactory base_factory(circuit);
00545   ringbuffer::NonBlockingWriterFactory non_blocking_factory(base_factory);
00546 
00547   auto non_blocking_writer =
00548     non_blocking_factory.create_non_blocking_writer_to_inside();
00549 
00550   // More than the circuit size can be written, since overflows are queued
00551   i = 0;
00552   for (; i < target_writes; ++i)
00553   {
00554     const bool succeeded =
00555       non_blocking_writer->try_write(big_message, message_body);
00556     if (!succeeded)
00557     {
00558       break;
00559     }
00560   }
00561 
00562   REQUIRE(i == target_writes);
00563 
00564   // To read all these pending messages, the pending queue must be flushed
00565   // multiple times
00566   size_t total_read = 0;
00567   while (true)
00568   {
00569     const size_t n_read =
00570       processor_inside.read_n(target_writes, circuit.read_from_outside());
00571     REQUIRE(n_read > 0);
00572     total_read += n_read;
00573 
00574     if (!non_blocking_writer->try_flush_pending())
00575     {
00576       break;
00577     }
00578   }
00579 
00580   // Read remaining messages
00581   const size_t n_read =
00582     processor_inside.read_n(target_writes, circuit.read_from_outside());
00583   REQUIRE(n_read > 0);
00584 }
00585 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE DISPATCHER_SET_MESSAGE_HANDLER LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/test/messaging.cpp...
Preprocessing /data/git/CCF/src/ds/test/openapi.cpp...
#include ds/openapi.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 7612 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00008 
00009 
00010 using namespace ds;
00011 
00012 #define REQUIRE_ELEMENT(j, name, type_fn) 
00013 
00014 
00015 
00016 
00017 
00018 
00019 static constexpr auto server_url = "https://not.a.real.server.com/testing_only";
00020 
00021 // This is only a very basic check - assume full validation is done by external
00022 // validator
00023 void required_doc_elements(const nlohmann::json& j)
00024 {
00025   REQUIRE_ELEMENT(j, openapi, is_string);
00026   REQUIRE_ELEMENT(j, info, is_object);
00027   REQUIRE_ELEMENT(j, paths, is_object);
00028 }
00029 
00030 TEST_CASE("Manual construction")
00031 {
00032   auto doc = openapi::create_document(
00033     "Test generated API",
00034     "Some longer description enhanced with **Markdown**",
00035     "0.1.42");
00036 
00037   openapi::server(doc, server_url);
00038 
00039   const auto string_schema = nlohmann::json{{"type", "string"}};
00040 
00041   auto& foo = openapi::path(doc, "/users/foo");
00042   auto& foo_post = openapi::path_operation(foo, HTTP_POST);
00043   auto& foo_post_request = openapi::request_body(foo_post);
00044   auto& foo_post_request_json = openapi::media_type(
00045     foo_post_request, http::headervalues::contenttype::JSON);
00046   auto& foo_post_request_json_schema = openapi::schema(foo_post_request_json);
00047   foo_post_request_json_schema = string_schema;
00048 
00049   auto& foo_post_response_ok = openapi::response(
00050     foo_post, HTTP_STATUS_OK, "Indicates that everything went ok");
00051   auto& foo_post_response_ok_json = openapi::media_type(
00052     foo_post_response_ok, http::headervalues::contenttype::JSON);
00053   auto& foo_post_response_ok_json_schema =
00054     openapi::schema(foo_post_response_ok_json);
00055   foo_post_response_ok_json_schema = string_schema;
00056 
00057   required_doc_elements(doc);
00058 
00059   const auto& info_element = doc["info"];
00060   REQUIRE_ELEMENT(info_element, title, is_string);
00061   REQUIRE_ELEMENT(info_element, description, is_string);
00062   REQUIRE_ELEMENT(info_element, version, is_string);
00063 
00064   REQUIRE_ELEMENT(doc, servers, is_array);
00065   const auto& servers_element = doc["servers"];
00066   REQUIRE(servers_element.size() == 1);
00067   const auto& first_server = servers_element[0];
00068   REQUIRE_ELEMENT(first_server, url, is_string);
00069 }
00070 
00071 struct Foo
00072 {
00073   size_t n;
00074   std::string s;
00075 };
00076 DECLARE_JSON_TYPE(Foo);
00077 DECLARE_JSON_REQUIRED_FIELDS(Foo, n, s);
00078 
00079 TEST_CASE("Simple custom types")
00080 {
00081   auto doc = openapi::create_document(
00082     "Test generated API",
00083     "Some longer description enhanced with **Markdown**",
00084     "0.1.42");
00085 
00086   openapi::server(doc, server_url);
00087 
00088   openapi::add_request_body_schema<Foo>(
00089     doc, "/app/foo", HTTP_POST, http::headervalues::contenttype::JSON);
00090   openapi::add_response_schema<size_t>(
00091     doc,
00092     "/app/foo",
00093     HTTP_POST,
00094     HTTP_STATUS_OK,
00095     http::headervalues::contenttype::JSON);
00096   openapi::add_response_schema<Foo>(
00097     doc,
00098     "/app/foo",
00099     HTTP_POST,
00100     HTTP_STATUS_OK,
00101     http::headervalues::contenttype::JSON);
00102 
00103   required_doc_elements(doc);
00104 }
00105 
00106 struct Bar
00107 {
00108   std::string name;
00109   double f;
00110 };
00111 DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(Bar);
00112 DECLARE_JSON_REQUIRED_FIELDS(Bar, name);
00113 DECLARE_JSON_OPTIONAL_FIELDS(Bar, f);
00114 
00115 enum class Vehicle
00116 {
00117   Car,
00118   Pedalo,
00119   Submarine,
00120 };
00121 
00122 DECLARE_JSON_ENUM(
00123   Vehicle,
00124   {{Vehicle::Car, "vroom vroom"},
00125    {Vehicle::Pedalo, "splash splash"},
00126    {Vehicle::Submarine, "glug glug"}});
00127 
00128 struct Baz : public Bar
00129 {
00130   uint16_t n;
00131   double x;
00132   double y;
00133   Vehicle v;
00134 };
00135 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(Baz, Bar);
00136 DECLARE_JSON_REQUIRED_FIELDS(Baz, n, v);
00137 DECLARE_JSON_OPTIONAL_FIELDS(Baz, x, y);
00138 
00139 struct Buzz : public Baz
00140 {
00141   Foo required_and_only_in_c;
00142   uint16_t optional_and_only_in_c;
00143 };
00144 DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(Buzz, Baz);
00145 DECLARE_JSON_REQUIRED_FIELDS_WITH_RENAMES(
00146   Buzz, required_and_only_in_c, RequiredJsonField);
00147 DECLARE_JSON_OPTIONAL_FIELDS_WITH_RENAMES(
00148   Buzz, optional_and_only_in_c, OptionalJsonField);
00149 
00150 TEST_CASE("Complex custom types")
00151 {
00152   auto doc = openapi::create_document(
00153     "Test generated API",
00154     "Some longer description enhanced with **Markdown**",
00155     "0.1.42");
00156 
00157   openapi::server(doc, server_url);
00158 
00159   openapi::add_response_schema<std::vector<Foo>>(
00160     doc,
00161     "/app/foos",
00162     HTTP_GET,
00163     HTTP_STATUS_OK,
00164     http::headervalues::contenttype::JSON);
00165   openapi::add_response_schema<std::vector<std::vector<Foo>>>(
00166     doc,
00167     "/app/fooss",
00168     HTTP_GET,
00169     HTTP_STATUS_OK,
00170     http::headervalues::contenttype::JSON);
00171   openapi::add_response_schema<Bar>(
00172     doc,
00173     "/app/bar",
00174     HTTP_GET,
00175     HTTP_STATUS_OK,
00176     http::headervalues::contenttype::JSON);
00177   openapi::add_response_schema<Baz>(
00178     doc,
00179     "/app/baz",
00180     HTTP_GET,
00181     HTTP_STATUS_OK,
00182     http::headervalues::contenttype::JSON);
00183   openapi::add_response_schema<std::map<std::string, Buzz>>(
00184     doc,
00185     "/app/buzz",
00186     HTTP_GET,
00187     HTTP_STATUS_OK,
00188     http::headervalues::contenttype::JSON);
00189 
00190   openapi::add_request_body_schema<std::optional<Bar>>(
00191     doc, "/app/complex", HTTP_POST, http::headervalues::contenttype::JSON);
00192   openapi::add_response_schema<std::map<Baz, std::vector<Buzz>>>(
00193     doc,
00194     "/app/complex",
00195     HTTP_POST,
00196     HTTP_STATUS_OK,
00197     http::headervalues::contenttype::JSON);
00198 
00199   required_doc_elements(doc);
00200 }
00201 
00202 // Required functions may be implemented manually, allowing the type to be used
00203 // in macro for a containing type
00204 namespace aaa
00205 {
00206   struct FriendlyName
00207   {
00208     std::string forename;
00209     std::string nickname;
00210     std::string surname;
00211   };
00212 
00213   void to_json(nlohmann::json& j, const FriendlyName& fn)
00214   {
00215     j = fmt::format("{} \"{}\" {}", fn.forename, fn.nickname, fn.surname);
00216   }
00217 
00218   void from_json(const nlohmann::json& j, FriendlyName& fn)
00219   {
00220     const auto s = j.get<std::string>();
00221     const auto nickname_start = s.find('"');
00222     const auto nickname_end = s.find('"', nickname_start + 1);
00223     fn.forename = s.substr(0, nickname_start - 1);
00224     fn.nickname =
00225       s.substr(nickname_start + 1, nickname_end - nickname_start - 1);
00226     fn.surname = s.substr(nickname_end + 2);
00227   }
00228 
00229   std::string schema_name(const FriendlyName&)
00230   {
00231     return "FriendlyName";
00232   }
00233 
00234   template <typename T>
00235   void add_schema_components(T& doc, nlohmann::json& j, const FriendlyName&)
00236   {
00237     j["type"] = "string";
00238     j["pattern"] = "^.* \".*\" .*$";
00239   }
00240 }
00241 
00242 namespace bbb
00243 {
00244   struct Person
00245   {
00246     aaa::FriendlyName name;
00247     size_t age;
00248   };
00249   DECLARE_JSON_TYPE(Person);
00250   DECLARE_JSON_REQUIRED_FIELDS(Person, name, age);
00251 }
00252 
00253 TEST_CASE("Manual function definitions")
00254 {
00255   {
00256     INFO("FriendlyName roundtrip");
00257     aaa::FriendlyName fn;
00258     fn.forename = "Dwayne";
00259     fn.nickname = "The Rock";
00260     fn.surname = "Johnson";
00261     const nlohmann::json j = fn;
00262     const auto fn2 = j.get<aaa::FriendlyName>();
00263     CHECK(fn.forename == fn2.forename);
00264     CHECK(fn.nickname == fn2.nickname);
00265     CHECK(fn.surname == fn2.surname);
00266 
00267     bbb::Person p;
00268     p.name = fn;
00269     p.age = 42;
00270     const nlohmann::json j2 = p;
00271     const auto p2 = j2.get<bbb::Person>();
00272     CHECK(p.name.forename == p2.name.forename);
00273     CHECK(p.name.nickname == p2.name.nickname);
00274     CHECK(p.name.surname == p2.name.surname);
00275     CHECK(p.age == p2.age);
00276   }
00277 
00278   {
00279     INFO("OpenAPI generation");
00280     auto doc = openapi::create_document(
00281       "Test generated API",
00282       "Some longer description enhanced with **Markdown**",
00283       "0.1.42");
00284 
00285     openapi::add_request_body_schema<bbb::Person>(
00286       doc, "/person", HTTP_POST, http::headervalues::contenttype::JSON);
00287 
00288     const auto components_schemas = doc["components"]["schemas"];
00289     REQUIRE(components_schemas.find("Person") != components_schemas.end());
00290     REQUIRE(
00291       components_schemas.find(aaa::schema_name(aaa::FriendlyName())) !=
00292       components_schemas.end());
00293   }
00294 }
00295 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN REQUIRE_ELEMENT 
---------
Parsing file /data/git/CCF/src/ds/test/openapi.cpp...
Preprocessing /data/git/CCF/src/ds/test/oversized.cpp...
#include messaging.h: already included! skipping...
#include ring_buffer.h: already included! skipping...
#include serialized.h: already included! skipping...
#include fmt/format.h: not found! skipping...
#include unordered_map: not found! skipping...
#include ../non_blocking.h: already included! skipping...
#include algorithm: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include functional: not found! skipping...
#include numeric: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 16208 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/ds/test/oversized.cpp" 2
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 enum : ringbuffer::Message
00015 {
00016   DEFINE_RINGBUFFER_MSG_TYPE(ascending),
00017   DEFINE_RINGBUFFER_MSG_TYPE(descending),
00018   DEFINE_RINGBUFFER_MSG_TYPE(unfragmented),
00019   DEFINE_RINGBUFFER_MSG_TYPE(random_contents),
00020   DEFINE_RINGBUFFER_MSG_TYPE(finish),
00021 };
00022 
00023 constexpr uint8_t unfragmented_magic_value = 42;
00024 
00025 
00026 {
00027   constexpr size_t payload_size = 100;
00028   std::vector<uint8_t> whole_message_ascending(payload_size);
00029   std::iota(whole_message_ascending.begin(), whole_message_ascending.end(), 0);
00030   std::vector<uint8_t> whole_message_descending(
00031     whole_message_ascending.rbegin(), whole_message_ascending.rend());
00032 
00033   messaging::RingbufferDispatcher disp("oversized");
00034   size_t complete_messages = 0;
00035 
00036   SUBCASE("Handler for fragment is registered for object lifetime")
00037   {
00038     {
00039       REQUIRE_FALSE(disp.has_handler(oversized::OversizedMessage::fragment));
00040       oversized::FragmentReconstructor fr(disp);
00041       REQUIRE(disp.has_handler(oversized::OversizedMessage::fragment));
00042     }
00043     REQUIRE_FALSE(disp.has_handler(oversized::OversizedMessage::fragment));
00044   }
00045 
00046   DISPATCHER_SET_MESSAGE_HANDLER(
00047     disp, ascending, [&](const uint8_t* data, size_t size) {
00048       REQUIRE(size == payload_size);
00049       REQUIRE(std::is_sorted(data, data + size, std::less_equal<uint8_t>()));
00050       ++complete_messages;
00051     });
00052 
00053   DISPATCHER_SET_MESSAGE_HANDLER(
00054     disp, descending, [&](const uint8_t* data, size_t size) {
00055       REQUIRE(size == payload_size);
00056       REQUIRE(std::is_sorted(data, data + size, std::greater_equal<uint8_t>()));
00057       ++complete_messages;
00058     });
00059 
00060   DISPATCHER_SET_MESSAGE_HANDLER(
00061     disp, unfragmented, [&](const uint8_t* data, size_t size) {
00062       REQUIRE(size == 1);
00063       REQUIRE(*data == unfragmented_magic_value);
00064       ++complete_messages;
00065     });
00066 
00067   struct MessageStream
00068   {
00069     ringbuffer::Message type;
00070     size_t id;
00071     size_t progress;
00072   };
00073 
00074   auto write_unfragmented = [&]() {
00075     const uint8_t data = unfragmented_magic_value;
00076     disp.dispatch(unfragmented, &data, sizeof(data));
00077   };
00078 
00079   auto write_more = [&](MessageStream& ms, size_t fragment_size) {
00080     if (ms.type != ascending && ms.type != descending)
00081       REQUIRE_MESSAGE(false, "Unexpected ms type");
00082 
00083     const auto complete_prior = complete_messages;
00084 
00085     std::vector<uint8_t> fragment_body(sizeof(ms.id));
00086     {
00087       // Write the identifier of the larger message
00088       uint8_t* raw = fragment_body.data();
00089       size_t remaining = fragment_body.size();
00090       serialized::write(raw, remaining, ms.id);
00091       REQUIRE(remaining == 0);
00092     }
00093 
00094     if (ms.progress == 0)
00095     {
00096       // Write header
00097       const auto init_size = fragment_body.size();
00098       fragment_body.resize(init_size + sizeof(ms.type) + sizeof(payload_size));
00099 
00100       uint8_t* raw = fragment_body.data() + init_size;
00101       size_t remaining = fragment_body.size() - init_size;
00102       serialized::write(raw, remaining, ms.type);
00103       serialized::write(raw, remaining, payload_size);
00104       REQUIRE(remaining == 0);
00105     }
00106 
00107     {
00108       // Write the fragment body
00109       const auto init_size = fragment_body.size();
00110       const auto remaining_body =
00111         std::min(fragment_size, payload_size - ms.progress);
00112       fragment_body.resize(init_size + remaining_body);
00113 
00114       uint8_t* raw = fragment_body.data() + init_size;
00115       size_t remaining = fragment_body.size() - init_size;
00116       const uint8_t* source = (ms.type == ascending ? whole_message_ascending :
00117                                                       whole_message_descending)
00118                                 .data();
00119       serialized::write(raw, remaining, source + ms.progress, remaining_body);
00120       ms.progress += remaining_body;
00121       REQUIRE(remaining == 0);
00122     }
00123 
00124     disp.dispatch(
00125       oversized::OversizedMessage::fragment,
00126       fragment_body.data(),
00127       fragment_body.size());
00128 
00129     // Return true iff dispatching completed another message
00130     return complete_prior < complete_messages;
00131   };
00132 
00133   constexpr size_t fragment_sizes[] = {payload_size,
00134                                        payload_size / 2,
00135                                        payload_size / 3,
00136                                        payload_size / 5,
00137                                        payload_size / 7};
00138   constexpr auto fragment_size_count =
00139     sizeof(fragment_sizes) / sizeof(fragment_sizes[0]);
00140 
00141   SUBCASE("Reconstruction of individual message")
00142   {
00143     oversized::FragmentReconstructor fr(disp);
00144 
00145     // Try several different message sizes, including awkward remainders
00146     for (size_t fragment_size : fragment_sizes)
00147     {
00148       const auto complete_prior = complete_messages;
00149 
00150       MessageStream ms{ascending, 0, 0};
00151 
00152       while (!write_more(ms, fragment_size))
00153       {
00154       }
00155 
00156       REQUIRE(complete_messages == complete_prior + 1);
00157     }
00158   }
00159 
00160   SUBCASE("Reconstruction from interleaved messages")
00161   {
00162     oversized::FragmentReconstructor fr(disp);
00163 
00164     std::vector<MessageStream> streams;
00165     streams.push_back({ascending, 0, 0});
00166     streams.push_back({ascending, 1, 0});
00167     streams.push_back({descending, 2, 0});
00168     streams.push_back({descending, 3, 0});
00169 
00170     srand(0x42);
00171 
00172     while (!streams.empty())
00173     {
00174       const auto complete_prior = complete_messages;
00175 
00176       const auto choice = rand() % (streams.size() + 1);
00177       if (choice == streams.size())
00178       {
00179         write_unfragmented();
00180         REQUIRE(complete_messages == complete_prior + 1);
00181       }
00182       else
00183       {
00184         // Vary fragment size, even within a single message stream
00185         const auto fragment_size = fragment_sizes[rand() % fragment_size_count];
00186 
00187         if (write_more(streams[choice], fragment_size))
00188         {
00189           REQUIRE(complete_messages == complete_prior + 1);
00190           streams.erase(streams.begin() + choice);
00191         }
00192       }
00193     }
00194   }
00195 }
00196 
00197 
00198 {
00199   constexpr size_t buf_size = 1 << 8;
00200   auto buffer = std::make_unique<ringbuffer::TestBuffer>(buf_size);
00201   ringbuffer::Reader rr(buffer->bd);
00202 
00203   constexpr auto fragment_max = buf_size / 8;
00204   constexpr auto total_max = buf_size / 3;
00205   oversized::Writer writer(
00206     std::make_unique<ringbuffer::Writer>(rr), fragment_max, total_max);
00207 
00208   std::vector<uint8_t> whole_message_ascending(total_max);
00209   std::iota(whole_message_ascending.begin(), whole_message_ascending.end(), 0);
00210   std::vector<uint8_t> whole_message_descending(
00211     whole_message_ascending.rbegin(), whole_message_ascending.rend());
00212 
00213   SUBCASE("Bad maximum fragment sizes are disallowed")
00214   {
00215     REQUIRE_THROWS_AS(
00216       oversized::Writer(
00217         std::make_unique<ringbuffer::Writer>(rr),
00218         sizeof(oversized::InitialFragmentHeader),
00219         total_max),
00220       std::logic_error);
00221     REQUIRE_NOTHROW(oversized::Writer(
00222       std::make_unique<ringbuffer::Writer>(rr),
00223       sizeof(oversized::InitialFragmentHeader) + 1,
00224       total_max));
00225 
00226     REQUIRE_NOTHROW(oversized::Writer(
00227       std::make_unique<ringbuffer::Writer>(rr), total_max - 1, total_max));
00228     REQUIRE_THROWS_AS(
00229       oversized::Writer(
00230         std::make_unique<ringbuffer::Writer>(rr), total_max, total_max),
00231       std::logic_error);
00232   }
00233 
00234   SUBCASE("Attempting write larger than max will throw")
00235   {
00236     REQUIRE_THROWS_AS(
00237       writer.write(
00238         ascending,
00239         serializer::ByteRange{whole_message_ascending.data(), total_max + 1}),
00240       std::logic_error);
00241   }
00242 
00243   messaging::BufferProcessor bp("oversized");
00244 
00245   auto read_single = [&]() {
00246     // When reading the padding at the end of the ringbuffer, the first call to
00247     // read will return 0 even though there's still a message at the start to be
00248     // read. To guarantee a read of a single message (and be sure it was the
00249     // only message), we want to read up-to-1-message 3 times. That will either
00250     // return {1, 0, 0} (most of the time), or {0, 1, 0} occasionally.
00251 
00252     auto first_read = bp.read_n(1, rr);
00253     auto second_read = bp.read_n(1, rr);
00254     auto third_read = bp.read_n(1, rr);
00255 
00256     REQUIRE(first_read <= 1);
00257 
00258     if (first_read == 1)
00259       REQUIRE(second_read == 0);
00260     else
00261       REQUIRE(second_read == 1);
00262 
00263     REQUIRE(third_read == 0);
00264   };
00265 
00266   size_t last_message_size = 0;
00267   size_t ascending_reads = 0;
00268   size_t descending_reads = 0;
00269 
00270   DISPATCHER_SET_MESSAGE_HANDLER(
00271     bp, ascending, [&](const uint8_t* data, size_t size) {
00272       REQUIRE(std::is_sorted(data, data + size, std::less_equal<uint8_t>()));
00273       last_message_size = size;
00274       ++ascending_reads;
00275     });
00276 
00277   DISPATCHER_SET_MESSAGE_HANDLER(
00278     bp, descending, [&](const uint8_t* data, size_t size) {
00279       REQUIRE(std::is_sorted(data, data + size, std::greater_equal<uint8_t>()));
00280       last_message_size = size;
00281       ++descending_reads;
00282     });
00283 
00284   DISPATCHER_SET_MESSAGE_HANDLER(
00285     bp, finish, [&](const uint8_t* data, size_t size) {
00286       bp.set_finished(true);
00287     });
00288 
00289   SUBCASE("Small writes succeed")
00290   {
00291     for (size_t msg_size = 0; msg_size <= fragment_max; ++msg_size)
00292     {
00293       const size_t ascending_prior = ascending_reads;
00294       REQUIRE(writer.try_write(
00295         ascending,
00296         serializer::ByteRange{whole_message_ascending.data(), msg_size}));
00297       read_single();
00298       REQUIRE(last_message_size == msg_size);
00299       REQUIRE(ascending_reads == ascending_prior + 1);
00300 
00301       const size_t descending_prior = descending_reads;
00302       REQUIRE(writer.try_write(
00303         descending,
00304         serializer::ByteRange{whole_message_descending.data(), msg_size}));
00305       read_single();
00306       REQUIRE(last_message_size == msg_size);
00307       REQUIRE(descending_reads == descending_prior + 1);
00308     }
00309   }
00310 
00311   SUBCASE("Large writes can succeed")
00312   {
00313     size_t ascending_writes = ascending_reads;
00314     size_t descending_writes = descending_reads;
00315     constexpr auto last_send_size = total_max - 1;
00316 
00317     // If the caller is not willing to wait, then the write can fail due to
00318     // insufficient space
00319     while (writer.try_write(
00320       ascending,
00321       serializer::ByteRange{whole_message_ascending.data(), fragment_max}))
00322     {
00323       ++ascending_writes;
00324     }
00325 
00326     // If a reader is making progress (in this case - reconstructing the larger
00327     // message from fragments), large writes which are willing to wait will
00328     // eventually succeed
00329     std::thread reader_thread([&]() {
00330       oversized::FragmentReconstructor fr(bp.get_dispatcher());
00331 
00332       bp.run(rr);
00333     });
00334 
00335     REQUIRE_NOTHROW(writer.write(
00336       ascending,
00337       serializer::ByteRange{whole_message_ascending.data(), total_max}));
00338     ++ascending_writes;
00339 
00340     REQUIRE_NOTHROW(writer.write(
00341       ascending,
00342       serializer::ByteRange{whole_message_ascending.data(), total_max}));
00343     ++ascending_writes;
00344 
00345     REQUIRE_NOTHROW(writer.write(
00346       descending,
00347       serializer::ByteRange{whole_message_descending.data(), total_max}));
00348     ++descending_writes;
00349 
00350     REQUIRE_NOTHROW(writer.write(
00351       ascending,
00352       serializer::ByteRange{whole_message_ascending.data(), total_max}));
00353     ++ascending_writes;
00354 
00355     REQUIRE_NOTHROW(writer.write(
00356       descending,
00357       serializer::ByteRange{whole_message_descending.data(), total_max}));
00358     ++descending_writes;
00359 
00360     REQUIRE_NOTHROW(writer.write(
00361       ascending,
00362       serializer::ByteRange{whole_message_ascending.data(), last_send_size}));
00363     ++ascending_writes;
00364 
00365     REQUIRE_NOTHROW(writer.write(finish));
00366 
00367     reader_thread.join();
00368 
00369     REQUIRE(last_message_size == last_send_size);
00370 
00371     REQUIRE(ascending_reads == ascending_writes);
00372     REQUIRE(descending_reads == descending_writes);
00373   }
00374 
00375   SUBCASE("Progress with low limits")
00376   {
00377     // Construct a worst-case Writer, which can only fit the minimal payload in
00378     // each message. It will still complete, eventually
00379     constexpr auto small_fragment_limit =
00380       sizeof(oversized::InitialFragmentHeader) + 1;
00381     constexpr auto large_message_size = buf_size;
00382     oversized::Writer writer(
00383       std::make_unique<ringbuffer::Writer>(rr),
00384       small_fragment_limit,
00385       large_message_size);
00386 
00387     std::vector<uint8_t> large_ascending(large_message_size);
00388     std::iota(large_ascending.begin(), large_ascending.end(), 0);
00389 
00390     std::thread reader_thread([&]() {
00391       oversized::FragmentReconstructor fr(bp.get_dispatcher());
00392 
00393       bp.run(rr);
00394     });
00395 
00396     const auto ascending_prior = ascending_reads;
00397 
00398     REQUIRE_NOTHROW(writer.write(
00399       ascending,
00400       serializer::ByteRange{large_ascending.data(), large_message_size}));
00401 
00402     REQUIRE_NOTHROW(writer.write(finish));
00403 
00404     reader_thread.join();
00405 
00406     REQUIRE(last_message_size == large_message_size);
00407     REQUIRE(ascending_reads == ascending_prior + 1);
00408   }
00409 }
00410 
00411 
00412 {
00413   INFO("Nested fragment messages are allowed, and parsed correctly");
00414   std::vector<uint8_t> payload;
00415   payload.push_back(unfragmented_magic_value);
00416 
00417   ringbuffer::Message type = unfragmented;
00418 
00419   // For some number of nested layers
00420   for (size_t i = 0; i < 20; ++i)
00421   {
00422     std::vector<uint8_t> wrapper;
00423 
00424     // Create a new fragment message containing the previous payload...
00425     {
00426       // [ID, type, total_size, payload...]
00427       wrapper.resize(
00428         sizeof(size_t) + sizeof(ringbuffer::Message) + sizeof(size_t) +
00429         payload.size());
00430 
00431       auto data = wrapper.data();
00432       auto size = wrapper.size();
00433       serialized::write(data, size, i);
00434       serialized::write(data, size, type);
00435       serialized::write(data, size, payload.size());
00436       serialized::write(data, size, payload.data(), payload.size());
00437 
00438       REQUIRE(size == 0);
00439     }
00440 
00441     // ...and set this to be the payload for the next iteration
00442     payload = wrapper;
00443     type = oversized::OversizedMessage::fragment;
00444   }
00445 
00446   // Dispatch the resulting coccoon
00447   messaging::RingbufferDispatcher disp("Nesting");
00448 
00449   bool core_received = false;
00450   DISPATCHER_SET_MESSAGE_HANDLER(
00451     disp, unfragmented, [&](const uint8_t* data, size_t size) {
00452       core_received = true;
00453     });
00454 
00455   {
00456     oversized::FragmentReconstructor fr(disp);
00457     disp.dispatch(type, payload.data(), payload.size());
00458     REQUIRE(core_received);
00459   }
00460 }
00461 
00462 
00463 {
00464   using namespace ringbuffer;
00465 
00466   constexpr auto circuit_size = 1 << 8;
00467 
00468   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(circuit_size);
00469   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(circuit_size);
00470 
00471   ringbuffer::Circuit circuit(in_buffer->bd, out_buffer->bd);
00472 
00473   constexpr auto max_fragment_size = circuit_size / 5;
00474   constexpr auto max_total_size = circuit_size * 4;
00475   oversized::WriterConfig writer_config{max_fragment_size, max_total_size};
00476 
00477   // We want a basic writer...
00478   ringbuffer::WriterFactory basic_factory(circuit);
00479 
00480   // ...wrapped in a writer which will queue rather than blocking
00481   // indefinitely...
00482   ringbuffer::NonBlockingWriterFactory non_blocking_factory(basic_factory);
00483 
00484   // ...wrapped in a writer which will split large messages into fragments
00485   oversized::WriterFactory oversized_factory(
00486     non_blocking_factory, writer_config);
00487 
00488   auto writer = oversized_factory.create_writer_to_inside();
00489 
00490   // Build some large messages
00491   constexpr auto num_messages = 10;
00492   std::vector<std::vector<uint8_t>> messages;
00493   for (size_t i = 0; i < num_messages; ++i)
00494   {
00495     auto& message = messages.emplace_back(max_total_size);
00496     for (auto& n : message)
00497     {
00498       n = rand();
00499     }
00500   }
00501 
00502   // Write them all
00503   for (const auto& message : messages)
00504   {
00505     writer->write(random_contents, message);
00506   }
00507 
00508   decltype(messages) received;
00509   auto random_handler = [&](const uint8_t* data, size_t size) {
00510     received.emplace_back(data, data + size);
00511   };
00512 
00513   messaging::BufferProcessor processor_inside;
00514   DISPATCHER_SET_MESSAGE_HANDLER(
00515     processor_inside, random_contents, random_handler);
00516 
00517   oversized::FragmentReconstructor reconstructor(
00518     processor_inside.get_dispatcher());
00519 
00520   // Read them all, by flushing repeatedly
00521   while (true)
00522   {
00523     const bool done_flushing = non_blocking_factory.flush_all_inbound();
00524 
00525     size_t n_read =
00526       processor_inside.read_n(num_messages, circuit.read_from_outside());
00527 
00528     // Sometimes we flush yet have no more readable messages. Not sure why, but
00529     // the test works regardless.
00530     // REQUIRE(n_read > 0);
00531 
00532     if (received.size() == messages.size())
00533     {
00534       REQUIRE(done_flushing);
00535       REQUIRE(received == messages);
00536       break;
00537     }
00538   }
00539 }
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE DISPATCHER_SET_MESSAGE_HANDLER LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/test/oversized.cpp...
Preprocessing /data/git/CCF/src/ds/test/ring_buffer.cpp...
#include ../ring_buffer.h: already included! skipping...
#include ../serialized.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 12135 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00008 
00009 
00010 
00011 
00012 using namespace ringbuffer;
00013 
00014 enum : Message
00015 {
00016   empty_message = Const::msg_min,
00017   small_message,
00018   awkward_message,
00019   big_message,
00020 };
00021 
00022 static constexpr auto awkward_size = 5;
00023 static constexpr auto big_size = 512;
00024 
00025 std::vector<uint8_t> last_message_body;
00026 
00027 void handle_message(Message m, const uint8_t* data, size_t size)
00028 {
00029   size_t expected_size = 0;
00030   switch (m)
00031   {
00032     case empty_message:
00033     {
00034       expected_size = 0;
00035       break;
00036     }
00037     case small_message:
00038     {
00039       expected_size = 1;
00040       break;
00041     }
00042     case awkward_message:
00043     {
00044       expected_size = awkward_size;
00045       break;
00046     }
00047     case big_message:
00048     {
00049       expected_size = big_size;
00050       break;
00051     }
00052   }
00053 
00054   REQUIRE(expected_size == size);
00055   last_message_body.clear();
00056   last_message_body.insert(last_message_body.end(), data, data + size);
00057 }
00058 
00059 void nop_handler(ringbuffer::Message, const uint8_t*, size_t) {}
00060 
00061 
00062 {
00063   constexpr uint8_t size = 32;
00064   constexpr uint8_t full_count = 2;
00065 
00066   auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00067   Reader r(buffer->bd);
00068   Writer w(r);
00069 
00070   INFO("Single write-read");
00071   {
00072     const uint8_t n = 42;
00073     REQUIRE(w.try_write(small_message, n));
00074     REQUIRE(r.read(1, handle_message) == 1);
00075     REQUIRE(last_message_body[0] == n);
00076   }
00077 
00078   INFO("Even write-read loop");
00079   {
00080     for (uint8_t i = 0; i < 10 * full_count; ++i)
00081     {
00082       REQUIRE(w.try_write(small_message, i));
00083       REQUIRE(r.read(1, handle_message) == 1);
00084       REQUIRE(last_message_body[0] == i);
00085     }
00086   }
00087 
00088   INFO("Over-writing fails politely");
00089   {
00090     for (uint8_t i = 0; i < full_count; ++i)
00091     {
00092       REQUIRE(w.try_write(small_message, i));
00093     }
00094 
00095     for (uint8_t i = 0; i < 2 * full_count; ++i)
00096     {
00097       REQUIRE_FALSE(w.try_write(small_message, i));
00098     }
00099   }
00100 
00101   INFO("Over-reading fails politely");
00102   {
00103     for (uint8_t i = 0; i < full_count; ++i)
00104     {
00105       REQUIRE(r.read(1, handle_message) == 1);
00106     }
00107 
00108     for (uint8_t i = 0; i < 2 * full_count; ++i)
00109     {
00110       REQUIRE(r.read(1, handle_message) == 0);
00111     }
00112   }
00113 
00114   INFO("Writer throws exception");
00115   {
00116     REQUIRE_THROWS_AS(w.write(Const::msg_none), std::logic_error);
00117     REQUIRE_THROWS_AS(
00118       w.write(small_message, serializer::ByteRange{nullptr, 0xffffffff}),
00119       std::logic_error);
00120     REQUIRE_THROWS_AS(
00121       w.write(small_message, serializer::ByteRange{nullptr, size + 1}),
00122       std::logic_error);
00123   }
00124 }
00125 
00126 
00127 {
00128   constexpr size_t size = 1 << 8;
00129 
00130   auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00131   Reader r(buffer->bd);
00132   Writer w(r);
00133 
00134   const char v0 = 'h';
00135   const size_t v1 = 0xdeadbeef;
00136   const bool v2 = false;
00137   const float v3 = 3.14f;
00138   const std::vector<uint8_t> v4 = {0xab, 0xac, 0xad, 0xae, 0xaf};
00139 
00140   const size_t v5_limit = 3;
00141   const char v6 = 'x';
00142 
00143   // NB: byte-vector is dumped directly, not length-prefixed, so length must be
00144   // manually inserted where required
00145   w.write(
00146     Const::msg_min,
00147     v0,
00148     v1,
00149     v2,
00150     v3,
00151     v4.size(),
00152     v4,
00153     v5_limit,
00154     serializer::ByteRange{v4.data(), v5_limit},
00155     v6);
00156 
00157   r.read(1, [&](Message m, const uint8_t* data, size_t size) {
00158     REQUIRE(Const::msg_min == m);
00159 
00160     auto r0 = serialized::read<std::remove_const_t<decltype(v0)>>(data, size);
00161     REQUIRE(v0 == r0);
00162 
00163     auto r1 = serialized::read<std::remove_const_t<decltype(v1)>>(data, size);
00164     REQUIRE(v1 == r1);
00165 
00166     auto r2 = serialized::read<std::remove_const_t<decltype(v2)>>(data, size);
00167     REQUIRE(v2 == r2);
00168 
00169     auto r3 = serialized::read<std::remove_const_t<decltype(v3)>>(data, size);
00170     REQUIRE(v3 == r3);
00171 
00172     auto s4 =
00173       serialized::read<std::remove_const_t<decltype(v4.size())>>(data, size);
00174     REQUIRE(v4.size() == s4);
00175 
00176     for (size_t i = 0; i < s4; ++i)
00177     {
00178       auto r4i =
00179         serialized::read<std::remove_const_t<decltype(v4)>::value_type>(
00180           data, size);
00181       REQUIRE(v4[i] == r4i);
00182     }
00183 
00184     auto s5 =
00185       serialized::read<std::remove_const_t<decltype(v5_limit)>>(data, size);
00186     REQUIRE(v5_limit == s5);
00187 
00188     for (size_t i = 0; i < s5; ++i)
00189     {
00190       auto r5i =
00191         serialized::read<std::remove_const_t<decltype(v4)>::value_type>(
00192           data, size);
00193       REQUIRE(v4[i] == r5i);
00194     }
00195 
00196     auto r6 = serialized::read<std::remove_const_t<decltype(v6)>>(data, size);
00197     REQUIRE(v6 == r6);
00198 
00199     REQUIRE(size == 0);
00200   });
00201 }
00202 
00203 
00204 {
00205   // In an empty buffer, regardless of head position (previous writes), any
00206   // write up to the maximum size will succeed
00207 
00208   constexpr uint8_t buf_size = 32;
00209   constexpr auto max_res_size = Const::max_reservation_size(buf_size);
00210   constexpr auto max_msg_size = max_res_size - Const::header_size();
00211 
00212   {
00213     // Confirm this is actually the maximum msg size
00214     auto buffer = std::make_unique<ringbuffer::TestBuffer>(buf_size);
00215     Reader r(buffer->bd);
00216     Writer w(r);
00217 
00218     REQUIRE(w.prepare(small_message, max_msg_size, false).has_value());
00219     REQUIRE_THROWS_AS(
00220       w.prepare(small_message, max_msg_size + 1, false), std::logic_error);
00221   }
00222 
00223   // Use previous writes to set varied initial head positions
00224   std::vector<std::vector<size_t>> previous_writes = {
00225     {0},
00226     {1},
00227     {max_msg_size - 1},
00228     {max_msg_size},
00229     {1, 1},
00230     {1, max_msg_size},
00231     {max_msg_size, 1},
00232     {max_msg_size, max_msg_size},
00233     {1, 2, 3, 4, 5, 6, 7, 8}};
00234 
00235   // For each of these initial states...
00236   for (const auto& writes : previous_writes)
00237   {
00238     // For each allowed message size...
00239     for (size_t i = 0; i <= max_msg_size; ++i)
00240     {
00241       // Create a fresh buffer
00242       auto buffer = std::make_unique<ringbuffer::TestBuffer>(buf_size);
00243       Reader r(buffer->bd);
00244       Writer w(r);
00245 
00246       // Apply the initial state
00247       for (size_t write_size : writes)
00248       {
00249         auto p = w.prepare(empty_message, write_size, false);
00250         REQUIRE(p.has_value());
00251         w.finish(p.value());
00252         REQUIRE(r.read(-1, nop_handler) == 1);
00253       }
00254 
00255       // Confirm that we can prepare the desired message
00256       auto p = w.prepare(empty_message, i, false);
00257       REQUIRE(p.has_value());
00258       w.finish(p.value());
00259 
00260       REQUIRE(r.read(-1, nop_handler) == 1);
00261     }
00262   }
00263 }
00264 
00265 TEST_CASE(
00266   "Reading multiple messages from ringbuffer" *
00267   doctest::test_suite("ringbuffer"))
00268 {
00269   constexpr size_t size = 2 << 6;
00270 
00271   auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00272   Reader r(buffer->bd);
00273   Writer w(r);
00274 
00275   INFO("Can read less or more than was written");
00276   {
00277     REQUIRE_NOTHROW(w.write(empty_message));
00278     REQUIRE(r.read(0, handle_message) == 0);
00279     REQUIRE(r.read(2, handle_message) == 1);
00280   }
00281 
00282   for (size_t i = 0; i < 8; ++i)
00283   {
00284     REQUIRE_NOTHROW(w.write(empty_message));
00285   }
00286 
00287   INFO("Requesting multiple over-reads is safe");
00288   {
00289     REQUIRE(r.read(0, handle_message) == 0);
00290     REQUIRE(r.read(1, handle_message) == 1);
00291     REQUIRE(r.read(2, handle_message) == 2);
00292     REQUIRE(r.read(3, handle_message) == 3);
00293     REQUIRE(r.read(4, handle_message) == 2);
00294     REQUIRE(r.read(5, handle_message) == 0);
00295     REQUIRE(r.read(4, handle_message) == 0);
00296     REQUIRE(r.read(3, handle_message) == 0);
00297     REQUIRE(r.read(2, handle_message) == 0);
00298     REQUIRE(r.read(1, handle_message) == 0);
00299   }
00300 
00301   INFO("Reading over the ring edge requires multiple requests");
00302   {
00303     // Fill the buffer
00304     const uint8_t n = 42;
00305     size_t written = 0;
00306     while (w.try_write(small_message, n))
00307     {
00308       ++written;
00309     }
00310 
00311     const auto first_read = r.read(written, handle_message);
00312     CHECK(first_read < written);
00313 
00314     const auto second_read = r.read(written, handle_message);
00315     CHECK(second_read < written);
00316 
00317     REQUIRE(first_read + second_read == written);
00318   }
00319 }
00320 
00321 TEST_CASE(
00322   "Messages get a unique identifier" * doctest::test_suite("ringbuffer"))
00323 {
00324   constexpr size_t size = 2 << 6;
00325 
00326   auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00327   Reader r(buffer->bd);
00328   Writer w(r);
00329 
00330   std::set<size_t> ids;
00331 
00332   for (size_t msg_size = 0; msg_size < 8; ++msg_size)
00333   {
00334     for (size_t i = 0; i < 5 * size; ++i)
00335     {
00336       size_t id;
00337       auto p = w.prepare(small_message, msg_size, false, &id);
00338       REQUIRE(p.has_value());
00339       REQUIRE(ids.insert(id).second);
00340       w.finish(p.value());
00341       REQUIRE(r.read(-1, nop_handler) == 1);
00342     }
00343   }
00344 }
00345 
00346 
00347 {
00348   constexpr size_t size = 2 << 10;
00349 
00350   auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00351   Reader r(buffer->bd);
00352   Writer w(r);
00353 
00354   std::vector<uint8_t> empty;
00355   std::vector<uint8_t> small = {42};
00356 
00357   std::vector<uint8_t> awkward(awkward_size);
00358   for (size_t i = 0; i < awkward_size; ++i)
00359   {
00360     awkward[i] = (uint8_t)(i);
00361   }
00362 
00363   std::vector<uint8_t> big(big_size);
00364   for (size_t i = 0; i < big_size; ++i)
00365   {
00366     big[i] = (uint8_t)(i * i);
00367   }
00368 
00369   auto write_read_check = [&](const std::vector<Message>& ms) {
00370     for (auto mk : ms)
00371     {
00372       std::vector<uint8_t> data;
00373       switch (mk)
00374       {
00375         case empty_message:
00376         {
00377           data = empty;
00378           break;
00379         }
00380         case small_message:
00381         {
00382           data = small;
00383           break;
00384         }
00385         case awkward_message:
00386         {
00387           data = awkward;
00388           break;
00389         }
00390         case big_message:
00391         {
00392           data = big;
00393           break;
00394         }
00395       }
00396 
00397       REQUIRE(w.try_write(mk, data));
00398 
00399       // If we reach the end of the buffer, we'll read 0 messages. Allow a
00400       // single retry
00401       const auto read_count = r.read(1, handle_message);
00402       if (read_count == 0)
00403       {
00404         REQUIRE(r.read(1, handle_message) == 1);
00405       }
00406       else
00407       {
00408         REQUIRE(read_count == 1);
00409       }
00410       REQUIRE(last_message_body == data);
00411     }
00412   };
00413 
00414   INFO("Empty messages");
00415   {
00416     write_read_check(
00417       {empty_message, empty_message, empty_message, empty_message});
00418   }
00419 
00420   INFO("Small messages");
00421   {
00422     write_read_check(
00423       {small_message, small_message, small_message, small_message});
00424   }
00425 
00426   INFO("Awkward messages");
00427   {
00428     write_read_check(
00429       {awkward_message, awkward_message, awkward_message, awkward_message});
00430   }
00431 
00432   INFO("Big messages");
00433   {
00434     write_read_check({big_message, big_message, big_message, big_message});
00435   }
00436 
00437   INFO("Mixed messages");
00438   {
00439     write_read_check(
00440       {empty_message,   small_message,   awkward_message, big_message,
00441 
00442        empty_message,   awkward_message, small_message,   big_message,
00443 
00444        big_message,     big_message,     small_message,   small_message,
00445        empty_message,   empty_message,   awkward_message, awkward_message,
00446 
00447        awkward_message, big_message,     empty_message,   empty_message,
00448        big_message,     awkward_message, small_message,   empty_message,
00449        big_message,     awkward_message, small_message,   small_message,
00450        small_message,   big_message,     big_message,     awkward_message});
00451   }
00452 }
00453 
00454 
00455 {
00456   constexpr size_t size = 32u;
00457   auto pairify = std::make_pair<size_t, size_t>;
00458 
00459   for (auto [max_n, thread_count] : {
00460          pairify(2, 2), // Slight contention
00461          pairify(size * 3, 4), // Large workloads
00462          pairify(4, size * 3) // Many workers
00463        })
00464   {
00465     auto buffer = std::make_unique<ringbuffer::TestBuffer>(size);
00466     Reader r(buffer->bd);
00467     std::vector<std::thread> writer_threads;
00468 
00469     size_t reads = 0;
00470     std::atomic<size_t> writes = 0;
00471     size_t target = thread_count * max_n;
00472 
00473     // Create several threads writing more data than can fit at once
00474     for (size_t i = 0; i < thread_count; ++i)
00475     {
00476       writer_threads.push_back(std::thread([&r, &writes, i, n = max_n]() {
00477         Writer w(r);
00478 
00479         for (uint8_t j = 0u; j < n; ++j)
00480         {
00481           ++writes;
00482           w.write(small_message, j);
00483         }
00484       }));
00485     }
00486 
00487     while (reads < target)
00488     {
00489       REQUIRE(reads <= writes.load());
00490 
00491       auto read_count = r.read(1, handle_message);
00492       if (read_count == 1)
00493       {
00494         REQUIRE(last_message_body.size() == 1);
00495         REQUIRE(last_message_body[0] < max_n);
00496         ++reads;
00497       }
00498       CCF_PAUSE();
00499     }
00500 
00501     REQUIRE(reads == target);
00502     REQUIRE(writes.load() == target);
00503 
00504     for (auto& thr : writer_threads)
00505     {
00506       thr.join();
00507     }
00508   }
00509 }
00510 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD CCF_PAUSE 
---------
Parsing file /data/git/CCF/src/ds/test/ring_buffer.cpp...
Preprocessing /data/git/CCF/src/ds/test/ring_buffer_bench.cpp...
#include ../ring_buffer.h: already included! skipping...
#include picobench/picobench.hpp: not found! skipping...
#include thread: not found! skipping...
Preprocessor output (size: 4871 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00004 #define PICOBENCH_DONT_BIND_TO_ONE_CORE
00005 
00006 
00007 
00008 
00009 
00010 using namespace ringbuffer;
00011 
00012 constexpr Message msg_type = Const::msg_min + 1;
00013 
00014 using ReadHandler = void (*)(ringbuffer::Message, const uint8_t*, size_t);
00015 
00016 void nop_handler(ringbuffer::Message, const uint8_t*, size_t) {}
00017 
00018 template <size_t N>
00019 void spin_pause_handler(ringbuffer::Message m, const uint8_t*, size_t)
00020 {
00021   size_t i = 0;
00022   while (i++ < N)
00023     CCF_PAUSE();
00024 }
00025 
00026 template <size_t N>
00027 void sleep_handler(ringbuffer::Message m, const uint8_t*, size_t)
00028 {
00029   auto t = std::chrono::duration<size_t, std::nano>(N);
00030   std::this_thread::sleep_for(t);
00031 }
00032 
00033 template <ReadHandler H>
00034 static void write_impl(
00035   picobench::state& s,
00036   size_t buf_size,
00037   size_t message_size,
00038   size_t writer_count,
00039   size_t total_messages)
00040 {
00041   auto buffer = std::make_unique<ringbuffer::TestBuffer>(buf_size);
00042   Reader r(buffer->bd);
00043 
00044   std::vector<std::thread> writer_threads;
00045 
00046   size_t reads = 0;
00047 
00048   // Final writer(s) may get less
00049   const size_t messages_per_writer = total_messages / writer_count;
00050   if (messages_per_writer == 0)
00051     throw std::logic_error("Too few messages!");
00052 
00053   s.start_timer();
00054 
00055   // Create several threads writing more data than can fit at once
00056   for (size_t m = 0; m < total_messages; m += messages_per_writer)
00057   {
00058     const auto msg_count = std::min(total_messages - m, messages_per_writer);
00059     writer_threads.emplace_back([message_size, msg_count, &r]() {
00060       Writer w(r);
00061 
00062       std::vector<uint8_t> raw(msg_count * message_size);
00063       std::iota(raw.begin(), raw.end(), 0);
00064 
00065       auto start = raw.data();
00066       for (size_t m = 0u; m < msg_count; ++m)
00067       {
00068         w.write(msg_type, serializer::ByteRange{start, message_size});
00069         start += message_size;
00070       }
00071     });
00072   }
00073 
00074   while (reads < total_messages)
00075   {
00076     auto read_count = r.read(-1, H);
00077     reads += read_count;
00078     CCF_PAUSE();
00079   }
00080 
00081   s.stop_timer();
00082 
00083   if (reads != total_messages)
00084     throw std::logic_error("Read more messages than expected");
00085 
00086   for (auto& thr : writer_threads)
00087   {
00088     thr.join();
00089   }
00090 }
00091 
00092 //
00093 // Defaults
00094 //
00095 constexpr size_t DefaultBufSize = 64;
00096 constexpr size_t DefaultMessageSize = 16;
00097 constexpr size_t DefaultWriterCount = 4;
00098 
00099 // If you want to use this many messages, keep samples low
00100 const std::vector<int> msg_counts = {1000, 4000, 16000};
00101 
00102 //
00103 // Use s.iterations() as each test arg, template the remainder
00104 //
00105 template <
00106   size_t BufSize = DefaultBufSize,
00107   size_t MessageSize = DefaultMessageSize,
00108   size_t WriterCount = DefaultWriterCount,
00109   ReadHandler H = nop_handler>
00110 static void specialize(picobench::state& s)
00111 {
00112   const auto msg_count = s.iterations();
00113 
00114   write_impl<H>(s, BufSize, MessageSize, WriterCount, msg_count);
00115 }
00116 
00117 //
00118 // Benchmark suites
00119 //
00120 #define FIXED_PICO(NAME) 
00121 
00122 PICOBENCH_SUITE("default");
00123 auto base = specialize<>;
00124 FIXED_PICO(base);
00125 
00126 PICOBENCH_SUITE("increasing buffer size");
00127 auto buf_64b = specialize<64>;
00128 FIXED_PICO(buf_64b);
00129 auto buf_256b = specialize<256>;
00130 FIXED_PICO(buf_256b);
00131 auto buf_1k = specialize<1024>;
00132 FIXED_PICO(buf_1k);
00133 auto buf_4k = specialize<4096>;
00134 FIXED_PICO(buf_4k);
00135 auto buf_16k = specialize<16384>;
00136 FIXED_PICO(buf_16k);
00137 
00138 PICOBENCH_SUITE("increasing message size (4k buffer)");
00139 auto size_empty = specialize<4096, 0>;
00140 FIXED_PICO(size_empty);
00141 auto size_1b = specialize<4096, 1>;
00142 FIXED_PICO(size_1b);
00143 auto size_4b = specialize<4096, 4>;
00144 FIXED_PICO(size_4b);
00145 auto size_16b = specialize<4096, 16>;
00146 FIXED_PICO(size_16b);
00147 auto size_64b = specialize<4096, 64>;
00148 FIXED_PICO(size_64b);
00149 auto size_256b = specialize<4096, 256>;
00150 FIXED_PICO(size_256b);
00151 auto size_1k = specialize<4096, 1024>;
00152 FIXED_PICO(size_1k);
00153 
00154 PICOBENCH_SUITE("increasing writers (4k buffer, 64b per-message)");
00155 auto writers_1 = specialize<4096, 64, 1>;
00156 FIXED_PICO(writers_1);
00157 auto writers_2 = specialize<4096, 64, 2>;
00158 FIXED_PICO(writers_2);
00159 auto writers_4 = specialize<4096, 64, 4>;
00160 FIXED_PICO(writers_4);
00161 auto writers_8 = specialize<4096, 64, 8>;
00162 FIXED_PICO(writers_8);
00163 auto writers_16 = specialize<4096, 64, 16>;
00164 FIXED_PICO(writers_16);
00165 auto writers_32 = specialize<4096, 64, 32>;
00166 FIXED_PICO(writers_32);
00167 
00168 PICOBENCH_SUITE("high contention (32b buffer, 4b per-message)");
00169 auto contention_4 = specialize<32, 4, 4>;
00170 FIXED_PICO(contention_4);
00171 auto contention_8 = specialize<32, 4, 8>;
00172 FIXED_PICO(contention_8);
00173 auto contention_16 = specialize<32, 4, 16>;
00174 FIXED_PICO(contention_16);
00175 auto contention_32 = specialize<32, 4, 32>;
00176 FIXED_PICO(contention_32);
00177 
00178 PICOBENCH_SUITE("spinning reader (32b buffer, 1b per-message, 4 writers)");
00179 auto spin_100 = specialize<32, 1, 4, spin_pause_handler<100>>;
00180 FIXED_PICO(spin_100);
00181 auto spin_200 = specialize<32, 1, 4, spin_pause_handler<200>>;
00182 FIXED_PICO(spin_200);
00183 auto spin_400 = specialize<32, 1, 4, spin_pause_handler<400>>;
00184 FIXED_PICO(spin_400);
00185 
---------
Macros accessible in this file:
---------
PICOBENCH_DONT_BIND_TO_ONE_CORE FIXED_PICO RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE PICOBENCH_IMPLEMENT_WITH_MAIN DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD CCF_PAUSE 
---------
Parsing file /data/git/CCF/src/ds/test/ring_buffer_bench.cpp...
Preprocessing /data/git/CCF/src/ds/test/serializer.cpp...
#include ../serializer.h: already included! skipping...
#include ../ring_buffer.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 10966 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 using namespace ringbuffer;
00010 using namespace serializer;
00011 
00012 constexpr Message any_message = 42;
00013 
00014 const size_t n = 0xbeef;
00015 const char c = '!';
00016 const auto s = std::string("Some large message payload");
00017 
00018 // No way to actually check this, but useful to show examples of disallowed code
00019 // inline with working tests
00020 #define REQUIRE_COMPILE_ERROR(...)
00021 
00022 //
00023 // Utils
00024 //
00025 // A simple single-message Writer that we don't need to read from
00026 struct VectorWriter : public AbstractWriter
00027 {
00028   ringbuffer::Message message;
00029   std::vector<uint8_t> payload;
00030   bool done;
00031 
00032   virtual WriteMarker prepare(
00033     ringbuffer::Message m,
00034     size_t total_size,
00035     bool wait = true,
00036     size_t* identifier = nullptr) override
00037   {
00038     payload.resize(total_size);
00039     message = m;
00040     done = false;
00041     // WriteMarker is index into vector, start at the beginning
00042     return {0};
00043   }
00044 
00045   virtual void finish(const WriteMarker& marker) override
00046   {
00047     REQUIRE(marker.has_value());
00048     REQUIRE(marker.value() == 0);
00049     REQUIRE(!done);
00050     done = true;
00051   }
00052 
00053   virtual WriteMarker write_bytes(
00054     const WriteMarker& marker, const uint8_t* bytes, size_t size) override
00055   {
00056     REQUIRE(marker.has_value());
00057     auto index = marker.value();
00058     REQUIRE(index + size <= payload.size());
00059     ::memcpy(payload.data() + index, bytes, size);
00060     return {index + size};
00061   }
00062 
00063   template <typename FnCheckPayload>
00064   void require_done(ringbuffer::Message m, FnCheckPayload f)
00065   {
00066     REQUIRE(done);
00067     REQUIRE(message == m);
00068     REQUIRE(f(payload));
00069 
00070     // Clear for next iteration
00071     done = false;
00072     message = Const::msg_none;
00073     payload.clear();
00074   }
00075 };
00076 
00077 auto is_empty = [](const std::vector<uint8_t>& v) { return v.empty(); };
00078 auto is_not_empty = [](const std::vector<uint8_t>& v) { return !v.empty(); };
00079 
00080 // A section-serializer that converts all arguments into strings
00081 struct StringifiedSection : public AbstractSerializedSection
00082 {
00083   const std::string s;
00084   StringifiedSection(const std::string& s_) : s(s_) {}
00085   template <typename T>
00086   StringifiedSection(const T& t_) : s(std::to_string(t_))
00087   {}
00088 
00089   virtual const uint8_t* data() const override
00090   {
00091     return reinterpret_cast<const uint8_t*>(s.data());
00092   }
00093 
00094   virtual size_t size() const override
00095   {
00096     return s.size();
00097   }
00098 };
00099 
00100 struct StringifySerializer : private EmptySerializer
00101 {
00102   // Can also serialize empty messages
00103   using EmptySerializer::serialize;
00104 
00105   template <typename T, typename... Ts>
00106   static auto serialize(const T& t, const Ts&... ts)
00107   {
00108     return std::tuple_cat(
00109       std::make_tuple(std::make_shared<StringifiedSection>(t)),
00110       serialize(ts...));
00111   }
00112 };
00113 
00114 template <typename Serializer, typename... Ts>
00115 void require_minimum_serialized_arity(Ts&&... ts)
00116 {
00117   // Any serializer should produce at least as many sections as arguments (some
00118   // arguments may produce multiple sections)
00119   static_assert(
00120     std::tuple_size_v<decltype(Serializer::serialize(ts...))> >= sizeof...(ts));
00121   REQUIRE_NOTHROW(
00122     auto sections = Serializer::serialize(std::forward<Ts>(ts)...));
00123 }
00124 
00125 template <typename Serializer, typename... Ts>
00126 void require_roundtrip(Ts&&... ts)
00127 {
00128   const Message fresh_message = rand();
00129   VectorWriter w;
00130 
00131   w.write_with<Serializer>(fresh_message, std::forward<Ts>(ts)...);
00132   REQUIRE(w.done);
00133   REQUIRE(w.message == fresh_message);
00134 
00135   auto result =
00136     Serializer::template deserialize<Ts...>(w.payload.data(), w.payload.size());
00137 
00138   static_assert(std::tuple_size_v<decltype(result)> == sizeof...(Ts));
00139 
00140   REQUIRE(result == std::make_tuple(ts...));
00141 }
00142 
00143 
00144 {
00145   REQUIRE(std::make_tuple() == EmptySerializer::serialize());
00146   REQUIRE_COMPILE_ERROR(EmptySerializer::serialize(5));
00147 
00148   require_minimum_serialized_arity<CommonSerializer>(5);
00149   require_minimum_serialized_arity<CommonSerializer>(5, 6);
00150   require_minimum_serialized_arity<CommonSerializer>(5, 6, 7);
00151   require_minimum_serialized_arity<CommonSerializer>(
00152     5, (char)5, '5', std::string("5"));
00153 }
00154 
00155 
00156 {
00157   const std::vector<uint8_t> buffer = {
00158     'H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd'};
00159 
00160   const auto data = buffer.data();
00161   const auto size = buffer.size();
00162 
00163   {
00164     REQUIRE_NOTHROW(EmptySerializer::deserialize(data, 0));
00165     REQUIRE_THROWS(EmptySerializer::deserialize(data, 1));
00166     REQUIRE_COMPILE_ERROR(EmptySerializer::deserialize<int>(data, 1));
00167   }
00168 
00169   {
00170     auto deser = CommonSerializer::deserialize<uint8_t>(data, size);
00171     REQUIRE(std::get<0>(deser) == buffer[0]);
00172   }
00173 
00174   {
00175     auto deser =
00176       CommonSerializer::deserialize<uint8_t, uint8_t, uint8_t>(data, size);
00177     REQUIRE(std::get<0>(deser) == buffer[0]);
00178     REQUIRE(std::get<1>(deser) == buffer[1]);
00179     REQUIRE(std::get<2>(deser) == buffer[2]);
00180   }
00181 
00182   {
00183     auto deser = CommonSerializer::deserialize<uint16_t>(data, size);
00184     REQUIRE(std::get<0>(deser) == (buffer[0] | (size_t)buffer[1] << 8));
00185   }
00186 
00187   {
00188     auto deser =
00189       CommonSerializer::deserialize<uint16_t, uint8_t, uint16_t>(data, size);
00190     REQUIRE(std::get<0>(deser) == (buffer[0] | (size_t)buffer[1] << 8));
00191     REQUIRE(std::get<1>(deser) == buffer[2]);
00192     REQUIRE(std::get<2>(deser) == (buffer[3] | (size_t)buffer[4] << 8));
00193   }
00194 
00195   {
00196     auto deser =
00197       CommonSerializer::deserialize<std::vector<uint8_t>>(data, size);
00198     REQUIRE(std::get<0>(deser) == buffer);
00199   }
00200 
00201   SUBCASE("CommonSerializer")
00202   {
00203     VectorWriter w;
00204 
00205     // As string
00206     w.write_with<CommonSerializer>(any_message, buffer.size(), buffer);
00207     auto deser = CommonSerializer::deserialize<std::string>(
00208       w.payload.data(), w.payload.size());
00209     REQUIRE(strcmp(std::get<0>(deser).data(), "Hello World") == 0);
00210 
00211     // As ByteRange
00212     ByteRange br{buffer.data(), buffer.size()};
00213     w.write_with<CommonSerializer>(any_message, br);
00214     auto deser2 = CommonSerializer::deserialize<ByteRange>(
00215       w.payload.data(), w.payload.size());
00216     const ByteRange& res = std::get<0>(deser2);
00217     REQUIRE(res.size == buffer.size());
00218     REQUIRE(memcmp(res.data, buffer.data(), buffer.size()) == 0);
00219   }
00220 
00221   SUBCASE("PreciseSerializer")
00222   {
00223     using PS = PreciseSerializer<uint8_t, uint8_t, uint16_t>;
00224 
00225     REQUIRE_COMPILE_ERROR(PS::deserialize<uint8_t>(data, size));
00226     REQUIRE_COMPILE_ERROR(
00227       PS::deserialize<uint8_t, uint8_t, uint8_t>(data, size));
00228 
00229     {
00230       auto d = data;
00231       auto s = size;
00232 
00233       auto deser = PS::deserialize(data, size);
00234       static_assert(std::tuple_size_v<decltype(deser)> == 3);
00235 
00236       REQUIRE(std::get<0>(deser) == buffer[0]);
00237       REQUIRE(std::get<1>(deser) == buffer[1]);
00238       REQUIRE(std::get<2>(deser) == (buffer[2] | (size_t)buffer[3] << 8));
00239 
00240       auto deser2 = PS::deserialize<uint8_t, uint8_t, uint16_t>(d, s);
00241       REQUIRE(deser == deser2);
00242     }
00243   }
00244 }
00245 
00246 
00247 {
00248   VectorWriter w;
00249 
00250   // Curried function to create a functor which converts a byte-vector to
00251   // string, and does string comparison with the target
00252   auto is_string = [](const std::string& s) {
00253     return [&s](const std::vector<uint8_t>& vec) {
00254       auto actual =
00255         std::string(reinterpret_cast<const char*>(vec.data()), vec.size());
00256       return actual == s;
00257     };
00258   };
00259 
00260   w.write_with<StringifySerializer>(any_message);
00261   w.require_done(any_message, is_empty);
00262 
00263   w.write_with<StringifySerializer>(any_message, n);
00264   w.require_done(any_message, is_string(std::to_string(n)));
00265 
00266   w.write_with<StringifySerializer>(any_message, c);
00267   w.require_done(any_message, is_string(std::to_string(c)));
00268 
00269   w.write_with<StringifySerializer>(any_message, n, c, n, s);
00270   w.require_done(
00271     any_message,
00272     is_string(std::to_string(n) + std::to_string(c) + std::to_string(n) + s));
00273 }
00274 
00275 
00276 {
00277   VectorWriter w;
00278 
00279   SUBCASE("EmptySerializer")
00280   {
00281     require_roundtrip<EmptySerializer>();
00282 
00283     REQUIRE_COMPILE_ERROR(require_roundtrip<EmptySerializer>(n));
00284     REQUIRE_COMPILE_ERROR(require_roundtrip<EmptySerializer>(c));
00285   }
00286 
00287   SUBCASE("CommonSerializer")
00288   {
00289     require_roundtrip<CommonSerializer>();
00290 
00291     require_roundtrip<CommonSerializer>(n);
00292     require_roundtrip<CommonSerializer>(c);
00293     require_roundtrip<CommonSerializer>(s);
00294 
00295     require_roundtrip<CommonSerializer>(n, c);
00296     require_roundtrip<CommonSerializer>(n, s, n, s);
00297     require_roundtrip<CommonSerializer>(s, c, n, n + 1, s);
00298   }
00299 
00300   SUBCASE("PreciseSerializer")
00301   {
00302     using NCS_Serializer =
00303       PreciseSerializer<decltype(n), decltype(c), decltype(s)>;
00304 
00305     REQUIRE_COMPILE_ERROR(require_roundtrip<NCS_Serializer>());
00306     REQUIRE_COMPILE_ERROR(require_roundtrip<NCS_Serializer>(n, c));
00307     REQUIRE_COMPILE_ERROR(require_roundtrip<NCS_Serializer>(n, c, n));
00308     require_roundtrip<NCS_Serializer>(n, c, s);
00309 
00310     using NNSN_Serializer =
00311       PreciseSerializer<decltype(n), decltype(n), decltype(s), decltype(n)>;
00312 
00313     require_roundtrip<NNSN_Serializer>(n, n, s, n);
00314     require_roundtrip<NNSN_Serializer>(n, n + 1, s, n + 5);
00315   }
00316 
00317   SUBCASE("ByteRange to vector")
00318   {
00319     INFO(
00320       "A serializer which expects a byte vector can take a ByteRange in to "
00321       "serialize, but will always deserialize to a copied byte vector");
00322     using TV = std::vector<uint8_t>;
00323     using TS = PreciseSerializer<TV>;
00324 
00325     constexpr uint8_t size = 42;
00326     uint8_t raw[size];
00327     for (uint8_t i = 0; i < size; ++i)
00328     {
00329       raw[i] = i;
00330     }
00331 
00332     const ByteRange br{raw, size};
00333 
00334     VectorWriter w;
00335 
00336     w.write_with<TS>(any_message, br);
00337 
00338     auto [vec] = TS::deserialize(w.payload.data(), w.payload.size());
00339 
00340     static_assert(std::is_same_v<decltype(vec), TV>);
00341 
00342     REQUIRE(vec.size() == size);
00343 
00344     for (auto i = 0; i < size; ++i)
00345     {
00346       REQUIRE(vec[i] == raw[i]);
00347     }
00348   }
00349 
00350   SUBCASE("TupleSerializer")
00351   {
00352     {
00353       using T1 = std::tuple<decltype(n), decltype(c), decltype(s)>;
00354       using T1_Serializer = TupleSerializer<T1>;
00355 
00356       // Args don't need to be tuple-packed
00357       REQUIRE_COMPILE_ERROR(require_roundtrip<T1_Serializer>());
00358       REQUIRE_COMPILE_ERROR(require_roundtrip<T1_Serializer>(n, c, n));
00359       require_roundtrip<T1_Serializer>(n, c, s);
00360 
00361       // Variations in ref-ness and const-ness are accepted
00362       require_roundtrip<T1_Serializer>(
00363         std::add_const_t<decltype(n)>(n),
00364         std::add_const_t<decltype(c)>(c),
00365         std::remove_const_t<decltype(s)>(s));
00366 
00367       require_roundtrip<T1_Serializer>(
00368         std::add_lvalue_reference_t<std::remove_const_t<decltype(n)>>(n),
00369         std::remove_reference_t<std::add_const_t<decltype(c)>>(c),
00370         std::add_rvalue_reference_t<std::add_const_t<decltype(s)>>(s));
00371 
00372       require_roundtrip<T1_Serializer>(n + 1, '.', std::string("Some string"));
00373     }
00374 
00375     {
00376       // Types don't need to be unique
00377       using T2 = std::tuple<decltype(n), decltype(n), decltype(n)>;
00378       using T2_Serializer = TupleSerializer<T2>;
00379 
00380       REQUIRE_COMPILE_ERROR(require_roundtrip<T2_Serializer>(n));
00381       REQUIRE_COMPILE_ERROR(require_roundtrip<T2_Serializer>(n, n));
00382       require_roundtrip<T2_Serializer>(n, n, n);
00383       REQUIRE_COMPILE_ERROR(require_roundtrip<T2_Serializer>(n, n, n, n));
00384     }
00385   }
00386 }
00387 
---------
Macros accessible in this file:
---------
RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD REQUIRE_COMPILE_ERROR CCF_PAUSE 
---------
Parsing file /data/git/CCF/src/ds/test/serializer.cpp...
Preprocessing /data/git/CCF/src/ds/test/siphash_known_hashes.h...
Preprocessor output (size: 32681 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 const uint8_t siphash_2_4_vectors[64][8] = {{
00006                                               0x31,
00007                                               0x0e,
00008                                               0x0e,
00009                                               0xdd,
00010                                               0x47,
00011                                               0xdb,
00012                                               0x6f,
00013                                               0x72,
00014                                             },
00015                                             {
00016                                               0xfd,
00017                                               0x67,
00018                                               0xdc,
00019                                               0x93,
00020                                               0xc5,
00021                                               0x39,
00022                                               0xf8,
00023                                               0x74,
00024                                             },
00025                                             {
00026                                               0x5a,
00027                                               0x4f,
00028                                               0xa9,
00029                                               0xd9,
00030                                               0x09,
00031                                               0x80,
00032                                               0x6c,
00033                                               0x0d,
00034                                             },
00035                                             {
00036                                               0x2d,
00037                                               0x7e,
00038                                               0xfb,
00039                                               0xd7,
00040                                               0x96,
00041                                               0x66,
00042                                               0x67,
00043                                               0x85,
00044                                             },
00045                                             {
00046                                               0xb7,
00047                                               0x87,
00048                                               0x71,
00049                                               0x27,
00050                                               0xe0,
00051                                               0x94,
00052                                               0x27,
00053                                               0xcf,
00054                                             },
00055                                             {
00056                                               0x8d,
00057                                               0xa6,
00058                                               0x99,
00059                                               0xcd,
00060                                               0x64,
00061                                               0x55,
00062                                               0x76,
00063                                               0x18,
00064                                             },
00065                                             {
00066                                               0xce,
00067                                               0xe3,
00068                                               0xfe,
00069                                               0x58,
00070                                               0x6e,
00071                                               0x46,
00072                                               0xc9,
00073                                               0xcb,
00074                                             },
00075                                             {
00076                                               0x37,
00077                                               0xd1,
00078                                               0x01,
00079                                               0x8b,
00080                                               0xf5,
00081                                               0x00,
00082                                               0x02,
00083                                               0xab,
00084                                             },
00085                                             {
00086                                               0x62,
00087                                               0x24,
00088                                               0x93,
00089                                               0x9a,
00090                                               0x79,
00091                                               0xf5,
00092                                               0xf5,
00093                                               0x93,
00094                                             },
00095                                             {
00096                                               0xb0,
00097                                               0xe4,
00098                                               0xa9,
00099                                               0x0b,
00100                                               0xdf,
00101                                               0x82,
00102                                               0x00,
00103                                               0x9e,
00104                                             },
00105                                             {
00106                                               0xf3,
00107                                               0xb9,
00108                                               0xdd,
00109                                               0x94,
00110                                               0xc5,
00111                                               0xbb,
00112                                               0x5d,
00113                                               0x7a,
00114                                             },
00115                                             {
00116                                               0xa7,
00117                                               0xad,
00118                                               0x6b,
00119                                               0x22,
00120                                               0x46,
00121                                               0x2f,
00122                                               0xb3,
00123                                               0xf4,
00124                                             },
00125                                             {
00126                                               0xfb,
00127                                               0xe5,
00128                                               0x0e,
00129                                               0x86,
00130                                               0xbc,
00131                                               0x8f,
00132                                               0x1e,
00133                                               0x75,
00134                                             },
00135                                             {
00136                                               0x90,
00137                                               0x3d,
00138                                               0x84,
00139                                               0xc0,
00140                                               0x27,
00141                                               0x56,
00142                                               0xea,
00143                                               0x14,
00144                                             },
00145                                             {
00146                                               0xee,
00147                                               0xf2,
00148                                               0x7a,
00149                                               0x8e,
00150                                               0x90,
00151                                               0xca,
00152                                               0x23,
00153                                               0xf7,
00154                                             },
00155                                             {
00156                                               0xe5,
00157                                               0x45,
00158                                               0xbe,
00159                                               0x49,
00160                                               0x61,
00161                                               0xca,
00162                                               0x29,
00163                                               0xa1,
00164                                             },
00165                                             {
00166                                               0xdb,
00167                                               0x9b,
00168                                               0xc2,
00169                                               0x57,
00170                                               0x7f,
00171                                               0xcc,
00172                                               0x2a,
00173                                               0x3f,
00174                                             },
00175                                             {
00176                                               0x94,
00177                                               0x47,
00178                                               0xbe,
00179                                               0x2c,
00180                                               0xf5,
00181                                               0xe9,
00182                                               0x9a,
00183                                               0x69,
00184                                             },
00185                                             {
00186                                               0x9c,
00187                                               0xd3,
00188                                               0x8d,
00189                                               0x96,
00190                                               0xf0,
00191                                               0xb3,
00192                                               0xc1,
00193                                               0x4b,
00194                                             },
00195                                             {
00196                                               0xbd,
00197                                               0x61,
00198                                               0x79,
00199                                               0xa7,
00200                                               0x1d,
00201                                               0xc9,
00202                                               0x6d,
00203                                               0xbb,
00204                                             },
00205                                             {
00206                                               0x98,
00207                                               0xee,
00208                                               0xa2,
00209                                               0x1a,
00210                                               0xf2,
00211                                               0x5c,
00212                                               0xd6,
00213                                               0xbe,
00214                                             },
00215                                             {
00216                                               0xc7,
00217                                               0x67,
00218                                               0x3b,
00219                                               0x2e,
00220                                               0xb0,
00221                                               0xcb,
00222                                               0xf2,
00223                                               0xd0,
00224                                             },
00225                                             {
00226                                               0x88,
00227                                               0x3e,
00228                                               0xa3,
00229                                               0xe3,
00230                                               0x95,
00231                                               0x67,
00232                                               0x53,
00233                                               0x93,
00234                                             },
00235                                             {
00236                                               0xc8,
00237                                               0xce,
00238                                               0x5c,
00239                                               0xcd,
00240                                               0x8c,
00241                                               0x03,
00242                                               0x0c,
00243                                               0xa8,
00244                                             },
00245                                             {
00246                                               0x94,
00247                                               0xaf,
00248                                               0x49,
00249                                               0xf6,
00250                                               0xc6,
00251                                               0x50,
00252                                               0xad,
00253                                               0xb8,
00254                                             },
00255                                             {
00256                                               0xea,
00257                                               0xb8,
00258                                               0x85,
00259                                               0x8a,
00260                                               0xde,
00261                                               0x92,
00262                                               0xe1,
00263                                               0xbc,
00264                                             },
00265                                             {
00266                                               0xf3,
00267                                               0x15,
00268                                               0xbb,
00269                                               0x5b,
00270                                               0xb8,
00271                                               0x35,
00272                                               0xd8,
00273                                               0x17,
00274                                             },
00275                                             {
00276                                               0xad,
00277                                               0xcf,
00278                                               0x6b,
00279                                               0x07,
00280                                               0x63,
00281                                               0x61,
00282                                               0x2e,
00283                                               0x2f,
00284                                             },
00285                                             {
00286                                               0xa5,
00287                                               0xc9,
00288                                               0x1d,
00289                                               0xa7,
00290                                               0xac,
00291                                               0xaa,
00292                                               0x4d,
00293                                               0xde,
00294                                             },
00295                                             {
00296                                               0x71,
00297                                               0x65,
00298                                               0x95,
00299                                               0x87,
00300                                               0x66,
00301                                               0x50,
00302                                               0xa2,
00303                                               0xa6,
00304                                             },
00305                                             {
00306                                               0x28,
00307                                               0xef,
00308                                               0x49,
00309                                               0x5c,
00310                                               0x53,
00311                                               0xa3,
00312                                               0x87,
00313                                               0xad,
00314                                             },
00315                                             {
00316                                               0x42,
00317                                               0xc3,
00318                                               0x41,
00319                                               0xd8,
00320                                               0xfa,
00321                                               0x92,
00322                                               0xd8,
00323                                               0x32,
00324                                             },
00325                                             {
00326                                               0xce,
00327                                               0x7c,
00328                                               0xf2,
00329                                               0x72,
00330                                               0x2f,
00331                                               0x51,
00332                                               0x27,
00333                                               0x71,
00334                                             },
00335                                             {
00336                                               0xe3,
00337                                               0x78,
00338                                               0x59,
00339                                               0xf9,
00340                                               0x46,
00341                                               0x23,
00342                                               0xf3,
00343                                               0xa7,
00344                                             },
00345                                             {
00346                                               0x38,
00347                                               0x12,
00348                                               0x05,
00349                                               0xbb,
00350                                               0x1a,
00351                                               0xb0,
00352                                               0xe0,
00353                                               0x12,
00354                                             },
00355                                             {
00356                                               0xae,
00357                                               0x97,
00358                                               0xa1,
00359                                               0x0f,
00360                                               0xd4,
00361                                               0x34,
00362                                               0xe0,
00363                                               0x15,
00364                                             },
00365                                             {
00366                                               0xb4,
00367                                               0xa3,
00368                                               0x15,
00369                                               0x08,
00370                                               0xbe,
00371                                               0xff,
00372                                               0x4d,
00373                                               0x31,
00374                                             },
00375                                             {
00376                                               0x81,
00377                                               0x39,
00378                                               0x62,
00379                                               0x29,
00380                                               0xf0,
00381                                               0x90,
00382                                               0x79,
00383                                               0x02,
00384                                             },
00385                                             {
00386                                               0x4d,
00387                                               0x0c,
00388                                               0xf4,
00389                                               0x9e,
00390                                               0xe5,
00391                                               0xd4,
00392                                               0xdc,
00393                                               0xca,
00394                                             },
00395                                             {
00396                                               0x5c,
00397                                               0x73,
00398                                               0x33,
00399                                               0x6a,
00400                                               0x76,
00401                                               0xd8,
00402                                               0xbf,
00403                                               0x9a,
00404                                             },
00405                                             {
00406                                               0xd0,
00407                                               0xa7,
00408                                               0x04,
00409                                               0x53,
00410                                               0x6b,
00411                                               0xa9,
00412                                               0x3e,
00413                                               0x0e,
00414                                             },
00415                                             {
00416                                               0x92,
00417                                               0x59,
00418                                               0x58,
00419                                               0xfc,
00420                                               0xd6,
00421                                               0x42,
00422                                               0x0c,
00423                                               0xad,
00424                                             },
00425                                             {
00426                                               0xa9,
00427                                               0x15,
00428                                               0xc2,
00429                                               0x9b,
00430                                               0xc8,
00431                                               0x06,
00432                                               0x73,
00433                                               0x18,
00434                                             },
00435                                             {
00436                                               0x95,
00437                                               0x2b,
00438                                               0x79,
00439                                               0xf3,
00440                                               0xbc,
00441                                               0x0a,
00442                                               0xa6,
00443                                               0xd4,
00444                                             },
00445                                             {
00446                                               0xf2,
00447                                               0x1d,
00448                                               0xf2,
00449                                               0xe4,
00450                                               0x1d,
00451                                               0x45,
00452                                               0x35,
00453                                               0xf9,
00454                                             },
00455                                             {
00456                                               0x87,
00457                                               0x57,
00458                                               0x75,
00459                                               0x19,
00460                                               0x04,
00461                                               0x8f,
00462                                               0x53,
00463                                               0xa9,
00464                                             },
00465                                             {
00466                                               0x10,
00467                                               0xa5,
00468                                               0x6c,
00469                                               0xf5,
00470                                               0xdf,
00471                                               0xcd,
00472                                               0x9a,
00473                                               0xdb,
00474                                             },
00475                                             {
00476                                               0xeb,
00477                                               0x75,
00478                                               0x09,
00479                                               0x5c,
00480                                               0xcd,
00481                                               0x98,
00482                                               0x6c,
00483                                               0xd0,
00484                                             },
00485                                             {
00486                                               0x51,
00487                                               0xa9,
00488                                               0xcb,
00489                                               0x9e,
00490                                               0xcb,
00491                                               0xa3,
00492                                               0x12,
00493                                               0xe6,
00494                                             },
00495                                             {
00496                                               0x96,
00497                                               0xaf,
00498                                               0xad,
00499                                               0xfc,
00500                                               0x2c,
00501                                               0xe6,
00502                                               0x66,
00503                                               0xc7,
00504                                             },
00505                                             {
00506                                               0x72,
00507                                               0xfe,
00508                                               0x52,
00509                                               0x97,
00510                                               0x5a,
00511                                               0x43,
00512                                               0x64,
00513                                               0xee,
00514                                             },
00515                                             {
00516                                               0x5a,
00517                                               0x16,
00518                                               0x45,
00519                                               0xb2,
00520                                               0x76,
00521                                               0xd5,
00522                                               0x92,
00523                                               0xa1,
00524                                             },
00525                                             {
00526                                               0xb2,
00527                                               0x74,
00528                                               0xcb,
00529                                               0x8e,
00530                                               0xbf,
00531                                               0x87,
00532                                               0x87,
00533                                               0x0a,
00534                                             },
00535                                             {
00536                                               0x6f,
00537                                               0x9b,
00538                                               0xb4,
00539                                               0x20,
00540                                               0x3d,
00541                                               0xe7,
00542                                               0xb3,
00543                                               0x81,
00544                                             },
00545                                             {
00546                                               0xea,
00547                                               0xec,
00548                                               0xb2,
00549                                               0xa3,
00550                                               0x0b,
00551                                               0x22,
00552                                               0xa8,
00553                                               0x7f,
00554                                             },
00555                                             {
00556                                               0x99,
00557                                               0x24,
00558                                               0xa4,
00559                                               0x3c,
00560                                               0xc1,
00561                                               0x31,
00562                                               0x57,
00563                                               0x24,
00564                                             },
00565                                             {
00566                                               0xbd,
00567                                               0x83,
00568                                               0x8d,
00569                                               0x3a,
00570                                               0xaf,
00571                                               0xbf,
00572                                               0x8d,
00573                                               0xb7,
00574                                             },
00575                                             {
00576                                               0x0b,
00577                                               0x1a,
00578                                               0x2a,
00579                                               0x32,
00580                                               0x65,
00581                                               0xd5,
00582                                               0x1a,
00583                                               0xea,
00584                                             },
00585                                             {
00586                                               0x13,
00587                                               0x50,
00588                                               0x79,
00589                                               0xa3,
00590                                               0x23,
00591                                               0x1c,
00592                                               0xe6,
00593                                               0x60,
00594                                             },
00595                                             {
00596                                               0x93,
00597                                               0x2b,
00598                                               0x28,
00599                                               0x46,
00600                                               0xe4,
00601                                               0xd7,
00602                                               0x06,
00603                                               0x66,
00604                                             },
00605                                             {
00606                                               0xe1,
00607                                               0x91,
00608                                               0x5f,
00609                                               0x5c,
00610                                               0xb1,
00611                                               0xec,
00612                                               0xa4,
00613                                               0x6c,
00614                                             },
00615                                             {
00616                                               0xf3,
00617                                               0x25,
00618                                               0x96,
00619                                               0x5c,
00620                                               0xa1,
00621                                               0x6d,
00622                                               0x62,
00623                                               0x9f,
00624                                             },
00625                                             {
00626                                               0x57,
00627                                               0x5f,
00628                                               0xf2,
00629                                               0x8e,
00630                                               0x60,
00631                                               0x38,
00632                                               0x1b,
00633                                               0xe5,
00634                                             },
00635                                             {
00636                                               0x72,
00637                                               0x45,
00638                                               0x06,
00639                                               0xeb,
00640                                               0x4c,
00641                                               0x32,
00642                                               0x8a,
00643                                               0x95,
00644                                             }};
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/test/siphash_known_hashes.h...
Preprocessing /data/git/CCF/src/ds/test/thread_messaging.cpp...
#include ../thread_messaging.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 1148 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 struct Foo
00008 {
00009   static size_t count;
00010 
00011   Foo()
00012   {
00013     count++;
00014   }
00015 
00016   ~Foo()
00017   {
00018     count--;
00019   }
00020 };
00021 
00022 size_t Foo::count = 0;
00023 
00024 static bool happened = false;
00025 
00026 static void always(std::unique_ptr<threading::Tmsg<Foo>> msg)
00027 {
00028   happened = true;
00029 }
00030 
00031 static void never(std::unique_ptr<threading::Tmsg<Foo>> msg)
00032 {
00033   CHECK(false);
00034 }
00035 
00036 // Note: this only works with ASAN turned on, which catches m2 not being
00037 // freed.
00038 TEST_CASE("Unpopped messages are freed")
00039 {
00040   {
00041     threading::ThreadMessaging tm(1);
00042 
00043     auto m1 = std::make_unique<threading::Tmsg<Foo>>(&always);
00044     tm.add_task<Foo>(0, std::move(m1));
00045 
00046     // Task payload (and TMsg) is freed after running
00047     tm.run_one();
00048     CHECK(Foo::count == 0);
00049 
00050     auto m2 = std::make_unique<threading::Tmsg<Foo>>(&never);
00051     tm.add_task<Foo>(0, std::move(m2));
00052     // Task is owned by the queue, hasn't run
00053     CHECK(Foo::count == 1);
00054 
00055     tm.drop_tasks();
00056   }
00057   // Task payload (and TMsg) is also freed if it hasn't run
00058   // but the queue was destructed
00059   CHECK(Foo::count == 0);
00060 
00061   CHECK(happened);
00062 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/test/thread_messaging.cpp...
Preprocessing /data/git/CCF/src/ds/test/typed_messages.cpp...
#include ../oversized.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 3775 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 enum : ringbuffer::Message
00008 {
00009   DEFINE_RINGBUFFER_MSG_TYPE(large_block_message),
00010   DEFINE_RINGBUFFER_MSG_TYPE(large_compound_message),
00011   DEFINE_RINGBUFFER_MSG_TYPE(large_complex_message),
00012   DEFINE_RINGBUFFER_MSG_TYPE(finish),
00013 };
00014 
00015 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(large_block_message, std::vector<uint8_t>);
00016 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00017   large_compound_message, size_t, std::vector<uint8_t>);
00018 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00019   large_complex_message,
00020   uint16_t,
00021   bool,
00022   uint32_t,
00023   std::string,
00024   bool,
00025   uint16_t,
00026   uint64_t,
00027   std::vector<uint8_t>);
00028 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(finish);
00029 
00030 TEST_CASE(
00031   "Large message reconstruction" * doctest::test_suite("typed_messages"))
00032 {
00033   constexpr size_t buf_size = 1 << 8;
00034 
00035   auto buffer = std::make_unique<ringbuffer::TestBuffer>(buf_size);
00036   ringbuffer::Reader rr(buffer->bd);
00037 
00038   constexpr auto fragment_max = buf_size / 8;
00039   constexpr auto total_max = buf_size / 3;
00040   oversized::Writer writer(
00041     std::make_unique<ringbuffer::Writer>(rr), fragment_max, total_max);
00042   auto writer_p = &writer;
00043 
00044   messaging::BufferProcessor bp("typed_messages");
00045   oversized::FragmentReconstructor fr(bp.get_dispatcher());
00046   DISPATCHER_SET_MESSAGE_HANDLER(
00047     bp, finish, [&bp](const uint8_t* data, size_t size) {
00048       bp.set_finished(true);
00049     });
00050 
00051   SUBCASE("block message")
00052   {
00053     bool message_seen = false;
00054 
00055     std::vector<uint8_t> sent(fragment_max * 2);
00056     std::iota(sent.begin(), sent.end(), 0);
00057 
00058     DISPATCHER_SET_MESSAGE_HANDLER(
00059       bp, large_block_message, [&](const uint8_t* data, size_t size) {
00060         auto [body] = ringbuffer::read_message<large_block_message>(data, size);
00061         REQUIRE(body == sent);
00062 
00063         REQUIRE(!message_seen);
00064         message_seen = true;
00065       });
00066 
00067     RINGBUFFER_WRITE_MESSAGE(large_block_message, writer_p, sent);
00068     RINGBUFFER_WRITE_MESSAGE(finish, writer_p);
00069     bp.run(rr);
00070     REQUIRE(message_seen);
00071   }
00072 
00073   SUBCASE("compound message")
00074   {
00075     bool message_seen = false;
00076 
00077     size_t sent_n = 42u;
00078     std::vector<uint8_t> sent_body(fragment_max * 2);
00079     std::iota(sent_body.begin(), sent_body.end(), 0);
00080 
00081     DISPATCHER_SET_MESSAGE_HANDLER(
00082       bp, large_compound_message, [&](const uint8_t* data, size_t size) {
00083         auto [n, body] =
00084           ringbuffer::read_message<large_compound_message>(data, size);
00085 
00086         REQUIRE(n == sent_n);
00087         REQUIRE(body == sent_body);
00088 
00089         REQUIRE(!message_seen);
00090         message_seen = true;
00091       });
00092 
00093     RINGBUFFER_WRITE_MESSAGE(
00094       large_compound_message, writer_p, sent_n, sent_body);
00095     RINGBUFFER_WRITE_MESSAGE(finish, writer_p);
00096     bp.run(rr);
00097     REQUIRE(message_seen);
00098   }
00099 
00100   SUBCASE("complex message")
00101   {
00102     bool message_seen = false;
00103 
00104     const uint16_t a = 16;
00105     const bool b = true;
00106     const uint32_t c = 42;
00107     const std::string d = "COMPLEX";
00108     const bool e = false;
00109     const uint16_t f = 1661;
00110     const uint64_t g = 0xdeadbeef;
00111     const std::vector<uint8_t> h{1, 2, 3, 4, 5};
00112 
00113     DISPATCHER_SET_MESSAGE_HANDLER(
00114       bp, large_complex_message, [&](const uint8_t* data, size_t size) {
00115         auto [aa, bb, cc, dd, ee, ff, gg, hh] =
00116           ringbuffer::read_message<large_complex_message>(data, size);
00117 
00118         REQUIRE(a == aa);
00119         REQUIRE(b == bb);
00120         REQUIRE(c == cc);
00121         REQUIRE(d == dd);
00122         REQUIRE(e == ee);
00123         REQUIRE(f == ff);
00124         REQUIRE(g == gg);
00125         REQUIRE(h == hh);
00126 
00127         REQUIRE(!message_seen);
00128         message_seen = true;
00129       });
00130 
00131     RINGBUFFER_WRITE_MESSAGE(
00132       large_complex_message, writer_p, a, b, c, d, e, f, g, h);
00133     RINGBUFFER_WRITE_MESSAGE(finish, writer_p);
00134     bp.run(rr);
00135     REQUIRE(message_seen);
00136   }
00137 }
00138 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE DISPATCHER_SET_MESSAGE_HANDLER LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/ds/test/typed_messages.cpp...
Preprocessing /data/git/CCF/src/ds/thread_ids.h...
#include fmt/format.h: not found! skipping...
#include fmt/ostream.h: not found! skipping...
#include limits: not found! skipping...
#include map: not found! skipping...
#include thread: not found! skipping...
Preprocessor output (size: 877 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define FMT_HEADER_ONLY
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace threading
00013 {
00014   static constexpr size_t MAIN_THREAD_ID = 0;
00015 
00016   extern std::map<std::thread::id, uint16_t> thread_ids;
00017   static inline thread_local uint16_t thread_id =
00018     std::numeric_limits<uint16_t>::min();
00019 
00020   static inline uint16_t get_current_thread_id()
00021   {
00022     if (thread_id != std::numeric_limits<uint16_t>::min())
00023     {
00024       return thread_id;
00025     }
00026 
00027     if (thread_ids.empty())
00028     {
00029       return MAIN_THREAD_ID;
00030     }
00031 
00032     const auto tid = std::this_thread::get_id();
00033     const auto it = thread_ids.find(tid);
00034     if (it == thread_ids.end())
00035     {
00036       throw std::runtime_error(
00037         fmt::format("Accessed uninitialized thread_ids - ID {} unknown", tid));
00038     }
00039 
00040     thread_id = it->second;
00041 
00042     return thread_id;
00043   }
00044 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/ds/thread_ids.h...
Preprocessing /data/git/CCF/src/ds/thread_messaging.h...
#include ds/ccf_assert.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/thread_ids.h: not found! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include cstddef: not found! skipping...
Preprocessor output (size: 7938 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace threading
00014 {
00015   struct ThreadMsg
00016   {
00017     void (*cb)(std::unique_ptr<ThreadMsg>);
00018     std::atomic<ThreadMsg*> next = nullptr;
00019 
00020     ThreadMsg(void (*_cb)(std::unique_ptr<ThreadMsg>)) : cb(_cb) {}
00021 
00022     virtual ~ThreadMsg() = default;
00023   };
00024 
00025   template <typename Payload>
00026   struct alignas(16) Tmsg : public ThreadMsg
00027   {
00028     Payload data;
00029 
00030     template <typename... Args>
00031     Tmsg(void (*_cb)(std::unique_ptr<Tmsg<Payload>>), Args&&... args) :
00032       ThreadMsg(reinterpret_cast<void (*)(std::unique_ptr<ThreadMsg>)>(_cb)),
00033       data(std::forward<Args>(args)...)
00034     {}
00035 
00036     virtual ~Tmsg() = default;
00037   };
00038 
00039   class ThreadMessaging;
00040 
00041   class Task
00042   {
00043     std::atomic<ThreadMsg*> item_head = nullptr;
00044     ThreadMsg* local_msg = nullptr;
00045 
00046   public:
00047     Task() = default;
00048 
00049     bool run_next_task()
00050     {
00051       if (local_msg == nullptr && item_head != nullptr)
00052       {
00053         local_msg = item_head.exchange(nullptr);
00054         reverse_local_messages();
00055       }
00056 
00057       if (local_msg == nullptr)
00058       {
00059         return false;
00060       }
00061 
00062       ThreadMsg* current = local_msg;
00063       local_msg = local_msg->next;
00064 
00065       current->cb(std::unique_ptr<ThreadMsg>(current));
00066       return true;
00067     }
00068 
00069     void add_task(ThreadMsg* item)
00070     {
00071       ThreadMsg* tmp_head;
00072       do
00073       {
00074         tmp_head = item_head.load();
00075         item->next = tmp_head;
00076       } while (!item_head.compare_exchange_strong(tmp_head, item));
00077     }
00078 
00079     struct TimerEntry
00080     {
00081       TimerEntry() : time_offset(0), counter(0) {}
00082       TimerEntry(std::chrono::milliseconds time_offset_, uint64_t counter_) :
00083         time_offset(time_offset_),
00084         counter(counter_)
00085       {}
00086 
00087       std::chrono::milliseconds time_offset;
00088       uint64_t counter;
00089     };
00090 
00091     struct TimerEntryCompare
00092     {
00093       bool operator()(const TimerEntry& lhs, const TimerEntry& rhs) const
00094       {
00095         if (lhs.time_offset != rhs.time_offset)
00096         {
00097           return lhs.time_offset < rhs.time_offset;
00098         }
00099 
00100         return lhs.counter < rhs.counter;
00101       }
00102     };
00103 
00104     TimerEntry add_task_after(
00105       std::unique_ptr<ThreadMsg> item, std::chrono::milliseconds ms)
00106     {
00107       TimerEntry entry = {time_offset + ms, time_entry_counter++};
00108       if (timer_map.empty() || entry.time_offset <= next_time_offset)
00109       {
00110         next_time_offset = entry.time_offset;
00111       }
00112 
00113       timer_map.emplace(entry, std::move(item));
00114       return entry;
00115     }
00116 
00117     bool cancel_timer_task(TimerEntry timer_entry)
00118     {
00119       auto num_erased = timer_map.erase(timer_entry);
00120       CCF_ASSERT(num_erased <= 1, "Too many items erased");
00121       if (!timer_map.empty() && timer_entry.time_offset <= next_time_offset)
00122       {
00123         next_time_offset = timer_map.begin()->first.time_offset;
00124       }
00125       return num_erased != 0;
00126     }
00127 
00128     void tick(std::chrono::milliseconds elapsed)
00129     {
00130       time_offset += elapsed;
00131 
00132       bool updated = false;
00133 
00134       while (!timer_map.empty() && next_time_offset <= time_offset &&
00135              timer_map.begin()->first.time_offset <= time_offset)
00136       {
00137         updated = true;
00138         auto it = timer_map.begin();
00139 
00140         auto& cb = it->second->cb;
00141         auto msg = std::move(it->second);
00142         timer_map.erase(it);
00143         cb(std::move(msg));
00144       }
00145 
00146       if (updated)
00147       {
00148         next_time_offset = timer_map.begin()->first.time_offset;
00149       }
00150     }
00151 
00152     std::chrono::milliseconds get_current_time_offset()
00153     {
00154       return time_offset;
00155     }
00156 
00157   private:
00158     std::chrono::milliseconds time_offset = std::chrono::milliseconds(0);
00159     uint64_t time_entry_counter = 0;
00160     std::map<TimerEntry, std::unique_ptr<ThreadMsg>, TimerEntryCompare>
00161       timer_map;
00162     std::chrono::milliseconds next_time_offset;
00163 
00164     void reverse_local_messages()
00165     {
00166       if (local_msg == nullptr)
00167         return;
00168 
00169       ThreadMsg *prev = nullptr, *current = nullptr, *next = nullptr;
00170       current = local_msg;
00171       while (current != nullptr)
00172       {
00173         next = current->next;
00174         current->next = prev;
00175         prev = current;
00176         current = next;
00177       }
00178       // now let the head point at the last node (prev)
00179       local_msg = prev;
00180     }
00181 
00182     void drop()
00183     {
00184       while (true)
00185       {
00186         if (local_msg == nullptr && item_head != nullptr)
00187         {
00188           local_msg = item_head.exchange(nullptr);
00189           reverse_local_messages();
00190         }
00191 
00192         if (local_msg == nullptr)
00193         {
00194           break;
00195         }
00196 
00197         ThreadMsg* current = local_msg;
00198         local_msg = local_msg->next;
00199         delete current;
00200       }
00201     }
00202 
00203     friend ThreadMessaging;
00204   };
00205 
00206   class ThreadMessaging
00207   {
00208     std::atomic<bool> finished;
00209     std::vector<Task> tasks;
00210 
00211   public:
00212     static ThreadMessaging thread_messaging;
00213     static std::atomic<uint16_t> thread_count;
00214     static const uint16_t main_thread = MAIN_THREAD_ID;
00215 
00216     static const uint16_t max_num_threads = 24;
00217 
00218     ThreadMessaging(uint16_t num_threads = max_num_threads) :
00219       finished(false),
00220       tasks(num_threads)
00221     {}
00222 
00223     // Drop all pending tasks, this is only ever to be used
00224     // on shutdown, to avoid leaks, and after all thread but
00225     // the main one have been shut down.
00226     void drop_tasks()
00227     {
00228       for (auto& t : tasks)
00229       {
00230         t.drop();
00231       }
00232     }
00233 
00234     void set_finished(bool v = true)
00235     {
00236       finished.store(v);
00237     }
00238 
00239     void run()
00240     {
00241       Task& task = get_task(get_current_thread_id());
00242 
00243       while (!is_finished())
00244       {
00245         task.run_next_task();
00246       }
00247     }
00248 
00249     inline Task& get_task(uint16_t tid)
00250     {
00251       CCF_ASSERT_FMT(
00252         tid < thread_count || tid == 0,
00253         "Attempting to add task to tid > thread_count, tid:{}, thread_count:{}",
00254         tid,
00255         thread_count);
00256       return tasks[tid];
00257     }
00258 
00259     bool run_one()
00260     {
00261       Task& task = get_task(get_current_thread_id());
00262       return task.run_next_task();
00263     }
00264 
00265     template <typename Payload>
00266     void add_task(uint16_t tid, std::unique_ptr<Tmsg<Payload>> msg)
00267     {
00268       Task& task = get_task(tid);
00269 
00270       task.add_task(reinterpret_cast<ThreadMsg*>(msg.release()));
00271     }
00272 
00273     template <typename Payload>
00274     Task::TimerEntry add_task_after(
00275       std::unique_ptr<Tmsg<Payload>> msg, std::chrono::milliseconds ms)
00276     {
00277       Task& task = get_task(get_current_thread_id());
00278       return task.add_task_after(std::move(msg), ms);
00279     }
00280 
00281     bool cancel_timer_task(Task::TimerEntry timer_entry)
00282     {
00283       Task& task = get_task(get_current_thread_id());
00284       return task.cancel_timer_task(timer_entry);
00285     }
00286 
00287     std::chrono::milliseconds get_current_time_offset()
00288     {
00289       Task& task = get_task(get_current_thread_id());
00290       return task.get_current_time_offset();
00291     }
00292 
00293     struct TickMsg
00294     {
00295       TickMsg(std::chrono::milliseconds elapsed_, Task& task_) :
00296         elapsed(elapsed_),
00297         task(task_)
00298       {}
00299 
00300       std::chrono::milliseconds elapsed;
00301       Task& task;
00302     };
00303 
00304     static void tick_cb(std::unique_ptr<Tmsg<TickMsg>> msg)
00305     {
00306       msg->data.task.tick(msg->data.elapsed);
00307     }
00308 
00309     void tick(std::chrono::milliseconds elapsed)
00310     {
00311       for (auto i = 0; i < thread_count; ++i)
00312       {
00313         auto& task = get_task(i);
00314         auto msg = std::make_unique<Tmsg<TickMsg>>(&tick_cb, elapsed, task);
00315         task.add_task(msg.release());
00316       }
00317     }
00318 
00319     static uint16_t get_execution_thread(uint32_t i)
00320     {
00321       uint16_t tid = MAIN_THREAD_ID;
00322       if (thread_count > 1)
00323       {
00324         tid = (i % (thread_count - 1));
00325         ++tid;
00326       }
00327 
00328       return tid;
00329     }
00330 
00331     template <typename Payload>
00332     static void ChangeTmsgCallback(
00333       std::unique_ptr<Tmsg<Payload>>& msg,
00334       void (*cb_)(std::unique_ptr<Tmsg<Payload>>))
00335     {
00336       msg->cb = (reinterpret_cast<void (*)(std::unique_ptr<ThreadMsg>)>(cb_));
00337     }
00338 
00339   private:
00340     bool is_finished()
00341     {
00342       return finished.load();
00343     }
00344   };
00345 };
00346 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/ds/thread_messaging.h...
Preprocessing /data/git/CCF/src/enclave/app_interface.h...
#include node/historical_queries_interface.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
Preprocessor output (size: 738 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace ccfapp
00009 {
00010   struct AbstractNodeContext
00011   {
00012     virtual ~AbstractNodeContext() = default;
00013 
00014     virtual ccf::historical::AbstractStateCache& get_historical_state() = 0;
00015   };
00016 
00017   // SNIPPET_START: rpc_handler
00018   /** To be implemented by the application to be registered by CCF.
00019    *
00020    * @param network Access to the network's replicated tables
00021    * @param context Access to node and host services
00022    *
00023    * @return Shared pointer to the application handler instance
00024    */
00025   std::shared_ptr<ccf::UserRpcFrontend> get_rpc_handler(
00026     ccf::NetworkTables& network, AbstractNodeContext& context);
00027   // SNIPPET_END: rpc_handler
00028 }
00029 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/app_interface.h...
Preprocessing /data/git/CCF/src/enclave/ccf_v.h...
#include dlfcn.h: not found! skipping...
#include stdlib.h: not found! skipping...
#include string.h: not found! skipping...
#include wchar.h: not found! skipping...
#include ccf_args.h: not found! skipping...
Preprocessor output (size: 3361 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 #define OE_REPORT_DATA_SIZE
00018 
00019 #define OE_ENCLAVE_FLAG_DEBUG
00020 
00021 static void* virtual_enclave_handle;
00022 
00023 template <typename T>
00024 T get_enclave_exported_function(const char* func_name)
00025 {
00026   void* sym = dlsym(virtual_enclave_handle, func_name);
00027   if (sym == nullptr)
00028   {
00029     throw std::logic_error(
00030       fmt::format("Failed to find symbol: {}\n  {}", func_name, dlerror()));
00031   }
00032   return (T)sym;
00033 }
00034 
00035 // Repeat minimal required definitions for virtual build. It should not matter
00036 // if these do not match precisely OE's, so long as they can be used
00037 // consistently by the virtual build
00038 using oe_result_t = int;
00039 constexpr oe_result_t OE_OK = 0;
00040 constexpr oe_result_t OE_FAILURE = 1;
00041 
00042 using oe_enclave_t = void;
00043 
00044 enum oe_enclave_type_t
00045 {
00046   OE_ENCLAVE_TYPE_SGX = 2,
00047 };
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 #define oe_result_str(x) 
00059 
00060   typedef void (*oe_ocall_func_t)(
00061     const uint8_t* input_buffer,
00062     size_t input_buffer_size,
00063     uint8_t* output_buffer,
00064     size_t output_buffer_size,
00065     size_t* output_bytes_written);
00066 
00067   using create_node_func_t = bool (*)(
00068     void*,
00069     char*,
00070     size_t,
00071     uint8_t*,
00072     size_t,
00073     size_t*,
00074     uint8_t*,
00075     size_t,
00076     size_t*,
00077     StartType,
00078     ConsensusType,
00079     size_t,
00080     void*);
00081 
00082   using run_func_t = bool (*)();
00083 
00084   using tick_func_t = bool (*)(size_t, size_t);
00085 
00086   /*ocall function table*/
00087   static oe_ocall_func_t __ccf_ocall_function_table[] = {nullptr};
00088 
00089   inline void load_virtual_enclave(const char* path)
00090   {
00091     if (virtual_enclave_handle)
00092     {
00093       throw std::logic_error(
00094         "Current implementation is limited to a single virtual "
00095         "enclave per process");
00096     }
00097     virtual_enclave_handle = dlopen(path, RTLD_NOW);
00098     if (virtual_enclave_handle == nullptr)
00099     {
00100       throw std::logic_error(
00101         fmt::format("Could not load virtual enclave: {}", dlerror()));
00102     }
00103   }
00104 
00105   inline oe_result_t enclave_create_node(
00106     oe_enclave_t*,
00107     bool* _retval,
00108     void* enclave_config,
00109     char* ccf_config,
00110     size_t ccf_config_size,
00111     uint8_t* node_cert,
00112     size_t node_cert_size,
00113     size_t* node_cert_len,
00114     uint8_t* network_cert,
00115     size_t network_cert_size,
00116     size_t* network_cert_len,
00117     StartType start_type,
00118     ConsensusType consensus_type,
00119     size_t num_worker_thread,
00120     void* time_location)
00121   {
00122     static create_node_func_t create_node_func =
00123       get_enclave_exported_function<create_node_func_t>("enclave_create_node");
00124 
00125     *_retval = create_node_func(
00126       enclave_config,
00127       ccf_config,
00128       ccf_config_size,
00129       node_cert,
00130       node_cert_size,
00131       node_cert_len,
00132       network_cert,
00133       network_cert_size,
00134       network_cert_len,
00135       start_type,
00136       consensus_type,
00137       num_worker_thread,
00138       time_location);
00139     return *_retval ? OE_OK : OE_FAILURE;
00140   }
00141 
00142   inline oe_result_t enclave_run(oe_enclave_t*, bool* _retval)
00143   {
00144     static run_func_t run_func =
00145       get_enclave_exported_function<run_func_t>("enclave_run");
00146 
00147     *_retval = run_func();
00148     return *_retval ? OE_OK : OE_FAILURE;
00149   }
00150 
00151   inline oe_result_t oe_create_ccf_enclave(
00152     const char*,
00153     oe_enclave_type_t,
00154     uint32_t,
00155     const void*,
00156     uint32_t,
00157     oe_enclave_t**)
00158   {
00159     // this function is not supposed to be called when using a virtual enclave
00160     return OE_FAILURE;
00161   }
00162 
00163 
00164 
00165 
00166 
---------
Macros accessible in this file:
---------
OE_ENCLAVE_FLAG_DEBUG OE_REPORT_DATA_SIZE oe_result_str 
---------
Parsing file /data/git/CCF/src/enclave/ccf_v.h...
Preprocessing /data/git/CCF/src/enclave/client_endpoint.h...
#include http/http_builder.h: not found! skipping...
#include tls/msg_types.h: not found! skipping...
Preprocessor output (size: 948 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace enclave
00009 {
00010   class ClientEndpoint
00011   {
00012   protected:
00013     using HandleDataCallback = std::function<bool(
00014       http_status status,
00015       http::HeaderMap&& headers,
00016       std::vector<uint8_t>&& body)>;
00017 
00018     HandleDataCallback handle_data_cb;
00019 
00020     size_t session_id;
00021     ringbuffer::WriterPtr to_host;
00022 
00023   public:
00024     ClientEndpoint(
00025       size_t session_id, ringbuffer::AbstractWriterFactory& writer_factory) :
00026       session_id(session_id),
00027       to_host(writer_factory.create_writer_to_outside())
00028     {}
00029 
00030     virtual void send_request(std::vector<uint8_t>&& data) = 0;
00031 
00032     void connect(
00033       const std::string& hostname,
00034       const std::string& service,
00035       const HandleDataCallback f)
00036     {
00037       RINGBUFFER_WRITE_MESSAGE(
00038         tls::tls_connect, to_host, session_id, hostname, service);
00039       handle_data_cb = f;
00040     }
00041   };
00042 }
00043 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/client_endpoint.h...
Preprocessing /data/git/CCF/src/enclave/consensus_type.h...
Preprocessor output (size: 150 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 enum ConsensusType
00006 {
00007   CFT = 0,
00008   BFT = 1
00009 };
00010 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/consensus_type.h...
Preprocessing /data/git/CCF/src/enclave/enclave.h...
#include node/historical_queries_interface.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/oversized.h: not found! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include consensus/consensus_types.h: not found! skipping...
  #include ds/buffer.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/oversized.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/node_info_network.h: not found! skipping...
  #include tls/san.h: not found! skipping...
#include tls/tls.h: not found! skipping...
#include chrono: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/historical_queries.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/node_state.h: not found! skipping...
#include node/node_types.h: not found! skipping...
#include node/rpc/forwarder.h: not found! skipping...
#include node/rpc/node_frontend.h: not found! skipping...
#include node/entities.h: not found! skipping...
  #include ds/buffer.h: not found! skipping...
          #include http/http_builder.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/rpc/error.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include variant: not found! skipping...
#include vector: not found! skipping...
#include vector: not found! skipping...
#include chrono: not found! skipping...
#include limits: not found! skipping...
#include stdint.h: not found! skipping...
#include vector: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include forwarder_types.h: already included! skipping...
#include http/http_endpoint.h: not found! skipping...
#include rpc_handler.h: already included! skipping...
#include tls/cert.h: not found! skipping...
#include tls/client.h: not found! skipping...
#include tls/context.h: not found! skipping...
#include tls/server.h: not found! skipping...
#include limits: not found! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 13407 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 # 4 "/data/git/CCF/src/enclave/enclave.h" 2
00005 
00006 
00007 
00008 # 8 "/data/git/CCF/src/enclave/enclave.h" 2
00009 # 9 "/data/git/CCF/src/enclave/enclave.h" 2
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 # 17 "/data/git/CCF/src/enclave/enclave.h" 2
00018 # 18 "/data/git/CCF/src/enclave/enclave.h" 2
00019 
00020 namespace enclave
00021 {
00022   class Enclave
00023   {
00024   private:
00025     ringbuffer::Circuit circuit;
00026     ringbuffer::WriterFactory basic_writer_factory;
00027     oversized::WriterFactory writer_factory;
00028     ccf::NetworkState network;
00029     ccf::ShareManager share_manager;
00030     std::shared_ptr<ccf::NodeToNode> n2n_channels;
00031     std::shared_ptr<RPCMap> rpc_map;
00032     std::shared_ptr<RPCSessions> rpcsessions;
00033     std::unique_ptr<ccf::NodeState> node;
00034     std::shared_ptr<ccf::Forwarder<ccf::NodeToNode>> cmd_forwarder;
00035     ringbuffer::WriterPtr to_host = nullptr;
00036 
00037     CCFConfig ccf_config;
00038     StartType start_type;
00039 
00040     struct NodeContext : public ccfapp::AbstractNodeContext
00041     {
00042       ccf::historical::StateCache historical_state_cache;
00043 
00044       NodeContext(ccf::historical::StateCache&& hsc) :
00045         historical_state_cache(std::move(hsc))
00046       {}
00047 
00048       ccf::historical::AbstractStateCache& get_historical_state() override
00049       {
00050         return historical_state_cache;
00051       }
00052     } context;
00053 
00054   public:
00055     Enclave(
00056       const EnclaveConfig& ec,
00057       const CCFConfig::SignatureIntervals& signature_intervals,
00058       const ConsensusType& consensus_type_,
00059       const consensus::Config& consensus_config) :
00060       circuit(
00061         ringbuffer::BufferDef{ec.to_enclave_buffer_start,
00062                               ec.to_enclave_buffer_size,
00063                               ec.to_enclave_buffer_offsets},
00064         ringbuffer::BufferDef{ec.from_enclave_buffer_start,
00065                               ec.from_enclave_buffer_size,
00066                               ec.from_enclave_buffer_offsets}),
00067       basic_writer_factory(circuit),
00068       writer_factory(basic_writer_factory, ec.writer_config),
00069       network(consensus_type_),
00070       share_manager(network),
00071       n2n_channels(std::make_shared<ccf::NodeToNodeImpl>(writer_factory)),
00072       rpc_map(std::make_shared<RPCMap>()),
00073       rpcsessions(std::make_shared<RPCSessions>(writer_factory, rpc_map)),
00074       cmd_forwarder(std::make_shared<ccf::Forwarder<ccf::NodeToNode>>(
00075         rpcsessions, n2n_channels, rpc_map, consensus_type_)),
00076       context(ccf::historical::StateCache(
00077         *network.tables, writer_factory.create_writer_to_outside()))
00078     {
00079       logger::config::msg() = AdminMessage::log_msg;
00080       logger::config::writer() = writer_factory.create_writer_to_outside();
00081 
00082       to_host = writer_factory.create_writer_to_outside();
00083 
00084       node = std::make_unique<ccf::NodeState>(
00085         writer_factory, network, rpcsessions, share_manager);
00086 
00087       rpc_map->register_frontend<ccf::ActorsType::members>(
00088         std::make_unique<ccf::MemberRpcFrontend>(
00089           network, *node, share_manager));
00090 
00091       rpc_map->register_frontend<ccf::ActorsType::users>(
00092         ccfapp::get_rpc_handler(network, context));
00093 
00094       rpc_map->register_frontend<ccf::ActorsType::nodes>(
00095         std::make_unique<ccf::NodeRpcFrontend>(network, *node));
00096 
00097       for (auto& [actor, fe] : rpc_map->get_map())
00098       {
00099         fe->set_sig_intervals(
00100           signature_intervals.sig_tx_interval,
00101           signature_intervals.sig_ms_interval);
00102         fe->set_cmd_forwarder(cmd_forwarder);
00103       }
00104 
00105       node->initialize(
00106         consensus_config,
00107         n2n_channels,
00108         rpc_map,
00109         cmd_forwarder,
00110         signature_intervals.sig_tx_interval,
00111         signature_intervals.sig_ms_interval);
00112     }
00113 
00114     bool create_new_node(
00115       StartType start_type_,
00116       const CCFConfig& ccf_config_,
00117       uint8_t* node_cert,
00118       size_t node_cert_size,
00119       size_t* node_cert_len,
00120       uint8_t* network_cert,
00121       size_t network_cert_size,
00122       size_t* network_cert_len)
00123     {
00124       // node_cert_size and network_cert_size are ignored here, but we pass them
00125       // in because it allows us to set EDL an annotation so that node_cert_len
00126       // <= node_cert_size is checked by the EDL-generated wrapper
00127 
00128       start_type = start_type_;
00129       ccf_config = ccf_config_;
00130 
00131       ccf::NodeCreateInfo r;
00132       try
00133       {
00134         r = node->create(start_type, ccf_config);
00135       }
00136       catch (const std::runtime_error& e)
00137       {
00138         LOG_FAIL_FMT("Error starting node: {}", e.what());
00139         return false;
00140       }
00141 
00142       // Copy node and network certs out
00143       if (r.node_cert.size() > node_cert_size)
00144       {
00145         LOG_FAIL_FMT(
00146           "Insufficient space ({}) to copy node_cert out ({})",
00147           node_cert_size,
00148           r.node_cert.size());
00149         return false;
00150       }
00151       ::memcpy(node_cert, r.node_cert.data(), r.node_cert.size());
00152       *node_cert_len = r.node_cert.size();
00153 
00154       if (start_type == StartType::New || start_type == StartType::Recover)
00155       {
00156         // When starting a node in start or recover modes, fresh network secrets
00157         // are created and the associated certificate can be passed to the host
00158         if (r.network_cert.size() > network_cert_size)
00159         {
00160           LOG_FAIL_FMT(
00161             "Insufficient space ({}) to copy network_cert out ({})",
00162             network_cert_size,
00163             r.network_cert.size());
00164           return false;
00165         }
00166         ::memcpy(network_cert, r.network_cert.data(), r.network_cert.size());
00167         *network_cert_len = r.network_cert.size();
00168       }
00169 
00170       return true;
00171     }
00172 
00173     bool run_main()
00174     {
00175       LOG_DEBUG_FMT("Running main thread");
00176 
00177       try
00178 
00179       {
00180         messaging::BufferProcessor bp("Enclave");
00181 
00182         // reconstruct oversized messages sent to the enclave
00183         oversized::FragmentReconstructor fr(bp.get_dispatcher());
00184 
00185         DISPATCHER_SET_MESSAGE_HANDLER(
00186           bp, AdminMessage::stop, [&bp](const uint8_t*, size_t) {
00187             bp.set_finished();
00188             threading::ThreadMessaging::thread_messaging.set_finished();
00189           });
00190 
00191         DISPATCHER_SET_MESSAGE_HANDLER(
00192           bp,
00193           AdminMessage::tick,
00194           [this, &bp](const uint8_t* data, size_t size) {
00195             auto [ms_count] =
00196               ringbuffer::read_message<AdminMessage::tick>(data, size);
00197 
00198             if (ms_count > 0)
00199             {
00200               const auto message_counts =
00201                 bp.get_dispatcher().retrieve_message_counts();
00202               const auto j =
00203                 bp.get_dispatcher().convert_message_counts(message_counts);
00204               RINGBUFFER_WRITE_MESSAGE(
00205                 AdminMessage::work_stats, to_host, j.dump());
00206 
00207               std::chrono::milliseconds elapsed_ms(ms_count);
00208               logger::config::tick(elapsed_ms);
00209               node->tick(elapsed_ms);
00210               threading::ThreadMessaging::thread_messaging.tick(elapsed_ms);
00211               // When recovering, no signature should be emitted while the
00212               // public ledger is being read
00213               if (!node->is_reading_public_ledger())
00214               {
00215                 for (auto& r : rpc_map->get_map())
00216                 {
00217                   r.second->tick(elapsed_ms);
00218                 }
00219               }
00220               node->tick_end();
00221             }
00222           });
00223 
00224         DISPATCHER_SET_MESSAGE_HANDLER(
00225           bp, ccf::node_inbound, [this](const uint8_t* data, size_t size) {
00226             const auto [body] =
00227               ringbuffer::read_message<ccf::node_inbound>(data, size);
00228 
00229             auto p = body.data();
00230             auto psize = body.size();
00231 
00232             if (
00233               serialized::peek<ccf::NodeMsgType>(p, psize) ==
00234               ccf::NodeMsgType::forwarded_msg)
00235             {
00236               cmd_forwarder->recv_message(p, psize);
00237             }
00238             else
00239             {
00240               node->node_msg(std::move(body));
00241             }
00242           });
00243 
00244         DISPATCHER_SET_MESSAGE_HANDLER(
00245           bp,
00246           consensus::ledger_entry,
00247           [this](const uint8_t* data, size_t size) {
00248             const auto [index, purpose, body] =
00249               ringbuffer::read_message<consensus::ledger_entry>(data, size);
00250             switch (purpose)
00251             {
00252               case consensus::LedgerRequestPurpose::Recovery:
00253               {
00254                 if (
00255                   node->is_reading_public_ledger() ||
00256                   node->is_verifying_snapshot())
00257                   node->recover_public_ledger_entry(body);
00258                 else if (node->is_reading_private_ledger())
00259                   node->recover_private_ledger_entry(body);
00260                 else
00261                   LOG_FAIL_FMT("Cannot recover ledger entry: Unexpected state");
00262                 break;
00263               }
00264               case consensus::LedgerRequestPurpose::HistoricalQuery:
00265               {
00266                 context.historical_state_cache.handle_ledger_entry(index, body);
00267                 break;
00268               }
00269               default:
00270               {
00271                 LOG_FAIL_FMT("Unhandled purpose: {}", purpose);
00272               }
00273             }
00274           });
00275 
00276         DISPATCHER_SET_MESSAGE_HANDLER(
00277           bp,
00278           consensus::ledger_no_entry,
00279           [this](const uint8_t* data, size_t size) {
00280             const auto [index, purpose] =
00281               ringbuffer::read_message<consensus::ledger_no_entry>(data, size);
00282             switch (purpose)
00283             {
00284               case consensus::LedgerRequestPurpose::Recovery:
00285               {
00286                 if (node->is_verifying_snapshot())
00287                 {
00288                   node->verify_snapshot_end(ccf_config);
00289                 }
00290                 else
00291                 {
00292                   node->recover_ledger_end();
00293                 }
00294                 break;
00295               }
00296               case consensus::LedgerRequestPurpose::HistoricalQuery:
00297               {
00298                 context.historical_state_cache.handle_no_entry(index);
00299                 break;
00300               }
00301               default:
00302               {
00303                 LOG_FAIL_FMT("Unhandled purpose: {}", purpose);
00304               }
00305             }
00306           });
00307 
00308         rpcsessions->register_message_handlers(bp.get_dispatcher());
00309 
00310         if (start_type == StartType::Join)
00311         {
00312           // When joining from a snapshot, deserialise ledger suffix to verify
00313           // snapshot evidence. Otherwise, attempt to join straight away
00314           if (!ccf_config.startup_snapshot.empty())
00315           {
00316             node->start_ledger_recovery();
00317           }
00318           else
00319           {
00320             node->join(ccf_config);
00321           }
00322         }
00323         else if (start_type == StartType::Recover)
00324         {
00325           node->start_ledger_recovery();
00326         }
00327 
00328         // Maximum number of inbound ringbuffer messages which will be
00329         // processed in a single iteration
00330         static constexpr size_t max_messages = 256;
00331 
00332         size_t consecutive_idles = 0u;
00333         while (!bp.get_finished())
00334         {
00335           // First, read some messages from the ringbuffer
00336           auto read = bp.read_n(max_messages, circuit.read_from_outside());
00337 
00338           // Then, execute some thread messages
00339           size_t thread_msg = 0;
00340           while (thread_msg < max_messages &&
00341                  threading::ThreadMessaging::thread_messaging.run_one())
00342           {
00343             thread_msg++;
00344           }
00345 
00346           // If no messages were read from the ringbuffer and no thread
00347           // messages were executed, idle
00348           if (read == 0 && thread_msg == 0)
00349           {
00350             const auto time_now = enclave::get_enclave_time();
00351             static std::chrono::microseconds idling_start_time;
00352 
00353             if (consecutive_idles == 0)
00354             {
00355               idling_start_time = time_now;
00356             }
00357 
00358             // Handle initial idles by pausing, eventually sleep (in host)
00359             constexpr std::chrono::milliseconds timeout(5);
00360             if ((time_now - idling_start_time) > timeout)
00361             {
00362               std::this_thread::sleep_for(timeout * 10);
00363             }
00364             else
00365             {
00366               CCF_PAUSE();
00367             }
00368 
00369             consecutive_idles++;
00370           }
00371           else
00372           {
00373             // If some messages were read, reset consecutive idles count
00374             consecutive_idles = 0;
00375           }
00376         }
00377 
00378         LOG_INFO_FMT("Enclave stopped successfully. Stopping host...");
00379         RINGBUFFER_WRITE_MESSAGE(AdminMessage::stopped, to_host);
00380 
00381         return true;
00382       }
00383 
00384       catch (const std::exception& e)
00385       {
00386         RINGBUFFER_WRITE_MESSAGE(
00387           AdminMessage::fatal_error_msg, to_host, std::string(e.what()));
00388         return false;
00389       }
00390 
00391     }
00392 
00393     struct Msg
00394     {
00395       uint64_t tid;
00396     };
00397 
00398     static void init_thread_cb(std::unique_ptr<threading::Tmsg<Msg>> msg)
00399     {
00400       LOG_DEBUG_FMT("First thread CB:{}", msg->data.tid);
00401     }
00402 
00403     bool run_worker()
00404     {
00405       LOG_DEBUG_FMT("Running worker thread");
00406 
00407       try
00408 
00409       {
00410         auto msg = std::make_unique<threading::Tmsg<Msg>>(&init_thread_cb);
00411         msg->data.tid = threading::get_current_thread_id();
00412         threading::ThreadMessaging::thread_messaging.add_task(
00413           msg->data.tid, std::move(msg));
00414 
00415         threading::ThreadMessaging::thread_messaging.run();
00416       }
00417 
00418       catch (const std::exception& e)
00419       {
00420         RINGBUFFER_WRITE_MESSAGE(
00421           AdminMessage::fatal_error_msg, to_host, std::string(e.what()));
00422         return false;
00423       }
00424 
00425       return true;
00426     }
00427   };
00428 }
00429 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/enclave.h...
Preprocessing /data/git/CCF/src/enclave/enclave_time.h...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 569 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace enclave
00009 {
00010   extern std::atomic<std::chrono::microseconds>* host_time;
00011   extern std::chrono::microseconds last_value;
00012 
00013   static std::chrono::microseconds get_enclave_time()
00014   {
00015     // Update cached value if possible, but never move backwards
00016     if (host_time != nullptr)
00017     {
00018       const auto current_time = host_time->load();
00019       if (current_time > last_value)
00020       {
00021         last_value = current_time;
00022       }
00023     }
00024 
00025     return last_value;
00026   }
00027 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/enclave_time.h...
Preprocessing /data/git/CCF/src/enclave/endpoint.h...
#include vector: not found! skipping...
Preprocessor output (size: 358 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace enclave
00008 {
00009   class Endpoint : public std::enable_shared_from_this<Endpoint>
00010   {
00011   public:
00012     virtual ~Endpoint() {}
00013 
00014     virtual void recv(const uint8_t* data, size_t size) = 0;
00015     virtual void send(std::vector<uint8_t>&& data) = 0;
00016   };
00017 }
00018 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/endpoint.h...
Preprocessing /data/git/CCF/src/enclave/forwarder_types.h...
#include rpc_context.h: already included! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 736 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace enclave
00010 {
00011   class AbstractRPCResponder
00012   {
00013   public:
00014     virtual ~AbstractRPCResponder() {}
00015     virtual bool reply_async(size_t id, std::vector<uint8_t>&& data) = 0;
00016   };
00017 
00018   class AbstractForwarder
00019   {
00020   public:
00021     virtual ~AbstractForwarder() {}
00022 
00023     virtual bool forward_command(
00024       std::shared_ptr<enclave::RpcContext> rpc_ctx,
00025       ccf::NodeId to,
00026       std::set<ccf::NodeId> nodes,
00027       const std::vector<uint8_t>& caller_cert) = 0;
00028 
00029     virtual void send_request_hash_to_nodes(
00030       std::shared_ptr<enclave::RpcContext> rpc_ctx,
00031       std::set<ccf::NodeId> nodes,
00032       ccf::NodeId skip_node) = 0;
00033   };
00034 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/forwarder_types.h...
Preprocessing /data/git/CCF/src/enclave/interface.h...
#include consensus/consensus_types.h: not found! skipping...
#include consensus_type.h: already included! skipping...
#include ds/buffer.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/oversized.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/node_info_network.h: not found! skipping...
#include start_type.h: already included! skipping...
#include tls/san.h: not found! skipping...
#include tls/tls.h: not found! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 2974 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 /* Definition of the call-in and call-out interfaces
00004  */
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 struct EnclaveConfig
00023 {
00024   uint8_t* to_enclave_buffer_start;
00025   size_t to_enclave_buffer_size;
00026   ringbuffer::Offsets* to_enclave_buffer_offsets;
00027 
00028   uint8_t* from_enclave_buffer_start;
00029   size_t from_enclave_buffer_size;
00030   ringbuffer::Offsets* from_enclave_buffer_offsets;
00031 
00032   oversized::WriterConfig writer_config = {};
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 };
00042 
00043 struct CCFConfig
00044 {
00045   consensus::Config consensus_config = {};
00046   ccf::NodeInfoNetwork node_info_network = {};
00047   std::string domain;
00048   size_t snapshot_tx_interval;
00049 
00050   // Only if joining or recovering
00051   std::vector<uint8_t> startup_snapshot;
00052   size_t startup_snapshot_evidence_seqno;
00053 
00054   struct SignatureIntervals
00055   {
00056     size_t sig_tx_interval;
00057     size_t sig_ms_interval;
00058     MSGPACK_DEFINE(sig_tx_interval, sig_ms_interval);
00059   };
00060   SignatureIntervals signature_intervals = {};
00061 
00062   struct Genesis
00063   {
00064     std::vector<ccf::MemberPubInfo> members_info;
00065     std::string gov_script;
00066     size_t recovery_threshold;
00067     MSGPACK_DEFINE(members_info, gov_script, recovery_threshold);
00068   };
00069   Genesis genesis = {};
00070 
00071   struct Joining
00072   {
00073     std::string target_host;
00074     std::string target_port;
00075     std::vector<uint8_t> network_cert;
00076     size_t join_timer;
00077     MSGPACK_DEFINE(target_host, target_port, network_cert, join_timer);
00078   };
00079   Joining joining = {};
00080 
00081   std::string subject_name;
00082   std::vector<tls::SubjectAltName> subject_alternative_names;
00083 
00084   size_t jwt_key_refresh_interval_s;
00085 
00086   MSGPACK_DEFINE(
00087     consensus_config,
00088     node_info_network,
00089     domain,
00090     snapshot_tx_interval,
00091     startup_snapshot,
00092     startup_snapshot_evidence_seqno,
00093     signature_intervals,
00094     genesis,
00095     joining,
00096     subject_name,
00097     subject_alternative_names,
00098     jwt_key_refresh_interval_s);
00099 };
00100 
00101 /// General administrative messages
00102 enum AdminMessage : ringbuffer::Message
00103 {
00104   /// Log message. Enclave -> Host
00105   DEFINE_RINGBUFFER_MSG_TYPE(log_msg),
00106 
00107   /// Fatal error message. Enclave -> Host
00108   DEFINE_RINGBUFFER_MSG_TYPE(fatal_error_msg),
00109 
00110   /// Stop processing messages. Host -> Enclave
00111   DEFINE_RINGBUFFER_MSG_TYPE(stop),
00112 
00113   /// Stopped processing messages. Enclave -> Host
00114   DEFINE_RINGBUFFER_MSG_TYPE(stopped),
00115 
00116   /// Periodically update based on current time. Host -> Enclave
00117   DEFINE_RINGBUFFER_MSG_TYPE(tick),
00118 
00119   /// Notify the host of work done since last message. Enclave -> Host
00120 
00121 };
00122 
00123 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00124   AdminMessage::log_msg,
00125   std::chrono::milliseconds,
00126   std::string,
00127   size_t,
00128   logger::Level,
00129   uint16_t,
00130   std::string);
00131 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(AdminMessage::fatal_error_msg, std::string);
00132 DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD(AdminMessage::stop);
00133 DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD(AdminMessage::stopped);
00134 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(AdminMessage::tick, size_t);
00135 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(AdminMessage::work_stats, std::string);
00136 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/interface.h...
Preprocessing /data/git/CCF/src/enclave/main.cpp...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include ds/stacktrace_utils.h: not found! skipping...
#include app_interface.h: already included! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/oversized.h: not found! skipping...
#include enclave_time.h: already included! skipping...
#include interface.h: already included! skipping...
#include node/entities.h: not found! skipping...
#include node/historical_queries.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/node_state.h: not found! skipping...
#include node/node_types.h: not found! skipping...
#include node/rpc/forwarder.h: not found! skipping...
#include node/rpc/node_frontend.h: not found! skipping...
#include rpc_map.h: already included! skipping...
#include rpc_sessions.h: already included! skipping...
#include enclave_time.h: already included! skipping...
#include openenclave/edger8r/enclave.h: not found! skipping...
#include openenclave/enclave.h: not found! skipping...
#include chrono: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include thread: not found! skipping...
Preprocessor output (size: 4440 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/enclave/main.cpp" 2
00007 
00008 # 8 "/data/git/CCF/src/enclave/main.cpp" 2
00009 
00010 
00011 
00012 
00013 
00014 // the central enclave object
00015 static SpinLock create_lock;
00016 static std::atomic<enclave::Enclave*> e;
00017 
00018 
00019 
00020 
00021 std::atomic<std::chrono::milliseconds> logger::config::ms =
00022   std::chrono::milliseconds::zero();
00023 std::atomic<uint16_t> num_pending_threads = 0;
00024 std::atomic<uint16_t> num_complete_threads = 0;
00025 
00026 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00027 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00028 
00029 namespace enclave
00030 {
00031   std::atomic<std::chrono::microseconds>* host_time = nullptr;
00032   std::chrono::microseconds last_value(0);
00033 }
00034 
00035 extern "C"
00036 {
00037   bool enclave_create_node(
00038     void* enclave_config,
00039     char* ccf_config,
00040     size_t ccf_config_size,
00041     uint8_t* node_cert,
00042     size_t node_cert_size,
00043     size_t* node_cert_len,
00044     uint8_t* network_cert,
00045     size_t network_cert_size,
00046     size_t* network_cert_len,
00047     StartType start_type,
00048     ConsensusType consensus_type,
00049     size_t num_worker_threads,
00050     void* time_location)
00051   {
00052     std::lock_guard<SpinLock> guard(create_lock);
00053 
00054     if (e != nullptr)
00055     {
00056       return false;
00057     }
00058 
00059     num_pending_threads = (uint16_t)num_worker_threads + 1;
00060 
00061     if (
00062       num_pending_threads >
00063       threading::ThreadMessaging::thread_messaging.max_num_threads)
00064     {
00065       return false;
00066     }
00067 
00068     // Check that where we expect arguments to be in host-memory, they really
00069     // are. lfence after these checks to prevent speculative execution
00070     if (!oe_is_outside_enclave(time_location, sizeof(enclave::host_time)))
00071     {
00072       return false;
00073     }
00074 
00075     enclave::host_time =
00076       static_cast<decltype(enclave::host_time)>(time_location);
00077 
00078     if (!oe_is_outside_enclave(enclave_config, sizeof(EnclaveConfig)))
00079     {
00080       return false;
00081     }
00082 
00083     EnclaveConfig ec = *static_cast<EnclaveConfig*>(enclave_config);
00084 
00085     {
00086       // Check that ringbuffer memory ranges are entirely outside of the enclave
00087       if (!oe_is_outside_enclave(
00088             ec.to_enclave_buffer_start, ec.to_enclave_buffer_size))
00089       {
00090         return false;
00091       }
00092 
00093       if (!oe_is_outside_enclave(
00094             ec.from_enclave_buffer_start, ec.from_enclave_buffer_size))
00095       {
00096         return false;
00097       }
00098 
00099       if (!oe_is_outside_enclave(
00100             ec.to_enclave_buffer_offsets, sizeof(ringbuffer::Offsets)))
00101       {
00102         return false;
00103       }
00104 
00105       if (!oe_is_outside_enclave(
00106             ec.from_enclave_buffer_offsets, sizeof(ringbuffer::Offsets)))
00107       {
00108         return false;
00109       }
00110 
00111       oe_lfence();
00112     }
00113 
00114     if (!oe_is_outside_enclave(ccf_config, ccf_config_size))
00115     {
00116       return false;
00117     }
00118 
00119     oe_lfence();
00120 
00121     msgpack::object_handle oh = msgpack::unpack(ccf_config, ccf_config_size);
00122     msgpack::object obj = oh.get();
00123     CCFConfig cc;
00124     obj.convert(cc);
00125 
00126 
00127 
00128 
00129 
00130     auto enclave = new enclave::Enclave(
00131       ec, cc.signature_intervals, consensus_type, cc.consensus_config);
00132 
00133     bool result = enclave->create_new_node(
00134       start_type,
00135       cc,
00136       node_cert,
00137       node_cert_size,
00138       node_cert_len,
00139       network_cert,
00140       network_cert_size,
00141       network_cert_len);
00142     e.store(enclave);
00143 
00144     return result;
00145   }
00146 
00147   bool enclave_run()
00148   {
00149     if (e.load() != nullptr)
00150     {
00151       uint16_t tid;
00152       {
00153         std::lock_guard<SpinLock> guard(create_lock);
00154 
00155         tid = threading::ThreadMessaging::thread_count.fetch_add(1);
00156         threading::thread_ids.emplace(std::pair<std::thread::id, uint16_t>(
00157           std::this_thread::get_id(), tid));
00158         num_pending_threads.fetch_sub(1);
00159 
00160         LOG_INFO_FMT("Starting thread: {}", tid);
00161       }
00162 
00163       while (num_pending_threads != 0)
00164       {
00165       }
00166 
00167       LOG_INFO_FMT("All threads are ready!");
00168 
00169       if (tid == threading::MAIN_THREAD_ID)
00170       {
00171         auto s = e.load()->run_main();
00172         while (num_complete_threads !=
00173                threading::ThreadMessaging::thread_count - 1)
00174         {
00175         }
00176         // All threads are done, we can drop any remaining tasks safely and
00177         // completely
00178         threading::ThreadMessaging::thread_messaging.drop_tasks();
00179         return s;
00180       }
00181       else
00182       {
00183         auto s = e.load()->run_worker();
00184         num_complete_threads.fetch_add(1);
00185         return s;
00186       }
00187     }
00188     else
00189     {
00190       return false;
00191     }
00192   }
00193 }
00194 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/main.cpp...
Preprocessing /data/git/CCF/src/enclave/oe_shim.h...
#include openenclave/edger8r/enclave.h: not found! skipping...
#include openenclave/enclave.h: not found! skipping...
Preprocessor output (size: 172 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014  // For oe_lfence
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/oe_shim.h...
Preprocessing /data/git/CCF/src/enclave/rpc_context.h...
#include http/http_builder.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/rpc/error.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include variant: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 5740 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   static_assert(
00019     static_cast<int>(ws::Verb::WEBSOCKET) <
00020     static_cast<int>(llhttp_method::HTTP_DELETE));
00021   /*!
00022     Extension of llhttp_method including a special "WEBSOCKET" method,
00023     to allow make_*_endpoint() to be a single uniform interface to define
00024     handlers for either use cases.
00025 
00026     This may be removed if instead of exposing a single RpcContext, callbacks
00027     are instead given a specialised WsRpcContext, and make_endpoint becomes
00028     templated on Verb and specialised on the respective enum types.
00029   */
00030   class RESTVerb
00031   {
00032   private:
00033     int verb;
00034 
00035   public:
00036     RESTVerb() : verb(std::numeric_limits<int>::min()) {}
00037     RESTVerb(const llhttp_method& hm) : verb(hm) {}
00038     RESTVerb(const ws::Verb& wv) : verb(wv) {}
00039 
00040     std::optional<llhttp_method> get_http_method() const
00041     {
00042       if (verb == ws::WEBSOCKET)
00043       {
00044         return std::nullopt;
00045       }
00046 
00047       return static_cast<llhttp_method>(verb);
00048     }
00049 
00050     const char* c_str() const
00051     {
00052       if (verb == ws::WEBSOCKET)
00053       {
00054         return "WEBSOCKET";
00055       }
00056       else
00057       {
00058         return llhttp_method_name(static_cast<llhttp_method>(verb));
00059       }
00060     }
00061 
00062     bool operator<(const RESTVerb& o) const
00063     {
00064       return verb < o.verb;
00065     }
00066 
00067     bool operator==(const RESTVerb& o) const
00068     {
00069       return verb == o.verb;
00070     }
00071 
00072     bool operator!=(const RESTVerb& o) const
00073     {
00074       return !(*this == o);
00075     }
00076 
00077     MSGPACK_DEFINE(verb);
00078   };
00079 
00080   // Custom to_json and from_json specializations which encode RESTVerb in a
00081   // lower-cased string, so it can be used in OpenAPI and similar documents
00082   inline void to_json(nlohmann::json& j, const RESTVerb& verb)
00083   {
00084     std::string s(verb.c_str());
00085     nonstd::to_lower(s);
00086     j = s;
00087   }
00088 
00089   inline void from_json(const nlohmann::json& j, RESTVerb& verb)
00090   {
00091     if (!j.is_string())
00092     {
00093       throw std::runtime_error(fmt::format(
00094         "Cannot parse RESTVerb from non-string JSON value: {}", j.dump()));
00095     }
00096 
00097     std::string s = j.get<std::string>();
00098     nonstd::to_upper(s);
00099 
00100     if (s == "WEBSOCKET")
00101     {
00102       verb = RESTVerb(ws::Verb::WEBSOCKET);
00103     }
00104     else
00105     {
00106       verb = RESTVerb(http::http_method_from_str(s.c_str()));
00107     }
00108   }
00109 }
00110 
00111 namespace enclave
00112 {
00113   static constexpr size_t InvalidSessionId = std::numeric_limits<size_t>::max();
00114 
00115   struct SessionContext
00116   {
00117     size_t client_session_id = InvalidSessionId;
00118     // Usually a DER certificate, may be a PEM on forwardee
00119     std::vector<uint8_t> caller_cert = {};
00120     bool is_forwarding = false;
00121 
00122     //
00123     // Only set in the case of a forwarded RPC
00124     //
00125     bool is_forwarded = false;
00126 
00127     SessionContext(
00128       size_t client_session_id_, const std::vector<uint8_t>& caller_cert_) :
00129       client_session_id(client_session_id_),
00130       caller_cert(caller_cert_)
00131     {}
00132   };
00133 
00134   using PathParams = std::map<std::string, std::string>;
00135 
00136   class RpcContext
00137   {
00138   public:
00139     std::shared_ptr<SessionContext> session;
00140 
00141     virtual FrameFormat frame_format() const = 0;
00142 
00143     // raw bft Request
00144     std::vector<uint8_t> bft_raw = {};
00145 
00146     bool is_create_request = false;
00147     bool execute_on_node = false;
00148 
00149     RpcContext(std::shared_ptr<SessionContext> s) : session(s) {}
00150 
00151     RpcContext(
00152       std::shared_ptr<SessionContext> s, const std::vector<uint8_t>& bft_raw_) :
00153       session(s),
00154       bft_raw(bft_raw_)
00155     {}
00156 
00157     virtual ~RpcContext() {}
00158 
00159     /// Request details
00160     virtual size_t get_request_index() const = 0;
00161 
00162     virtual const std::vector<uint8_t>& get_request_body() const = 0;
00163     virtual const std::string& get_request_query() const = 0;
00164     virtual PathParams& get_request_path_params() = 0;
00165     virtual const ccf::RESTVerb& get_request_verb() const = 0;
00166     virtual std::string get_request_path() const = 0;
00167 
00168     virtual std::string get_method() const = 0;
00169     virtual void set_method(const std::string_view& method) = 0;
00170 
00171     virtual const http::HeaderMap& get_request_headers() const = 0;
00172     virtual std::optional<std::string> get_request_header(
00173       const std::string_view& name) = 0;
00174 
00175     virtual const std::vector<uint8_t>& get_serialised_request() = 0;
00176 
00177     /// Response details
00178     virtual void set_response_body(const std::vector<uint8_t>& body) = 0;
00179     virtual void set_response_body(std::vector<uint8_t>&& body) = 0;
00180     virtual void set_response_body(std::string&& body) = 0;
00181 
00182     virtual void set_response_status(int status) = 0;
00183     virtual int get_response_status() const = 0;
00184 
00185     virtual void set_seqno(kv::Version) = 0;
00186     virtual void set_view(kv::Consensus::View) = 0;
00187     virtual void set_global_commit(kv::Version) = 0;
00188 
00189     virtual void set_response_header(
00190       const std::string_view& name, const std::string_view& value) = 0;
00191     virtual void set_response_header(const std::string_view& name, size_t n)
00192     {
00193       set_response_header(name, fmt::format("{}", n));
00194     }
00195 
00196     virtual void set_error(
00197       http_status status, const std::string& code, std::string&& msg)
00198     {
00199       set_error({status, code, std::move(msg)});
00200     }
00201 
00202     virtual void set_error(ccf::ErrorDetails&& error)
00203     {
00204       nlohmann::json body = ccf::ODataErrorResponse{
00205         ccf::ODataError{std::move(error.code), std::move(error.msg)}};
00206       const auto s = body.dump();
00207       set_response_status(error.status);
00208       set_response_body(std::vector<uint8_t>(s.begin(), s.end()));
00209       set_response_header(
00210         http::headers::CONTENT_TYPE, http::headervalues::contenttype::JSON);
00211     }
00212 
00213     virtual void set_apply_writes(bool apply) = 0;
00214     virtual bool should_apply_writes() const = 0;
00215 
00216     virtual std::vector<uint8_t> serialise_response() const = 0;
00217   };
00218 }
00219 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/rpc_context.h...
Preprocessing /data/git/CCF/src/enclave/rpc_handler.h...
#include ds/buffer.h: not found! skipping...
#include forwarder_types.h: already included! skipping...
#include chrono: not found! skipping...
#include limits: not found! skipping...
#include stdint.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1091 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace kv
00013 {
00014   class Tx;
00015 }
00016 
00017 namespace enclave
00018 {
00019   class RpcHandler
00020   {
00021   public:
00022     virtual ~RpcHandler() {}
00023 
00024     // Used by enclave to initialise and tick frontends
00025     virtual void set_sig_intervals(
00026       size_t sig_tx_interval, size_t sig_ms_interval) = 0;
00027     virtual void set_cmd_forwarder(
00028       std::shared_ptr<AbstractForwarder> cmd_forwarder_) = 0;
00029     virtual void tick(std::chrono::milliseconds) {}
00030     virtual void open(std::optional<tls::Pem*> identity = std::nullopt) = 0;
00031     virtual bool is_open(kv::Tx& tx) = 0;
00032 
00033     // Used by rpcendpoint to process incoming client RPCs
00034     virtual std::optional<std::vector<uint8_t>> process(
00035       std::shared_ptr<RpcContext> ctx) = 0;
00036 
00037     // Used by BFT to execute commands
00038     struct ProcessBftResp
00039     {
00040       std::vector<uint8_t> result;
00041       kv::Version version;
00042     };
00043 
00044     virtual ProcessBftResp process_bft(
00045       std::shared_ptr<enclave::RpcContext> ctx) = 0;
00046     virtual void update_merkle_tree() = 0;
00047   };
00048 }
00049 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/rpc_handler.h...
Preprocessing /data/git/CCF/src/enclave/rpc_map.h...
#include node/entities.h: not found! skipping...
#include rpc_handler.h: already included! skipping...
Preprocessor output (size: 1025 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace enclave
00009 {
00010   class RPCMap
00011   {
00012   private:
00013     std::unordered_map<ccf::ActorsType, std::shared_ptr<RpcHandler>> map;
00014     std::map<std::string, ccf::ActorsType> actors_map;
00015 
00016   public:
00017     RPCMap() = default;
00018 
00019     template <ccf::ActorsType T>
00020     void register_frontend(std::shared_ptr<RpcHandler> handler_)
00021     {
00022       const auto name = get_actor_prefix(T);
00023       actors_map.emplace(name, T);
00024       map.emplace(T, handler_);
00025     }
00026 
00027     ccf::ActorsType resolve(const std::string& name)
00028     {
00029       auto search = actors_map.find(name);
00030       if (search == actors_map.end())
00031         return ccf::ActorsType::unknown;
00032 
00033       return search->second;
00034     }
00035 
00036     std::optional<std::shared_ptr<RpcHandler>> find(ccf::ActorsType index)
00037     {
00038       auto search = map.find(index);
00039       if (search == map.end())
00040         return {};
00041 
00042       return search->second;
00043     }
00044 
00045     auto& get_map()
00046     {
00047       return map;
00048     }
00049   };
00050 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/rpc_map.h...
Preprocessing /data/git/CCF/src/enclave/rpc_sessions.h...
#include ds/logger.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include forwarder_types.h: already included! skipping...
#include http/http_endpoint.h: not found! skipping...
#include rpc_handler.h: already included! skipping...
#include tls/cert.h: not found! skipping...
#include tls/client.h: not found! skipping...
#include tls/context.h: not found! skipping...
#include tls/server.h: not found! skipping...
#include limits: not found! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 4863 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 namespace enclave
00019 {
00020   using ServerEndpointImpl = http::HTTPServerEndpoint;
00021   using ClientEndpointImpl = http::HTTPClientEndpoint;
00022 
00023   class RPCSessions : public AbstractRPCResponder
00024   {
00025   private:
00026     static constexpr size_t max_open_sessions = 1000;
00027 
00028     ringbuffer::AbstractWriterFactory& writer_factory;
00029     ringbuffer::WriterPtr to_host = nullptr;
00030     std::shared_ptr<RPCMap> rpc_map;
00031     std::shared_ptr<tls::Cert> cert;
00032 
00033     SpinLock lock;
00034     std::unordered_map<size_t, std::shared_ptr<Endpoint>> sessions;
00035 
00036     // Upper half of sessions range is reserved for those originating from
00037     // the enclave via create_client().
00038     std::atomic<size_t> next_client_session_id =
00039       std::numeric_limits<size_t>::max() / 2;
00040 
00041   public:
00042     RPCSessions(
00043       ringbuffer::AbstractWriterFactory& writer_factory,
00044       std::shared_ptr<RPCMap> rpc_map_) :
00045       writer_factory(writer_factory),
00046       rpc_map(rpc_map_)
00047     {
00048       to_host = writer_factory.create_writer_to_outside();
00049     }
00050 
00051     void set_cert(const tls::Pem& cert_, const tls::Pem& pk)
00052     {
00053       std::lock_guard<SpinLock> guard(lock);
00054 
00055       // Caller authentication is done by each frontend by looking up
00056       // the caller's certificate in the relevant store table. The caller
00057       // certificate does not have to be signed by a known CA (nullptr,
00058       // tls::auth_optional).
00059       cert = std::make_shared<tls::Cert>(
00060         nullptr, cert_, pk, nullb, tls::auth_optional);
00061     }
00062 
00063     void accept(size_t id)
00064     {
00065       std::lock_guard<SpinLock> guard(lock);
00066 
00067       if (sessions.find(id) != sessions.end())
00068         throw std::logic_error(
00069           "Duplicate conn ID received inside enclave: " + std::to_string(id));
00070 
00071       if (sessions.size() >= max_open_sessions)
00072       {
00073         LOG_INFO_FMT(
00074           "Refusing a session inside the enclave - already have {} sessions "
00075           "and limit is {}: {}",
00076           sessions.size(),
00077           max_open_sessions,
00078           id);
00079 
00080         RINGBUFFER_WRITE_MESSAGE(
00081           tls::tls_stop, to_host, id, std::string("Session refused"));
00082         return;
00083       }
00084 
00085       LOG_DEBUG_FMT("Accepting a session inside the enclave: {}", id);
00086       auto ctx = std::make_unique<tls::Server>(cert);
00087 
00088       auto session = std::make_shared<ServerEndpointImpl>(
00089         rpc_map, id, writer_factory, std::move(ctx));
00090       sessions.insert(std::make_pair(id, std::move(session)));
00091     }
00092 
00093     bool reply_async(size_t id, std::vector<uint8_t>&& data) override
00094     {
00095       std::lock_guard<SpinLock> guard(lock);
00096 
00097       auto search = sessions.find(id);
00098       if (search == sessions.end())
00099       {
00100         LOG_FAIL_FMT("Replying to unknown session {}", id);
00101         return false;
00102       }
00103 
00104       LOG_DEBUG_FMT("Replying to session {}", id);
00105 
00106       search->second->send(std::move(data));
00107       return true;
00108     }
00109 
00110     void remove_session(size_t id)
00111     {
00112       std::lock_guard<SpinLock> guard(lock);
00113       LOG_DEBUG_FMT("Closing a session inside the enclave: {}", id);
00114       sessions.erase(id);
00115     }
00116 
00117     std::shared_ptr<ClientEndpoint> create_client(
00118       std::shared_ptr<tls::Cert> cert)
00119     {
00120       std::lock_guard<SpinLock> guard(lock);
00121       auto ctx = std::make_unique<tls::Client>(cert);
00122       auto id = ++next_client_session_id;
00123 
00124       LOG_DEBUG_FMT("Creating a new client session inside the enclave: {}", id);
00125 
00126       auto session = std::make_shared<ClientEndpointImpl>(
00127         id, writer_factory, std::move(ctx));
00128 
00129       // We do not check the max_open_sessions limit here, because we expect
00130       // this type of session to be rare and want it to succeed even when we are
00131       // busy.
00132       sessions.insert(std::make_pair(id, session));
00133       return session;
00134     }
00135 
00136     void register_message_handlers(
00137       messaging::Dispatcher<ringbuffer::Message>& disp)
00138     {
00139       DISPATCHER_SET_MESSAGE_HANDLER(
00140         disp, tls::tls_start, [this](const uint8_t* data, size_t size) {
00141           auto [id] = ringbuffer::read_message<tls::tls_start>(data, size);
00142           accept(id);
00143         });
00144 
00145       DISPATCHER_SET_MESSAGE_HANDLER(
00146         disp, tls::tls_inbound, [this](const uint8_t* data, size_t size) {
00147           auto [id, body] =
00148             ringbuffer::read_message<tls::tls_inbound>(data, size);
00149 
00150           auto search = sessions.find(id);
00151           if (search == sessions.end())
00152           {
00153             LOG_DEBUG_FMT(
00154               "Ignoring tls_inbound for unknown or refused session: {}", id);
00155             return;
00156           }
00157 
00158           search->second->recv(body.data, body.size);
00159         });
00160 
00161       DISPATCHER_SET_MESSAGE_HANDLER(
00162         disp, tls::tls_close, [this](const uint8_t* data, size_t size) {
00163           auto [id] = ringbuffer::read_message<tls::tls_close>(data, size);
00164           remove_session(id);
00165         });
00166     }
00167   };
00168 }
00169 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/rpc_sessions.h...
Preprocessing /data/git/CCF/src/enclave/snmalloc.cpp...
#include snmalloc/src/override/malloc.cc: not found! skipping...
#include snmalloc/src/override/new.cc: not found! skipping...
Preprocessor output (size: 138 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 #define NO_BOOTSTRAP_ALLOCATOR
00005 
00006 
00007 
00008 
---------
Macros accessible in this file:
---------
NO_BOOTSTRAP_ALLOCATOR 
---------
Parsing file /data/git/CCF/src/enclave/snmalloc.cpp...
Preprocessing /data/git/CCF/src/enclave/start_type.h...
Preprocessor output (size: 178 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 enum StartType
00006 {
00007   New = 1,
00008   Join = 2,
00009   Recover = 3,
00010   Unknown = 100
00011 };
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/start_type.h...
Preprocessing /data/git/CCF/src/enclave/thread_local.cpp...
#include ds/thread_ids.h: not found! skipping...
Preprocessor output (size: 178 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 namespace threading
00006 {
00007   std::map<std::thread::id, uint16_t> thread_ids;
00008 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/thread_local.cpp...
Preprocessing /data/git/CCF/src/enclave/tls_endpoint.h...
#include ds/logger.h: not found! skipping...
#include ds/messaging.h: not found! skipping...
#include ds/ring_buffer.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include vector: not found! skipping...
#include tls/context.h: not found! skipping...
#include tls/msg_types.h: not found! skipping...
#include exception: not found! skipping...
Preprocessor output (size: 14066 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 # 9 "/data/git/CCF/src/enclave/tls_endpoint.h" 2
00010 
00011 
00012 
00013 
00014 
00015 namespace enclave
00016 {
00017   class TLSEndpoint : public Endpoint
00018   {
00019   protected:
00020     ringbuffer::WriterPtr to_host;
00021     size_t session_id;
00022     size_t execution_thread;
00023 
00024     enum Status
00025     {
00026       handshake,
00027       ready,
00028       closed,
00029       authfail,
00030       error
00031     };
00032 
00033     Status get_status() const
00034     {
00035       return status;
00036     }
00037 
00038     virtual std::vector<uint8_t> oversized_message_error(
00039       size_t msg_size, size_t max_msg_size)
00040     {
00041       const auto s = fmt::format(
00042         "Requested message ({} bytes) is too large. Maximum allowed is {} "
00043         "bytes. Closing connection.",
00044         msg_size,
00045         max_msg_size);
00046       const auto data = (const uint8_t*)s.data();
00047       return std::vector<uint8_t>(data, data + s.size());
00048     }
00049 
00050   private:
00051     std::vector<uint8_t> pending_write;
00052     std::vector<uint8_t> pending_read;
00053     // Decrypted data, read through mbedtls
00054     std::vector<uint8_t> read_buffer;
00055 
00056     std::unique_ptr<tls::Context> ctx;
00057     Status status;
00058 
00059   public:
00060     TLSEndpoint(
00061       size_t session_id_,
00062       ringbuffer::AbstractWriterFactory& writer_factory_,
00063       std::unique_ptr<tls::Context> ctx_) :
00064       to_host(writer_factory_.create_writer_to_outside()),
00065       session_id(session_id_),
00066       ctx(move(ctx_)),
00067       status(handshake)
00068     {
00069       if (threading::ThreadMessaging::thread_count > 1)
00070       {
00071         execution_thread =
00072           (session_id_ % (threading::ThreadMessaging::thread_count - 1)) + 1;
00073       }
00074       else
00075       {
00076         execution_thread = threading::MAIN_THREAD_ID;
00077       }
00078       ctx->set_bio(this, send_callback, recv_callback, dbg_callback);
00079     }
00080 
00081     ~TLSEndpoint()
00082     {
00083       RINGBUFFER_WRITE_MESSAGE(tls::tls_closed, to_host, session_id);
00084     }
00085 
00086     std::string hostname()
00087     {
00088       if (status != ready)
00089       {
00090         return {};
00091       }
00092 
00093       return ctx->host();
00094     }
00095 
00096     std::vector<uint8_t> peer_cert()
00097     {
00098       if (status != ready)
00099       {
00100         return {};
00101       }
00102 
00103       auto client_cert = ctx->peer_cert();
00104       if (client_cert == nullptr)
00105       {
00106         return {};
00107       }
00108 
00109       return std::vector<uint8_t>(
00110         client_cert->raw.p, client_cert->raw.p + client_cert->raw.len);
00111     }
00112 
00113     // Returns count N of bytes read, which will be the first N bytes of data,
00114     // up to a maximum of size. If exact is true, will only return either size
00115     // or 0 (when size bytes are not currently available). data may be accessed
00116     // beyond N during operation, up to size, but only the first N should be
00117     // used by caller.
00118     size_t read(uint8_t* data, size_t size, bool exact = false)
00119     {
00120       LOG_TRACE_FMT("Requesting up to {} bytes", size);
00121 
00122       // This will return empty if the connection isn't
00123       // ready, but it will not block on the handshake.
00124       do_handshake();
00125 
00126       if (status != ready)
00127       {
00128         return 0;
00129       }
00130 
00131       // Send pending writes.
00132       flush();
00133 
00134       size_t offset = 0;
00135 
00136       if (read_buffer.size() > 0)
00137       {
00138         LOG_TRACE_FMT(
00139           "Have existing read_buffer of size: {}", read_buffer.size());
00140         offset = std::min(size, read_buffer.size());
00141         ::memcpy(data, read_buffer.data(), offset);
00142 
00143         if (offset < read_buffer.size())
00144           read_buffer.erase(read_buffer.begin(), read_buffer.begin() + offset);
00145         else
00146           read_buffer.clear();
00147 
00148         if (offset == size)
00149           return size;
00150 
00151         // NB: If we continue past here, read_buffer is empty
00152       }
00153 
00154       auto r = ctx->read(data + offset, size - offset);
00155       LOG_TRACE_FMT("ctx->read returned: {}", r);
00156 
00157       switch (r)
00158       {
00159         case 0:
00160         case MBEDTLS_ERR_NET_CONN_RESET:
00161         case MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY:
00162         {
00163           LOG_TRACE_FMT("TLS {} on read: {}", session_id, tls::error_string(r));
00164 
00165           stop(closed);
00166 
00167           if (!exact)
00168           {
00169             // Hit an error, but may still have some useful data from the
00170             // previous read_buffer
00171             return offset;
00172           }
00173 
00174           return 0;
00175         }
00176 
00177         case MBEDTLS_ERR_SSL_WANT_READ:
00178         case MBEDTLS_ERR_SSL_WANT_WRITE:
00179         {
00180           if (!exact)
00181           {
00182             return offset;
00183           }
00184 
00185           // May have read something but not enough - copy it into read_buffer
00186           // for next call
00187           read_buffer.insert(read_buffer.end(), data, data + offset);
00188           return 0;
00189         }
00190 
00191         default:
00192         {
00193         }
00194       }
00195 
00196       if (r < 0)
00197       {
00198         LOG_TRACE_FMT("TLS {} on read: {}", session_id, tls::error_string(r));
00199         stop(error);
00200         return 0;
00201       }
00202 
00203       auto total = r + offset;
00204 
00205       // We read _some_ data but not enough, and didn't get
00206       // MBEDTLS_ERR_SSL_WANT_READ. Probably hit an internal size limit - try
00207       // again
00208       if (exact && (total < size))
00209       {
00210         LOG_TRACE_FMT(
00211           "Asked for exactly {}, received {}, retrying", size, total);
00212         read_buffer.insert(read_buffer.end(), data, data + total);
00213         return read(data, size, exact);
00214       }
00215 
00216       return total;
00217     }
00218 
00219     void recv_buffered(const uint8_t* data, size_t size)
00220     {
00221       if (threading::get_current_thread_id() != execution_thread)
00222       {
00223         throw std::exception();
00224       }
00225       pending_read.insert(pending_read.end(), data, data + size);
00226       do_handshake();
00227     }
00228 
00229     struct SendRecvMsg
00230     {
00231       std::vector<uint8_t> data;
00232       std::shared_ptr<Endpoint> self;
00233     };
00234 
00235     static void send_raw_cb(std::unique_ptr<threading::Tmsg<SendRecvMsg>> msg)
00236     {
00237       reinterpret_cast<TLSEndpoint*>(msg->data.self.get())
00238         ->send_raw_thread(msg->data.data);
00239     }
00240 
00241     void send_raw(std::vector<uint8_t>&& data)
00242     {
00243       auto msg = std::make_unique<threading::Tmsg<SendRecvMsg>>(&send_raw_cb);
00244       msg->data.self = this->shared_from_this();
00245       msg->data.data = std::move(data);
00246 
00247       threading::ThreadMessaging::thread_messaging.add_task(
00248         execution_thread, std::move(msg));
00249     }
00250 
00251     void send_raw_thread(const std::vector<uint8_t>& data)
00252     {
00253       if (threading::get_current_thread_id() != execution_thread)
00254       {
00255         throw std::runtime_error(
00256           "Called send_raw_thread from incorrect thread");
00257       }
00258       // Writes as much of the data as possible. If the data cannot all
00259       // be written now, we store the remainder. We
00260       // will try to send pending writes again whenever write() is called.
00261       do_handshake();
00262 
00263       if (status == handshake)
00264       {
00265         pending_write.insert(pending_write.end(), data.begin(), data.end());
00266         return;
00267       }
00268 
00269       if (status != ready)
00270         return;
00271 
00272       pending_write.insert(pending_write.end(), data.begin(), data.end());
00273 
00274       flush();
00275     }
00276 
00277     void send_buffered(const std::vector<uint8_t>& data)
00278     {
00279       if (threading::get_current_thread_id() != execution_thread)
00280       {
00281         throw std::runtime_error("Called send_buffered from incorrect thread");
00282       }
00283 
00284       pending_write.insert(pending_write.end(), data.begin(), data.end());
00285     }
00286 
00287     void flush()
00288     {
00289       if (threading::get_current_thread_id() != execution_thread)
00290       {
00291         throw std::runtime_error("Called flush from incorrect thread");
00292       }
00293 
00294       do_handshake();
00295 
00296       if (status != ready)
00297         return;
00298 
00299       while (pending_write.size() > 0)
00300       {
00301         auto r = write_some(pending_write);
00302 
00303         if (r > 0)
00304         {
00305           pending_write.erase(pending_write.begin(), pending_write.begin() + r);
00306         }
00307         else if (r == 0)
00308         {
00309           break;
00310         }
00311         else
00312         {
00313           LOG_TRACE_FMT(
00314             "TLS {} on flush: {}", session_id, tls::error_string(r));
00315           stop(error);
00316         }
00317       }
00318     }
00319 
00320     struct EmptyMsg
00321     {
00322       std::shared_ptr<Endpoint> self;
00323     };
00324 
00325     static void close_cb(std::unique_ptr<threading::Tmsg<EmptyMsg>> msg)
00326     {
00327       reinterpret_cast<TLSEndpoint*>(msg->data.self.get())->close_thread();
00328     }
00329 
00330     void close()
00331     {
00332       auto msg = std::make_unique<threading::Tmsg<EmptyMsg>>(&close_cb);
00333       msg->data.self = this->shared_from_this();
00334 
00335       threading::ThreadMessaging::thread_messaging.add_task(
00336         execution_thread, std::move(msg));
00337     }
00338 
00339     void close_thread()
00340     {
00341       if (threading::get_current_thread_id() != execution_thread)
00342       {
00343         throw std::runtime_error("Called close_thread from incorrect thread");
00344       }
00345 
00346       switch (status)
00347       {
00348         case handshake:
00349         {
00350           LOG_TRACE_FMT("TLS {} closed during handshake", session_id);
00351           stop(closed);
00352           break;
00353         }
00354 
00355         case ready:
00356         {
00357           int r = ctx->close();
00358 
00359           switch (r)
00360           {
00361             case 0:
00362             case MBEDTLS_ERR_SSL_WANT_READ:
00363             case MBEDTLS_ERR_SSL_WANT_WRITE:
00364             {
00365               // mbedtls may return 0 when a close notify has not been
00366               // sent. This can't be disambiguated from a successful
00367               // close notify, so treat them the same.
00368               LOG_TRACE_FMT("TLS {} closed ({})", session_id, r);
00369               stop(closed);
00370               break;
00371             }
00372 
00373             default:
00374             {
00375               LOG_TRACE_FMT(
00376                 "TLS {} on_close: {}", session_id, tls::error_string(r));
00377               stop(error);
00378               break;
00379             }
00380           }
00381           break;
00382         }
00383 
00384         default:
00385         {
00386         }
00387       }
00388     }
00389 
00390   private:
00391     void do_handshake()
00392     {
00393       // This should be called when additional data is written to the
00394       // input buffer, until the handshake is complete.
00395       if (status != handshake)
00396         return;
00397 
00398       auto rc = ctx->handshake();
00399 
00400       switch (rc)
00401       {
00402         case 0:
00403         {
00404           status = ready;
00405           break;
00406         }
00407 
00408         case MBEDTLS_ERR_SSL_WANT_READ:
00409         case MBEDTLS_ERR_SSL_WANT_WRITE:
00410           break;
00411 
00412         case MBEDTLS_ERR_SSL_NO_CLIENT_CERTIFICATE:
00413         case MBEDTLS_ERR_SSL_PEER_VERIFY_FAILED:
00414         {
00415           LOG_TRACE_FMT(
00416             "TLS {} on handshake: {}", session_id, tls::error_string(rc));
00417           stop(authfail);
00418           break;
00419         }
00420 
00421         case MBEDTLS_ERR_SSL_PEER_CLOSE_NOTIFY:
00422         {
00423           LOG_TRACE_FMT(
00424             "TLS {} on handshake: {}", session_id, tls::error_string(rc));
00425           stop(closed);
00426           break;
00427         }
00428 
00429         case MBEDTLS_ERR_X509_CERT_VERIFY_FAILED:
00430         {
00431           std::vector<char> buf(512);
00432           auto r = mbedtls_x509_crt_verify_info(
00433             buf.data(),
00434             buf.size(),
00435             "Cert verify failed: ",
00436             ctx->verify_result());
00437 
00438           if (r > 0)
00439           {
00440             buf.resize(r);
00441             LOG_TRACE_FMT(
00442               "Certificate verify failed: {}",
00443               std::string(buf.data(), buf.size()));
00444           }
00445 
00446           LOG_TRACE_FMT(
00447             "TLS {} on handshake: {}", session_id, tls::error_string(rc));
00448           stop(authfail);
00449           return;
00450         }
00451 
00452         default:
00453         {
00454           LOG_TRACE_FMT(
00455             "TLS {} on handshake: {}", session_id, tls::error_string(rc));
00456           stop(error);
00457           break;
00458         }
00459       }
00460     }
00461 
00462     int write_some(const std::vector<uint8_t>& data)
00463     {
00464       auto r = ctx->write(data.data(), data.size());
00465 
00466       switch (r)
00467       {
00468         case MBEDTLS_ERR_SSL_WANT_READ:
00469         case MBEDTLS_ERR_SSL_WANT_WRITE:
00470           return 0;
00471 
00472         default:
00473           return r;
00474       }
00475     }
00476 
00477     void stop(Status status_)
00478     {
00479       switch (status)
00480       {
00481         case closed:
00482         case authfail:
00483         case error:
00484           return;
00485 
00486         default:
00487         {
00488         }
00489       }
00490 
00491       status = status_;
00492 
00493       switch (status)
00494       {
00495         case closed:
00496         {
00497           RINGBUFFER_WRITE_MESSAGE(
00498             tls::tls_stop, to_host, session_id, std::string("Session closed"));
00499           break;
00500         }
00501 
00502         case authfail:
00503         {
00504           RINGBUFFER_WRITE_MESSAGE(
00505             tls::tls_stop,
00506             to_host,
00507             session_id,
00508             std::string("Authentication failed"));
00509         }
00510         case error:
00511         {
00512           RINGBUFFER_WRITE_MESSAGE(
00513             tls::tls_stop, to_host, session_id, std::string("Error"));
00514           break;
00515         }
00516 
00517         default:
00518         {
00519         }
00520       }
00521     }
00522 
00523     int handle_send(const uint8_t* buf, size_t len)
00524     {
00525       // Either write all of the data or none of it.
00526       auto wrote = RINGBUFFER_TRY_WRITE_MESSAGE(
00527         tls::tls_outbound,
00528         to_host,
00529         session_id,
00530         serializer::ByteRange{buf, len});
00531 
00532       if (!wrote)
00533         return MBEDTLS_ERR_SSL_WANT_WRITE;
00534 
00535       return (int)len;
00536     }
00537 
00538     int handle_recv(uint8_t* buf, size_t len)
00539     {
00540       if (threading::get_current_thread_id() != execution_thread)
00541       {
00542         throw std::runtime_error("Called handle_recv from incorrect thread");
00543       }
00544       if (pending_read.size() > 0)
00545       {
00546         // Use the pending data vector. This is populated when the host
00547         // writes a chunk larger than the size requested by the enclave.
00548         size_t rd = std::min(len, pending_read.size());
00549         ::memcpy(buf, pending_read.data(), rd);
00550 
00551         if (rd >= pending_read.size())
00552         {
00553           pending_read.clear();
00554         }
00555         else
00556         {
00557           pending_read.erase(pending_read.begin(), pending_read.begin() + rd);
00558         }
00559 
00560         return (int)rd;
00561       }
00562 
00563       return MBEDTLS_ERR_SSL_WANT_READ;
00564     }
00565 
00566     static int send_callback(void* ctx, const unsigned char* buf, size_t len)
00567     {
00568       return reinterpret_cast<TLSEndpoint*>(ctx)->handle_send(buf, len);
00569     }
00570 
00571     static int recv_callback(void* ctx, unsigned char* buf, size_t len)
00572     {
00573       return reinterpret_cast<TLSEndpoint*>(ctx)->handle_recv(buf, len);
00574     }
00575 
00576     static void dbg_callback(
00577       void*, int, const char* file, int line, const char* str)
00578     {
00579       LOG_DEBUG_FMT("{}:{}: {}", file, line, str);
00580     }
00581   };
00582 }
00583 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/enclave/tls_endpoint.h...
Preprocessing /data/git/CCF/src/host/after_io.h...
#include uv.h: not found! skipping...
Preprocessor output (size: 1089 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/host/after_io.h" 2
00006 
00007 namespace asynchost
00008 {
00009   template <typename Behaviour>
00010   class AfterIO : public with_uv_handle<uv_check_t>
00011   {
00012   private:
00013     friend class close_ptr<AfterIO<Behaviour>>;
00014     Behaviour behaviour;
00015 
00016     template <typename... Args>
00017     AfterIO(Args&&... args) : behaviour(std::forward<Args>(args)...)
00018     {
00019       int rc;
00020 
00021       if ((rc = uv_check_init(uv_default_loop(), &uv_handle)) < 0)
00022       {
00023         LOG_FAIL_FMT("uv_check_init failed: {}", uv_strerror(rc));
00024         throw std::logic_error("uv_check_init failed");
00025       }
00026 
00027       uv_handle.data = this;
00028 
00029       if ((rc = uv_check_start(&uv_handle, on_check)) < 0)
00030       {
00031         LOG_FAIL_FMT("uv_check_start failed: {}", uv_strerror(rc));
00032         throw std::logic_error("uv_check_start failed");
00033       }
00034     }
00035 
00036     static void on_check(uv_check_t* handle)
00037     {
00038       static_cast<AfterIO*>(handle->data)->on_check();
00039     }
00040 
00041     void on_check()
00042     {
00043       behaviour.after_io();
00044     }
00045   };
00046 }
00047 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/after_io.h...
Preprocessing /data/git/CCF/src/host/before_io.h...
#include proxy.h: already included! skipping...
Preprocessor output (size: 1077 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace asynchost
00008 {
00009   template <typename Behaviour>
00010   class BeforeIO : public with_uv_handle<uv_prepare_t>
00011   {
00012   private:
00013     friend class close_ptr<BeforeIO<Behaviour>>;
00014     Behaviour behaviour;
00015 
00016     template <typename... Args>
00017     BeforeIO(Args&&... args) : behaviour(std::forward<Args>(args)...)
00018     {
00019       int rc;
00020 
00021       if ((rc = uv_prepare_init(uv_default_loop(), &uv_handle)) < 0)
00022       {
00023         LOG_FAIL_FMT("uv_prepare_init failed: {}", uv_strerror(rc));
00024         throw std::logic_error("uv_prepare_init failed");
00025       }
00026 
00027       uv_handle.data = this;
00028 
00029       if ((rc = uv_prepare_start(&uv_handle, on_prepare)) < 0)
00030       {
00031         LOG_FAIL_FMT("uv_prepare_start failed: {}", uv_strerror(rc));
00032         throw std::logic_error("uv_prepare_start failed");
00033       }
00034     }
00035 
00036     static void on_prepare(uv_prepare_t* handle)
00037     {
00038       static_cast<BeforeIO*>(handle->data)->on_prepare();
00039     }
00040 
00041     void on_prepare()
00042     {
00043       behaviour.before_io();
00044     }
00045   };
00046 }
00047 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/before_io.h...
Preprocessing /data/git/CCF/src/host/dns.h...
#include ../ds/logger.h: already included! skipping...
#include uv.h: not found! skipping...
Preprocessor output (size: 1609 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace asynchost
00010 {
00011   class DNS
00012   {
00013   public:
00014     static bool resolve(
00015       const std::string& host,
00016       const std::string& service,
00017       void* ud,
00018       uv_getaddrinfo_cb cb,
00019       bool async)
00020     {
00021       struct addrinfo hints;
00022       hints.ai_family = AF_UNSPEC;
00023       hints.ai_socktype = SOCK_STREAM;
00024       hints.ai_protocol = IPPROTO_TCP;
00025       hints.ai_flags = 0;
00026 
00027       auto resolver = new uv_getaddrinfo_t;
00028       resolver->data = ud;
00029 
00030       int rc;
00031 
00032       if (async)
00033       {
00034         if (
00035           (rc = uv_getaddrinfo(
00036              uv_default_loop(),
00037              resolver,
00038              cb,
00039              host.c_str(),
00040              service.c_str(),
00041              &hints)) < 0)
00042         {
00043           LOG_FAIL_FMT(
00044             "uv_getaddrinfo for host:service [{}:{}] failed (async) with error "
00045             "{}",
00046             host,
00047             service,
00048             uv_strerror(rc));
00049           delete resolver;
00050           return false;
00051         }
00052       }
00053       else
00054       {
00055         if (
00056           (rc = uv_getaddrinfo(
00057              uv_default_loop(),
00058              resolver,
00059              nullptr,
00060              host.c_str(),
00061              service.c_str(),
00062              &hints)) < 0)
00063         {
00064           LOG_FAIL_FMT(
00065             "uv_getaddrinfo for host:service [{}:{}] failed with error {}",
00066             host,
00067             service,
00068             uv_strerror(rc));
00069           delete resolver;
00070           return false;
00071         }
00072 
00073         cb(resolver, rc, &hints);
00074       }
00075 
00076       return true;
00077     }
00078   };
00079 }
00080 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/dns.h...
Preprocessing /data/git/CCF/src/host/enclave.h...
#include crypto/hash.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/interface.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include dlfcn.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include ccf_u.h: not found! skipping...
#include openenclave/bits/result.h: not found! skipping...
#include openenclave/host.h: not found! skipping...
Preprocessor output (size: 3053 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 // Marker to create virtual enclaves, should be distinct from any valid
00021 // OE_ENCLAVE_FLAG combinations
00022 constexpr static uint32_t ENCLAVE_FLAG_VIRTUAL = -1;
00023 
00024 namespace host
00025 {
00026   /**
00027    * Wraps an oe_enclave and associated ECalls. New ECalls should be added as
00028    * methods which construct an appropriate EGeneric-derived param type and pass
00029    * it to call.
00030    */
00031   class Enclave
00032   {
00033   private:
00034     bool is_virtual_enclave;
00035 
00036     oe_enclave_t* e;
00037 
00038   public:
00039     /**
00040      * Create an uninitialized enclave hosting the given library.
00041      *
00042      * @param path Path to signed enclave library file
00043      * @param flags Flags passed to oe_create_enclave. eg OE_ENCLAVE_FLAG_DEBUG,
00044      * OE_ENCLAVE_FLAG_SIMULATE. Alternatively, ENCLAVE_FLAG_VIRTUAL will not
00045      * use OE at all, instead loading a shared library directly
00046      */
00047     Enclave(const std::string& path, uint32_t flags) :
00048       is_virtual_enclave(false),
00049       e(nullptr)
00050     {
00051       if (flags == ENCLAVE_FLAG_VIRTUAL)
00052       {
00053 
00054 
00055 
00056         is_virtual_enclave = true;
00057       }
00058       else
00059       {
00060         auto err = oe_create_ccf_enclave(
00061           path.c_str(), OE_ENCLAVE_TYPE_SGX, flags, nullptr, 0, &e);
00062 
00063         if (err != OE_OK)
00064         {
00065           throw std::logic_error(
00066             fmt::format("Could not create enclave: {}", oe_result_str(err)));
00067         }
00068       }
00069     }
00070 
00071     bool create_node(
00072       const EnclaveConfig& enclave_config,
00073       const CCFConfig& ccf_config,
00074       std::vector<uint8_t>& node_cert,
00075       std::vector<uint8_t>& network_cert,
00076       StartType start_type,
00077       ConsensusType consensus_type,
00078       size_t num_worker_thread,
00079       void* time_location)
00080     {
00081       bool ret;
00082       size_t node_cert_len = 0;
00083       size_t network_cert_len = 0;
00084 
00085       msgpack::sbuffer sbuf;
00086       msgpack::pack(sbuf, ccf_config);
00087 
00088       auto err = enclave_create_node(
00089         e,
00090         &ret,
00091         (void*)&enclave_config,
00092         sbuf.data(),
00093         sbuf.size(),
00094         node_cert.data(),
00095         node_cert.size(),
00096         &node_cert_len,
00097         network_cert.data(),
00098         network_cert.size(),
00099         &network_cert_len,
00100         start_type,
00101         consensus_type,
00102         num_worker_thread,
00103         time_location);
00104 
00105       if (err != OE_OK)
00106       {
00107         throw std::logic_error(fmt::format(
00108           "Failed to call in enclave_create_node: {}", oe_result_str(err)));
00109       }
00110 
00111       if (!ret)
00112       {
00113         throw std::logic_error("An error occurred when creating CCF node");
00114       }
00115 
00116       node_cert.resize(node_cert_len);
00117       network_cert.resize(network_cert_len);
00118 
00119       return ret;
00120     }
00121 
00122     // Run a processor over this circuit inside the enclave - should be called
00123     // from a thread
00124     bool run()
00125     {
00126       bool ret;
00127       auto err = enclave_run(e, &ret);
00128 
00129       if (err != OE_OK)
00130       {
00131         throw std::logic_error(
00132           fmt::format("Failed to call in enclave_run: {}", oe_result_str(err)));
00133       }
00134 
00135       return ret;
00136     }
00137   };
00138 }
00139 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/enclave.h...
Preprocessing /data/git/CCF/src/host/every_io.h...
#include proxy.h: already included! skipping...
Preprocessor output (size: 1170 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace asynchost
00008 {
00009   // This runs every loop. If any instance of this is active, the loop's poll
00010   // timeout will be 0 (see uv_prepare_t vs uv_idle_t)
00011   template <typename Behaviour>
00012   class EveryIO : public with_uv_handle<uv_idle_t>
00013   {
00014   private:
00015     friend class close_ptr<EveryIO<Behaviour>>;
00016     Behaviour behaviour;
00017 
00018     template <typename... Args>
00019     EveryIO(Args&&... args) : behaviour(std::forward<Args>(args)...)
00020     {
00021       int rc;
00022 
00023       if ((rc = uv_idle_init(uv_default_loop(), &uv_handle)) < 0)
00024       {
00025         LOG_FAIL_FMT("uv_idle_init failed: {}", uv_strerror(rc));
00026         throw std::logic_error("uv_idle_init failed");
00027       }
00028 
00029       uv_handle.data = this;
00030 
00031       if ((rc = uv_idle_start(&uv_handle, on_every)) < 0)
00032       {
00033         LOG_FAIL_FMT("uv_idle_start failed: {}", uv_strerror(rc));
00034         throw std::logic_error("uv_idle_start failed");
00035       }
00036     }
00037 
00038     static void on_every(uv_idle_t* handle)
00039     {
00040       static_cast<EveryIO*>(handle->data)->on_every();
00041     }
00042 
00043     void on_every()
00044     {
00045       behaviour.every();
00046     }
00047   };
00048 }
00049 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/every_io.h...
Preprocessing /data/git/CCF/src/host/handle_ring_buffer.h...
#include cstring: not found! skipping...
#include fstream: not found! skipping...
#include glob.h: not found! skipping...
#include iostream: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include optional: not found! skipping...
#include sstream: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include ../ds/logger.h: already included! skipping...
#include ../enclave/interface.h: already included! skipping...
#include proxy.h: already included! skipping...
#include chrono: not found! skipping...
#include chrono: not found! skipping...
#include ctime: not found! skipping...
#include iomanip: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include string: not found! skipping...
#include sys/types.h: not found! skipping...
#include unistd.h: not found! skipping...
Preprocessor output (size: 2068 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/host/handle_ring_buffer.h" 2
00006 
00007 
00008 # 8 "/data/git/CCF/src/host/handle_ring_buffer.h" 2
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 namespace asynchost
00019 {
00020   class HandleRingbufferImpl
00021   {
00022   private:
00023     // Maximum number of outbound ringbuffer messages which will be processed in
00024     // a single iteration
00025     static constexpr size_t max_messages = 256;
00026 
00027     messaging::BufferProcessor& bp;
00028     ringbuffer::Reader& r;
00029     ringbuffer::NonBlockingWriterFactory& nbwf;
00030 
00031   public:
00032     HandleRingbufferImpl(
00033       messaging::BufferProcessor& bp,
00034       ringbuffer::Reader& r,
00035       ringbuffer::NonBlockingWriterFactory& nbwf) :
00036       bp(bp),
00037       r(r),
00038       nbwf(nbwf)
00039     {
00040       // Register message handler for log message from enclave
00041       DISPATCHER_SET_MESSAGE_HANDLER(
00042         bp, AdminMessage::log_msg, [](const uint8_t* data, size_t size) {
00043           auto [elapsed, file_name, line_number, log_level, thread_id, msg] =
00044             ringbuffer::read_message<AdminMessage::log_msg>(data, size);
00045 
00046           logger::Out::write(
00047             file_name, line_number, log_level, thread_id, msg, elapsed.count());
00048         });
00049 
00050       DISPATCHER_SET_MESSAGE_HANDLER(
00051         bp,
00052         AdminMessage::fatal_error_msg,
00053         [](const uint8_t* data, size_t size) {
00054           auto [msg] =
00055             ringbuffer::read_message<AdminMessage::fatal_error_msg>(data, size);
00056 
00057           std::cerr << msg << std::endl << std::flush;
00058           throw std::logic_error(msg);
00059         });
00060 
00061       DISPATCHER_SET_MESSAGE_HANDLER(
00062         bp, AdminMessage::stopped, [](const uint8_t*, size_t) {
00063           uv_stop(uv_default_loop());
00064           LOG_INFO_FMT("Host stopped successfully");
00065         });
00066     }
00067 
00068     void on_timer()
00069     {
00070       // Regularly read (and process) some outbound ringbuffer messages...
00071       bp.read_n(max_messages, r);
00072 
00073       // ...flush any pending inbound messages...
00074       nbwf.flush_all_inbound();
00075     }
00076   };
00077 
00078   using HandleRingbuffer = proxy_ptr<Timer<HandleRingbufferImpl>>;
00079 }
00080 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/handle_ring_buffer.h...
Preprocessing /data/git/CCF/src/host/ledger.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/messaging.h: not found! skipping...
#include cstdint: not found! skipping...
#include cstdio: not found! skipping...
#include filesystem: not found! skipping...
#include limits: not found! skipping...
#include linux/limits.h: not found! skipping...
#include list: not found! skipping...
#include map: not found! skipping...
#include string: not found! skipping...
#include sys/types.h: not found! skipping...
#include unistd.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 25954 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 namespace fs = std::filesystem;
00022 
00023 namespace asynchost
00024 {
00025   static constexpr size_t ledger_max_read_cache_files_default = 5;
00026 
00027   static constexpr auto ledger_committed_suffix = "committed";
00028   static constexpr auto ledger_start_idx_delimiter = "_";
00029   static constexpr auto ledger_last_idx_delimiter = "-";
00030 
00031   static inline bool is_ledger_file_committed(const std::string& file_name)
00032   {
00033     auto pos = file_name.find(".");
00034     if (pos == std::string::npos)
00035     {
00036       return false;
00037     }
00038     return file_name.substr(pos + 1) == ledger_committed_suffix;
00039   }
00040 
00041   static inline size_t get_start_idx_from_file_name(
00042     const std::string& file_name)
00043   {
00044     auto pos = file_name.find(ledger_start_idx_delimiter);
00045     if (pos == std::string::npos)
00046     {
00047       throw std::logic_error(fmt::format(
00048         "Ledger file name {} does not contain a start idx", file_name));
00049     }
00050 
00051     return std::stol(file_name.substr(pos + 1));
00052   }
00053 
00054   static inline std::optional<size_t> get_last_idx_from_file_name(
00055     const std::string& file_name)
00056   {
00057     auto pos = file_name.find(ledger_last_idx_delimiter);
00058     if (pos == std::string::npos)
00059     {
00060       // Non-committed file names do not contain a last idx
00061       return std::nullopt;
00062     }
00063 
00064     return std::stol(file_name.substr(pos + 1));
00065   }
00066 
00067   std::optional<std::string> get_file_name_with_idx(
00068     const std::string& dir, size_t idx)
00069   {
00070     std::optional<std::string> match = std::nullopt;
00071     for (auto const& f : fs::directory_iterator(dir))
00072     {
00073       // If any file, based on its name, contains idx. Only committed files
00074       // (i.e. those with a last idx) are considered here.
00075       auto f_name = f.path().filename();
00076       auto start_idx = get_start_idx_from_file_name(f_name);
00077       auto last_idx = get_last_idx_from_file_name(f_name);
00078       if (idx >= start_idx && last_idx.has_value() && idx <= last_idx.value())
00079       {
00080         match = f_name;
00081         break;
00082       }
00083     }
00084 
00085     return match;
00086   }
00087 
00088   class LedgerFile
00089   {
00090   private:
00091     using positions_offset_header_t = size_t;
00092     static constexpr auto file_name_prefix = "ledger";
00093     static constexpr size_t frame_header_size = sizeof(uint32_t);
00094 
00095     const std::string dir;
00096 
00097     // This uses C stdio instead of fstream because an fstream
00098     // cannot be truncated.
00099     FILE* file;
00100 
00101     size_t start_idx = 1;
00102     size_t total_len = 0;
00103     std::vector<uint32_t> positions;
00104 
00105     bool completed = false;
00106     bool committed = false;
00107 
00108   public:
00109     LedgerFile(const std::string& dir, size_t start_idx) :
00110       dir(dir),
00111       file(nullptr),
00112       start_idx(start_idx)
00113     {
00114       const auto filename = fmt::format("{}_{}", file_name_prefix, start_idx);
00115       const auto file_path = fs::path(dir) / fs::path(filename);
00116       file = fopen(file_path.c_str(), "w+b");
00117       if (!file)
00118       {
00119         throw std::logic_error(fmt::format(
00120           "Unable to open ledger file {}: {}", file_path, strerror(errno)));
00121       }
00122 
00123       // Header reserved for the offset to the position table
00124       fseeko(file, sizeof(positions_offset_header_t), SEEK_SET);
00125       total_len = sizeof(positions_offset_header_t);
00126     }
00127 
00128     // Used when recovering an existing ledger file
00129     LedgerFile(const std::string& dir, const std::string& file_name) :
00130       dir(dir),
00131       file(nullptr)
00132     {
00133       auto full_path = (fs::path(dir) / fs::path(file_name));
00134       file = fopen(full_path.c_str(), "r+b");
00135       if (!file)
00136       {
00137         throw std::logic_error(fmt::format(
00138           "Unable to open ledger file {}: {}", full_path, strerror(errno)));
00139       }
00140 
00141       committed = is_ledger_file_committed(file_name);
00142       start_idx = get_start_idx_from_file_name(file_name);
00143 
00144       // First, get full size of file
00145       fseeko(file, 0, SEEK_END);
00146       size_t total_file_size = ftello(file);
00147 
00148       // Second, read offset to header table
00149       fseeko(file, 0, SEEK_SET);
00150       positions_offset_header_t table_offset;
00151       if (fread(&table_offset, sizeof(positions_offset_header_t), 1, file) != 1)
00152       {
00153         throw std::logic_error(fmt::format(
00154           "Failed to read positions offset from ledger file {}", full_path));
00155       }
00156 
00157       if (table_offset != 0)
00158       {
00159         // If the chunk was completed, read positions table from file directly
00160         total_len = table_offset;
00161         fseeko(file, table_offset, SEEK_SET);
00162 
00163         positions.resize(
00164           (total_file_size - table_offset) / sizeof(positions.at(0)));
00165 
00166         if (
00167           fread(
00168             positions.data(),
00169             sizeof(positions.at(0)),
00170             positions.size(),
00171             file) != positions.size())
00172         {
00173           throw std::logic_error(fmt::format(
00174             "Failed to read positions table from ledger file {}", full_path));
00175         }
00176         completed = true;
00177       }
00178       else
00179       {
00180         // If the chunk was not completed, read all entries to reconstruct
00181         // positions table
00182         total_len = total_file_size;
00183 
00184         auto len = total_len - sizeof(positions_offset_header_t);
00185         size_t pos = sizeof(positions_offset_header_t);
00186         uint32_t entry_size = 0;
00187 
00188         while (len >= frame_header_size)
00189         {
00190           if (fread(&entry_size, frame_header_size, 1, file) != 1)
00191           {
00192             throw std::logic_error(fmt::format(
00193               "Failed to read frame from ledger file {}", full_path));
00194           }
00195 
00196           len -= frame_header_size;
00197 
00198           if (len < entry_size)
00199           {
00200             throw std::logic_error(
00201               fmt::format("Malformed ledger file {}", full_path));
00202           }
00203 
00204           fseeko(file, entry_size, SEEK_CUR);
00205           len -= entry_size;
00206 
00207           positions.push_back(pos);
00208           pos += (entry_size + frame_header_size);
00209         }
00210         completed = false;
00211       }
00212     }
00213 
00214     ~LedgerFile()
00215     {
00216       if (file)
00217       {
00218         fclose(file);
00219       }
00220     }
00221 
00222     std::string get_file_name() const
00223     {
00224       int fd = fileno(file);
00225       auto path = fmt::format("/proc/self/fd/{}", fd);
00226       char result[PATH_MAX];
00227       ::memset(result, 0, sizeof(result));
00228       if (readlink(path.c_str(), result, sizeof(result) - 1) < 0)
00229       {
00230         throw std::logic_error("Could not read ledger file name");
00231       }
00232 
00233       return fs::path(result).filename();
00234     }
00235 
00236     size_t get_start_idx() const
00237     {
00238       return start_idx;
00239     }
00240 
00241     size_t get_last_idx() const
00242     {
00243       return start_idx + positions.size() - 1;
00244     }
00245 
00246     size_t get_current_size() const
00247     {
00248       return total_len;
00249     }
00250 
00251     bool is_committed() const
00252     {
00253       return committed;
00254     }
00255 
00256     bool is_complete() const
00257     {
00258       return completed;
00259     }
00260 
00261     size_t write_entry(const uint8_t* data, size_t size, bool committable)
00262     {
00263       fseeko(file, total_len, SEEK_SET);
00264       positions.push_back(total_len);
00265       size_t new_idx = get_last_idx();
00266 
00267       uint32_t frame = (uint32_t)size;
00268       if (fwrite(&frame, frame_header_size, 1, file) != 1)
00269       {
00270         throw std::logic_error("Failed to write entry header to ledger");
00271       }
00272 
00273       if (fwrite(data, size, 1, file) != 1)
00274       {
00275         throw std::logic_error("Failed to write entry to ledger");
00276       }
00277 
00278       // Committable entries get flushed straight away
00279       if (committable && fflush(file) != 0)
00280       {
00281         throw std::logic_error(
00282           fmt::format("Failed to flush entry to ledger: {}", strerror(errno)));
00283       }
00284 
00285       total_len += (size + frame_header_size);
00286 
00287       return new_idx;
00288     }
00289 
00290     size_t framed_entries_size(size_t from, size_t to) const
00291     {
00292       if ((from < start_idx) || (to < from) || (to > get_last_idx()))
00293       {
00294         return 0;
00295       }
00296 
00297       if (to == get_last_idx())
00298       {
00299         return total_len - positions.at(from - start_idx);
00300       }
00301       else
00302       {
00303         return positions.at(to - start_idx + 1) -
00304           positions.at(from - start_idx);
00305       }
00306     }
00307 
00308     size_t entry_size(size_t idx) const
00309     {
00310       auto framed_size = framed_entries_size(idx, idx);
00311       return (framed_size != 0) ? framed_size - frame_header_size : 0;
00312     }
00313 
00314     std::optional<std::vector<uint8_t>> read_entry(size_t idx) const
00315     {
00316       if ((idx < start_idx) || (idx > get_last_idx()))
00317       {
00318         return std::nullopt;
00319       }
00320 
00321       auto len = entry_size(idx);
00322       std::vector<uint8_t> entry(len);
00323       fseeko(file, positions.at(idx - start_idx) + frame_header_size, SEEK_SET);
00324 
00325       if (fread(entry.data(), len, 1, file) != 1)
00326       {
00327         throw std::logic_error(
00328           fmt::format("Failed to read entry {} from file", idx));
00329       }
00330 
00331       return entry;
00332     }
00333 
00334     std::optional<std::vector<uint8_t>> read_framed_entries(
00335       size_t from, size_t to) const
00336     {
00337       if ((from < start_idx) || (to > get_last_idx()) || (to < from))
00338       {
00339         LOG_FAIL_FMT("Unknown entries range: {} - {}", from, to);
00340         return std::nullopt;
00341       }
00342 
00343       auto framed_size = framed_entries_size(from, to);
00344       std::vector<uint8_t> framed_entries(framed_size);
00345       fseeko(file, positions.at(from - start_idx), SEEK_SET);
00346 
00347       if (fread(framed_entries.data(), framed_size, 1, file) != 1)
00348       {
00349         throw std::logic_error(fmt::format(
00350           "Failed to read entry range {} - {} from file", from, to));
00351       }
00352 
00353       return framed_entries;
00354     }
00355 
00356     bool truncate(size_t idx)
00357     {
00358       if (committed || (idx < start_idx - 1) || (idx >= get_last_idx()))
00359       {
00360         return false;
00361       }
00362 
00363       if (idx == start_idx - 1)
00364       {
00365         // Truncating everything triggers file deletion
00366         if (!fs::remove(fs::path(dir) / fs::path(get_file_name())))
00367         {
00368           throw std::logic_error(
00369             fmt::format("Could not remove file {}", get_file_name()));
00370         }
00371         return true;
00372       }
00373 
00374       // Reset positions offset header
00375       fseeko(file, 0, SEEK_SET);
00376       positions_offset_header_t table_offset = 0;
00377       if (fwrite(&table_offset, sizeof(table_offset), 1, file) != 1)
00378       {
00379         throw std::logic_error("Failed to reset positions table offset");
00380       }
00381 
00382       completed = false;
00383       total_len = positions.at(idx - start_idx + 1);
00384       positions.resize(idx - start_idx + 1);
00385 
00386       if (fflush(file) != 0)
00387       {
00388         throw std::logic_error(
00389           fmt::format("Failed to flush ledger file: {}", strerror(errno)));
00390       }
00391 
00392       if (ftruncate(fileno(file), total_len))
00393       {
00394         throw std::logic_error(
00395           fmt::format("Failed to truncate ledger: {}", strerror(errno)));
00396       }
00397 
00398       fseeko(file, total_len, SEEK_SET);
00399       return false;
00400     }
00401 
00402     void complete()
00403     {
00404       if (completed)
00405       {
00406         return;
00407       }
00408 
00409       fseeko(file, total_len, SEEK_SET);
00410       size_t table_offset = ftello(file);
00411 
00412       if (
00413         fwrite(
00414           reinterpret_cast<uint8_t*>(positions.data()),
00415           sizeof(positions.at(0)),
00416           positions.size(),
00417           file) != positions.size())
00418       {
00419         throw std::logic_error("Failed to write positions table to ledger");
00420       }
00421 
00422       // Write positions table offset at start of file
00423       if (fseeko(file, 0, SEEK_SET) != 0)
00424       {
00425         throw std::logic_error("Failed to set file offset to 0");
00426       }
00427 
00428       if (fwrite(&table_offset, sizeof(table_offset), 1, file) != 1)
00429       {
00430         throw std::logic_error("Failed to write positions table to ledger");
00431       }
00432 
00433       if (fflush(file) != 0)
00434       {
00435         throw std::logic_error(
00436           fmt::format("Failed to flush ledger file: {}", strerror(errno)));
00437       }
00438 
00439       completed = true;
00440     }
00441 
00442     bool commit(size_t idx)
00443     {
00444       if (!completed || committed || (idx != get_last_idx()))
00445       {
00446         // No effect if commit idx is not last idx
00447         return false;
00448       }
00449 
00450       if (fflush(file) != 0)
00451       {
00452         throw std::logic_error(
00453           fmt::format("Failed to flush ledger file: {}", strerror(errno)));
00454       }
00455 
00456       const auto committed_file_name = fmt::format(
00457         "{}_{}-{}.{}",
00458         file_name_prefix,
00459         start_idx,
00460         get_last_idx(),
00461         ledger_committed_suffix);
00462 
00463       fs::rename(
00464         fs::path(dir) / fs::path(get_file_name()),
00465         fs::path(dir) / fs::path(committed_file_name));
00466 
00467       committed = true;
00468       return true;
00469     }
00470   };
00471 
00472   class Ledger
00473   {
00474   private:
00475     static constexpr size_t max_chunk_threshold_size =
00476       std::numeric_limits<uint32_t>::max(); // 4GB
00477 
00478     ringbuffer::WriterPtr to_enclave;
00479 
00480     // Main ledger directory (write and read)
00481     const std::string ledger_dir;
00482 
00483     // Ledger directories (read-only)
00484     std::vector<std::string> read_ledger_dirs;
00485 
00486     // Keep tracks of all ledger files for writing.
00487     // Current ledger file is always the last one
00488     std::list<std::shared_ptr<LedgerFile>> files;
00489 
00490     // Cache of ledger files for reading
00491     size_t max_read_cache_files;
00492     std::list<std::shared_ptr<LedgerFile>> files_read_cache;
00493 
00494     const size_t chunk_threshold;
00495     size_t last_idx = 0;
00496     size_t committed_idx = 0;
00497 
00498     // True if a new file should be created when writing an entry
00499     bool require_new_file;
00500 
00501     auto get_it_contains_idx(size_t idx) const
00502     {
00503       if (idx == 0)
00504       {
00505         return files.end();
00506       }
00507 
00508       auto f = std::upper_bound(
00509         files.begin(),
00510         files.end(),
00511         idx,
00512         [](size_t idx, const std::shared_ptr<LedgerFile>& f) {
00513           return (idx <= f->get_last_idx());
00514         });
00515 
00516       return f;
00517     }
00518 
00519     std::shared_ptr<LedgerFile> get_file_from_cache(size_t idx)
00520     {
00521       if (idx == 0)
00522       {
00523         return nullptr;
00524       }
00525 
00526       // First, try to find file from read cache
00527       for (auto const& f : files_read_cache)
00528       {
00529         if (f->get_start_idx() <= idx && idx <= f->get_last_idx())
00530         {
00531           return f;
00532         }
00533       }
00534 
00535       // If the file is not in the cache, find the file from the ledger
00536       // directories, inspecting the main ledger directory first
00537       std::string ledger_dir_;
00538       auto match = get_file_name_with_idx(ledger_dir, idx);
00539       if (match.has_value())
00540       {
00541         ledger_dir_ = ledger_dir;
00542       }
00543       else
00544       {
00545         for (auto const& dir : read_ledger_dirs)
00546         {
00547           match = get_file_name_with_idx(dir, idx);
00548           if (match.has_value())
00549           {
00550             ledger_dir_ = dir;
00551             break;
00552           }
00553         }
00554       }
00555 
00556       if (!match.has_value())
00557       {
00558         return nullptr;
00559       }
00560 
00561       // Emplace file in the max-sized read cache, replacing the oldest entry if
00562       // the read cache is full
00563       auto match_file =
00564         std::make_shared<LedgerFile>(ledger_dir_, match.value());
00565       if (files_read_cache.size() >= max_read_cache_files)
00566       {
00567         files_read_cache.erase(files_read_cache.begin());
00568       }
00569       files_read_cache.emplace_back(match_file);
00570 
00571       return match_file;
00572     }
00573 
00574     std::shared_ptr<LedgerFile> get_file_from_idx(size_t idx)
00575     {
00576       if (idx == 0)
00577       {
00578         return nullptr;
00579       }
00580 
00581       // First, check if the file is in the list of files open for writing
00582       auto f = std::upper_bound(
00583         files.rbegin(),
00584         files.rend(),
00585         idx,
00586         [](size_t idx, const std::shared_ptr<LedgerFile>& f) {
00587           return idx >= f->get_start_idx();
00588         });
00589 
00590       if (f != files.rend())
00591       {
00592         return *f;
00593       }
00594 
00595       // Otherwise, return file from read cache
00596       return get_file_from_cache(idx);
00597     }
00598 
00599     std::shared_ptr<LedgerFile> get_latest_file() const
00600     {
00601       if (files.empty())
00602       {
00603         return nullptr;
00604       }
00605       return files.back();
00606     }
00607 
00608   public:
00609     Ledger(
00610       const std::string& ledger_dir,
00611       ringbuffer::AbstractWriterFactory& writer_factory,
00612       size_t chunk_threshold,
00613       size_t max_read_cache_files = ledger_max_read_cache_files_default,
00614       std::vector<std::string> read_ledger_dirs = {}) :
00615       to_enclave(writer_factory.create_writer_to_inside()),
00616       ledger_dir(ledger_dir),
00617       read_ledger_dirs(read_ledger_dirs),
00618       max_read_cache_files(max_read_cache_files),
00619       chunk_threshold(chunk_threshold)
00620     {
00621       if (chunk_threshold == 0 || chunk_threshold > max_chunk_threshold_size)
00622       {
00623         throw std::logic_error(fmt::format(
00624           "Error: Ledger chunk threshold should be between 1-{}",
00625           max_chunk_threshold_size));
00626       }
00627 
00628       // Recover last idx from read-only ledger directories
00629       for (const auto& read_dir : read_ledger_dirs)
00630       {
00631         LOG_DEBUG_FMT("Recovering read-only ledger directory \"{}\"", read_dir);
00632         if (!fs::is_directory(read_dir))
00633         {
00634           throw std::logic_error(
00635             fmt::format("\"{}\" is not a directory", read_dir));
00636         }
00637 
00638         for (auto const& f : fs::directory_iterator(read_dir))
00639         {
00640           auto last_idx_ = get_last_idx_from_file_name(f.path().filename());
00641           if (!last_idx_.has_value())
00642           {
00643             LOG_DEBUG_FMT(
00644               "Read-only ledger file {} is ignored as not committed",
00645               f.path().filename());
00646             continue;
00647           }
00648 
00649           if (last_idx_.value() > last_idx)
00650           {
00651             last_idx = last_idx_.value();
00652             committed_idx = last_idx;
00653           }
00654         }
00655       }
00656 
00657       if (fs::is_directory(ledger_dir))
00658       {
00659         // If the ledger directory exists, recover ledger files from it
00660         for (auto const& f : fs::directory_iterator(ledger_dir))
00661         {
00662           files.push_back(
00663             std::make_shared<LedgerFile>(ledger_dir, f.path().filename()));
00664         }
00665 
00666         if (files.empty())
00667         {
00668           LOG_TRACE_FMT(
00669             "Ledger directory \"{}\" is empty: no ledger file to recover",
00670             ledger_dir);
00671           require_new_file = true;
00672           return;
00673         }
00674 
00675         files.sort([](
00676                      const std::shared_ptr<LedgerFile>& a,
00677                      const std::shared_ptr<LedgerFile>& b) {
00678           return a->get_last_idx() < b->get_last_idx();
00679         });
00680 
00681         auto main_ledger_dir_last_idx = get_latest_file()->get_last_idx();
00682         if (main_ledger_dir_last_idx < last_idx)
00683         {
00684           throw std::logic_error(fmt::format(
00685             "Ledger directory last idx ({}) is less than read-only "
00686             "ledger directories last idx ({})",
00687             main_ledger_dir_last_idx,
00688             last_idx));
00689         }
00690 
00691         last_idx = main_ledger_dir_last_idx;
00692 
00693         for (auto f = files.begin(); f != files.end();)
00694         {
00695           if ((*f)->is_committed())
00696           {
00697             committed_idx = (*f)->get_last_idx();
00698             auto f_ = f;
00699             f++;
00700             files.erase(f_);
00701           }
00702           else
00703           {
00704             f++;
00705           }
00706         }
00707 
00708         // Continue writing at the end of last file only if that file is not
00709         // complete
00710         if (files.size() > 0 && !files.back()->is_complete())
00711         {
00712           require_new_file = false;
00713         }
00714         else
00715         {
00716           require_new_file = true;
00717         }
00718       }
00719       else
00720       {
00721         if (!fs::create_directory(ledger_dir))
00722         {
00723           throw std::logic_error(fmt::format(
00724             "Error: Could not create ledger directory: {}", ledger_dir));
00725         }
00726         require_new_file = true;
00727       }
00728 
00729       LOG_INFO_FMT(
00730         "Recovered ledger entries up to {}, committed to {}",
00731         last_idx,
00732         committed_idx);
00733     }
00734 
00735     Ledger(const Ledger& that) = delete;
00736 
00737     void init(size_t idx)
00738     {
00739       // Used to initialise the ledger when starting from a non-empty state,
00740       // i.e. snapshot. It is assumed that idx is included in a committed ledger
00741       // file
00742 
00743       // As it is possible that some ledger files containing indices later than
00744       // snapshot index already exist (e.g. to verify the snapshot evidence),
00745       // delete those so that ledger can restart neatly.
00746       bool has_deleted = false;
00747       for (auto const& f : fs::directory_iterator(ledger_dir))
00748       {
00749         auto file_name = f.path().filename();
00750         if (get_start_idx_from_file_name(file_name) > idx)
00751         {
00752           LOG_INFO_FMT(
00753             "Deleting {} file as it is later than init index {}",
00754             file_name,
00755             idx);
00756           fs::remove(f);
00757           has_deleted = true;
00758         }
00759       }
00760 
00761       if (has_deleted)
00762       {
00763         files.clear();
00764         require_new_file = true;
00765       }
00766 
00767       LOG_DEBUG_FMT("Setting last known index to {}", idx);
00768       last_idx = idx;
00769     }
00770 
00771     size_t get_last_idx() const
00772     {
00773       return last_idx;
00774     }
00775 
00776     std::optional<std::vector<uint8_t>> read_entry(size_t idx)
00777     {
00778       auto f = get_file_from_idx(idx);
00779       if (f == nullptr)
00780       {
00781         return std::nullopt;
00782       }
00783       return f->read_entry(idx);
00784     }
00785 
00786     std::optional<std::vector<uint8_t>> read_framed_entries(
00787       size_t from, size_t to)
00788     {
00789       if ((from <= 0) || (to > last_idx) || (to < from))
00790       {
00791         return std::nullopt;
00792       }
00793 
00794       std::vector<uint8_t> entries;
00795       size_t idx = from;
00796       while (idx <= to)
00797       {
00798         auto f_from = get_file_from_idx(idx);
00799         if (f_from == nullptr)
00800         {
00801           return std::nullopt;
00802         }
00803         auto to_ = std::min(f_from->get_last_idx(), to);
00804         auto v = f_from->read_framed_entries(idx, to_);
00805         if (!v.has_value())
00806         {
00807           return std::nullopt;
00808         }
00809         entries.insert(
00810           entries.end(),
00811           std::make_move_iterator(v->begin()),
00812           std::make_move_iterator(v->end()));
00813         idx = to_ + 1;
00814       }
00815 
00816       return entries;
00817     }
00818 
00819     size_t write_entry(
00820       const uint8_t* data, size_t size, bool committable, bool force_chunk)
00821     {
00822       if (require_new_file)
00823       {
00824         files.push_back(std::make_shared<LedgerFile>(ledger_dir, last_idx + 1));
00825         require_new_file = false;
00826       }
00827       auto f = get_latest_file();
00828       last_idx = f->write_entry(data, size, committable);
00829 
00830       LOG_DEBUG_FMT(
00831         "Wrote entry at {} [committable: {}, forced: {}]",
00832         last_idx,
00833         committable,
00834         force_chunk);
00835 
00836       if (
00837         committable &&
00838         (force_chunk || f->get_current_size() >= chunk_threshold))
00839       {
00840         f->complete();
00841         require_new_file = true;
00842         LOG_INFO_FMT("Ledger chunk completed at {}", last_idx);
00843       }
00844 
00845       return last_idx;
00846     }
00847 
00848     void truncate(size_t idx)
00849     {
00850       LOG_DEBUG_FMT("Ledger truncate: {}/{}", idx, last_idx);
00851 
00852       if (idx >= last_idx || idx < committed_idx)
00853       {
00854         return;
00855       }
00856 
00857       require_new_file = true;
00858 
00859       auto f_from = get_it_contains_idx(idx + 1);
00860       auto f_to = get_it_contains_idx(last_idx);
00861       auto f_end = std::next(f_to);
00862 
00863       for (auto it = f_from; it != f_end;)
00864       {
00865         // Truncate the first file to the truncation index while the more recent
00866         // files are deleted entirely
00867         auto truncate_idx = (it == f_from) ? idx : (*it)->get_start_idx() - 1;
00868         if ((*it)->truncate(truncate_idx))
00869         {
00870           auto it_ = it;
00871           it++;
00872           files.erase(it_);
00873         }
00874         else
00875         {
00876           // A new file will not be required on the next written entry if the
00877           // file is _not_ deleted entirely
00878           require_new_file = false;
00879           it++;
00880         }
00881       }
00882 
00883       last_idx = idx;
00884     }
00885 
00886     void commit(size_t idx)
00887     {
00888       LOG_DEBUG_FMT("Ledger commit: {}/{}", idx, last_idx);
00889 
00890       if (idx <= committed_idx)
00891       {
00892         return;
00893       }
00894 
00895       auto f_from = (committed_idx == 0) ? get_it_contains_idx(1) :
00896                                            get_it_contains_idx(committed_idx);
00897       auto f_to = get_it_contains_idx(idx);
00898       auto f_end = std::next(f_to);
00899 
00900       for (auto it = f_from; it != f_end;)
00901       {
00902         // Commit all previous file to their latest index while the latest
00903         // file is committed to the committed index
00904         auto commit_idx = (it == f_to) ? idx : (*it)->get_last_idx();
00905         if (
00906           (*it)->commit(commit_idx) &&
00907           (it != f_to || (idx == (*it)->get_last_idx())))
00908         {
00909           auto it_ = it;
00910           it++;
00911           files.erase(it_);
00912         }
00913         else
00914         {
00915           it++;
00916         }
00917       }
00918 
00919       committed_idx = idx;
00920     }
00921 
00922     void register_message_handlers(
00923       messaging::Dispatcher<ringbuffer::Message>& disp)
00924     {
00925       DISPATCHER_SET_MESSAGE_HANDLER(
00926         disp, consensus::ledger_init, [this](const uint8_t* data, size_t size) {
00927           auto idx = serialized::read<consensus::Index>(data, size);
00928           init(idx);
00929         });
00930 
00931       DISPATCHER_SET_MESSAGE_HANDLER(
00932         disp,
00933         consensus::ledger_append,
00934         [this](const uint8_t* data, size_t size) {
00935           auto committable = serialized::read<bool>(data, size);
00936           auto force_chunk = serialized::read<bool>(data, size);
00937           write_entry(data, size, committable, force_chunk);
00938         });
00939 
00940       DISPATCHER_SET_MESSAGE_HANDLER(
00941         disp,
00942         consensus::ledger_truncate,
00943         [this](const uint8_t* data, size_t size) {
00944           auto idx = serialized::read<consensus::Index>(data, size);
00945           truncate(idx);
00946         });
00947 
00948       DISPATCHER_SET_MESSAGE_HANDLER(
00949         disp,
00950         consensus::ledger_commit,
00951         [this](const uint8_t* data, size_t size) {
00952           auto idx = serialized::read<consensus::Index>(data, size);
00953           commit(idx);
00954         });
00955 
00956       DISPATCHER_SET_MESSAGE_HANDLER(
00957         disp, consensus::ledger_get, [&](const uint8_t* data, size_t size) {
00958           auto [idx, purpose] =
00959             ringbuffer::read_message<consensus::ledger_get>(data, size);
00960 
00961           auto entry = read_entry(idx);
00962 
00963           if (entry.has_value())
00964           {
00965             RINGBUFFER_WRITE_MESSAGE(
00966               consensus::ledger_entry, to_enclave, idx, purpose, entry.value());
00967           }
00968           else
00969           {
00970             RINGBUFFER_WRITE_MESSAGE(
00971               consensus::ledger_no_entry, to_enclave, idx, purpose);
00972           }
00973         });
00974     }
00975   };
00976 }
00977 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/ledger.h...
Preprocessing /data/git/CCF/src/host/load_monitor.h...
#include ds/messaging.h: not found! skipping...
#include timer.h: already included! skipping...
Preprocessor output (size: 3161 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace asynchost
00009 {
00010   class LoadMonitorImpl
00011   {
00012     using TClock = std::chrono::system_clock;
00013     std::chrono::milliseconds last_update;
00014 
00015     messaging::Dispatcher<ringbuffer::Message>& dispatcher;
00016 
00017     std::fstream host_output_file;
00018 
00019     std::fstream enclave_output_file;
00020     nlohmann::json enclave_counts;
00021 
00022   public:
00023     LoadMonitorImpl(messaging::BufferProcessor& bp) :
00024       dispatcher(bp.get_dispatcher())
00025     {
00026       dispatcher.retrieve_message_counts();
00027       last_update = std::chrono::duration_cast<std::chrono::milliseconds>(
00028         TClock::now().time_since_epoch());
00029 
00030       host_output_file.open("host_load.log", std::fstream::out);
00031 
00032       enclave_output_file.open("enclave_load.log", std::fstream::out);
00033       enclave_counts = nlohmann::json::object();
00034 
00035       // Register message handler for work_stats message from enclave
00036       DISPATCHER_SET_MESSAGE_HANDLER(
00037         bp, AdminMessage::work_stats, [this](const uint8_t* data, size_t size) {
00038           auto [dumped_json] =
00039             ringbuffer::read_message<AdminMessage::work_stats>(data, size);
00040 
00041           nlohmann::json j;
00042           try
00043           {
00044             j = nlohmann::json::parse(dumped_json);
00045           }
00046           catch (const nlohmann::json::parse_error& e)
00047           {
00048             LOG_FAIL_FMT("Received unparseable work_stats from enclave");
00049             return;
00050           }
00051 
00052           for (const auto& [outer_key, outer_value] : j.items())
00053           {
00054             for (const auto& [inner_key, inner_value] : outer_value.items())
00055             {
00056               auto& outer_obj = enclave_counts[outer_key];
00057               auto it = outer_obj.find(inner_key);
00058               if (it == outer_obj.end())
00059               {
00060                 outer_obj[inner_key] = inner_value;
00061               }
00062               else
00063               {
00064                 const auto prev = it.value().get<size_t>();
00065                 outer_obj[inner_key] = prev + inner_value.get<size_t>();
00066               }
00067             }
00068           }
00069         });
00070     }
00071 
00072     void on_timer()
00073     {
00074       const auto message_counts = dispatcher.retrieve_message_counts();
00075       const auto time_now =
00076         std::chrono::duration_cast<std::chrono::milliseconds>(
00077           TClock::now().time_since_epoch());
00078 
00079       if (!message_counts.empty())
00080       {
00081         auto j = nlohmann::json::object();
00082 
00083         j["start_time_ms"] = last_update.count();
00084         j["end_time_ms"] = time_now.count();
00085 
00086         {
00087           j["ringbuffer_messages"] =
00088             dispatcher.convert_message_counts(message_counts);
00089 
00090           const auto line = j.dump();
00091           host_output_file.write(line.data(), line.size());
00092           host_output_file << std::endl;
00093         }
00094 
00095         {
00096           j["ringbuffer_messages"] = enclave_counts;
00097           enclave_counts = nlohmann::json::object();
00098 
00099           const auto line = j.dump();
00100           enclave_output_file.write(line.data(), line.size());
00101           enclave_output_file << std::endl;
00102         }
00103 
00104         last_update = time_now;
00105       }
00106     }
00107   };
00108 
00109   using LoadMonitor = proxy_ptr<Timer<LoadMonitorImpl>>;
00110 }
00111 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/load_monitor.h...
Preprocessing /data/git/CCF/src/host/main.cpp...
#include ds/cli_helper.h: not found! skipping...
#include ds/files.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/net.h: not found! skipping...
#include ds/non_blocking.h: not found! skipping...
#include ds/oversized.h: not found! skipping...
#include ds/stacktrace_utils.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/interface.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include dlfcn.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include ccf_u.h: not found! skipping...
#include openenclave/bits/result.h: not found! skipping...
#include openenclave/host.h: not found! skipping...
#include ../ds/files.h: already included! skipping...
#include ../ds/logger.h: already included! skipping...
#include ../enclave/interface.h: already included! skipping...
#include timer.h: already included! skipping...
#include chrono: not found! skipping...
#include ctime: not found! skipping...
#include iomanip: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include string: not found! skipping...
#include sys/types.h: not found! skipping...
#include unistd.h: not found! skipping...
#include ds/messaging.h: not found! skipping...
#include timer.h: already included! skipping...
#include consensus/aft/raft_types.h: not found! skipping...
#include host/timer.h: not found! skipping...
  #include consensus/ledger_enclave_types.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/messaging.h: not found! skipping...
#include cstdint: not found! skipping...
#include cstdio: not found! skipping...
#include filesystem: not found! skipping...
#include limits: not found! skipping...
#include linux/limits.h: not found! skipping...
#include list: not found! skipping...
#include map: not found! skipping...
#include string: not found! skipping...
#include sys/types.h: not found! skipping...
#include unistd.h: not found! skipping...
#include vector: not found! skipping...
#include node/node_types.h: not found! skipping...
  #include ../ds/logger.h: already included! skipping...
    #include proxy.h: already included! skipping...
    #include ../ds/logger.h: already included! skipping...
#include uv.h: not found! skipping...
#include proxy.h: already included! skipping...
#include unordered_map: not found! skipping...
  #include ../ds/ring_buffer_types.h: already included! skipping...
#include tcp.h: already included! skipping...
#include unordered_map: not found! skipping...
#include enclave.h: already included! skipping...
  #include proxy.h: already included! skipping...
#include chrono: not found! skipping...
#include chrono: not found! skipping...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include host/ledger.h: not found! skipping...
#include charconv: not found! skipping...
#include filesystem: not found! skipping...
#include fstream: not found! skipping...
#include iostream: not found! skipping...
#include optional: not found! skipping...
#include enclave.h: already included! skipping...
#include timer.h: already included! skipping...
#include chrono: not found! skipping...
#include timer.h: already included! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include version.h: not found! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
#include codecvt: not found! skipping...
#include fstream: not found! skipping...
#include iostream: not found! skipping...
#include locale: not found! skipping...
#include string: not found! skipping...
#include sys/types.h: not found! skipping...
#include thread: not found! skipping...
#include unistd.h: not found! skipping...
Preprocessor output (size: 25277 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 # 10 "/data/git/CCF/src/host/main.cpp" 2
00011 # 11 "/data/git/CCF/src/host/main.cpp" 2
00012 # 12 "/data/git/CCF/src/host/main.cpp" 2
00013 # 13 "/data/git/CCF/src/host/main.cpp" 2
00014 # 14 "/data/git/CCF/src/host/main.cpp" 2
00015 # 15 "/data/git/CCF/src/host/main.cpp" 2
00016 # 16 "/data/git/CCF/src/host/main.cpp" 2
00017 # 17 "/data/git/CCF/src/host/main.cpp" 2
00018 # 18 "/data/git/CCF/src/host/main.cpp" 2
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 using namespace std::string_literals;
00032 using namespace std::chrono_literals;
00033 
00034 ::timespec logger::config::start{0, 0};
00035 
00036 size_t asynchost::TCPImpl::remaining_read_quota;
00037 
00038 void print_version(size_t)
00039 {
00040   std::cout << "CCF host: " << ccf::ccf_version << std::endl;
00041   exit(0);
00042 }
00043 
00044 int main(int argc, char** argv)
00045 {
00046   // ignore SIGPIPE
00047   signal(SIGPIPE, SIG_IGN);
00048   stacktrace::init_sig_handlers();
00049 
00050   CLI::App app{"ccf"};
00051 
00052   app.set_config("--config", "", "Read an INI or TOML file", false);
00053   app.allow_config_extras(false);
00054 
00055   app.add_flag(
00056     "-v, --version", print_version, "Display CCF host version and exit");
00057 
00058   app.require_subcommand(1, 1);
00059 
00060   std::string enclave_file;
00061   app.add_option("-e,--enclave-file", enclave_file, "CCF application")
00062     ->required()
00063     ->check(CLI::ExistingFile);
00064 
00065   enum EnclaveType
00066   {
00067     RELEASE,
00068     DEBUG,
00069     VIRTUAL
00070   };
00071 
00072   std::vector<std::pair<std::string, EnclaveType>> enclave_type_map = {
00073     {"release", EnclaveType::RELEASE},
00074     {"debug", EnclaveType::DEBUG},
00075     {"virtual", EnclaveType::VIRTUAL}};
00076 
00077   EnclaveType enclave_type;
00078   app.add_option("-t,--enclave-type", enclave_type, "Enclave type")
00079     ->required()
00080     ->transform(CLI::CheckedTransformer(enclave_type_map, CLI::ignore_case));
00081 
00082   ConsensusType consensus;
00083   std::vector<std::pair<std::string, ConsensusType>> consensus_map{
00084     {"cft", ConsensusType::CFT}, {"bft", ConsensusType::BFT}};
00085   app.add_option("-c,--consensus", consensus, "Consensus")
00086     ->required()
00087     ->transform(CLI::CheckedTransformer(consensus_map, CLI::ignore_case));
00088 
00089   size_t num_worker_threads = 0;
00090   app
00091     .add_option(
00092       "-w,--worker-threads",
00093       num_worker_threads,
00094       "Number of worker threads inside the enclave")
00095     ->capture_default_str();
00096 
00097   cli::ParsedAddress node_address;
00098   cli::add_address_option(
00099     app,
00100     node_address,
00101     "--node-address",
00102     "Address on which to listen for TLS commands coming from other nodes")
00103     ->required();
00104 
00105   std::string node_address_file = {};
00106   app.add_option(
00107     "--node-address-file",
00108     node_address_file,
00109     "Path to which the node's node-to-node address (including potentially "
00110     "auto-assigned port) will be written. If empty (default), write nothing");
00111 
00112   cli::ParsedAddress rpc_address;
00113   cli::add_address_option(
00114     app,
00115     rpc_address,
00116     "--rpc-address",
00117     "Address on which to listen for TLS commands coming from clients. Port "
00118     "defaults to 443 if unspecified.",
00119     "443")
00120     ->required();
00121 
00122   std::string rpc_address_file = {};
00123   app.add_option(
00124     "--rpc-address-file",
00125     rpc_address_file,
00126     "Path to which the node's RPC address (including potentially "
00127     "auto-assigned port) will be written. If empty (default), write nothing");
00128 
00129   cli::ParsedAddress public_rpc_address;
00130   auto public_rpc_address_option = cli::add_address_option(
00131     app,
00132     public_rpc_address,
00133     "--public-rpc-address",
00134     "Address to advertise publicly to clients (defaults to same as "
00135     "--rpc-address)",
00136     "443");
00137 
00138   std::string ledger_dir("ledger");
00139   app.add_option("--ledger-dir", ledger_dir, "Ledger directory")
00140     ->capture_default_str();
00141 
00142   std::vector<std::string> read_only_ledger_dirs;
00143   app
00144     .add_option(
00145       "--read-only-ledger-dir",
00146       read_only_ledger_dirs,
00147       "Additional read-only ledger directory (optional)")
00148     ->type_size(-1);
00149 
00150   std::string snapshot_dir("snapshots");
00151   app.add_option("--snapshot-dir", snapshot_dir, "Snapshots directory")
00152     ->capture_default_str();
00153 
00154   size_t ledger_chunk_bytes = 5'000'000;
00155   app
00156     .add_option(
00157       "--ledger-chunk-bytes",
00158       ledger_chunk_bytes,
00159       "Size (bytes) at which a new ledger chunk is created")
00160     ->capture_default_str()
00161     ->transform(CLI::AsSizeValue(true)); // 1000 is kb
00162 
00163   size_t snapshot_tx_interval = 10'000;
00164   app
00165     .add_option(
00166       "--snapshot-tx-interval",
00167       snapshot_tx_interval,
00168       "Number of transactions between snapshots")
00169     ->capture_default_str();
00170 
00171   logger::Level host_log_level{logger::Level::INFO};
00172   std::vector<std::pair<std::string, logger::Level>> level_map;
00173   for (int i = logger::TRACE; i < logger::MAX_LOG_LEVEL; i++)
00174   {
00175     level_map.emplace_back(
00176       logger::config::LevelNames[i], static_cast<logger::Level>(i));
00177   }
00178   app
00179     .add_option(
00180       "-l,--host-log-level",
00181       host_log_level,
00182       "Only emit host log messages above that level")
00183     ->capture_default_str()
00184     ->transform(CLI::CheckedTransformer(level_map, CLI::ignore_case));
00185 
00186   bool log_format_json = false;
00187   app.add_flag(
00188     "--log-format-json", log_format_json, "Set node stdout log format to JSON");
00189 
00190   std::string node_cert_file("nodecert.pem");
00191   app
00192     .add_option(
00193       "--node-cert-file",
00194       node_cert_file,
00195       "Path to which the node certificate will be written")
00196     ->capture_default_str();
00197 
00198   std::string node_pid_file = fmt::format("{}.pid", argv[0]);
00199   app
00200     .add_option(
00201       "--node-pid-file",
00202       node_pid_file,
00203       "Path to which the node PID will be written")
00204     ->capture_default_str();
00205 
00206   size_t sig_tx_interval = 5000;
00207   app
00208     .add_option(
00209       "--sig-tx-interval",
00210       sig_tx_interval,
00211       "Number of transactions between signatures")
00212     ->capture_default_str();
00213 
00214   size_t sig_ms_interval = 1000;
00215   app
00216     .add_option(
00217       "--sig-ms-interval", sig_ms_interval, "Milliseconds between signatures")
00218     ->capture_default_str();
00219 
00220   size_t circuit_size_shift = 22;
00221   app
00222     .add_option(
00223       "--circuit-size-shift",
00224       circuit_size_shift,
00225       "Size of the internal ringbuffers, as a power of 2")
00226     ->capture_default_str();
00227 
00228   size_t raft_timeout = 100;
00229   app
00230     .add_option(
00231       "--raft-timeout-ms",
00232       raft_timeout,
00233       "Raft timeout in milliseconds. The Raft leader sends heartbeats to its "
00234       "followers at regular intervals defined by this timeout. This should be "
00235       "set to a significantly lower value than --raft-election-timeout-ms.")
00236     ->capture_default_str();
00237 
00238   size_t raft_election_timeout = 5000;
00239   app
00240     .add_option(
00241       "--raft-election-timeout-ms",
00242       raft_election_timeout,
00243       "Raft election timeout in milliseconds. If a follower does not receive "
00244       "any "
00245       "heartbeat from the leader after this timeout, the follower triggers a "
00246       "new "
00247       "election.")
00248     ->capture_default_str();
00249 
00250   size_t bft_view_change_timeout = 5000;
00251   app
00252     .add_option(
00253       "--bft-view-change-timeout-ms",
00254       bft_view_change_timeout,
00255       "bft view change timeout in milliseconds. If a backup does not receive "
00256       "the pre-prepare message for a request forwarded to the primary after "
00257       "this "
00258       "timeout, the backup triggers a new view change.")
00259     ->capture_default_str();
00260 
00261   size_t bft_status_interval = 100;
00262   app
00263     .add_option(
00264       "--bft-status-interval-ms",
00265       bft_status_interval,
00266       "bft status timer interval in milliseconds. All bft nodes send "
00267       "messages "
00268       "containing their status to all other known nodes at regular intervals "
00269       "defined by this timer interval.")
00270     ->capture_default_str();
00271 
00272   size_t max_msg_size = 24;
00273   app
00274     .add_option(
00275       "--max-msg-size",
00276       max_msg_size,
00277       "Determines maximum total number of bytes for a message sent over the "
00278       "ringbuffer. Messages may be split into multiple fragments, but this "
00279       "limits the total size of the sum of those fragments. Value is used as a "
00280       "shift factor, ie - given N, the limit is (1 << N)")
00281     ->capture_default_str();
00282 
00283   size_t max_fragment_size = 16;
00284   app
00285     .add_option(
00286       "--max-fragment-size",
00287       max_fragment_size,
00288       "Determines maximum size of individual ringbuffer message fragments. "
00289       "Messages larger than this will be split into multiple fragments. Value "
00290       "is used as a shift factor, ie - given N, the limit is (1 << N)")
00291     ->capture_default_str();
00292 
00293   size_t tick_period_ms = 10;
00294   app
00295     .add_option(
00296       "--tick-period-ms",
00297       tick_period_ms,
00298       "Wait between ticks sent to the enclave. Lower values reduce minimum "
00299       "latency at a cost to throughput")
00300     ->capture_default_str();
00301 
00302   std::string domain;
00303   app.add_option(
00304     "--domain", domain, "DNS to use for TLS certificate validation");
00305 
00306   std::string subject_name("CN=CCF Node");
00307   app
00308     .add_option(
00309       "--sn", subject_name, "Subject Name in node certificate, eg. CN=CCF Node")
00310     ->capture_default_str();
00311 
00312   std::vector<tls::SubjectAltName> subject_alternative_names;
00313   cli::add_subject_alternative_name_option(
00314     app,
00315     subject_alternative_names,
00316     "--san",
00317     "Subject Alternative Name in node certificate. Can be either "
00318     "iPAddress:xxx.xxx.xxx.xxx, or dNSName:sub.domain.tld");
00319 
00320   size_t jwt_key_refresh_interval_s = 1800;
00321   app
00322     .add_option(
00323       "--jwt-key-refresh-interval-s",
00324       jwt_key_refresh_interval_s,
00325       "Interval in seconds for JWT public signing key refresh.")
00326     ->capture_default_str();
00327 
00328   size_t memory_reserve_startup = 0;
00329   app
00330     .add_option(
00331       "--memory-reserve-startup",
00332       memory_reserve_startup,
00333 
00334 
00335 
00336       "Unused"
00337 
00338       )
00339     ->capture_default_str();
00340 
00341   // The network certificate file can either be an input or output parameter,
00342   // depending on the subcommand.
00343   std::string network_cert_file = "networkcert.pem";
00344 
00345   auto start = app.add_subcommand("start", "Start new network");
00346   start->configurable();
00347 
00348   start
00349     ->add_option(
00350       "--network-cert-file",
00351       network_cert_file,
00352       "Destination path to freshly created network certificate")
00353     ->capture_default_str()
00354     ->check(CLI::NonexistentPath);
00355 
00356   std::string gov_script = "gov.lua";
00357   start
00358     ->add_option(
00359       "--gov-script",
00360       gov_script,
00361       "Path to Lua file that defines the contents of the "
00362       "public:ccf.gov.governance.scripts table")
00363     ->capture_default_str()
00364     ->check(CLI::ExistingFile)
00365     ->required();
00366 
00367   std::vector<cli::ParsedMemberInfo> members_info;
00368   cli::add_member_info_option(
00369     *start,
00370     members_info,
00371     "--member-info",
00372     "Initial consortium members information "
00373     "(member_cert.pem[,member_enc_pubk.pem[,member_data.json]])")
00374     ->required();
00375 
00376   std::optional<size_t> recovery_threshold = std::nullopt;
00377   start
00378     ->add_option(
00379       "--recovery-threshold",
00380       recovery_threshold,
00381       "Number of member shares required for recovery. Defaults to total number "
00382       "of initial consortium members with a public encryption key.")
00383     ->check(CLI::PositiveNumber)
00384     ->type_name("UINT");
00385 
00386   auto join = app.add_subcommand("join", "Join existing network");
00387   join->configurable();
00388 
00389   join
00390     ->add_option(
00391       "--network-cert-file",
00392       network_cert_file,
00393       "Path to certificate of existing network to join")
00394     ->capture_default_str()
00395     ->check(CLI::ExistingFile);
00396 
00397   size_t join_timer = 1000;
00398   join
00399     ->add_option(
00400       "--join-timer",
00401       join_timer,
00402       "Duration after which the joining node will resend join requests to "
00403       "existing network (ms)")
00404     ->capture_default_str();
00405 
00406   cli::ParsedAddress target_rpc_address;
00407   cli::add_address_option(
00408     *join,
00409     target_rpc_address,
00410     "--target-rpc-address",
00411     "RPC over TLS listening address of target network node")
00412     ->required();
00413 
00414   auto recover = app.add_subcommand("recover", "Recover crashed network");
00415   recover->configurable();
00416 
00417   recover
00418     ->add_option(
00419       "--network-cert-file",
00420       network_cert_file,
00421       "Destination path to freshly created network certificate")
00422     ->capture_default_str()
00423     ->check(CLI::NonexistentPath);
00424 
00425   CLI11_PARSE(app, argc, argv);
00426 
00427   if (!(*public_rpc_address_option))
00428   {
00429     public_rpc_address = rpc_address;
00430   }
00431 
00432   // set json log formatter to write to std::out
00433   if (log_format_json)
00434   {
00435     logger::config::initialize_with_json_console();
00436   }
00437 
00438   const auto cli_config = app.config_to_str(true, false);
00439   LOG_INFO_FMT("Run with following options:\n{}", cli_config);
00440 
00441   uint32_t oe_flags = 0;
00442   try
00443   {
00444     if (domain.empty() && !ds::is_valid_ip(rpc_address.hostname.c_str()))
00445     {
00446       throw std::logic_error(fmt::format(
00447         "--rpc-address ({}) does not appear to specify valid IP address. "
00448         "Please specify a domain name via the --domain option",
00449         rpc_address.hostname));
00450     }
00451 
00452     if (*start && files::exists(ledger_dir))
00453     {
00454       throw std::logic_error(fmt::format(
00455         "On start, ledger directory should not exist ({})", ledger_dir));
00456     }
00457     else if (*recover && !files::exists(ledger_dir))
00458     {
00459       throw std::logic_error(fmt::format(
00460         "On recovery, ledger directory should exist ({}) ", ledger_dir));
00461     }
00462 
00463     if (*start)
00464     {
00465       // Count members with public encryption key as only these members will be
00466       // handed a recovery share.
00467       // Note that it is acceptable to start a network without any member having
00468       // a recovery share. The service will check that at least one recovery
00469       // member is added before the service can be opened.
00470       size_t members_with_pubk_count = 0;
00471       for (auto const& mi : members_info)
00472       {
00473         if (mi.enc_pubk_file.has_value())
00474         {
00475           members_with_pubk_count++;
00476         }
00477       }
00478 
00479       if (!recovery_threshold.has_value())
00480       {
00481         LOG_INFO_FMT(
00482           "Recovery threshold unset. Defaulting to number of initial "
00483           "consortium members with a public encryption key ({}).",
00484           members_with_pubk_count);
00485         recovery_threshold = members_with_pubk_count;
00486       }
00487       else if (recovery_threshold.value() > members_with_pubk_count)
00488       {
00489         throw std::logic_error(fmt::format(
00490           "Recovery threshold ({}) cannot be greater than total number ({})"
00491           "of initial consortium members with a public encryption "
00492           "key (specified via --member-info options)",
00493           recovery_threshold.value(),
00494           members_with_pubk_count));
00495       }
00496     }
00497 
00498     switch (enclave_type)
00499     {
00500       case EnclaveType::RELEASE:
00501       {
00502         break;
00503       }
00504       case EnclaveType::DEBUG:
00505       {
00506         oe_flags |= OE_ENCLAVE_FLAG_DEBUG;
00507         break;
00508       }
00509       case EnclaveType::VIRTUAL:
00510       {
00511         oe_flags = ENCLAVE_FLAG_VIRTUAL;
00512         break;
00513       }
00514       default:
00515       {
00516         throw std::logic_error(
00517           fmt::format("Invalid enclave type: {}", enclave_type));
00518       }
00519     }
00520   }
00521   catch (const std::logic_error& e)
00522   {
00523     LOG_FATAL_FMT("{}. Exiting.", e.what());
00524     return static_cast<int>(CLI::ExitCodes::ValidationError);
00525   }
00526 
00527   // Write PID to disk
00528   files::dump(fmt::format("{}", ::getpid()), node_pid_file);
00529 
00530   // set the host log level
00531   logger::config::level() = host_log_level;
00532 
00533   // create the enclave
00534   host::Enclave enclave(enclave_file, oe_flags);
00535 
00536   // messaging ring buffers
00537   const auto buffer_size = 1 << circuit_size_shift;
00538 
00539   std::vector<uint8_t> to_enclave_buffer(buffer_size);
00540   ringbuffer::Offsets to_enclave_offsets;
00541   ringbuffer::BufferDef to_enclave_def{
00542     to_enclave_buffer.data(), to_enclave_buffer.size(), &to_enclave_offsets};
00543 
00544   std::vector<uint8_t> from_enclave_buffer(buffer_size);
00545   ringbuffer::Offsets from_enclave_offsets;
00546   ringbuffer::BufferDef from_enclave_def{from_enclave_buffer.data(),
00547                                          from_enclave_buffer.size(),
00548                                          &from_enclave_offsets};
00549 
00550   ringbuffer::Circuit circuit(to_enclave_def, from_enclave_def);
00551   messaging::BufferProcessor bp("Host");
00552 
00553   // To prevent deadlock, all blocking writes from the host to the ringbuffer
00554   // will be queued if the ringbuffer is full
00555   ringbuffer::WriterFactory base_factory(circuit);
00556   ringbuffer::NonBlockingWriterFactory non_blocking_factory(base_factory);
00557 
00558   // Factory for creating writers which will handle writing of large messages
00559   oversized::WriterConfig writer_config{(size_t)(1 << max_fragment_size),
00560                                         (size_t)(1 << max_msg_size)};
00561   oversized::WriterFactory writer_factory(non_blocking_factory, writer_config);
00562 
00563   // reconstruct oversized messages sent to the host
00564   oversized::FragmentReconstructor fr(bp.get_dispatcher());
00565 
00566   {
00567     // provide regular ticks to the enclave
00568     const std::chrono::milliseconds tick_period(tick_period_ms);
00569     asynchost::Ticker ticker(tick_period, writer_factory, [](auto s) {
00570       logger::config::set_start(s);
00571     });
00572 
00573     // reset the inbound-TCP processing quota each iteration
00574     asynchost::ResetTCPReadQuota reset_tcp_quota;
00575 
00576     // regularly update the time given to the enclave
00577     asynchost::TimeUpdater time_updater(1ms);
00578 
00579     // regularly record some load statistics
00580     asynchost::LoadMonitor load_monitor(500ms, bp);
00581 
00582     // handle outbound messages from the enclave
00583     asynchost::HandleRingbuffer handle_ringbuffer(
00584       1ms, bp, circuit.read_from_inside(), non_blocking_factory);
00585 
00586     // graceful shutdown on sigterm
00587     asynchost::Sigterm sigterm(writer_factory);
00588 
00589     asynchost::Ledger ledger(
00590       ledger_dir,
00591       writer_factory,
00592       ledger_chunk_bytes,
00593       asynchost::ledger_max_read_cache_files_default,
00594       read_only_ledger_dirs);
00595     ledger.register_message_handlers(bp.get_dispatcher());
00596 
00597     asynchost::SnapshotManager snapshots(snapshot_dir, ledger);
00598     snapshots.register_message_handlers(bp.get_dispatcher());
00599 
00600     // Begin listening for node-to-node and RPC messages.
00601     // This includes DNS resolution and potentially dynamic port assignment (if
00602     // requesting port 0). The hostname and port may be modified - after calling
00603     // it holds the final assigned values.
00604     asynchost::NodeConnectionsTickingReconnect node(
00605       20ms, //< Flush reconnections every 20ms
00606       bp.get_dispatcher(),
00607       ledger,
00608       writer_factory,
00609       node_address.hostname,
00610       node_address.port);
00611     if (!node_address_file.empty())
00612     {
00613       files::dump(
00614         fmt::format("{}\n{}", node_address.hostname, node_address.port),
00615         node_address_file);
00616     }
00617 
00618     asynchost::RPCConnections rpc(writer_factory);
00619     rpc.register_message_handlers(bp.get_dispatcher());
00620     rpc.listen(0, rpc_address.hostname, rpc_address.port);
00621     if (!rpc_address_file.empty())
00622     {
00623       files::dump(
00624         fmt::format("{}\n{}", rpc_address.hostname, rpc_address.port),
00625         rpc_address_file);
00626     }
00627     if (public_rpc_address.port == "0")
00628     {
00629       public_rpc_address.port = rpc_address.port;
00630     }
00631 
00632     // Initialise the enclave and create a CCF node in it
00633     const size_t certificate_size = 4096;
00634     std::vector<uint8_t> node_cert(certificate_size);
00635     std::vector<uint8_t> network_cert(certificate_size);
00636 
00637     StartType start_type = StartType::Unknown;
00638 
00639     EnclaveConfig enclave_config;
00640     enclave_config.to_enclave_buffer_start = to_enclave_buffer.data();
00641     enclave_config.to_enclave_buffer_size = to_enclave_buffer.size();
00642     enclave_config.to_enclave_buffer_offsets = &to_enclave_offsets;
00643     enclave_config.from_enclave_buffer_start = from_enclave_buffer.data();
00644     enclave_config.from_enclave_buffer_size = from_enclave_buffer.size();
00645     enclave_config.from_enclave_buffer_offsets = &from_enclave_offsets;
00646 
00647     enclave_config.writer_config = writer_config;
00648 
00649 
00650 
00651 
00652     CCFConfig ccf_config;
00653     ccf_config.consensus_config = {raft_timeout,
00654                                    raft_election_timeout,
00655                                    bft_view_change_timeout,
00656                                    bft_status_interval};
00657     ccf_config.signature_intervals = {sig_tx_interval, sig_ms_interval};
00658     ccf_config.node_info_network = {rpc_address.hostname,
00659                                     public_rpc_address.hostname,
00660                                     node_address.hostname,
00661                                     node_address.port,
00662                                     rpc_address.port,
00663                                     public_rpc_address.port};
00664     ccf_config.domain = domain;
00665     ccf_config.snapshot_tx_interval = snapshot_tx_interval;
00666 
00667     ccf_config.subject_name = subject_name;
00668     ccf_config.subject_alternative_names = subject_alternative_names;
00669 
00670     ccf_config.jwt_key_refresh_interval_s = jwt_key_refresh_interval_s;
00671 
00672     if (*start)
00673     {
00674       start_type = StartType::New;
00675 
00676       for (auto const& m_info : members_info)
00677       {
00678         std::optional<std::vector<uint8_t>> public_encryption_key_file =
00679           std::nullopt;
00680         if (m_info.enc_pubk_file.has_value())
00681         {
00682           public_encryption_key_file =
00683             files::slurp(m_info.enc_pubk_file.value());
00684         }
00685 
00686         nlohmann::json md = nullptr;
00687         if (m_info.member_data_file.has_value())
00688         {
00689           md = nlohmann::json::parse(
00690             files::slurp(m_info.member_data_file.value()));
00691         }
00692 
00693         ccf_config.genesis.members_info.emplace_back(
00694           files::slurp(m_info.cert_file), public_encryption_key_file, md);
00695       }
00696       ccf_config.genesis.gov_script = files::slurp_string(gov_script);
00697       ccf_config.genesis.recovery_threshold = recovery_threshold.value();
00698       LOG_INFO_FMT(
00699         "Creating new node: new network (with {} initial member(s) and {} "
00700         "member(s) required for recovery)",
00701         ccf_config.genesis.members_info.size(),
00702         ccf_config.genesis.recovery_threshold);
00703     }
00704     else if (*join)
00705     {
00706       LOG_INFO_FMT(
00707         "Creating new node - joining existing network at {}:{}",
00708         target_rpc_address.hostname,
00709         target_rpc_address.port);
00710       start_type = StartType::Join;
00711 
00712       ccf_config.joining.target_host = target_rpc_address.hostname;
00713       ccf_config.joining.target_port = target_rpc_address.port;
00714       ccf_config.joining.network_cert = files::slurp(network_cert_file);
00715       ccf_config.joining.join_timer = join_timer;
00716     }
00717     else if (*recover)
00718     {
00719       LOG_INFO_FMT("Creating new node - recover");
00720       start_type = StartType::Recover;
00721     }
00722 
00723     if (*join || *recover)
00724     {
00725       auto snapshot_file = snapshots.find_latest_committed_snapshot();
00726       if (snapshot_file.has_value())
00727       {
00728         auto& snapshot = snapshot_file.value();
00729         auto snapshot_evidence_idx =
00730           asynchost::get_snapshot_evidence_idx_from_file_name(snapshot);
00731         if (!snapshot_evidence_idx.has_value())
00732         {
00733           throw std::logic_error(fmt::format(
00734             "Snapshot file \"{}\" does not include snapshot evidence seqno",
00735             snapshot));
00736         }
00737 
00738         ccf_config.startup_snapshot = files::slurp(snapshot);
00739         ccf_config.startup_snapshot_evidence_seqno =
00740           snapshot_evidence_idx->first;
00741         LOG_INFO_FMT(
00742           "Found latest snapshot file: {} (size: {}, evidence seqno: {})",
00743           snapshot,
00744           ccf_config.startup_snapshot.size(),
00745           ccf_config.startup_snapshot_evidence_seqno);
00746       }
00747       else
00748       {
00749         LOG_FAIL_FMT(
00750           "No snapshot found: Node will request all historical transactions");
00751       }
00752     }
00753 
00754     if (start_type == StartType::Unknown)
00755     {
00756       LOG_FATAL_FMT("Start command should be start|join|recover. Exiting.");
00757     }
00758 
00759     enclave.create_node(
00760       enclave_config,
00761       ccf_config,
00762       node_cert,
00763       network_cert,
00764       start_type,
00765       consensus,
00766       num_worker_threads,
00767       time_updater->behaviour.get_value());
00768 
00769     LOG_INFO_FMT("Created new node");
00770 
00771     // Write the node and network certs to disk.
00772     files::dump(node_cert, node_cert_file);
00773     if (*start || *recover)
00774     {
00775       files::dump(network_cert, network_cert_file);
00776     }
00777 
00778     auto enclave_thread_start = [&]() {
00779 
00780       try
00781 
00782       {
00783         enclave.run();
00784       }
00785 
00786       catch (const std::exception& e)
00787       {
00788         LOG_FAIL_FMT("Exception in enclave::run: {}", e.what());
00789 
00790         // This exception should be rethrown, probably aborting the process, but
00791         // we sleep briefly to allow more outbound messages to be processed. If
00792         // the enclave sent logging messages, it is useful to read and print
00793         // them before dying.
00794         std::this_thread::sleep_for(1s);
00795         throw;
00796       }
00797 
00798     };
00799 
00800     // Start threads which will ECall and process messages inside the enclave
00801     std::vector<std::thread> threads;
00802     for (uint32_t i = 0; i < (num_worker_threads + 1); ++i)
00803     {
00804       threads.emplace_back(std::thread(enclave_thread_start));
00805     }
00806 
00807     uv_run(uv_default_loop(), UV_RUN_DEFAULT);
00808     for (auto& t : threads)
00809     {
00810       t.join();
00811     }
00812   }
00813 
00814   // Continue running the loop long enough for the on_close
00815   // callbacks to be despatched, so as to avoid memory being
00816   // leaked by handles. Capped out of abundance of caution.
00817   size_t close_iterations = 100;
00818   while (uv_loop_alive(uv_default_loop()) && close_iterations > 0)
00819   {
00820     uv_run(uv_default_loop(), UV_RUN_NOWAIT);
00821     close_iterations--;
00822   }
00823   LOG_INFO_FMT("Ran an extra {} cleanup iteration(s)", 100 - close_iterations);
00824 
00825   auto rc = uv_loop_close(uv_default_loop());
00826   if (rc)
00827     LOG_FAIL_FMT("Failed to close uv loop cleanly: {}", uv_err_name(rc));
00828 
00829   return rc;
00830 }
00831 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/main.cpp...
Preprocessing /data/git/CCF/src/host/node_connections.h...
#include consensus/aft/raft_types.h: not found! skipping...
#include host/timer.h: not found! skipping...
#include ledger.h: already included! skipping...
#include node/node_types.h: not found! skipping...
#include tcp.h: already included! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 10410 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace asynchost
00014 {
00015   class NodeConnections
00016   {
00017   private:
00018     class ConnectionBehaviour : public TCPBehaviour
00019     {
00020     public:
00021       NodeConnections& parent;
00022       ccf::NodeId node;
00023       uint32_t msg_size = (uint32_t)-1;
00024       std::vector<uint8_t> pending;
00025 
00026       ConnectionBehaviour(NodeConnections& parent, ccf::NodeId node) :
00027         parent(parent),
00028         node(node)
00029       {}
00030 
00031       void on_read(size_t len, uint8_t*& incoming)
00032       {
00033         LOG_DEBUG_FMT("from node {} received {} bytes", node, len);
00034 
00035         pending.insert(pending.end(), incoming, incoming + len);
00036 
00037         const uint8_t* data = pending.data();
00038         size_t size = pending.size();
00039         size_t used = 0;
00040 
00041         while (true)
00042         {
00043           if (msg_size == (uint32_t)-1)
00044           {
00045             if (size < sizeof(uint32_t))
00046               break;
00047 
00048             msg_size = serialized::read<uint32_t>(data, size);
00049             used += sizeof(uint32_t);
00050           }
00051 
00052           if (size < msg_size)
00053           {
00054             LOG_DEBUG_FMT(
00055               "from node {} have {}/{} bytes", node, size, msg_size);
00056             break;
00057           }
00058 
00059           auto p = data;
00060           auto psize = size;
00061           auto msg_type = serialized::read<ccf::NodeMsgType>(p, psize);
00062           auto header = serialized::read<ccf::Header>(p, psize);
00063 
00064           if (node == ccf::NoNode)
00065             associate(header.from_node);
00066 
00067           LOG_DEBUG_FMT(
00068             "node in: from node {}, size {}, type {}",
00069             node,
00070             msg_size,
00071             msg_type);
00072 
00073           RINGBUFFER_WRITE_MESSAGE(
00074             ccf::node_inbound,
00075             parent.to_enclave,
00076             serializer::ByteRange{data, msg_size});
00077 
00078           data += msg_size;
00079           used += msg_size;
00080           size -= msg_size;
00081           msg_size = (uint32_t)-1;
00082         }
00083 
00084         if (used > 0)
00085           pending.erase(pending.begin(), pending.begin() + used);
00086       }
00087 
00088       virtual void associate(ccf::NodeId) {}
00089     };
00090 
00091     class IncomingBehaviour : public ConnectionBehaviour
00092     {
00093     public:
00094       size_t id;
00095 
00096       IncomingBehaviour(NodeConnections& parent, size_t id) :
00097         ConnectionBehaviour(parent, ccf::NoNode),
00098         id(id)
00099       {}
00100 
00101       void on_disconnect()
00102       {
00103         LOG_DEBUG_FMT("node incoming disconnect {} with node {}", id, node);
00104 
00105         parent.incoming.erase(id);
00106 
00107         if (node != ccf::NoNode)
00108           parent.associated.erase(node);
00109       }
00110 
00111       virtual void associate(ccf::NodeId n)
00112       {
00113         node = n;
00114         parent.associated.emplace(node, parent.incoming.at(id));
00115         LOG_DEBUG_FMT("node incoming {} associated with {}", id, node);
00116       }
00117     };
00118 
00119     class OutgoingBehaviour : public ConnectionBehaviour
00120     {
00121     public:
00122       OutgoingBehaviour(NodeConnections& parent, ccf::NodeId node) :
00123         ConnectionBehaviour(parent, node)
00124       {}
00125 
00126       void on_resolve_failed()
00127       {
00128         LOG_DEBUG_FMT("node resolve failed {}", node);
00129         reconnect();
00130       }
00131 
00132       void on_connect_failed()
00133       {
00134         LOG_DEBUG_FMT("node connect failed {}", node);
00135         reconnect();
00136       }
00137 
00138       void on_disconnect()
00139       {
00140         LOG_DEBUG_FMT("node disconnect failed {}", node);
00141         reconnect();
00142       }
00143 
00144       void reconnect()
00145       {
00146         parent.request_reconnect(node);
00147       }
00148     };
00149 
00150     class NodeServerBehaviour : public TCPServerBehaviour
00151     {
00152     public:
00153       NodeConnections& parent;
00154 
00155       NodeServerBehaviour(NodeConnections& parent) : parent(parent) {}
00156 
00157       void on_listening(
00158         const std::string& host, const std::string& service) override
00159       {
00160         LOG_INFO_FMT("Listening for node-to-node on {}:{}", host, service);
00161       }
00162 
00163       void on_accept(TCP& peer) override
00164       {
00165         auto id = parent.get_next_id();
00166         peer->set_behaviour(std::make_unique<IncomingBehaviour>(parent, id));
00167         parent.incoming.emplace(id, peer);
00168 
00169         LOG_DEBUG_FMT("node accept {}", id);
00170       }
00171     };
00172 
00173     Ledger& ledger;
00174     TCP listener;
00175 
00176     // The lifetime of outgoing connections is handled by node channels in the
00177     // enclave
00178     std::unordered_map<ccf::NodeId, TCP> outgoing;
00179 
00180     std::unordered_map<size_t, TCP> incoming;
00181     std::unordered_map<ccf::NodeId, TCP> associated;
00182     size_t next_id = 1;
00183     ringbuffer::WriterPtr to_enclave;
00184     std::set<ccf::NodeId> reconnect_queue;
00185 
00186   public:
00187     NodeConnections(
00188       messaging::Dispatcher<ringbuffer::Message>& disp,
00189       Ledger& ledger,
00190       ringbuffer::AbstractWriterFactory& writer_factory,
00191       std::string& host,
00192       std::string& service) :
00193       ledger(ledger),
00194       to_enclave(writer_factory.create_writer_to_inside())
00195     {
00196       listener->set_behaviour(std::make_unique<NodeServerBehaviour>(*this));
00197       listener->listen(host, service);
00198       host = listener->get_host();
00199       service = listener->get_service();
00200 
00201       register_message_handlers(disp);
00202     }
00203 
00204     void register_message_handlers(
00205       messaging::Dispatcher<ringbuffer::Message>& disp)
00206     {
00207       DISPATCHER_SET_MESSAGE_HANDLER(
00208         disp, ccf::add_node, [this](const uint8_t* data, size_t size) {
00209           auto [id, hostname, service] =
00210             ringbuffer::read_message<ccf::add_node>(data, size);
00211           add_node(id, hostname, service);
00212         });
00213 
00214       DISPATCHER_SET_MESSAGE_HANDLER(
00215         disp, ccf::remove_node, [this](const uint8_t* data, size_t size) {
00216           auto [id] = ringbuffer::read_message<ccf::remove_node>(data, size);
00217           remove_node(id);
00218         });
00219 
00220       DISPATCHER_SET_MESSAGE_HANDLER(
00221         disp, ccf::node_outbound, [this](const uint8_t* data, size_t size) {
00222           auto to = serialized::read<ccf::NodeId>(data, size);
00223           auto node = find(to, true);
00224 
00225           if (!node)
00226             return;
00227 
00228           auto data_to_send = data;
00229           auto size_to_send = size;
00230 
00231           // If the message is a consensus append entries message, affix the
00232           // corresponding ledger entries
00233           auto msg_type = serialized::read<ccf::NodeMsgType>(data, size);
00234           if (
00235             msg_type == ccf::NodeMsgType::consensus_msg &&
00236             (serialized::peek<aft::RaftMsgType>(data, size) ==
00237              aft::raft_append_entries))
00238           {
00239             // Parse the indices to be sent to the recipient.
00240             auto p = data;
00241             auto psize = size;
00242 
00243             serialized::overlay<consensus::ConsensusHeader<ccf::Node2NodeMsg>>(
00244               p, psize);
00245 
00246             const auto& ae =
00247               serialized::overlay<consensus::AppendEntriesIndex>(p, psize);
00248 
00249             // Find the total frame size, and write it along with the header.
00250             uint32_t frame = (uint32_t)size_to_send;
00251             std::optional<std::vector<uint8_t>> framed_entries = std::nullopt;
00252 
00253             framed_entries =
00254               ledger.read_framed_entries(ae.prev_idx + 1, ae.idx);
00255             if (framed_entries.has_value())
00256             {
00257               frame += (uint32_t)framed_entries->size();
00258               node.value()->write(sizeof(uint32_t), (uint8_t*)&frame);
00259               node.value()->write(size_to_send, data_to_send);
00260 
00261               frame = (uint32_t)framed_entries->size();
00262               node.value()->write(frame, framed_entries->data());
00263             }
00264             else
00265             {
00266               // Header-only AE
00267               node.value()->write(sizeof(uint32_t), (uint8_t*)&frame);
00268               node.value()->write(size_to_send, data_to_send);
00269             }
00270 
00271             LOG_DEBUG_FMT(
00272               "send AE to node {} [{}]: {}, {}",
00273               to,
00274               frame,
00275               ae.idx,
00276               ae.prev_idx);
00277           }
00278           else
00279           {
00280             // Write as framed data to the recipient.
00281             uint32_t frame = (uint32_t)size_to_send;
00282 
00283             LOG_DEBUG_FMT("node send to {} [{}]", to, frame);
00284 
00285             node.value()->write(sizeof(uint32_t), (uint8_t*)&frame);
00286             node.value()->write(size_to_send, data_to_send);
00287           }
00288         });
00289     }
00290 
00291     void request_reconnect(ccf::NodeId node)
00292     {
00293       reconnect_queue.insert(node);
00294     }
00295 
00296     void on_timer()
00297     {
00298       // Swap to local copy of queue. Although this should only be modified by
00299       // this thread, it may be modified recursively (ie - executing this
00300       // function may result in calls to request_reconnect). These recursive
00301       // calls are queued until the next iteration
00302       decltype(reconnect_queue) local_queue;
00303       std::swap(reconnect_queue, local_queue);
00304 
00305       for (const auto node : local_queue)
00306       {
00307         LOG_DEBUG_FMT("reconnecting node {}", node);
00308         auto s = outgoing.find(node);
00309         if (s != outgoing.end())
00310         {
00311           s->second->reconnect();
00312         }
00313       }
00314     }
00315 
00316   private:
00317     bool add_node(
00318       ccf::NodeId node, const std::string& host, const std::string& service)
00319     {
00320       if (outgoing.find(node) != outgoing.end())
00321       {
00322         LOG_FAIL_FMT("Cannot add node connection {}: already in use", node);
00323         return false;
00324       }
00325 
00326       TCP s;
00327       s->set_behaviour(std::make_unique<OutgoingBehaviour>(*this, node));
00328 
00329       if (!s->connect(host, service))
00330       {
00331         LOG_DEBUG_FMT("Node failed initial connect {}", node);
00332         return false;
00333       }
00334 
00335       outgoing.emplace(node, s);
00336 
00337       LOG_DEBUG_FMT(
00338         "Added node connection with {} ({}:{})", node, host, service);
00339       return true;
00340     }
00341 
00342     std::optional<TCP> find(ccf::NodeId node, bool use_incoming = false)
00343     {
00344       auto s = outgoing.find(node);
00345 
00346       if (s != outgoing.end())
00347         return s->second;
00348 
00349       if (use_incoming)
00350       {
00351         auto s = associated.find(node);
00352 
00353         if (s != associated.end())
00354           return s->second;
00355       }
00356 
00357       LOG_FAIL_FMT("Unknown node connection {}", node);
00358       return {};
00359     }
00360 
00361     bool remove_node(ccf::NodeId node)
00362     {
00363       if (outgoing.erase(node) < 1)
00364       {
00365         LOG_FAIL_FMT("Cannot remove node connection {}: does not exist", node);
00366         return false;
00367       }
00368 
00369       LOG_DEBUG_FMT("Removed node connection with {}", node);
00370 
00371       return true;
00372     }
00373 
00374     size_t get_next_id()
00375     {
00376       auto id = next_id++;
00377 
00378       while (incoming.find(id) != incoming.end())
00379         id = next_id++;
00380 
00381       return id;
00382     }
00383   };
00384 
00385   using NodeConnectionsTickingReconnect = proxy_ptr<Timer<NodeConnections>>;
00386 }
00387 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/node_connections.h...
Preprocessing /data/git/CCF/src/host/proxy.h...
#include uv.h: not found! skipping...
Preprocessor output (size: 2023 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace asynchost
00008 {
00009   template <typename T>
00010   class proxy_ptr;
00011 
00012   template <typename T>
00013   class close_ptr
00014   {
00015   private:
00016     // Use a raw pointer, such that the libuv object is only deleted after
00017     // closing.
00018     friend class proxy_ptr<T>;
00019     T* raw;
00020 
00021   public:
00022     template <typename... Args>
00023     close_ptr(Args&&... args)
00024     {
00025       raw = new T(std::forward<Args>(args)...);
00026     }
00027 
00028     ~close_ptr()
00029     {
00030       raw->close();
00031     }
00032   };
00033 
00034   template <typename T>
00035   class proxy_ptr
00036   {
00037   private:
00038     std::shared_ptr<close_ptr<T>> internal;
00039 
00040   public:
00041     proxy_ptr(proxy_ptr<T>& that) : internal(that.internal) {}
00042     proxy_ptr(const proxy_ptr<T>& that) : internal(that.internal) {}
00043     proxy_ptr(proxy_ptr<T>&& that) : internal(std::move(that.internal)) {}
00044     proxy_ptr(std::nullptr_t that) : internal(that) {}
00045 
00046     template <typename... Args>
00047     proxy_ptr(Args&&... args) :
00048       internal(std::make_shared<close_ptr<T>>(std::forward<Args>(args)...))
00049     {}
00050 
00051     T* operator->()
00052     {
00053       return internal.get()->raw;
00054     }
00055 
00056     proxy_ptr<T>& operator=(const proxy_ptr<T>& that) = default;
00057 
00058     bool is_null()
00059     {
00060       return internal == nullptr;
00061     }
00062   };
00063 
00064   template <typename handle_type>
00065   class with_uv_handle
00066   {
00067   protected:
00068     handle_type uv_handle;
00069 
00070     with_uv_handle() {}
00071     with_uv_handle(const with_uv_handle<handle_type>& that) = delete;
00072     with_uv_handle(with_uv_handle<handle_type>&& that) = delete;
00073 
00074     virtual ~with_uv_handle() = default;
00075 
00076   private:
00077     template <typename T>
00078     friend class close_ptr;
00079 
00080     void close()
00081     {
00082       uv_close((uv_handle_t*)&uv_handle, on_close);
00083     }
00084 
00085     static void on_close(uv_handle_t* handle)
00086     {
00087       static_cast<with_uv_handle<handle_type>*>(handle->data)->on_close();
00088     }
00089 
00090     void on_close()
00091     {
00092       // We are being notified asynchronously that libuv has finished closing
00093       // our handle.
00094       delete this;
00095     }
00096   };
00097 }
00098 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/proxy.h...
Preprocessing /data/git/CCF/src/host/rpc_connections.h...
#include ../tls/msg_types.h: already included! skipping...
#include tcp.h: already included! skipping...
#include unordered_map: not found! skipping...
Preprocessor output (size: 6284 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace asynchost
00011 {
00012   class RPCConnections
00013   {
00014   private:
00015     class ClientBehaviour : public TCPBehaviour
00016     {
00017     public:
00018       RPCConnections& parent;
00019       int64_t id;
00020 
00021       ClientBehaviour(RPCConnections& parent, int64_t id) :
00022         parent(parent),
00023         id(id)
00024       {}
00025 
00026       void on_resolve_failed()
00027       {
00028         LOG_DEBUG_FMT("rpc resolve failed {}", id);
00029         cleanup();
00030       }
00031 
00032       void on_connect_failed()
00033       {
00034         LOG_DEBUG_FMT("rpc connect failed {}", id);
00035         cleanup();
00036       }
00037 
00038       void on_read(size_t len, uint8_t*& data)
00039       {
00040         LOG_DEBUG_FMT("rpc read {}: {}", id, len);
00041 
00042         RINGBUFFER_WRITE_MESSAGE(
00043           tls::tls_inbound,
00044           parent.to_enclave,
00045           (size_t)id,
00046           serializer::ByteRange{data, len});
00047       }
00048 
00049       void on_disconnect()
00050       {
00051         LOG_DEBUG_FMT("rpc disconnect {}", id);
00052         cleanup();
00053       }
00054 
00055       void cleanup()
00056       {
00057         RINGBUFFER_WRITE_MESSAGE(tls::tls_close, parent.to_enclave, (size_t)id);
00058       }
00059     };
00060 
00061     class RPCServerBehaviour : public TCPServerBehaviour
00062     {
00063     public:
00064       RPCConnections& parent;
00065       int64_t id;
00066 
00067       RPCServerBehaviour(RPCConnections& parent, int64_t id) :
00068         parent(parent),
00069         id(id)
00070       {}
00071 
00072       void on_listening(
00073         const std::string& host, const std::string& service) override
00074       {
00075         LOG_INFO_FMT("Listening for RPCs on {}:{}", host, service);
00076       }
00077 
00078       void on_accept(TCP& peer) override
00079       {
00080         auto client_id = parent.get_next_id();
00081         peer->set_behaviour(
00082           std::make_unique<ClientBehaviour>(parent, client_id));
00083 
00084         parent.sockets.emplace(client_id, peer);
00085 
00086         LOG_DEBUG_FMT("rpc accept {}", client_id);
00087 
00088         RINGBUFFER_WRITE_MESSAGE(
00089           tls::tls_start, parent.to_enclave, (size_t)client_id);
00090       }
00091 
00092       void cleanup()
00093       {
00094         parent.sockets.erase(id);
00095       }
00096     };
00097 
00098     std::unordered_map<int64_t, TCP> sockets;
00099     int64_t next_id = 1;
00100 
00101     ringbuffer::WriterPtr to_enclave;
00102 
00103   public:
00104     RPCConnections(ringbuffer::AbstractWriterFactory& writer_factory) :
00105       to_enclave(writer_factory.create_writer_to_inside())
00106     {}
00107 
00108     bool listen(int64_t id, std::string& host, std::string& service)
00109     {
00110       if (id == 0)
00111         id = get_next_id();
00112 
00113       if (sockets.find(id) != sockets.end())
00114       {
00115         LOG_FAIL_FMT("Cannot listen on id {}: already in use", id);
00116         return false;
00117       }
00118 
00119       TCP s;
00120       s->set_behaviour(std::make_unique<RPCServerBehaviour>(*this, id));
00121 
00122       if (!s->listen(host, service))
00123         return false;
00124 
00125       host = s->get_host();
00126       service = s->get_service();
00127 
00128       sockets.emplace(id, s);
00129       return true;
00130     }
00131 
00132     bool connect(
00133       int64_t id, const std::string& host, const std::string& service)
00134     {
00135       if (id == 0)
00136         id = get_next_id();
00137 
00138       if (sockets.find(id) != sockets.end())
00139       {
00140         LOG_FAIL_FMT("Cannot connect on id {}: already in use", id);
00141         return false;
00142       }
00143 
00144       TCP s;
00145       s->set_behaviour(std::make_unique<ClientBehaviour>(*this, id));
00146 
00147       if (!s->connect(host, service))
00148         return false;
00149 
00150       sockets.emplace(id, s);
00151       return true;
00152     }
00153 
00154     bool write(int64_t id, size_t len, const uint8_t* data)
00155     {
00156       auto s = sockets.find(id);
00157 
00158       if (s == sockets.end())
00159       {
00160         LOG_FAIL_FMT(
00161           "Received an outbound message for id {} which is not a known "
00162           "connection. Ignoring message of {} bytes",
00163           id,
00164           len);
00165         return false;
00166       }
00167 
00168       if (s->second.is_null())
00169         return false;
00170 
00171       return s->second->write(len, data);
00172     }
00173 
00174     bool stop(int64_t id)
00175     {
00176       // Invalidating the TCP socket will result in the handle being closed. No
00177       // more messages will be read from or written to the TCP socket.
00178       sockets[id] = nullptr;
00179       RINGBUFFER_WRITE_MESSAGE(tls::tls_close, to_enclave, (size_t)id);
00180 
00181       return true;
00182     }
00183 
00184     bool close(int64_t id)
00185     {
00186       if (sockets.erase(id) < 1)
00187       {
00188         LOG_FAIL_FMT("Cannot close id {}: does not exist", id);
00189         return false;
00190       }
00191 
00192       return true;
00193     }
00194 
00195     void register_message_handlers(
00196       messaging::Dispatcher<ringbuffer::Message>& disp)
00197     {
00198       DISPATCHER_SET_MESSAGE_HANDLER(
00199         disp, tls::tls_outbound, [this](const uint8_t* data, size_t size) {
00200           auto [id, body] =
00201             ringbuffer::read_message<tls::tls_outbound>(data, size);
00202 
00203           int64_t connect_id = (int64_t)id;
00204           LOG_DEBUG_FMT("rpc write from enclave {}: {}", connect_id, body.size);
00205 
00206           write(connect_id, body.size, body.data);
00207         });
00208 
00209       DISPATCHER_SET_MESSAGE_HANDLER(
00210         disp, tls::tls_connect, [this](const uint8_t* data, size_t size) {
00211           auto [id, host, service] =
00212             ringbuffer::read_message<tls::tls_connect>(data, size);
00213 
00214           int64_t connect_id = (int64_t)id;
00215           LOG_DEBUG_FMT("rpc connect request from enclave {}", connect_id);
00216 
00217           if (check_enclave_side_id(connect_id))
00218             connect(connect_id, host, service);
00219         });
00220 
00221       DISPATCHER_SET_MESSAGE_HANDLER(
00222         disp, tls::tls_stop, [this](const uint8_t* data, size_t size) {
00223           auto [id, msg] = ringbuffer::read_message<tls::tls_stop>(data, size);
00224 
00225           LOG_DEBUG_FMT("rpc stop from enclave {}, {}", id, msg);
00226           stop(id);
00227         });
00228 
00229       DISPATCHER_SET_MESSAGE_HANDLER(
00230         disp, tls::tls_closed, [this](const uint8_t* data, size_t size) {
00231           auto [id] = ringbuffer::read_message<tls::tls_closed>(data, size);
00232 
00233           LOG_DEBUG_FMT("rpc closed from enclave {}", id);
00234           close(id);
00235         });
00236     }
00237 
00238   private:
00239     int64_t get_next_id()
00240     {
00241       auto id = next_id++;
00242 
00243       if (next_id < 0)
00244         next_id = 1;
00245 
00246       while (sockets.find(id) != sockets.end())
00247       {
00248         id++;
00249 
00250         if (id < 0)
00251           id = 1;
00252       }
00253 
00254       return id;
00255     }
00256 
00257     bool check_enclave_side_id(int64_t id)
00258     {
00259       bool ok = id < 0;
00260 
00261       if (!ok)
00262       {
00263         LOG_FAIL_FMT("rpc id is not in dedicated range ({})", id);
00264       }
00265 
00266       return ok;
00267     }
00268   };
00269 }
00270 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/rpc_connections.h...
Preprocessing /data/git/CCF/src/host/sig_term.h...
#include enclave.h: already included! skipping...
#include signal.h: already included! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 584 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace asynchost
00011 {
00012   class SigtermImpl
00013   {
00014   private:
00015     ringbuffer::WriterPtr to_enclave;
00016 
00017   public:
00018     SigtermImpl(ringbuffer::AbstractWriterFactory& writer_factory) :
00019       to_enclave(writer_factory.create_writer_to_inside())
00020     {}
00021 
00022     void on_signal()
00023     {
00024       LOG_INFO_FMT("SIGTERM: Shutting down enclave gracefully...");
00025       RINGBUFFER_WRITE_MESSAGE(AdminMessage::stop, to_enclave);
00026     }
00027   };
00028 
00029   using Sigterm = proxy_ptr<Signal<SIGTERM, SigtermImpl>>;
00030 }
00031 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/sig_term.h...
Preprocessing /data/git/CCF/src/host/signal.h...
#include proxy.h: already included! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 1126 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace asynchost
00010 {
00011   template <int signum, typename Behaviour>
00012   class Signal : public with_uv_handle<uv_signal_t>
00013   {
00014   private:
00015     friend class close_ptr<Signal<signum, Behaviour>>;
00016     Behaviour behaviour;
00017 
00018     template <typename... Args>
00019     Signal(Args&&... args) : behaviour(std::forward<Args>(args)...)
00020     {
00021       int rc;
00022 
00023       if ((rc = uv_signal_init(uv_default_loop(), &uv_handle)) < 0)
00024       {
00025         LOG_FAIL_FMT("uv_signal_init failed: {}", uv_strerror(rc));
00026         throw std::logic_error("uv_signal_init failed");
00027       }
00028 
00029       uv_handle.data = this;
00030 
00031       if ((rc = uv_signal_start(&uv_handle, on_signal, signum)) < 0)
00032       {
00033         LOG_FAIL_FMT("uv_signal_start failed: {}", uv_strerror(rc));
00034         throw std::logic_error("uv_signal_start failed");
00035       }
00036     }
00037 
00038     static void on_signal(uv_signal_t* handle, int)
00039     {
00040       static_cast<Signal*>(handle->data)->on_signal();
00041     }
00042 
00043     void on_signal()
00044     {
00045       behaviour.on_signal();
00046       uv_signal_stop(&uv_handle);
00047     }
00048   };
00049 }
00050 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/signal.h...
Preprocessing /data/git/CCF/src/host/snapshot.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include host/ledger.h: not found! skipping...
#include charconv: not found! skipping...
#include filesystem: not found! skipping...
#include fstream: not found! skipping...
#include iostream: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 7934 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace fs = std::filesystem;
00015 
00016 namespace asynchost
00017 {
00018   static constexpr auto snapshot_file_prefix = "snapshot";
00019   static constexpr auto snapshot_idx_delimiter = "_";
00020   static constexpr auto snapshot_committed_suffix = "committed";
00021 
00022   std::optional<std::pair<size_t, size_t>>
00023   get_snapshot_evidence_idx_from_file_name(const std::string& file_name)
00024   {
00025     // Returns snapshot evidence and evidence commit proof indices
00026     auto commit_pos =
00027       file_name.find(fmt::format(".{}", snapshot_committed_suffix));
00028     if (commit_pos == std::string::npos)
00029     {
00030       // Snapshot is not yet committed
00031       return std::nullopt;
00032     }
00033 
00034     auto idx_pos = file_name.find_first_of(snapshot_idx_delimiter);
00035     if (idx_pos == std::string::npos)
00036     {
00037       // Snapshot has no idx
00038       return std::nullopt;
00039     }
00040 
00041     auto evidence_pos =
00042       file_name.find_first_of(snapshot_idx_delimiter, idx_pos + 1);
00043     if (evidence_pos == std::string::npos)
00044     {
00045       // Snapshot has no evidence idx
00046       return std::nullopt;
00047     }
00048 
00049     auto evidence_proof_pos = file_name.find_last_of(snapshot_idx_delimiter);
00050     if (evidence_proof_pos == std::string::npos)
00051     {
00052       // Snapshot has no evidence proof idx
00053       return std::nullopt;
00054     }
00055 
00056     size_t evidence_idx;
00057     const auto evidence_start = evidence_pos + 1;
00058     const auto str_evidence_idx =
00059       file_name.substr(evidence_start, commit_pos - evidence_start);
00060     if (
00061       std::from_chars(
00062         str_evidence_idx.data(),
00063         str_evidence_idx.data() + str_evidence_idx.size(),
00064         evidence_idx)
00065         .ec != std::errc())
00066     {
00067       return std::nullopt;
00068     }
00069 
00070     size_t evidence_commit_idx;
00071     const auto str_evidence_commit_idx =
00072       file_name.substr(evidence_proof_pos + 1);
00073     if (
00074       std::from_chars(
00075         str_evidence_commit_idx.data(),
00076         str_evidence_commit_idx.data() + str_evidence_commit_idx.size(),
00077         evidence_commit_idx)
00078         .ec != std::errc())
00079     {
00080       return std::nullopt;
00081     }
00082 
00083     return std::make_pair(evidence_idx, evidence_commit_idx);
00084   }
00085 
00086   class SnapshotManager
00087   {
00088   private:
00089     const std::string snapshot_dir;
00090     const Ledger& ledger;
00091 
00092     static constexpr auto snapshot_file_prefix = "snapshot";
00093     static constexpr auto snapshot_idx_delimiter = "_";
00094     static constexpr auto snapshot_committed_suffix = "committed";
00095 
00096     size_t get_snapshot_idx_from_file_name(const std::string& file_name)
00097     {
00098       // Assumes snapshot file is not committed
00099       auto pos = file_name.find(snapshot_idx_delimiter);
00100       if (pos == std::string::npos)
00101       {
00102         throw std::logic_error(fmt::format(
00103           "Snapshot file name {} does not contain seqno", file_name));
00104       }
00105 
00106       return std::stol(file_name.substr(pos + 1));
00107     }
00108 
00109   public:
00110     SnapshotManager(const std::string& snapshot_dir_, const Ledger& ledger_) :
00111       snapshot_dir(snapshot_dir_),
00112       ledger(ledger_)
00113     {
00114       if (fs::is_directory(snapshot_dir))
00115       {
00116         LOG_INFO_FMT(
00117           "Snapshots will be stored in existing directory: {}", snapshot_dir);
00118       }
00119       else if (!fs::create_directory(snapshot_dir))
00120       {
00121         throw std::logic_error(fmt::format(
00122           "Error: Could not create snapshot directory: {}", snapshot_dir));
00123       }
00124     }
00125 
00126     void write_snapshot(
00127       consensus::Index idx,
00128       consensus::Index evidence_idx,
00129       const uint8_t* snapshot_data,
00130       size_t snapshot_size)
00131     {
00132       auto snapshot_file_name = fmt::format(
00133         "{}{}{}{}{}",
00134         snapshot_file_prefix,
00135         snapshot_idx_delimiter,
00136         idx,
00137         snapshot_idx_delimiter,
00138         evidence_idx);
00139       auto full_snapshot_path =
00140         fs::path(snapshot_dir) / fs::path(snapshot_file_name);
00141 
00142       if (fs::exists(full_snapshot_path))
00143       {
00144         throw std::logic_error(fmt::format(
00145           "Cannot write snapshot at {} since file already exists: {}",
00146           idx,
00147           full_snapshot_path));
00148       }
00149 
00150       LOG_INFO_FMT(
00151         "Writing new snapshot to {} [{}]", snapshot_file_name, snapshot_size);
00152 
00153       std::ofstream snapshot_file(
00154         full_snapshot_path, std::ios::out | std::ios::binary);
00155       snapshot_file.write(
00156         reinterpret_cast<const char*>(snapshot_data), snapshot_size);
00157     }
00158 
00159     void commit_snapshot(
00160       consensus::Index snapshot_idx, consensus::Index evidence_commit_idx)
00161     {
00162       // Find previously-generated snapshot for snapshot_idx and rename file,
00163       // including evidence_commit_idx in name too
00164       for (auto const& f : fs::directory_iterator(snapshot_dir))
00165       {
00166         auto file_name = f.path().filename().string();
00167         if (
00168           !get_snapshot_evidence_idx_from_file_name(file_name).has_value() &&
00169           get_snapshot_idx_from_file_name(file_name) == snapshot_idx)
00170         {
00171           LOG_INFO_FMT(
00172             "Committing snapshot file \"{}\" with evidence proof committed "
00173             "at "
00174             "{}",
00175             file_name,
00176             evidence_commit_idx);
00177 
00178           const auto committed_file_name = fmt::format(
00179             "{}.{}{}{}",
00180             file_name,
00181             snapshot_committed_suffix,
00182             snapshot_idx_delimiter,
00183             evidence_commit_idx);
00184 
00185           fs::rename(
00186             fs::path(snapshot_dir) / fs::path(file_name),
00187             fs::path(snapshot_dir) / fs::path(committed_file_name));
00188 
00189           return;
00190         }
00191       }
00192 
00193       LOG_FAIL_FMT("Could not find snapshot to commit at {}", snapshot_idx);
00194     }
00195 
00196     std::optional<std::string> find_latest_committed_snapshot()
00197     {
00198       std::optional<std::string> snapshot_file = std::nullopt;
00199       size_t latest_idx = 0;
00200 
00201       size_t ledger_last_idx = ledger.get_last_idx();
00202 
00203       for (auto& f : fs::directory_iterator(snapshot_dir))
00204       {
00205         auto file_name = f.path().filename().string();
00206         if (
00207           file_name.find(fmt::format(
00208             "{}{}", snapshot_file_prefix, snapshot_idx_delimiter)) ==
00209           std::string::npos)
00210         {
00211           LOG_INFO_FMT("Ignoring non-snapshot file \"{}\"", file_name);
00212           continue;
00213         }
00214 
00215         auto evidence_indices =
00216           get_snapshot_evidence_idx_from_file_name(file_name);
00217         if (!evidence_indices.has_value())
00218         {
00219           LOG_INFO_FMT("Ignoring uncommitted snapshot file \"{}\"", file_name);
00220           continue;
00221         }
00222 
00223         if (evidence_indices->second > ledger.get_last_idx())
00224         {
00225           LOG_INFO_FMT(
00226             "Ignoring \"{}\" because ledger does not contain evidence commit "
00227             "seqno: evidence commit seqno {} > last ledger seqno {}",
00228             file_name,
00229             evidence_indices->second,
00230             ledger_last_idx);
00231           continue;
00232         }
00233 
00234         auto pos = file_name.find(snapshot_idx_delimiter);
00235         size_t snapshot_idx = std::stol(file_name.substr(pos + 1));
00236         if (snapshot_idx > latest_idx)
00237         {
00238           snapshot_file = f.path().string();
00239           latest_idx = snapshot_idx;
00240         }
00241       }
00242 
00243       return snapshot_file;
00244     }
00245 
00246     void register_message_handlers(
00247       messaging::Dispatcher<ringbuffer::Message>& disp)
00248     {
00249       DISPATCHER_SET_MESSAGE_HANDLER(
00250         disp, consensus::snapshot, [this](const uint8_t* data, size_t size) {
00251           auto idx = serialized::read<consensus::Index>(data, size);
00252           auto evidence_idx = serialized::read<consensus::Index>(data, size);
00253           write_snapshot(idx, evidence_idx, data, size);
00254         });
00255 
00256       DISPATCHER_SET_MESSAGE_HANDLER(
00257         disp,
00258         consensus::snapshot_commit,
00259         [this](const uint8_t* data, size_t size) {
00260           auto snapshot_idx = serialized::read<consensus::Index>(data, size);
00261           auto evidence_commit_idx =
00262             serialized::read<consensus::Index>(data, size);
00263           commit_snapshot(snapshot_idx, evidence_commit_idx);
00264         });
00265     }
00266   };
00267 }
00268 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/snapshot.h...
Preprocessing /data/git/CCF/src/host/tcp.h...
#include ../ds/logger.h: already included! skipping...
#include before_io.h: already included! skipping...
#include dns.h: already included! skipping...
#include proxy.h: already included! skipping...
Preprocessor output (size: 15831 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace asynchost
00011 {
00012   class TCPImpl;
00013   using TCP = proxy_ptr<TCPImpl>;
00014 
00015   class TCPBehaviour
00016   {
00017   public:
00018     virtual ~TCPBehaviour() {}
00019 
00020     virtual void on_resolve_failed() {}
00021     virtual void on_listen_failed() {}
00022     virtual void on_listening(
00023       const std::string& host, const std::string& service)
00024     {
00025       LOG_INFO_FMT("Listening on {}:{}", host, service);
00026     }
00027     virtual void on_accept(TCP&) {}
00028     virtual void on_connect() {}
00029     virtual void on_connect_failed() {}
00030     virtual void on_read(size_t, uint8_t*&) {}
00031     virtual void on_disconnect() {}
00032   };
00033 
00034   class TCPServerBehaviour : public TCPBehaviour
00035   {
00036   public:
00037     virtual void on_resolve_failed() override
00038     {
00039       throw std::runtime_error("TCP server resolve failed");
00040     }
00041 
00042     virtual void on_listen_failed() override
00043     {
00044       throw std::runtime_error("TCP server listen failed");
00045     }
00046   };
00047 
00048   class TCPImpl : public with_uv_handle<uv_tcp_t>
00049   {
00050   private:
00051     friend class close_ptr<TCPImpl>;
00052 
00053     static constexpr int backlog = 128;
00054     static constexpr size_t max_read_size = 16384;
00055 
00056     // Each uv iteration, read only a capped amount from all sockets.
00057     static constexpr auto max_read_quota = max_read_size * 4;
00058     static size_t remaining_read_quota;
00059 
00060     enum Status
00061     {
00062       FRESH,
00063       LISTENING_RESOLVING,
00064       LISTENING,
00065       CONNECTING_RESOLVING,
00066       CONNECTING,
00067       CONNECTED,
00068       DISCONNECTED,
00069       RESOLVING_FAILED,
00070       LISTENING_FAILED,
00071       CONNECTING_FAILED,
00072       RECONNECTING
00073     };
00074 
00075     struct PendingWrite
00076     {
00077       uv_write_t* req;
00078       size_t len;
00079 
00080       PendingWrite(uv_write_t* req, size_t len) : req(req), len(len) {}
00081 
00082       PendingWrite(PendingWrite&& that) : req(that.req), len(that.len)
00083       {
00084         that.req = nullptr;
00085       }
00086 
00087       ~PendingWrite()
00088       {
00089         free_write(req);
00090       }
00091     };
00092 
00093     Status status;
00094     std::unique_ptr<TCPBehaviour> behaviour;
00095     std::vector<PendingWrite> pending_writes;
00096 
00097     std::string host;
00098     std::string service;
00099     addrinfo* addr_base = nullptr;
00100     addrinfo* addr_current = nullptr;
00101 
00102     bool service_assigned() const
00103     {
00104       return service != "0";
00105     }
00106 
00107     std::string get_address_name() const
00108     {
00109       const std::string port_suffix =
00110         service_assigned() ? fmt::format(":{}", service) : "";
00111 
00112       if (addr_current != nullptr && addr_current->ai_family == AF_INET6)
00113       {
00114         return fmt::format("[{}]{}", host, port_suffix);
00115       }
00116       else
00117       {
00118         return fmt::format("{}{}", host, port_suffix);
00119       }
00120     }
00121 
00122     TCPImpl() : status(FRESH)
00123     {
00124       if (!init())
00125         throw std::logic_error("uv tcp initialization failed");
00126 
00127       uv_handle.data = this;
00128     }
00129 
00130     ~TCPImpl()
00131     {
00132       if (addr_base != nullptr)
00133         uv_freeaddrinfo(addr_base);
00134     }
00135 
00136   public:
00137     static void reset_read_quota()
00138     {
00139       remaining_read_quota = max_read_quota;
00140     }
00141 
00142     void set_behaviour(std::unique_ptr<TCPBehaviour> b)
00143     {
00144       behaviour = std::move(b);
00145     }
00146 
00147     std::string get_host() const
00148     {
00149       return host;
00150     }
00151 
00152     std::string get_service() const
00153     {
00154       return service;
00155     }
00156 
00157     bool connect(const std::string& host, const std::string& service)
00158     {
00159       assert_status(FRESH, CONNECTING_RESOLVING);
00160       return resolve(host, service, false);
00161     }
00162 
00163     bool reconnect()
00164     {
00165       switch (status)
00166       {
00167         case RESOLVING_FAILED:
00168         case CONNECTING_FAILED:
00169         {
00170           // Try again, starting with DNS.
00171           LOG_DEBUG_FMT("Reconnect from DNS");
00172           status = CONNECTING_RESOLVING;
00173           return resolve(host, service, false);
00174         }
00175 
00176         case DISCONNECTED:
00177         {
00178           // Close and reset the uv_handle before trying again with the same
00179           // addr_current that succeeded previously.
00180           LOG_DEBUG_FMT("Reconnect from resolved address");
00181           status = RECONNECTING;
00182           uv_close((uv_handle_t*)&uv_handle, on_reconnect);
00183           return true;
00184         }
00185 
00186         default:
00187         {
00188           LOG_DEBUG_FMT(
00189             "Unexpected status during reconnect, ignoring: {}", status);
00190         }
00191       }
00192 
00193       return false;
00194     }
00195 
00196     bool listen(const std::string& host, const std::string& service)
00197     {
00198       assert_status(FRESH, LISTENING_RESOLVING);
00199       return resolve(host, service, false);
00200     }
00201 
00202     bool write(size_t len, const uint8_t* data)
00203     {
00204       auto req = new uv_write_t;
00205       char* copy = new char[len];
00206       if (data)
00207         memcpy(copy, data, len);
00208       req->data = copy;
00209 
00210       switch (status)
00211       {
00212         case CONNECTING_RESOLVING:
00213         case CONNECTING:
00214         case RESOLVING_FAILED:
00215         case CONNECTING_FAILED:
00216         case RECONNECTING:
00217         {
00218           pending_writes.emplace_back(req, len);
00219           break;
00220         }
00221 
00222         case CONNECTED:
00223         {
00224           return send_write(req, len);
00225         }
00226 
00227         case DISCONNECTED:
00228         {
00229           LOG_DEBUG_FMT("Disconnected: Ignoring write of size {}", len);
00230           free_write(req);
00231           break;
00232         }
00233 
00234         default:
00235         {
00236           free_write(req);
00237           throw std::logic_error(
00238             fmt::format("Unexpected status during write: {}", status));
00239         }
00240       }
00241 
00242       return true;
00243     }
00244 
00245   private:
00246     bool init()
00247     {
00248       assert_status(FRESH, FRESH);
00249       int rc;
00250 
00251       if ((rc = uv_tcp_init(uv_default_loop(), &uv_handle)) < 0)
00252       {
00253         LOG_FAIL_FMT("uv_tcp_init failed: {}", uv_strerror(rc));
00254         return false;
00255       }
00256 
00257       if ((rc = uv_tcp_keepalive(&uv_handle, 1, 30)) < 0)
00258       {
00259         LOG_FAIL_FMT("uv_tcp_keepalive failed: {}", uv_strerror(rc));
00260         return false;
00261       }
00262 
00263       uv_handle.data = this;
00264       return true;
00265     }
00266 
00267     bool send_write(uv_write_t* req, size_t len)
00268     {
00269       char* copy = (char*)req->data;
00270 
00271       uv_buf_t buf;
00272       buf.base = copy;
00273       buf.len = len;
00274 
00275       int rc;
00276 
00277       if ((rc = uv_write(req, (uv_stream_t*)&uv_handle, &buf, 1, on_write)) < 0)
00278       {
00279         free_write(req);
00280         LOG_FAIL_FMT("uv_write failed: {}", uv_strerror(rc));
00281         assert_status(CONNECTED, DISCONNECTED);
00282         behaviour->on_disconnect();
00283         return false;
00284       }
00285 
00286       return true;
00287     }
00288 
00289     void update_resolved_address(int address_family, sockaddr* sa)
00290     {
00291       constexpr auto buf_len = UV_IF_NAMESIZE;
00292       char buf[buf_len] = {};
00293       int rc;
00294 
00295       if (address_family == AF_INET6)
00296       {
00297         const auto in6 = (const sockaddr_in6*)sa;
00298         if ((rc = uv_ip6_name(in6, buf, buf_len)) != 0)
00299         {
00300           LOG_FAIL_FMT("uv_ip6_name failed: {}", uv_strerror(rc));
00301         }
00302 
00303         host = buf;
00304         service = fmt::format("{}", ntohs(in6->sin6_port));
00305       }
00306       else
00307       {
00308         const auto in4 = (const sockaddr_in*)sa;
00309         if ((rc = uv_ip4_name(in4, buf, buf_len)) != 0)
00310         {
00311           LOG_FAIL_FMT("uv_ip4_name failed: {}", uv_strerror(rc));
00312         }
00313 
00314         host = buf;
00315         service = fmt::format("{}", ntohs(in4->sin_port));
00316       }
00317     }
00318 
00319     void listen_resolved()
00320     {
00321       int rc;
00322 
00323       while (addr_current != nullptr)
00324       {
00325         update_resolved_address(addr_current->ai_family, addr_current->ai_addr);
00326 
00327         if ((rc = uv_tcp_bind(&uv_handle, addr_current->ai_addr, 0)) < 0)
00328         {
00329           addr_current = addr_current->ai_next;
00330           LOG_FAIL_FMT(
00331             "uv_tcp_bind failed on {}: {}",
00332             get_address_name(),
00333             uv_strerror(rc));
00334           continue;
00335         }
00336 
00337         if ((rc = uv_listen((uv_stream_t*)&uv_handle, backlog, on_accept)) < 0)
00338         {
00339           LOG_FAIL_FMT(
00340             "uv_listen failed on {}: {}", get_address_name(), uv_strerror(rc));
00341           addr_current = addr_current->ai_next;
00342           continue;
00343         }
00344 
00345         // If bound on port 0 (ie - asking the OS to assign a port), then we
00346         // need to call uv_tcp_getsockname to retrieve the bound port
00347         // (addr_current will not contain it)
00348         if (!service_assigned())
00349         {
00350           sockaddr_storage sa_storage;
00351           const auto sa = (sockaddr*)&sa_storage;
00352           int sa_len = sizeof(sa_storage);
00353           if ((rc = uv_tcp_getsockname(&uv_handle, sa, &sa_len)) != 0)
00354           {
00355             LOG_FAIL_FMT("uv_tcp_getsockname failed: {}", uv_strerror(rc));
00356           }
00357           update_resolved_address(addr_current->ai_family, sa);
00358         }
00359 
00360         assert_status(LISTENING_RESOLVING, LISTENING);
00361         behaviour->on_listening(host, service);
00362         return;
00363       }
00364 
00365       assert_status(LISTENING_RESOLVING, LISTENING_FAILED);
00366       behaviour->on_listen_failed();
00367     }
00368 
00369     bool connect_resolved()
00370     {
00371       auto req = new uv_connect_t;
00372       int rc;
00373 
00374       while (addr_current != nullptr)
00375       {
00376         if (
00377           (rc = uv_tcp_connect(
00378              req, &uv_handle, addr_current->ai_addr, on_connect)) < 0)
00379         {
00380           LOG_DEBUG_FMT("uv_tcp_connect retry: {}", uv_strerror(rc));
00381           addr_current = addr_current->ai_next;
00382           continue;
00383         }
00384 
00385         assert_status(CONNECTING_RESOLVING, CONNECTING);
00386         return true;
00387       }
00388 
00389       assert_status(CONNECTING_RESOLVING, CONNECTING_FAILED);
00390       delete req;
00391 
00392       LOG_DEBUG_FMT(
00393         "unable to connect: all resolved addresses failed: {}:{}",
00394         host,
00395         service);
00396 
00397       behaviour->on_connect_failed();
00398       return false;
00399     }
00400 
00401     void assert_status(Status from, Status to)
00402     {
00403       if (status != from)
00404       {
00405         throw std::logic_error(fmt::format(
00406           "Trying to transition from {} to {} but current status is {}",
00407           from,
00408           to,
00409           status));
00410       }
00411 
00412       status = to;
00413     }
00414 
00415     bool resolve(
00416       const std::string& host, const std::string& service, bool async = true)
00417     {
00418       this->host = host;
00419       this->service = service;
00420 
00421       if (addr_base != nullptr)
00422       {
00423         uv_freeaddrinfo(addr_base);
00424         addr_base = nullptr;
00425         addr_current = nullptr;
00426       }
00427 
00428       if (!DNS::resolve(host, service, this, on_resolved, async))
00429       {
00430         status = RESOLVING_FAILED;
00431         return false;
00432       }
00433 
00434       return true;
00435     }
00436 
00437     static void on_resolved(uv_getaddrinfo_t* req, int rc, struct addrinfo*)
00438     {
00439       static_cast<TCPImpl*>(req->data)->on_resolved(req, rc);
00440     }
00441 
00442     void on_resolved(uv_getaddrinfo_t* req, int rc)
00443     {
00444       // It is possible that on_resolved is triggered after there has been a
00445       // request to close uv_handle. In this scenario, we should not try to
00446       // do anything with the handle and return immediately (otherwise,
00447       // uv_close cb will abort).
00448       if (uv_is_closing((uv_handle_t*)&uv_handle))
00449       {
00450         uv_freeaddrinfo(req->addrinfo);
00451         delete req;
00452         return;
00453       }
00454 
00455       if (rc < 0)
00456       {
00457         status = RESOLVING_FAILED;
00458         LOG_TRACE_FMT("TCP resolve failed: {}", uv_strerror(rc));
00459         behaviour->on_resolve_failed();
00460       }
00461       else
00462       {
00463         addr_base = req->addrinfo;
00464         addr_current = addr_base;
00465 
00466         switch (status)
00467         {
00468           case CONNECTING_RESOLVING:
00469           {
00470             connect_resolved();
00471             break;
00472           }
00473 
00474           case LISTENING_RESOLVING:
00475           {
00476             listen_resolved();
00477             break;
00478           }
00479 
00480           default:
00481           {
00482             throw std::logic_error(
00483               fmt::format("Unexpected status during on_resolved: {}", status));
00484           }
00485         }
00486       }
00487 
00488       delete req;
00489     }
00490 
00491     static void on_accept(uv_stream_t* handle, int rc)
00492     {
00493       static_cast<TCPImpl*>(handle->data)->on_accept(rc);
00494     }
00495 
00496     void on_accept(int rc)
00497     {
00498       if (rc < 0)
00499       {
00500         LOG_DEBUG_FMT("on_accept failed: {}", uv_strerror(rc));
00501         return;
00502       }
00503 
00504       TCP peer;
00505 
00506       if (
00507         (rc = uv_accept(
00508            (uv_stream_t*)&uv_handle, (uv_stream_t*)&peer->uv_handle)) < 0)
00509       {
00510         LOG_DEBUG_FMT("uv_accept failed: {}", uv_strerror(rc));
00511         return;
00512       }
00513 
00514       peer->assert_status(FRESH, CONNECTED);
00515 
00516       if (!peer->read_start())
00517         return;
00518 
00519       behaviour->on_accept(peer);
00520     }
00521 
00522     static void on_connect(uv_connect_t* req, int rc)
00523     {
00524       auto self = static_cast<TCPImpl*>(req->handle->data);
00525       delete req;
00526       self->on_connect(rc);
00527     }
00528 
00529     void on_connect(int rc)
00530     {
00531       if (rc < 0)
00532       {
00533         // Try again on the next address.
00534         LOG_DEBUG_FMT("uv_tcp_connect async retry: {}", uv_strerror(rc));
00535         addr_current = addr_current->ai_next;
00536         assert_status(CONNECTING, CONNECTING_RESOLVING);
00537         connect_resolved();
00538       }
00539       else
00540       {
00541         assert_status(CONNECTING, CONNECTED);
00542 
00543         if (!read_start())
00544           return;
00545 
00546         for (auto& w : pending_writes)
00547         {
00548           send_write(w.req, w.len);
00549           w.req = nullptr;
00550         }
00551 
00552         std::vector<PendingWrite>().swap(pending_writes);
00553         behaviour->on_connect();
00554       }
00555     }
00556 
00557     bool read_start()
00558     {
00559       int rc;
00560 
00561       if ((rc = uv_read_start((uv_stream_t*)&uv_handle, on_alloc, on_read)) < 0)
00562       {
00563         assert_status(CONNECTED, DISCONNECTED);
00564         LOG_FAIL_FMT("uv_read_start failed: {}", uv_strerror(rc));
00565 
00566         if (behaviour)
00567           behaviour->on_disconnect();
00568 
00569         return false;
00570       }
00571 
00572       return true;
00573     }
00574 
00575     static void on_alloc(
00576       uv_handle_t* handle, size_t suggested_size, uv_buf_t* buf)
00577     {
00578       static_cast<TCPImpl*>(handle->data)->on_alloc(suggested_size, buf);
00579     }
00580 
00581     void on_alloc(size_t suggested_size, uv_buf_t* buf)
00582     {
00583       auto alloc_size = std::min(suggested_size, max_read_size);
00584 
00585       alloc_size = std::min(alloc_size, remaining_read_quota);
00586       remaining_read_quota -= alloc_size;
00587       LOG_TRACE_FMT(
00588         "Allocating {} bytes for TCP read ({} of quota remaining)",
00589         alloc_size,
00590         remaining_read_quota);
00591 
00592       buf->base = new char[alloc_size];
00593       buf->len = alloc_size;
00594     }
00595 
00596     void on_free(const uv_buf_t* buf)
00597     {
00598       delete[] buf->base;
00599     }
00600 
00601     static void on_read(uv_stream_t* handle, ssize_t sz, const uv_buf_t* buf)
00602     {
00603       static_cast<TCPImpl*>(handle->data)->on_read(sz, buf);
00604     }
00605 
00606     void on_read(ssize_t sz, const uv_buf_t* buf)
00607     {
00608       if (sz == 0)
00609       {
00610         on_free(buf);
00611         return;
00612       }
00613 
00614       if (sz == UV_ENOBUFS)
00615       {
00616         LOG_DEBUG_FMT("TCP on_read reached allocation quota");
00617         on_free(buf);
00618         return;
00619       }
00620 
00621       if (sz < 0)
00622       {
00623         assert_status(CONNECTED, DISCONNECTED);
00624         on_free(buf);
00625         uv_read_stop((uv_stream_t*)&uv_handle);
00626 
00627         LOG_DEBUG_FMT("TCP on_read: {}", uv_strerror(sz));
00628         behaviour->on_disconnect();
00629         return;
00630       }
00631 
00632       uint8_t* p = (uint8_t*)buf->base;
00633       behaviour->on_read((size_t)sz, p);
00634 
00635       if (p != nullptr)
00636         on_free(buf);
00637     }
00638 
00639     static void on_write(uv_write_t* req, int)
00640     {
00641       free_write(req);
00642     }
00643 
00644     static void free_write(uv_write_t* req)
00645     {
00646       if (req == nullptr)
00647         return;
00648 
00649       char* copy = (char*)req->data;
00650       delete[] copy;
00651       delete req;
00652     }
00653 
00654     static void on_reconnect(uv_handle_t* handle)
00655     {
00656       static_cast<TCPImpl*>(handle->data)->on_reconnect();
00657     }
00658 
00659     void on_reconnect()
00660     {
00661       assert_status(RECONNECTING, FRESH);
00662 
00663       if (!init())
00664       {
00665         assert_status(FRESH, CONNECTING_FAILED);
00666         behaviour->on_connect_failed();
00667         return;
00668       }
00669 
00670       assert_status(FRESH, CONNECTING_RESOLVING);
00671       connect_resolved();
00672     }
00673   };
00674 
00675   class ResetTCPReadQuotaImpl
00676   {
00677   public:
00678     ResetTCPReadQuotaImpl() {}
00679 
00680     void before_io()
00681     {
00682       TCPImpl::reset_read_quota();
00683     }
00684   };
00685 
00686   using ResetTCPReadQuota = proxy_ptr<BeforeIO<ResetTCPReadQuotaImpl>>;
00687 }
00688 
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/host/tcp.h...
Preprocessing /data/git/CCF/src/host/test/ledger.cpp...
#include host/ledger.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include host/snapshot.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 28912 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 using namespace asynchost;
00013 
00014 // Used throughout
00015 using frame_header_type = uint32_t;
00016 static constexpr size_t frame_header_size = sizeof(frame_header_type);
00017 static constexpr auto ledger_dir = "ledger_dir";
00018 static constexpr auto snapshot_dir = "snapshot_dir";
00019 
00020 static const auto dummy_snapshot = std::vector<uint8_t>(128, 42);
00021 
00022 constexpr auto buffer_size = 1024;
00023 auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00024 auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00025 ringbuffer::Circuit eio(in_buffer->bd, out_buffer->bd);
00026 
00027 auto wf = ringbuffer::WriterFactory(eio);
00028 
00029 std::string get_snapshot_file_name(
00030   size_t idx, size_t evidence_idx, size_t evidence_commit_idx)
00031 {
00032   return fmt::format(
00033     "{}/snapshot_{}_{}.committed_{}",
00034     snapshot_dir,
00035     idx,
00036     evidence_idx,
00037     evidence_commit_idx);
00038 }
00039 
00040 // Ledger entry type
00041 template <typename T>
00042 struct LedgerEntry
00043 {
00044   T value_ = 0;
00045 
00046   uint8_t* data()
00047   {
00048     return reinterpret_cast<uint8_t*>(&value_);
00049   }
00050 
00051   auto value() const
00052   {
00053     return value_;
00054   }
00055 
00056   auto set_value(T v)
00057   {
00058     value_ = v;
00059   }
00060 
00061   LedgerEntry() = default;
00062   LedgerEntry(T v) : value_(v) {}
00063   LedgerEntry(const std::vector<uint8_t>& raw)
00064   {
00065     const uint8_t* data = raw.data();
00066     size_t size = raw.size();
00067     value_ = serialized::read<T>(data, size);
00068   }
00069 };
00070 using TestLedgerEntry = LedgerEntry<uint32_t>;
00071 
00072 size_t number_of_files_in_ledger_dir()
00073 {
00074   size_t file_count = 0;
00075   for (auto const& f : fs::directory_iterator(ledger_dir))
00076   {
00077     file_count++;
00078   }
00079   return file_count;
00080 }
00081 
00082 size_t number_of_committed_files_in_ledger_dir()
00083 {
00084   size_t committed_file_count = 0;
00085   for (auto const& f : fs::directory_iterator(ledger_dir))
00086   {
00087     if (is_ledger_file_committed(f.path().string()))
00088     {
00089       committed_file_count++;
00090     }
00091   }
00092 
00093   return committed_file_count;
00094 }
00095 
00096 void verify_framed_entries_range(
00097   const std::vector<uint8_t>& framed_entries, size_t from, size_t to)
00098 {
00099   size_t idx = from;
00100   for (int i = 0; i < framed_entries.size();)
00101   {
00102     const uint8_t* data = &framed_entries[i];
00103     size_t size = framed_entries.size() - i;
00104 
00105     auto frame = serialized::read<frame_header_type>(data, size);
00106     auto entry = serialized::read(data, size, frame);
00107     REQUIRE(TestLedgerEntry(entry).value() == idx);
00108     i += frame_header_size + frame;
00109     idx++;
00110   }
00111 
00112   REQUIRE(idx == to + 1);
00113 }
00114 
00115 void read_entry_from_ledger(Ledger& ledger, size_t idx)
00116 {
00117   REQUIRE(TestLedgerEntry(ledger.read_entry(idx).value()).value() == idx);
00118 }
00119 
00120 void read_entries_range_from_ledger(Ledger& ledger, size_t from, size_t to)
00121 {
00122   verify_framed_entries_range(
00123     ledger.read_framed_entries(from, to).value(), from, to);
00124 }
00125 
00126 // Keeps track of ledger entries written to the ledger.
00127 // An entry submitted at index i has for value i so that it is easy to verify
00128 // that the ledger entry read from the ledger at a specific index is right.
00129 class TestEntrySubmitter
00130 {
00131 private:
00132   Ledger& ledger;
00133   size_t last_idx;
00134 
00135 public:
00136   TestEntrySubmitter(Ledger& ledger, size_t initial_last_idx = 0) :
00137     ledger(ledger),
00138     last_idx(initial_last_idx)
00139   {}
00140 
00141   size_t get_last_idx()
00142   {
00143     return last_idx;
00144   }
00145 
00146   void write(bool is_committable, bool force_chunk = false)
00147   {
00148     auto e = TestLedgerEntry(++last_idx);
00149     REQUIRE(
00150       ledger.write_entry(
00151         e.data(), sizeof(TestLedgerEntry), is_committable, force_chunk) ==
00152       last_idx);
00153   }
00154 
00155   void truncate(size_t idx)
00156   {
00157     ledger.truncate(idx);
00158 
00159     // Check that we can read until truncated entry but cannot read after it
00160     if (idx > 0)
00161     {
00162       read_entries_range_from_ledger(ledger, 1, idx);
00163     }
00164     REQUIRE_FALSE(ledger.read_framed_entries(1, idx + 1).has_value());
00165 
00166     if (idx < last_idx)
00167     {
00168       last_idx = idx;
00169     }
00170   }
00171 };
00172 
00173 size_t get_entries_per_chunk(size_t chunk_threshold)
00174 {
00175   // The number of entries per chunk is a function of the threshold (minus the
00176   // size of the fixes space for the offset at the size of each file) and the
00177   // size of each _framed_ entry
00178   return ceil(
00179     (static_cast<float>(chunk_threshold - sizeof(size_t))) /
00180     (frame_header_size + sizeof(TestLedgerEntry)));
00181 }
00182 
00183 // Assumes that no entries have been written yet
00184 size_t initialise_ledger(
00185   TestEntrySubmitter& entry_submitter,
00186   size_t chunk_threshold,
00187   size_t chunk_count)
00188 {
00189   size_t end_of_first_chunk_idx = 0;
00190   bool is_committable = true;
00191   size_t entries_per_chunk = get_entries_per_chunk(chunk_threshold);
00192 
00193   for (int i = 0; i < entries_per_chunk * chunk_count; i++)
00194   {
00195     entry_submitter.write(is_committable);
00196   }
00197 
00198   REQUIRE(number_of_files_in_ledger_dir() == chunk_count);
00199 
00200   return entries_per_chunk;
00201 }
00202 
00203 TEST_CASE("Regular chunking")
00204 {
00205   fs::remove_all(ledger_dir);
00206 
00207   INFO("Cannot create a ledger with a chunk threshold of 0");
00208   {
00209     size_t chunk_threshold = 0;
00210     REQUIRE_THROWS(Ledger(ledger_dir, wf, chunk_threshold));
00211   }
00212 
00213   size_t chunk_threshold = 30;
00214   size_t entries_per_chunk = get_entries_per_chunk(chunk_threshold);
00215   Ledger ledger(ledger_dir, wf, chunk_threshold);
00216   TestEntrySubmitter entry_submitter(ledger);
00217 
00218   size_t end_of_first_chunk_idx = 0;
00219   bool is_committable = true;
00220 
00221   INFO("Not quite enough entries before chunk threshold");
00222   {
00223     is_committable = true;
00224     for (int i = 0; i < entries_per_chunk - 1; i++)
00225     {
00226       entry_submitter.write(is_committable);
00227     }
00228 
00229     // Writing committable entries without reaching the chunk threshold
00230     // does not create new ledger files
00231     REQUIRE(number_of_files_in_ledger_dir() == 1);
00232   }
00233 
00234   INFO("Additional non-committable entries do not trigger chunking");
00235   {
00236     is_committable = false;
00237     entry_submitter.write(is_committable);
00238     entry_submitter.write(is_committable);
00239     REQUIRE(number_of_files_in_ledger_dir() == 1);
00240   }
00241 
00242   INFO("Additional committable entry triggers chunking");
00243   {
00244     is_committable = true;
00245     entry_submitter.write(is_committable);
00246     REQUIRE(number_of_files_in_ledger_dir() == 1);
00247 
00248     // Threshold is passed, a new ledger file should be created
00249     entry_submitter.write(false);
00250     end_of_first_chunk_idx = entry_submitter.get_last_idx() - 1;
00251     REQUIRE(number_of_files_in_ledger_dir() == 2);
00252   }
00253 
00254   INFO(
00255     "Submitting more committable entries trigger chunking at regular interval");
00256   {
00257     size_t chunk_count = 10;
00258     size_t number_of_files_before = number_of_files_in_ledger_dir();
00259     for (int i = 0; i < entries_per_chunk * chunk_count; i++)
00260     {
00261       entry_submitter.write(is_committable);
00262     }
00263     REQUIRE(
00264       number_of_files_in_ledger_dir() == chunk_count + number_of_files_before);
00265   }
00266 
00267   INFO("Forcing early chunk from a committable entry");
00268   {
00269     size_t number_of_files_before = number_of_files_in_ledger_dir();
00270 
00271     // Write committable entries until a new chunk with one entry is created
00272     is_committable = true;
00273     while (number_of_files_in_ledger_dir() == number_of_files_before)
00274     {
00275       entry_submitter.write(is_committable);
00276     }
00277 
00278     size_t number_of_files_after = number_of_files_in_ledger_dir();
00279 
00280     // Write a new committable entry that forces a new ledger chunk
00281     is_committable = true;
00282     bool force_new_chunk = true;
00283     entry_submitter.write(is_committable, force_new_chunk);
00284     REQUIRE(number_of_files_in_ledger_dir() == number_of_files_after);
00285 
00286     // Because of forcing a new chunk, the next entry will create a new chunk
00287     is_committable = false;
00288     entry_submitter.write(is_committable);
00289 
00290     // A new chunk is created as the entry is committable _and_ forced
00291     REQUIRE(number_of_files_in_ledger_dir() == number_of_files_after + 1);
00292 
00293     is_committable = true;
00294     force_new_chunk = true;
00295     entry_submitter.write(is_committable, force_new_chunk);
00296     // No new chunk is created as the entry is committable but doesn't force a
00297     // new chunk
00298     REQUIRE(number_of_files_in_ledger_dir() == number_of_files_after + 1);
00299   }
00300 
00301   INFO("Reading entries across all chunks");
00302   {
00303     is_committable = false;
00304     entry_submitter.write(is_committable);
00305     auto last_idx = entry_submitter.get_last_idx();
00306 
00307     // Reading the last entry succeeds
00308     read_entry_from_ledger(ledger, last_idx);
00309 
00310     // Reading in the future fails
00311     REQUIRE_FALSE(ledger.read_entry(last_idx + 1).has_value());
00312 
00313     // Reading at 0 fails
00314     REQUIRE_FALSE(ledger.read_entry(0).has_value());
00315 
00316     // Reading in the past succeeds
00317     read_entry_from_ledger(ledger, 1);
00318     read_entry_from_ledger(ledger, end_of_first_chunk_idx);
00319     read_entry_from_ledger(ledger, end_of_first_chunk_idx + 1);
00320     read_entry_from_ledger(ledger, last_idx);
00321   }
00322 
00323   INFO("Reading range of entries across all chunks");
00324   {
00325     // Note: only testing write cache as no chunk has yet been committed
00326     auto last_idx = entry_submitter.get_last_idx();
00327 
00328     // Reading from 0 fails
00329     REQUIRE_FALSE(
00330       ledger.read_framed_entries(0, end_of_first_chunk_idx).has_value());
00331 
00332     // Reading in the future fails
00333     REQUIRE_FALSE(ledger.read_framed_entries(1, last_idx + 1).has_value());
00334     REQUIRE_FALSE(
00335       ledger.read_framed_entries(last_idx, last_idx + 1).has_value());
00336 
00337     // Reading from the start to any valid index succeeds
00338     read_entries_range_from_ledger(ledger, 1, 1);
00339     read_entries_range_from_ledger(
00340       ledger, end_of_first_chunk_idx - 1, end_of_first_chunk_idx);
00341     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx);
00342     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx + 1);
00343     read_entries_range_from_ledger(ledger, 1, last_idx - 1);
00344     read_entries_range_from_ledger(ledger, 1, last_idx);
00345 
00346     // Reading from just before/after a chunk succeeds
00347     read_entries_range_from_ledger(
00348       ledger, end_of_first_chunk_idx, end_of_first_chunk_idx + 1);
00349     read_entries_range_from_ledger(
00350       ledger, end_of_first_chunk_idx, last_idx - 1);
00351     read_entries_range_from_ledger(ledger, end_of_first_chunk_idx, last_idx);
00352     read_entries_range_from_ledger(
00353       ledger, end_of_first_chunk_idx + 1, last_idx);
00354     read_entries_range_from_ledger(
00355       ledger, end_of_first_chunk_idx + 1, last_idx - 1);
00356   }
00357 }
00358 
00359 TEST_CASE("Truncation")
00360 {
00361   fs::remove_all(ledger_dir);
00362 
00363   size_t chunk_threshold = 30;
00364   Ledger ledger(ledger_dir, wf, chunk_threshold);
00365   TestEntrySubmitter entry_submitter(ledger);
00366 
00367   size_t chunk_count = 3;
00368   size_t end_of_first_chunk_idx =
00369     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00370 
00371   // Write another entry to create a new chunk
00372   entry_submitter.write(true);
00373 
00374   size_t chunks_so_far = number_of_files_in_ledger_dir();
00375   auto last_idx = entry_submitter.get_last_idx();
00376 
00377   INFO("Truncating latest index has no effect");
00378   {
00379     entry_submitter.truncate(last_idx);
00380     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far);
00381   }
00382 
00383   INFO("Truncating last entry in penultimate chunk closes latest file");
00384   {
00385     entry_submitter.truncate(last_idx - 1);
00386     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far - 1);
00387 
00388     // New file gets open when one more entry gets submitted
00389     entry_submitter.write(true);
00390     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far);
00391     entry_submitter.write(true);
00392     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far);
00393   }
00394 
00395   INFO("Truncating any entry in penultimate chunk closes latest file");
00396   {
00397     entry_submitter.truncate(last_idx - 2);
00398     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far - 1);
00399 
00400     // New file gets opened when two more entries are submitted
00401     entry_submitter.write(true);
00402     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far - 1);
00403     entry_submitter.write(true);
00404     REQUIRE(number_of_files_in_ledger_dir() == chunks_so_far);
00405   }
00406 
00407   INFO("Truncating entry at the start of second chunk");
00408   {
00409     entry_submitter.truncate(end_of_first_chunk_idx + 1);
00410     REQUIRE(number_of_files_in_ledger_dir() == 2);
00411   }
00412 
00413   INFO("Truncating entry at the end of first chunk");
00414   {
00415     entry_submitter.truncate(end_of_first_chunk_idx);
00416     REQUIRE(number_of_files_in_ledger_dir() == 1);
00417     entry_submitter.write(true);
00418   }
00419 
00420   INFO("Truncating very first entry");
00421   {
00422     entry_submitter.truncate(1);
00423     REQUIRE(number_of_files_in_ledger_dir() == 1);
00424   }
00425 
00426   INFO("Truncating all the things");
00427   {
00428     entry_submitter.truncate(0);
00429     REQUIRE(number_of_files_in_ledger_dir() == 0);
00430     entry_submitter.write(true);
00431   }
00432 }
00433 
00434 TEST_CASE("Commit")
00435 {
00436   fs::remove_all(ledger_dir);
00437 
00438   size_t chunk_threshold = 30;
00439   Ledger ledger(ledger_dir, wf, chunk_threshold);
00440   TestEntrySubmitter entry_submitter(ledger);
00441 
00442   size_t chunk_count = 3;
00443   size_t end_of_first_chunk_idx =
00444     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00445 
00446   entry_submitter.write(true);
00447   size_t last_idx = entry_submitter.get_last_idx();
00448   REQUIRE(number_of_committed_files_in_ledger_dir() == 0);
00449 
00450   INFO("Comitting end of first chunk");
00451   {
00452     ledger.commit(end_of_first_chunk_idx);
00453     REQUIRE(number_of_committed_files_in_ledger_dir() == 1);
00454 
00455     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx + 1);
00456   }
00457 
00458   INFO("Comitting in the middle on complete chunk");
00459   {
00460     ledger.commit(end_of_first_chunk_idx + 1);
00461     REQUIRE(number_of_committed_files_in_ledger_dir() == 1); // No effect
00462     ledger.commit(2 * end_of_first_chunk_idx - 1); // No effect
00463     REQUIRE(number_of_committed_files_in_ledger_dir() == 1);
00464   }
00465 
00466   INFO("Comitting at the end of a complete chunk");
00467   {
00468     ledger.commit(2 * end_of_first_chunk_idx);
00469     REQUIRE(number_of_committed_files_in_ledger_dir() == 2);
00470     read_entries_range_from_ledger(ledger, 1, 2 * end_of_first_chunk_idx + 1);
00471   }
00472 
00473   INFO("Comitting at the end of last complete chunk");
00474   {
00475     ledger.commit(last_idx - 1);
00476     REQUIRE(number_of_committed_files_in_ledger_dir() == 3);
00477     read_entries_range_from_ledger(ledger, 1, last_idx);
00478   }
00479 
00480   INFO("Comitting incomplete chunk");
00481   {
00482     ledger.commit(last_idx); // No effect
00483     REQUIRE(number_of_committed_files_in_ledger_dir() == 3);
00484   }
00485 
00486   INFO("Complete latest chunk and commit");
00487   {
00488     entry_submitter.write(true);
00489     entry_submitter.write(true);
00490     last_idx = entry_submitter.get_last_idx();
00491     ledger.commit(last_idx);
00492     REQUIRE(number_of_committed_files_in_ledger_dir() == 4);
00493     read_entries_range_from_ledger(ledger, 1, last_idx);
00494   }
00495 
00496   INFO("Ledger cannot be truncated earlier than commit");
00497   {
00498     ledger.truncate(1); // No effect
00499     read_entries_range_from_ledger(ledger, 1, last_idx);
00500 
00501     ledger.truncate(2 * end_of_first_chunk_idx); // No effect
00502     read_entries_range_from_ledger(ledger, 1, last_idx);
00503 
00504     // Write and truncate a new entry past commit
00505     entry_submitter.write(true);
00506     last_idx = entry_submitter.get_last_idx();
00507     ledger.truncate(last_idx - 1); // Deletes entry at last_idx
00508     read_entries_range_from_ledger(ledger, 1, last_idx - 1);
00509     REQUIRE_FALSE(ledger.read_framed_entries(1, last_idx).has_value());
00510   }
00511 }
00512 
00513 TEST_CASE("Restore existing ledger")
00514 {
00515   fs::remove_all(ledger_dir);
00516 
00517   size_t chunk_threshold = 30;
00518   size_t last_idx = 0;
00519   size_t end_of_first_chunk_idx = 0;
00520   size_t chunk_count = 3;
00521   size_t number_of_ledger_files = 0;
00522 
00523   SUBCASE("Restoring uncommitted chunks")
00524   {
00525     INFO("Initialise first ledger with complete chunks");
00526     {
00527       Ledger ledger(ledger_dir, wf, chunk_threshold);
00528       TestEntrySubmitter entry_submitter(ledger);
00529 
00530       end_of_first_chunk_idx =
00531         initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00532       number_of_ledger_files = number_of_files_in_ledger_dir();
00533       last_idx = chunk_count * end_of_first_chunk_idx;
00534     }
00535 
00536     Ledger ledger2(ledger_dir, wf, chunk_threshold);
00537     read_entries_range_from_ledger(ledger2, 1, last_idx);
00538 
00539     // Restored ledger can be written to
00540     TestEntrySubmitter entry_submitter(ledger2, last_idx);
00541     entry_submitter.write(true);
00542     // On restore, we write a new file as all restored chunks were complete
00543     REQUIRE(number_of_files_in_ledger_dir() == number_of_ledger_files + 1);
00544     entry_submitter.write(true);
00545     entry_submitter.write(true);
00546 
00547     // Restored ledger can be truncated
00548     entry_submitter.truncate(end_of_first_chunk_idx + 1);
00549     entry_submitter.truncate(end_of_first_chunk_idx);
00550     entry_submitter.truncate(1);
00551   }
00552 
00553   SUBCASE("Restoring truncated ledger")
00554   {
00555     INFO("Initialise first ledger with truncation");
00556     {
00557       Ledger ledger(ledger_dir, wf, chunk_threshold);
00558       TestEntrySubmitter entry_submitter(ledger);
00559 
00560       end_of_first_chunk_idx =
00561         initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00562 
00563       entry_submitter.truncate(end_of_first_chunk_idx + 1);
00564       last_idx = entry_submitter.get_last_idx();
00565       number_of_ledger_files = number_of_files_in_ledger_dir();
00566     }
00567 
00568     Ledger ledger2(ledger_dir, wf, chunk_threshold);
00569     read_entries_range_from_ledger(ledger2, 1, last_idx);
00570 
00571     TestEntrySubmitter entry_submitter(ledger2, last_idx);
00572     entry_submitter.write(true);
00573     // On restore, we write at the end of the last file is that file is not
00574     // complete
00575     REQUIRE(number_of_files_in_ledger_dir() == number_of_ledger_files);
00576   }
00577 
00578   SUBCASE("Restoring some committed chunks")
00579   {
00580     // This is the scenario on recovery
00581     size_t committed_idx = 0;
00582     INFO("Initialise first ledger with committed chunks");
00583     {
00584       Ledger ledger(ledger_dir, wf, chunk_threshold);
00585       TestEntrySubmitter entry_submitter(ledger);
00586 
00587       end_of_first_chunk_idx =
00588         initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00589 
00590       committed_idx = 2 * end_of_first_chunk_idx + 1;
00591       entry_submitter.write(true);
00592       last_idx = entry_submitter.get_last_idx();
00593       ledger.commit(committed_idx);
00594     }
00595 
00596     Ledger ledger2(ledger_dir, wf, chunk_threshold);
00597     read_entries_range_from_ledger(ledger2, 1, last_idx);
00598 
00599     // Restored ledger cannot be truncated before last idx of last committed
00600     // chunk
00601     TestEntrySubmitter entry_submitter(ledger2, last_idx);
00602     entry_submitter.truncate(committed_idx - 1); // Successful
00603 
00604     ledger2.truncate(committed_idx - 2); // Unsuccessful
00605     read_entries_range_from_ledger(ledger2, 1, end_of_first_chunk_idx);
00606   }
00607 
00608   SUBCASE("Restoring ledger with different chunking threshold")
00609   {
00610     INFO("Initialise first ledger with committed chunks");
00611     {
00612       Ledger ledger(ledger_dir, wf, chunk_threshold);
00613       TestEntrySubmitter entry_submitter(ledger);
00614 
00615       end_of_first_chunk_idx =
00616         initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00617 
00618       entry_submitter.write(true);
00619       last_idx = entry_submitter.get_last_idx();
00620     }
00621 
00622     INFO("Restore new ledger with twice the chunking threshold");
00623     {
00624       Ledger ledger2(ledger_dir, wf, 2 * chunk_threshold);
00625       read_entries_range_from_ledger(ledger2, 1, last_idx);
00626 
00627       TestEntrySubmitter entry_submitter(ledger2, last_idx);
00628 
00629       size_t orig_number_files = number_of_files_in_ledger_dir();
00630       while (number_of_files_in_ledger_dir() == orig_number_files)
00631       {
00632         entry_submitter.write(true);
00633       }
00634       last_idx = entry_submitter.get_last_idx();
00635     }
00636 
00637     INFO("Restore new ledger with half the chunking threshold");
00638     {
00639       Ledger ledger2(ledger_dir, wf, chunk_threshold / 2);
00640       read_entries_range_from_ledger(ledger2, 1, last_idx);
00641 
00642       TestEntrySubmitter entry_submitter(ledger2, last_idx);
00643 
00644       size_t orig_number_files = number_of_files_in_ledger_dir();
00645       while (number_of_files_in_ledger_dir() == orig_number_files)
00646       {
00647         entry_submitter.write(true);
00648       }
00649     }
00650   }
00651 }
00652 
00653 size_t number_open_fd()
00654 {
00655   size_t fd_count = 0;
00656   for (auto const& f : fs::directory_iterator("/proc/self/fd"))
00657   {
00658     fd_count++;
00659   }
00660   return fd_count;
00661 }
00662 
00663 TEST_CASE("Limit number of open files")
00664 {
00665   fs::remove_all(ledger_dir);
00666 
00667   size_t chunk_threshold = 30;
00668   size_t chunk_count = 5;
00669   size_t max_read_cache_size = 2;
00670   Ledger ledger(ledger_dir, wf, chunk_threshold, max_read_cache_size);
00671   TestEntrySubmitter entry_submitter(ledger);
00672 
00673   size_t initial_number_fd = number_open_fd();
00674   size_t last_idx = 0;
00675 
00676   size_t end_of_first_chunk_idx =
00677     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00678   REQUIRE(number_open_fd() == initial_number_fd + chunk_count);
00679 
00680   INFO("Writing a new chunk opens a new file");
00681   {
00682     entry_submitter.write(true);
00683     last_idx = entry_submitter.get_last_idx();
00684     REQUIRE(number_open_fd() == initial_number_fd + chunk_count + 1);
00685   }
00686 
00687   INFO("Commit closes files and reading committed chunks opens those");
00688   {
00689     ledger.commit(1); // No file committed
00690     REQUIRE(number_open_fd() == initial_number_fd + chunk_count + 1);
00691 
00692     ledger.commit(end_of_first_chunk_idx); // One file now committed
00693     REQUIRE(number_open_fd() == initial_number_fd + chunk_count);
00694     read_entry_from_ledger(ledger, 1);
00695     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx);
00696     // Committed file is open in read cache
00697     REQUIRE(number_open_fd() == initial_number_fd + chunk_count + 1);
00698 
00699     ledger.commit(2 * end_of_first_chunk_idx); // Two files now committed
00700     REQUIRE(number_open_fd() == initial_number_fd + chunk_count);
00701     read_entries_range_from_ledger(ledger, 1, 2 * end_of_first_chunk_idx);
00702     // Two committed files open in read cache
00703     REQUIRE(number_open_fd() == initial_number_fd + chunk_count + 1);
00704 
00705     ledger.commit(last_idx); // All but one file committed
00706     // One file open for write, two files open for read
00707     REQUIRE(number_open_fd() == initial_number_fd + 3);
00708 
00709     read_entries_range_from_ledger(ledger, 1, last_idx);
00710     // Number of open files is capped by size of read cache
00711     REQUIRE(number_open_fd() == initial_number_fd + 1 + max_read_cache_size);
00712 
00713     // Reading out of order succeeds
00714     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx);
00715     read_entries_range_from_ledger(
00716       ledger, 2 * end_of_first_chunk_idx, 3 * end_of_first_chunk_idx);
00717     read_entries_range_from_ledger(ledger, 1, last_idx);
00718     read_entries_range_from_ledger(
00719       ledger, 3 * end_of_first_chunk_idx, last_idx - 1);
00720     read_entries_range_from_ledger(ledger, 1, end_of_first_chunk_idx);
00721   }
00722 
00723   INFO("Close and commit latest file");
00724   {
00725     entry_submitter.write(true);
00726     entry_submitter.write(true);
00727     last_idx = entry_submitter.get_last_idx();
00728     ledger.commit(last_idx);
00729 
00730     read_entries_range_from_ledger(ledger, 1, last_idx);
00731     REQUIRE(number_open_fd() == initial_number_fd + max_read_cache_size);
00732   }
00733 
00734   INFO("Still possible to recover a new ledger");
00735   {
00736     initial_number_fd = number_open_fd();
00737     Ledger ledger2(ledger_dir, wf, chunk_threshold, max_read_cache_size);
00738 
00739     // Committed files are not open for write
00740     REQUIRE(number_open_fd() == initial_number_fd);
00741 
00742     read_entries_range_from_ledger(ledger2, 1, last_idx);
00743     REQUIRE(number_open_fd() == initial_number_fd + max_read_cache_size);
00744   }
00745 }
00746 
00747 TEST_CASE("Multiple ledger paths")
00748 {
00749   static constexpr auto ledger_dir_2 = "ledger_dir_2";
00750   static constexpr auto empty_write_ledger_dir = "ledger_dir_empty";
00751 
00752   fs::remove_all(ledger_dir);
00753   fs::remove_all(ledger_dir_2);
00754   fs::remove_all(empty_write_ledger_dir);
00755 
00756   size_t max_read_cache_size = 2;
00757   size_t chunk_threshold = 30;
00758   size_t chunk_count = 5;
00759 
00760   size_t last_committed_idx = 0;
00761   size_t last_idx = 0;
00762 
00763   INFO("Write many entries on first ledger");
00764   {
00765     Ledger ledger(ledger_dir, wf, chunk_threshold);
00766     TestEntrySubmitter entry_submitter(ledger);
00767 
00768     // Writing some committed chunks...
00769     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00770     last_committed_idx = entry_submitter.get_last_idx();
00771     ledger.commit(last_committed_idx);
00772 
00773     // ... and an uncommitted suffix
00774     bool is_committable = true;
00775     entry_submitter.write(is_committable);
00776     entry_submitter.write(is_committable);
00777     last_idx = entry_submitter.get_last_idx();
00778   }
00779 
00780   INFO("Copy uncommitted suffix from initial ledger directory");
00781   {
00782     fs::create_directory(ledger_dir_2);
00783     for (auto const& f : fs::directory_iterator(ledger_dir))
00784     {
00785       if (!is_ledger_file_committed(f.path().filename()))
00786       {
00787         fs::copy(f.path(), ledger_dir_2);
00788       }
00789     }
00790   }
00791 
00792   INFO("Restored ledger cannot read past uncommitted files");
00793   {
00794     Ledger ledger(ledger_dir_2, wf, chunk_threshold);
00795 
00796     for (size_t i = 1; i <= last_committed_idx; i++)
00797     {
00798       REQUIRE_FALSE(ledger.read_entry(i).has_value());
00799     }
00800 
00801     read_entry_from_ledger(ledger, last_idx);
00802   }
00803 
00804   INFO("Restore ledger with previous directory");
00805   {
00806     Ledger ledger(
00807       ledger_dir_2, wf, chunk_threshold, max_read_cache_size, {ledger_dir});
00808 
00809     for (size_t i = 1; i <= last_committed_idx; i++)
00810     {
00811       read_entry_from_ledger(ledger, i);
00812     }
00813 
00814     // Read framed entries across both directories
00815     read_entries_range_from_ledger(ledger, 1, last_idx);
00816   }
00817 
00818   INFO("Only committed files can be read from read-only directory");
00819   {
00820     Ledger ledger(
00821       empty_write_ledger_dir,
00822       wf,
00823       chunk_threshold,
00824       max_read_cache_size,
00825       {ledger_dir});
00826 
00827     for (size_t i = 1; i <= last_committed_idx; i++)
00828     {
00829       read_entry_from_ledger(ledger, i);
00830     }
00831 
00832     // Even though the ledger file for last_idx is in ledger_dir, the entry
00833     // cannot be read
00834     REQUIRE_FALSE(ledger.read_entry(last_idx).has_value());
00835   }
00836 }
00837 
00838 TEST_CASE("Recover from read-only ledger directory only")
00839 {
00840   static constexpr auto ledger_dir_2 = "ledger_dir_2";
00841 
00842   fs::remove_all(ledger_dir);
00843   fs::remove_all(ledger_dir_2);
00844 
00845   size_t max_read_cache_size = 2;
00846   size_t chunk_threshold = 30;
00847   size_t chunk_count = 5;
00848 
00849   size_t last_idx = 0;
00850 
00851   INFO("Write many entries on first ledger");
00852   {
00853     Ledger ledger(ledger_dir, wf, chunk_threshold);
00854     TestEntrySubmitter entry_submitter(ledger);
00855 
00856     // Writing some committed chunks
00857     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00858     last_idx = entry_submitter.get_last_idx();
00859     ledger.commit(last_idx);
00860   }
00861 
00862   INFO("Recover from read-only ledger entry only");
00863   {
00864     Ledger ledger(
00865       ledger_dir_2, wf, chunk_threshold, max_read_cache_size, {ledger_dir});
00866 
00867     read_entries_range_from_ledger(ledger, 1, last_idx);
00868 
00869     TestEntrySubmitter entry_submitter(ledger, last_idx);
00870 
00871     for (size_t i = 0; i < chunk_count; i++)
00872     {
00873       entry_submitter.write(true);
00874     }
00875 
00876     read_entries_range_from_ledger(ledger, 1, entry_submitter.get_last_idx());
00877   }
00878 }
00879 
00880 TEST_CASE("Find latest snapshot with corresponding ledger chunk")
00881 {
00882   fs::remove_all(ledger_dir);
00883   fs::remove_all(snapshot_dir);
00884 
00885   size_t chunk_threshold = 30;
00886   size_t chunk_count = 5;
00887   size_t last_idx = 0;
00888 
00889   Ledger ledger(ledger_dir, wf, chunk_threshold);
00890   TestEntrySubmitter entry_submitter(ledger);
00891 
00892   SnapshotManager snapshots(snapshot_dir, ledger);
00893 
00894   INFO("Write many entries on first ledger");
00895   {
00896     // Writing some committed chunks
00897     initialise_ledger(entry_submitter, chunk_threshold, chunk_count);
00898     last_idx = entry_submitter.get_last_idx();
00899     ledger.commit(last_idx);
00900   }
00901 
00902   INFO("Create, commit and retrieve latest snapshot");
00903   {
00904     size_t snapshot_idx = last_idx / 2;
00905     // Assumes evidence idx and evidence commit idx as next indices
00906     size_t snapshot_evidence_idx = snapshot_idx + 1;
00907     size_t snapshot_evidence_commit_idx = snapshot_evidence_idx + 1;
00908 
00909     snapshots.write_snapshot(
00910       snapshot_idx,
00911       snapshot_evidence_idx,
00912       dummy_snapshot.data(),
00913       dummy_snapshot.size());
00914 
00915     // Snapshot is not yet committed
00916     REQUIRE_FALSE(snapshots.find_latest_committed_snapshot().has_value());
00917 
00918     snapshots.commit_snapshot(snapshot_idx, snapshot_evidence_commit_idx);
00919 
00920     auto snapshot_file_name = get_snapshot_file_name(
00921       snapshot_idx, snapshot_evidence_idx, snapshot_evidence_commit_idx);
00922 
00923     REQUIRE(
00924       snapshots.find_latest_committed_snapshot().value() == snapshot_file_name);
00925 
00926     fs::remove(snapshot_file_name);
00927   }
00928 
00929   INFO("Snapshot evidence commit past last ledger index");
00930   {
00931     // Snapshot evidence commit idx is past last ledger idx
00932     size_t snapshot_idx = last_idx - 1;
00933     size_t snapshot_evidence_idx = snapshot_idx + 1; // Still covered by ledger
00934     size_t snapshot_evidence_commit_idx = snapshot_evidence_idx + 1;
00935 
00936     snapshots.write_snapshot(
00937       snapshot_idx,
00938       snapshot_evidence_idx,
00939       dummy_snapshot.data(),
00940       dummy_snapshot.size());
00941 
00942     snapshots.commit_snapshot(snapshot_idx, snapshot_evidence_commit_idx);
00943 
00944     // Even though snapshot is committed, evidence commit is past last ledger
00945     // index
00946     REQUIRE_FALSE(snapshots.find_latest_committed_snapshot().has_value());
00947 
00948     // Add another entry to ledger, so that ledger's last idx ==
00949     // snapshot_evidence_commit_idx
00950     entry_submitter.write(true); // note: is_committable flag does not matter
00951 
00952     // Snapshot is now valid
00953     REQUIRE(
00954       snapshots.find_latest_committed_snapshot().value() ==
00955       get_snapshot_file_name(
00956         snapshot_idx, snapshot_evidence_idx, snapshot_evidence_commit_idx));
00957   }
00958 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/host/test/ledger.cpp...
Preprocessing /data/git/CCF/src/host/ticker.h...
#include enclave.h: already included! skipping...
#include timer.h: already included! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 943 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace asynchost
00011 {
00012   class TickerImpl
00013   {
00014   private:
00015     ringbuffer::WriterPtr to_enclave;
00016     std::chrono::time_point<std::chrono::system_clock> last;
00017 
00018   public:
00019     TickerImpl(
00020       ringbuffer::AbstractWriterFactory& writer_factory,
00021       std::function<void(std::chrono::time_point<std::chrono::system_clock>)>
00022         set_start) :
00023       to_enclave(writer_factory.create_writer_to_inside()),
00024       last(std::chrono::system_clock::now())
00025     {
00026       set_start(last);
00027     }
00028 
00029     void on_timer()
00030     {
00031       auto next = std::chrono::system_clock::now();
00032       auto elapsed =
00033         std::chrono::duration_cast<std::chrono::milliseconds>(next - last);
00034       last = next;
00035 
00036       RINGBUFFER_WRITE_MESSAGE(
00037         AdminMessage::tick, to_enclave, (size_t)elapsed.count());
00038     }
00039   };
00040 
00041   using Ticker = proxy_ptr<Timer<TickerImpl>>;
00042 }
00043 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/ticker.h...
Preprocessing /data/git/CCF/src/host/time_updater.h...
#include timer.h: already included! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 723 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace asynchost
00011 {
00012   class TimeUpdaterImpl
00013   {
00014     using TClock = std::chrono::steady_clock;
00015     TClock::time_point creation_time;
00016 
00017     std::atomic<std::chrono::microseconds> us_since_creation;
00018 
00019   public:
00020     TimeUpdaterImpl() : creation_time(TClock::now()) {}
00021 
00022     std::atomic<std::chrono::microseconds>* get_value()
00023     {
00024       return &us_since_creation;
00025     }
00026 
00027     void on_timer()
00028     {
00029       const auto now = TClock::now();
00030       us_since_creation = std::chrono::duration_cast<std::chrono::microseconds>(
00031         now - creation_time);
00032     }
00033   };
00034 
00035   using TimeUpdater = proxy_ptr<Timer<TimeUpdaterImpl>>;
00036 }
00037 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/time_updater.h...
Preprocessing /data/git/CCF/src/host/timer.h...
#include proxy.h: already included! skipping...
#include chrono: not found! skipping...
Preprocessor output (size: 1118 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace asynchost
00010 {
00011   template <typename Behaviour>
00012   class Timer : public with_uv_handle<uv_timer_t>
00013   {
00014   public:
00015     Behaviour behaviour;
00016 
00017   private:
00018     friend class close_ptr<Timer<Behaviour>>;
00019 
00020     template <typename... Args>
00021     Timer(std::chrono::milliseconds repeat_ms, Args&&... args) :
00022       behaviour(std::forward<Args>(args)...)
00023     {
00024       int rc;
00025 
00026       if ((rc = uv_timer_init(uv_default_loop(), &uv_handle)) < 0)
00027       {
00028         LOG_FAIL_FMT("uv_timer_init failed: {}", uv_strerror(rc));
00029         throw std::logic_error("uv_timer_init failed");
00030       }
00031 
00032       uv_handle.data = this;
00033 
00034       if ((rc = uv_timer_start(&uv_handle, on_timer, 0, repeat_ms.count())) < 0)
00035       {
00036         LOG_FAIL_FMT("uv_timer_start failed: {}", uv_strerror(rc));
00037         throw std::logic_error("uv_timer_start failed");
00038       }
00039     }
00040 
00041     static void on_timer(uv_timer_t* handle)
00042     {
00043       static_cast<Timer*>(handle->data)->on_timer();
00044     }
00045 
00046     void on_timer()
00047     {
00048       behaviour.on_timer();
00049     }
00050   };
00051 }
00052 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/host/timer.h...
Preprocessing /data/git/CCF/src/http/authentication/authentication_types.h...
#include enclave/rpc_context.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 1842 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   struct AuthnIdentity
00013   {
00014     virtual ~AuthnIdentity() = default;
00015   };
00016 
00017   class AuthnPolicy
00018   {
00019   public:
00020     using OpenAPISecuritySchema = std::pair<std::string, nlohmann::json>;
00021     static const OpenAPISecuritySchema unauthenticated_schema;
00022 
00023     virtual ~AuthnPolicy() = default;
00024 
00025     virtual std::unique_ptr<AuthnIdentity> authenticate(
00026       kv::ReadOnlyTx& tx,
00027       const std::shared_ptr<enclave::RpcContext>& ctx,
00028       std::string& error_reason) = 0;
00029 
00030     virtual void set_unauthenticated_error(
00031       std::shared_ptr<enclave::RpcContext>& ctx, std::string&& error_reason)
00032     {
00033       ctx->set_error(
00034         HTTP_STATUS_UNAUTHORIZED,
00035         ccf::errors::InvalidAuthenticationInfo,
00036         std::move(error_reason));
00037     }
00038 
00039     virtual std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00040       const = 0;
00041   };
00042 
00043   inline const AuthnPolicy::OpenAPISecuritySchema
00044     AuthnPolicy::unauthenticated_schema = std::make_pair("", nlohmann::json());
00045 
00046   // To make authentication _optional_, we list no-auth as one of several
00047   // specified policies
00048   struct EmptyAuthnIdentity : public AuthnIdentity
00049   {};
00050 
00051   class EmptyAuthnPolicy : public AuthnPolicy
00052   {
00053   public:
00054     std::unique_ptr<AuthnIdentity> authenticate(
00055       kv::ReadOnlyTx&,
00056       const std::shared_ptr<enclave::RpcContext>&,
00057       std::string&) override
00058     {
00059       return std::make_unique<EmptyAuthnIdentity>();
00060     }
00061 
00062     void set_unauthenticated_error(
00063       std::shared_ptr<enclave::RpcContext>&, std::string&&) override
00064     {
00065       throw std::logic_error("Should not happen");
00066     }
00067 
00068     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00069       const override
00070     {
00071       return unauthenticated_schema;
00072     }
00073   };
00074 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/authentication/authentication_types.h...
Preprocessing /data/git/CCF/src/http/authentication/cert_auth.h...
#include enclave/rpc_context.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include memory: not found! skipping...
#include node/certs.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/users.h: not found! skipping...
#include tls/pem.h: not found! skipping...
Preprocessor output (size: 4597 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/http/authentication/cert_auth.h" 2
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct UserCertAuthnIdentity : public AuthnIdentity
00015   {
00016     /** CCF user ID, as defined in @c public:ccf.gov.users table */
00017     UserId user_id;
00018     /** User certificate, as established by TLS */
00019     tls::Pem user_cert;
00020     /** Additional user data, as defined in @c public:ccf.gov.users */
00021     nlohmann::json user_data;
00022   };
00023 
00024   class UserCertAuthnPolicy : public AuthnPolicy
00025   {
00026   public:
00027     std::unique_ptr<AuthnIdentity> authenticate(
00028       kv::ReadOnlyTx& tx,
00029       const std::shared_ptr<enclave::RpcContext>& ctx,
00030       std::string& error_reason) override
00031     {
00032       const auto caller_cert = ctx->session->caller_cert;
00033 
00034       CertDERs users_by_cert(Tables::USER_CERT_DERS);
00035       auto by_certs_view = tx.get_read_only_view(users_by_cert);
00036       const auto user_id = by_certs_view->get(caller_cert);
00037 
00038       if (user_id.has_value())
00039       {
00040         Users users_table(Tables::USERS);
00041         auto users_view = tx.get_read_only_view(users_table);
00042         const auto user = users_view->get(user_id.value());
00043         if (!user.has_value())
00044         {
00045           throw std::logic_error("Users and user certs tables do not match");
00046         }
00047 
00048         auto identity = std::make_unique<UserCertAuthnIdentity>();
00049         identity->user_id = user_id.value();
00050         identity->user_cert = user->cert;
00051         identity->user_data = user->user_data;
00052         return identity;
00053       }
00054       else
00055       {
00056         error_reason = "Could not find matching user certificate";
00057       }
00058 
00059       return nullptr;
00060     }
00061 
00062     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00063       const override
00064     {
00065       return std::nullopt;
00066     }
00067   };
00068 
00069   struct MemberCertAuthnIdentity : public AuthnIdentity
00070   {
00071     MemberId member_id;
00072     tls::Pem member_cert;
00073     nlohmann::json member_data;
00074   };
00075 
00076   class MemberCertAuthnPolicy : public AuthnPolicy
00077   {
00078   public:
00079     std::unique_ptr<AuthnIdentity> authenticate(
00080       kv::ReadOnlyTx& tx,
00081       const std::shared_ptr<enclave::RpcContext>& ctx,
00082       std::string& error_reason) override
00083     {
00084       const auto caller_cert = ctx->session->caller_cert;
00085 
00086       CertDERs members_by_cert(Tables::MEMBER_CERT_DERS);
00087       auto by_certs_view = tx.get_read_only_view(members_by_cert);
00088       const auto member_id = by_certs_view->get(caller_cert);
00089 
00090       if (member_id.has_value())
00091       {
00092         Members members_table(Tables::MEMBERS);
00093         auto members_view = tx.get_read_only_view(members_table);
00094         const auto member = members_view->get(member_id.value());
00095         if (!member.has_value())
00096         {
00097           throw std::logic_error(
00098             "Members and member certs tables do not match");
00099         }
00100 
00101         auto identity = std::make_unique<MemberCertAuthnIdentity>();
00102         identity->member_id = member_id.value();
00103         identity->member_cert = member->cert;
00104         identity->member_data = member->member_data;
00105         return identity;
00106       }
00107       else
00108       {
00109         error_reason = "Could not find matching member certificate";
00110       }
00111 
00112       return nullptr;
00113     }
00114 
00115     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00116       const override
00117     {
00118       return std::nullopt;
00119     }
00120   };
00121 
00122   struct NodeCertAuthnIdentity : public AuthnIdentity
00123   {
00124     ccf::NodeId node_id;
00125     ccf::NodeInfo node_info;
00126   };
00127 
00128   class NodeCertAuthnPolicy : public AuthnPolicy
00129   {
00130   public:
00131     std::unique_ptr<AuthnIdentity> authenticate(
00132       kv::ReadOnlyTx& tx,
00133       const std::shared_ptr<enclave::RpcContext>& ctx,
00134       std::string& error_reason) override
00135     {
00136       const auto caller_cert_pem =
00137         tls::cert_der_to_pem(ctx->session->caller_cert);
00138 
00139       std::unique_ptr<NodeCertAuthnIdentity> identity = nullptr;
00140 
00141       auto nodes_view = tx.get_read_only_view<ccf::Nodes>(Tables::NODES);
00142       nodes_view->foreach(
00143         [&caller_cert_pem, &identity](const auto& id, const auto& info) {
00144           if (info.cert == caller_cert_pem)
00145           {
00146             identity = std::make_unique<NodeCertAuthnIdentity>();
00147             identity->node_id = id;
00148             identity->node_info = info;
00149             return false;
00150           }
00151 
00152           return true;
00153         });
00154 
00155       if (identity == nullptr)
00156       {
00157         error_reason = "Caller cert does not match any known node cert";
00158       }
00159 
00160       return identity;
00161     }
00162 
00163     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00164       const override
00165     {
00166       return std::nullopt;
00167     }
00168   };
00169 }
00170 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/authentication/cert_auth.h...
Preprocessing /data/git/CCF/src/http/authentication/jwt_auth.h...
#include authentication_types.h: already included! skipping...
#include http/http_jwt.h: not found! skipping...
#include node/jwt.h: not found! skipping...
Preprocessor output (size: 2707 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   struct JwtAuthnIdentity : public AuthnIdentity
00012   {
00013     /** JWT key issuer, as defined in @c
00014      * public:ccf.gov.jwt_public_signing_key_issuer */
00015     std::string key_issuer;
00016     /** JWT header */
00017     nlohmann::json header;
00018     /** JWT payload */
00019     nlohmann::json payload;
00020   };
00021 
00022   class JwtAuthnPolicy : public AuthnPolicy
00023   {
00024   protected:
00025     static const OpenAPISecuritySchema security_schema;
00026 
00027   public:
00028     std::unique_ptr<AuthnIdentity> authenticate(
00029       kv::ReadOnlyTx& tx,
00030       const std::shared_ptr<enclave::RpcContext>& ctx,
00031       std::string& error_reason) override
00032     {
00033       const auto& headers = ctx->get_request_headers();
00034 
00035       const auto token =
00036         http::JwtVerifier::extract_token(headers, error_reason);
00037 
00038       if (token.has_value())
00039       {
00040         auto keys_view = tx.get_read_only_view<JwtPublicSigningKeys>(
00041           ccf::Tables::JWT_PUBLIC_SIGNING_KEYS);
00042         auto key_issuer_view = tx.get_read_only_view<JwtPublicSigningKeyIssuer>(
00043           ccf::Tables::JWT_PUBLIC_SIGNING_KEY_ISSUER);
00044         const auto key_id = token.value().header_typed.kid;
00045         const auto token_key = keys_view->get(key_id);
00046         if (!token_key.has_value())
00047         {
00048           error_reason = "JWT signing key not found";
00049         }
00050         else if (!http::JwtVerifier::validate_token_signature(
00051                    token.value(), token_key.value()))
00052         {
00053           error_reason = "JWT signature is invalid";
00054         }
00055         else
00056         {
00057           auto identity = std::make_unique<JwtAuthnIdentity>();
00058           identity->key_issuer = key_issuer_view->get(key_id).value();
00059           identity->header = std::move(token->header);
00060           identity->payload = std::move(token->payload);
00061           return identity;
00062         }
00063       }
00064 
00065       return nullptr;
00066     }
00067 
00068     void set_unauthenticated_error(
00069       std::shared_ptr<enclave::RpcContext>& ctx,
00070       std::string&& error_reason) override
00071     {
00072       ctx->set_error(
00073         HTTP_STATUS_UNAUTHORIZED,
00074         ccf::errors::InvalidAuthenticationInfo,
00075         std::move(error_reason));
00076       ctx->set_response_header(
00077         http::headers::WWW_AUTHENTICATE,
00078         "Bearer realm=\"JWT bearer token access\", error=\"invalid_token\"");
00079     }
00080 
00081     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00082       const override
00083     {
00084       return security_schema;
00085     }
00086   };
00087 
00088   inline const AuthnPolicy::OpenAPISecuritySchema
00089     JwtAuthnPolicy::security_schema = std::make_pair(
00090       "bearer_jwt",
00091       nlohmann::json{
00092         {"type", "http"}, {"scheme", "bearer"}, {"bearerFormat", "JWT"}});
00093 }
00094 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/authentication/jwt_auth.h...
Preprocessing /data/git/CCF/src/http/authentication/sig_auth.h...
#include authentication_types.h: already included! skipping...
#include http/http_sig.h: not found! skipping...
Preprocessor output (size: 6467 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace ccf
00009 {
00010   namespace
00011   {
00012     static std::optional<SignedReq> parse_signed_request(
00013       const std::shared_ptr<enclave::RpcContext>& ctx)
00014     {
00015       return http::HttpSignatureVerifier::parse(
00016         ctx->get_request_verb().c_str(),
00017         ctx->get_request_path(),
00018         ctx->get_request_query(),
00019         ctx->get_request_headers(),
00020         ctx->get_request_body());
00021     }
00022   }
00023 
00024   struct UserSignatureAuthnIdentity : public AuthnIdentity
00025   {
00026     /** CCF user ID, as defined in @c public:ccf.gov.users table */
00027     UserId user_id;
00028     /** User certificate, as established by TLS */
00029     tls::Pem user_cert;
00030     /** Additional user data, as defined @c in public:ccf.gov.users */
00031     nlohmann::json user_data;
00032     /** Canonicalised request and associated signature */
00033     SignedReq signed_request;
00034   };
00035 
00036   class UserSignatureAuthnPolicy : public AuthnPolicy
00037   {
00038   protected:
00039     static const OpenAPISecuritySchema security_schema;
00040 
00041   public:
00042     std::unique_ptr<AuthnIdentity> authenticate(
00043       kv::ReadOnlyTx& tx,
00044       const std::shared_ptr<enclave::RpcContext>& ctx,
00045       std::string& error_reason) override
00046     {
00047       const auto signed_request = parse_signed_request(ctx);
00048       if (signed_request.has_value())
00049       {
00050         auto digests_view =
00051           tx.get_read_only_view<CertDigests>(Tables::USER_DIGESTS);
00052         auto user_id = digests_view->get(signed_request->key_id);
00053 
00054         // This should be removed once
00055         // https://github.com/microsoft/CCF/issues/2018 is completed
00056         if (!user_id.has_value())
00057         {
00058           auto user_certs_view =
00059             tx.get_read_only_view<CertDERs>(Tables::USER_CERT_DERS);
00060           user_id = user_certs_view->get(ctx->session->caller_cert);
00061         }
00062 
00063         if (user_id.has_value())
00064         {
00065           Users users_table(Tables::USERS);
00066           auto users_view = tx.get_read_only_view(users_table);
00067           const auto user = users_view->get(user_id.value());
00068           if (!user.has_value())
00069           {
00070             throw std::logic_error("Users and user certs tables do not match");
00071           }
00072 
00073           auto identity = std::make_unique<UserSignatureAuthnIdentity>();
00074           identity->user_id = user_id.value();
00075           identity->user_cert = user->cert;
00076           identity->user_data = user->user_data;
00077           identity->signed_request = signed_request.value();
00078           return identity;
00079         }
00080         else
00081         {
00082           error_reason = "Signer is not a known user";
00083         }
00084       }
00085       else
00086       {
00087         error_reason = "Missing signature";
00088       }
00089 
00090       return nullptr;
00091     }
00092 
00093     void set_unauthenticated_error(
00094       std::shared_ptr<enclave::RpcContext>& ctx,
00095       std::string&& error_reason) override
00096     {
00097       ctx->set_error(
00098         HTTP_STATUS_UNAUTHORIZED,
00099         ccf::errors::InvalidAuthenticationInfo,
00100         std::move(error_reason));
00101       ctx->set_response_header(
00102         http::headers::WWW_AUTHENTICATE,
00103         fmt::format(
00104           "Signature realm=\"Signed request access\", "
00105           "headers=\"{}\"",
00106           fmt::join(http::required_signature_headers, " ")));
00107     }
00108 
00109     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00110       const override
00111     {
00112       return security_schema;
00113     }
00114   };
00115 
00116   inline const AuthnPolicy::OpenAPISecuritySchema
00117     UserSignatureAuthnPolicy::security_schema = std::make_pair(
00118       "user_signature",
00119       nlohmann::json{{"type", "http"}, {"scheme", "signature"}});
00120 
00121   struct MemberSignatureAuthnIdentity : public AuthnIdentity
00122   {
00123     MemberId member_id;
00124     tls::Pem member_cert;
00125     nlohmann::json member_data;
00126     SignedReq signed_request;
00127   };
00128 
00129   class MemberSignatureAuthnPolicy : public AuthnPolicy
00130   {
00131   protected:
00132     static const OpenAPISecuritySchema security_schema;
00133 
00134   public:
00135     std::unique_ptr<AuthnIdentity> authenticate(
00136       kv::ReadOnlyTx& tx,
00137       const std::shared_ptr<enclave::RpcContext>& ctx,
00138       std::string& error_reason) override
00139     {
00140       const auto signed_request = parse_signed_request(ctx);
00141       if (signed_request.has_value())
00142       {
00143         auto digests_view =
00144           tx.get_read_only_view<CertDigests>(Tables::MEMBER_DIGESTS);
00145         auto member_id = digests_view->get(signed_request->key_id);
00146 
00147         // This should be removed once
00148         // https://github.com/microsoft/CCF/issues/2018 is completed
00149         if (!member_id.has_value())
00150         {
00151           auto member_certs_view =
00152             tx.get_read_only_view<CertDERs>(Tables::MEMBER_CERT_DERS);
00153           member_id = member_certs_view->get(ctx->session->caller_cert);
00154         }
00155 
00156         if (member_id.has_value())
00157         {
00158           Members members_table(Tables::MEMBERS);
00159           auto members_view = tx.get_read_only_view(members_table);
00160           const auto member = members_view->get(member_id.value());
00161           if (!member.has_value())
00162           {
00163             throw std::logic_error(
00164               "Members and member certs tables do not match");
00165           }
00166 
00167           auto identity = std::make_unique<MemberSignatureAuthnIdentity>();
00168           identity->member_id = member_id.value();
00169           identity->member_cert = member->cert;
00170           identity->member_data = member->member_data;
00171           identity->signed_request = signed_request.value();
00172           return identity;
00173         }
00174         else
00175         {
00176           error_reason = "Signer is not a known member";
00177         }
00178       }
00179       else
00180       {
00181         error_reason = "Missing signature";
00182       }
00183 
00184       return nullptr;
00185     }
00186 
00187     void set_unauthenticated_error(
00188       std::shared_ptr<enclave::RpcContext>& ctx,
00189       std::string&& error_reason) override
00190     {
00191       ctx->set_error(
00192         HTTP_STATUS_UNAUTHORIZED,
00193         ccf::errors::InvalidAuthenticationInfo,
00194         std::move(error_reason));
00195       ctx->set_response_header(
00196         http::headers::WWW_AUTHENTICATE,
00197         fmt::format(
00198           "Signature realm=\"Signed request access\", "
00199           "headers=\"{}\"",
00200           fmt::join(http::required_signature_headers, " ")));
00201     }
00202 
00203     std::optional<OpenAPISecuritySchema> get_openapi_security_schema()
00204       const override
00205     {
00206       return security_schema;
00207     }
00208   };
00209 
00210   inline const AuthnPolicy::OpenAPISecuritySchema
00211     MemberSignatureAuthnPolicy::security_schema = std::make_pair(
00212       "member_signature",
00213       nlohmann::json{{"type", "http"}, {"scheme", "signature"}});
00214 }
00215 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/authentication/sig_auth.h...
Preprocessing /data/git/CCF/src/http/http_builder.h...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 6120 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/http/http_builder.h" 2
00006 # 6 "/data/git/CCF/src/http/http_builder.h" 2
00007 
00008 
00009 
00010 #define FMT_HEADER_ONLY
00011 
00012 
00013 
00014 
00015 
00016 
00017 namespace http
00018 {
00019   using HeaderMap = std::map<std::string, std::string, std::less<>>;
00020 
00021   static std::string get_header_string(const HeaderMap& headers)
00022   {
00023     std::string header_string;
00024     for (const auto& [k, v] : headers)
00025     {
00026       header_string += fmt::format("{}: {}\r\n", k, v);
00027     }
00028 
00029     return header_string;
00030   }
00031 
00032 // Most builder function are unused from enclave
00033 
00034 
00035   static llhttp_method http_method_from_str(const char* s)
00036   {
00037 #define XX(num, name, string) 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045     throw std::logic_error(fmt::format("Unknown HTTP method '{}'", s));
00046   }
00047 
00048 
00049   class Message
00050   {
00051   protected:
00052     HeaderMap headers;
00053     const uint8_t* body = nullptr;
00054     size_t body_size = 0;
00055 
00056     Message() = default;
00057 
00058   public:
00059     const HeaderMap& get_headers() const
00060     {
00061       return headers;
00062     }
00063 
00064     void set_header(std::string k, const std::string& v)
00065     {
00066       // Store all headers lower-cased to simplify case-insensitive lookup
00067       nonstd::to_lower(k);
00068       headers[k] = v;
00069     }
00070 
00071     void clear_headers()
00072     {
00073       headers.clear();
00074     }
00075 
00076     size_t get_content_length() const
00077     {
00078       if (body == nullptr)
00079       {
00080         return 0;
00081       }
00082       else
00083       {
00084         return body_size;
00085       }
00086     }
00087 
00088     const uint8_t* get_content_data() const
00089     {
00090       return body;
00091     }
00092 
00093     void set_body(const std::vector<uint8_t>* b)
00094     {
00095       if (b != nullptr)
00096       {
00097         set_body(b->data(), b->size());
00098       }
00099       else
00100       {
00101         set_body(nullptr, 0);
00102       }
00103     }
00104 
00105     void set_body(const uint8_t* b, size_t s)
00106     {
00107       body = b;
00108       body_size = s;
00109 
00110       headers[headers::CONTENT_LENGTH] =
00111         fmt::format("{}", get_content_length());
00112     }
00113   };
00114 
00115   class Request : public Message
00116   {
00117   private:
00118     llhttp_method method;
00119     std::string path = "/";
00120     std::map<std::string, std::string> query_params = {};
00121 
00122   public:
00123     Request(const std::string_view& p = "/", llhttp_method m = HTTP_POST) :
00124       Message(),
00125       method(m)
00126     {
00127       set_path(p);
00128     }
00129 
00130     llhttp_method get_method() const
00131     {
00132       return method;
00133     }
00134 
00135     void set_path(const std::string_view& p)
00136     {
00137       if (p.size() > 0 && p[0] == '/')
00138       {
00139         path = p;
00140       }
00141       else
00142       {
00143         path = fmt::format("/{}", p);
00144       }
00145     }
00146 
00147     std::string get_path() const
00148     {
00149       return path;
00150     }
00151 
00152     void set_query_param(const std::string& k, const std::string& v)
00153     {
00154       query_params[k] = v;
00155     }
00156 
00157     void set_query_params(const nlohmann::json& j)
00158     {
00159       for (auto it = j.begin(); it != j.end(); ++it)
00160       {
00161         set_query_param(it.key(), it.value().dump());
00162       }
00163     }
00164 
00165     std::string get_formatted_query() const
00166     {
00167       std::string formatted_query;
00168       bool first = true;
00169       for (const auto& it : query_params)
00170       {
00171         formatted_query +=
00172           fmt::format("{}{}={}", (first ? '?' : '&'), it.first, it.second);
00173         first = false;
00174       }
00175       return formatted_query;
00176     }
00177 
00178     std::vector<uint8_t> build_request(bool header_only = false) const
00179     {
00180       const auto uri = fmt::format("{}{}", path, get_formatted_query());
00181 
00182       const auto body_view = (header_only || body == nullptr) ?
00183         std::string_view() :
00184         std::string_view((char const*)body, body_size);
00185 
00186       const auto request_string = fmt::format(
00187         "{} {} HTTP/1.1\r\n"
00188         "{}"
00189         "\r\n"
00190         "{}",
00191         llhttp_method_name(method),
00192         uri,
00193         get_header_string(headers),
00194         body_view);
00195 
00196       return std::vector<uint8_t>(request_string.begin(), request_string.end());
00197     }
00198   };
00199 
00200   class Response : public Message
00201   {
00202   private:
00203     http_status status;
00204 
00205   public:
00206     Response(http_status s = HTTP_STATUS_OK) : status(s) {}
00207 
00208     std::vector<uint8_t> build_response(bool header_only = false) const
00209     {
00210       const auto body_view = (header_only || body == nullptr) ?
00211         std::string_view() :
00212         std::string_view((char const*)body, body_size);
00213 
00214       const auto response_string = fmt::format(
00215         "HTTP/1.1 {} {}\r\n"
00216         "{}"
00217         "\r\n"
00218         "{}",
00219         status,
00220         http_status_str(status),
00221         get_header_string(headers),
00222         body_view);
00223 
00224       return std::vector<uint8_t>(
00225         response_string.begin(), response_string.end());
00226     }
00227   };
00228 
00229 // Most builder function are unused from enclave
00230 
00231 
00232 
00233   // Generic
00234   static std::vector<uint8_t> build_header(
00235     llhttp_method method, const std::vector<uint8_t>& body)
00236   {
00237     Request r("/", method);
00238     r.set_body(&body);
00239     return r.build_request(true);
00240   }
00241 
00242   static std::vector<uint8_t> build_request(
00243     llhttp_method method, const std::vector<uint8_t>& body)
00244   {
00245     Request r("/", method);
00246     r.set_body(&body);
00247     return r.build_request(false);
00248   }
00249 
00250   // HTTP_DELETE
00251   static std::vector<uint8_t> build_delete_header(
00252     const std::vector<uint8_t>& body)
00253   {
00254     return build_header(HTTP_DELETE, body);
00255   }
00256 
00257   static std::vector<uint8_t> build_delete_request(
00258     const std::vector<uint8_t>& body)
00259   {
00260     return build_request(HTTP_DELETE, body);
00261   }
00262 
00263   // HTTP_GET
00264   static std::vector<uint8_t> build_get_header(const std::vector<uint8_t>& body)
00265   {
00266     return build_header(HTTP_GET, body);
00267   }
00268 
00269   static std::vector<uint8_t> build_get_request(
00270     const std::vector<uint8_t>& body)
00271   {
00272     return build_request(HTTP_GET, body);
00273   }
00274 
00275   // HTTP_POST
00276   static std::vector<uint8_t> build_post_header(
00277     const std::vector<uint8_t>& body)
00278   {
00279     return build_header(HTTP_POST, body);
00280   }
00281 
00282   static std::vector<uint8_t> build_post_request(
00283     const std::vector<uint8_t>& body)
00284   {
00285     return build_request(HTTP_POST, body);
00286   }
00287 
00288   // HTTP_PUT
00289   static std::vector<uint8_t> build_put_header(const std::vector<uint8_t>& body)
00290   {
00291     return build_header(HTTP_PUT, body);
00292   }
00293 
00294   static std::vector<uint8_t> build_put_request(
00295     const std::vector<uint8_t>& body)
00296   {
00297     return build_request(HTTP_PUT, body);
00298   }
00299 
00300 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_builder.h...
Preprocessing /data/git/CCF/src/http/http_consts.h...
Preprocessor output (size: 2199 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 namespace http
00006 {
00007   namespace headers
00008   {
00009     // All HTTP headers are expected to be lowercase
00010     static constexpr auto ACCEPT = "accept";
00011     static constexpr auto ALLOW = "allow";
00012     static constexpr auto AUTHORIZATION = "authorization";
00013     static constexpr auto CONTENT_LENGTH = "content-length";
00014     static constexpr auto CONTENT_TYPE = "content-type";
00015     static constexpr auto DATE = "date";
00016     static constexpr auto DIGEST = "digest";
00017     static constexpr auto HOST = "host";
00018     static constexpr auto LOCATION = "location";
00019     static constexpr auto RETRY_AFTER = "retry-after";
00020     static constexpr auto WWW_AUTHENTICATE = "www-authenticate";
00021 
00022     static constexpr auto CCF_TX_SEQNO = "x-ccf-tx-seqno";
00023     static constexpr auto CCF_TX_VIEW = "x-ccf-tx-view";
00024 
00025     // Deprecated, will be removed in a later release
00026     static constexpr auto CCF_GLOBAL_COMMIT = "x-ccf-global-commit";
00027   }
00028 
00029   namespace headervalues
00030   {
00031     namespace contenttype
00032     {
00033       static constexpr auto JSON = "application/json";
00034       static constexpr auto MSGPACK = "application/msgpack";
00035       static constexpr auto TEXT = "text/plain";
00036       static constexpr auto OCTET_STREAM = "application/octet-stream";
00037     }
00038   }
00039 
00040   namespace auth
00041   {
00042     static constexpr auto DIGEST_SHA256 = "SHA-256";
00043 
00044     static constexpr auto SIGN_AUTH_SCHEME = "Signature";
00045     static constexpr auto SIGN_PARAMS_KEYID = "keyId";
00046     static constexpr auto SIGN_PARAMS_SIGNATURE = "signature";
00047     static constexpr auto SIGN_PARAMS_ALGORITHM = "algorithm";
00048     static constexpr auto SIGN_PARAMS_HEADERS = "headers";
00049     static constexpr auto SIGN_ALGORITHM_ECDSA_SHA256 = "ecdsa-sha256";
00050     static constexpr auto SIGN_ALGORITHM_HS_2019 = "hs2019";
00051 
00052     static constexpr auto SIGN_HEADER_REQUEST_TARGET = "(request-target)";
00053 
00054     static constexpr auto SIGN_PARAMS_DELIMITER = ",";
00055     static constexpr auto SIGN_PARAMS_HEADERS_DELIMITER = " ";
00056 
00057     static constexpr auto BEARER_AUTH_SCHEME = "Bearer";
00058   }
00059 
00060   static constexpr char const* required_signature_headers[] = {
00061     auth::SIGN_HEADER_REQUEST_TARGET, headers::DIGEST};
00062 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/http_consts.h...
Preprocessing /data/git/CCF/src/http/http_endpoint.h...
#include ds/logger.h: not found! skipping...
#include enclave/client_endpoint.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include enclave/tls_endpoint.h: not found! skipping...
  #include http_consts.h: already included! skipping...
#include http_status.h: already included! skipping...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
  #include enclave/tls_endpoint.h: not found! skipping...
#include http_builder.h: already included! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include endian.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include queue: not found! skipping...
#include string: not found! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include queue: not found! skipping...
#include regex: not found! skipping...
#include string: not found! skipping...
#include string_view: not found! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include http_parser.h: already included! skipping...
  #include http_consts.h: already included! skipping...
#include http_parser.h: already included! skipping...
#include node/client_signatures.h: not found! skipping...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
#include node/rpc/error.h: not found! skipping...
  #include enclave/tls_endpoint.h: not found! skipping...
#include http_proc.h: already included! skipping...
    #include cstddef: not found! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include endian.h: not found! skipping...
#include string: not found! skipping...
  #include ../ds/serialized.h: already included! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include http_parser.h: already included! skipping...
#include http_sig.h: already included! skipping...
#include node/rpc/error.h: not found! skipping...
    #include ../ds/serialized.h: already included! skipping...
      #include crypto/hash.h: not found! skipping...
#include ds/nonstd.h: not found! skipping...
#include enclave/consensus_type.h: not found! skipping...
        #include tls/pem.h: not found! skipping...
#include array: not found! skipping...
#include chrono: not found! skipping...
#include functional: not found! skipping...
#include limits: not found! skipping...
#include memory: not found! skipping...
#include string: not found! skipping...
#include unordered_set: not found! skipping...
#include vector: not found! skipping...
#include ws_parser.h: already included! skipping...
#include arpa/inet.h: not found! skipping...
#include ws_parser.h: already included! skipping...
#include ws_rpc_context.h: already included! skipping...
#include http_parser.h: already included! skipping...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 8963 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 # 8 "/data/git/CCF/src/http/http_endpoint.h" 2
00009 # 9 "/data/git/CCF/src/http/http_endpoint.h" 2
00010 
00011 
00012 # 12 "/data/git/CCF/src/http/http_endpoint.h" 2
00013 
00014 namespace http
00015 {
00016   class HTTPEndpoint : public enclave::TLSEndpoint
00017   {
00018   protected:
00019     http::Parser& p;
00020     ws::Parser& wp;
00021     bool is_websocket = false;
00022     size_t ws_next_read = ws::INITIAL_READ;
00023 
00024     HTTPEndpoint(
00025       http::Parser& p_,
00026       ws::Parser& wp_,
00027       size_t session_id,
00028       ringbuffer::AbstractWriterFactory& writer_factory,
00029       std::unique_ptr<tls::Context> ctx) :
00030       TLSEndpoint(session_id, writer_factory, std::move(ctx)),
00031       p(p_),
00032       wp(wp_)
00033     {}
00034 
00035   public:
00036     static void recv_cb(std::unique_ptr<threading::Tmsg<SendRecvMsg>> msg)
00037     {
00038       reinterpret_cast<HTTPEndpoint*>(msg->data.self.get())
00039         ->recv_(msg->data.data.data(), msg->data.data.size());
00040     }
00041 
00042     void recv(const uint8_t* data, size_t size) override
00043     {
00044       auto msg = std::make_unique<threading::Tmsg<SendRecvMsg>>(&recv_cb);
00045       msg->data.self = this->shared_from_this();
00046       msg->data.data.assign(data, data + size);
00047 
00048       threading::ThreadMessaging::thread_messaging.add_task(
00049         execution_thread, std::move(msg));
00050     }
00051 
00052     void recv_(const uint8_t* data_, size_t size_)
00053     {
00054       recv_buffered(data_, size_);
00055 
00056       LOG_TRACE_FMT("recv called with {} bytes", size_);
00057 
00058       if (is_websocket)
00059       {
00060         std::vector<uint8_t> buf(ws_next_read);
00061         while (true)
00062         {
00063           if (ws_next_read > buf.size())
00064           {
00065             buf.resize(ws_next_read);
00066           }
00067 
00068           auto r = read(buf.data(), ws_next_read, true);
00069           if (r == 0)
00070           {
00071             return;
00072           }
00073           else
00074           {
00075             ws_next_read = wp.consume(buf.data(), r);
00076             if (!ws_next_read)
00077             {
00078               close();
00079               return;
00080             }
00081           }
00082         }
00083       }
00084       else
00085       {
00086         constexpr auto read_block_size = 4096;
00087         std::vector<uint8_t> buf(read_block_size);
00088         auto data = buf.data();
00089         auto n_read = read(data, buf.size(), false);
00090 
00091         while (true)
00092         {
00093           if (n_read == 0)
00094           {
00095             return;
00096           }
00097 
00098           LOG_TRACE_FMT("Going to parse {} bytes", n_read);
00099 
00100           try
00101           {
00102             p.execute(data, n_read);
00103 
00104             // Used all provided bytes - check if more are available
00105             n_read = read(buf.data(), buf.size(), false);
00106           }
00107           catch (const std::exception& e)
00108           {
00109             LOG_FAIL_FMT("Error parsing request");
00110             LOG_DEBUG_FMT("Error parsing request: {}", e.what());
00111             close();
00112             break;
00113           }
00114         }
00115       }
00116     }
00117   };
00118 
00119   class HTTPServerEndpoint : public HTTPEndpoint, public http::RequestProcessor
00120   {
00121   private:
00122     http::RequestParser request_parser;
00123     ws::RequestParser ws_request_parser;
00124 
00125     std::shared_ptr<enclave::RPCMap> rpc_map;
00126     std::shared_ptr<enclave::RpcHandler> handler;
00127     std::shared_ptr<enclave::SessionContext> session_ctx;
00128     size_t session_id;
00129     size_t request_index = 0;
00130 
00131   public:
00132     HTTPServerEndpoint(
00133       std::shared_ptr<enclave::RPCMap> rpc_map,
00134       size_t session_id,
00135       ringbuffer::AbstractWriterFactory& writer_factory,
00136       std::unique_ptr<tls::Context> ctx) :
00137       HTTPEndpoint(
00138         request_parser,
00139         ws_request_parser,
00140         session_id,
00141         writer_factory,
00142         std::move(ctx)),
00143       request_parser(*this),
00144       ws_request_parser(*this),
00145       rpc_map(rpc_map),
00146       session_id(session_id)
00147     {}
00148 
00149     void send(std::vector<uint8_t>&& data) override
00150     {
00151       send_raw(std::move(data));
00152     }
00153 
00154     void handle_request(
00155       llhttp_method verb,
00156       const std::string_view& path,
00157       const std::string& query,
00158       const std::string&,
00159       http::HeaderMap&& headers,
00160       std::vector<uint8_t>&& body) override
00161     {
00162       LOG_TRACE_FMT(
00163         "Processing msg({}, {}, {}, [{} bytes])",
00164         llhttp_method_name(verb),
00165         path,
00166         query,
00167         body.size());
00168 
00169       try
00170       {
00171         // Check if the client requested upgrade to websocket, and complete
00172         // handshake if necessary
00173         auto upgrade_resp =
00174           http::WebSocketUpgrader::upgrade_if_necessary(headers);
00175         if (upgrade_resp.has_value())
00176         {
00177           LOG_TRACE_FMT("Upgraded to websocket");
00178           is_websocket = true;
00179           send_raw(std::move(upgrade_resp.value()));
00180           return;
00181         }
00182 
00183         if (session_ctx == nullptr)
00184         {
00185           session_ctx =
00186             std::make_shared<enclave::SessionContext>(session_id, peer_cert());
00187         }
00188 
00189         std::shared_ptr<enclave::RpcContext> rpc_ctx = nullptr;
00190         try
00191         {
00192           if (is_websocket)
00193           {
00194             rpc_ctx = std::make_shared<ws::WsRpcContext>(
00195               request_index++, session_ctx, path, std::move(body));
00196           }
00197           else
00198           {
00199             rpc_ctx = std::make_shared<HttpRpcContext>(
00200               request_index++,
00201               session_ctx,
00202               verb,
00203               path,
00204               query,
00205               std::move(headers),
00206               std::move(body));
00207           }
00208         }
00209         catch (std::exception& e)
00210         {
00211           if (is_websocket)
00212           {
00213             send_raw(ws::error(
00214               HTTP_STATUS_INTERNAL_SERVER_ERROR,
00215               ccf::errors::InternalError,
00216               e.what()));
00217           }
00218           else
00219           {
00220             send_raw(http::error(
00221               HTTP_STATUS_INTERNAL_SERVER_ERROR,
00222               ccf::errors::InternalError,
00223               e.what()));
00224           }
00225         }
00226 
00227         const auto actor_opt = http::extract_actor(*rpc_ctx);
00228         if (!actor_opt.has_value())
00229         {
00230           rpc_ctx->set_error(
00231             HTTP_STATUS_NOT_FOUND,
00232             ccf::errors::ResourceNotFound,
00233             fmt::format(
00234               "Request path must contain '/[actor]/[method]'. Unable to parse "
00235               "'{}'.",
00236               rpc_ctx->get_method()));
00237           send_raw(rpc_ctx->serialise_response());
00238           return;
00239         }
00240 
00241         const auto& actor_s = actor_opt.value();
00242         auto actor = rpc_map->resolve(actor_s);
00243         auto search = rpc_map->find(actor);
00244         if (actor == ccf::ActorsType::unknown || !search.has_value())
00245         {
00246           rpc_ctx->set_error(
00247             HTTP_STATUS_NOT_FOUND,
00248             ccf::errors::ResourceNotFound,
00249             fmt::format("Unknown actor '{}'.", actor_s));
00250           send_raw(rpc_ctx->serialise_response());
00251           return;
00252         }
00253 
00254         auto response = search.value()->process(rpc_ctx);
00255 
00256         if (!response.has_value())
00257         {
00258           // If the RPC is pending, hold the connection.
00259           LOG_TRACE_FMT("Pending");
00260           return;
00261         }
00262         else
00263         {
00264           send_buffered(response.value());
00265           flush();
00266         }
00267       }
00268       catch (const std::exception& e)
00269       {
00270         if (is_websocket)
00271         {
00272           send_raw(ws::error(
00273             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00274             ccf::errors::InternalError,
00275             fmt::format("Exception: {}", e.what())));
00276         }
00277         else
00278         {
00279           send_raw(http::error(
00280             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00281             ccf::errors::InternalError,
00282             fmt::format("Exception: {}", e.what())));
00283         }
00284 
00285         // On any exception, close the connection.
00286         LOG_FAIL_FMT("Closing connection");
00287         LOG_DEBUG_FMT("Closing connection due to exception: {}", e.what());
00288         close();
00289         throw;
00290       }
00291     }
00292   };
00293 
00294   class HTTPClientEndpoint : public HTTPEndpoint,
00295                              public enclave::ClientEndpoint,
00296                              public http::ResponseProcessor
00297   {
00298   private:
00299     http::ResponseParser response_parser;
00300     ws::ResponseParser ws_response_parser;
00301 
00302   public:
00303     HTTPClientEndpoint(
00304       size_t session_id,
00305       ringbuffer::AbstractWriterFactory& writer_factory,
00306       std::unique_ptr<tls::Context> ctx) :
00307       HTTPEndpoint(
00308         response_parser,
00309         ws_response_parser,
00310         session_id,
00311         writer_factory,
00312         std::move(ctx)),
00313       ClientEndpoint(session_id, writer_factory),
00314       response_parser(*this),
00315       ws_response_parser(*this)
00316     {}
00317 
00318     void send_request(std::vector<uint8_t>&& data) override
00319     {
00320       send_raw(std::move(data));
00321     }
00322 
00323     void send(std::vector<uint8_t>&&) override
00324     {
00325       throw std::logic_error(
00326         "send() should not be called directly on HTTPClient");
00327     }
00328 
00329     void handle_response(
00330       http_status status,
00331       http::HeaderMap&& headers,
00332       std::vector<uint8_t>&& body) override
00333     {
00334       handle_data_cb(status, std::move(headers), std::move(body));
00335 
00336       LOG_TRACE_FMT("Closing connection, message handled");
00337       close();
00338     }
00339   };
00340 }
00341 
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_endpoint.h...
Preprocessing /data/git/CCF/src/http/http_jwt.h...
#include crypto/hash.h: not found! skipping...
#include http_consts.h: already included! skipping...
#include http_parser.h: already included! skipping...
#include tls/base64.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 4584 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define FMT_HEADER_ONLY
00012 
00013 
00014 
00015 
00016 namespace http
00017 {
00018   enum class JwtCryptoAlgorithm
00019   {
00020     RS256
00021   };
00022   DECLARE_JSON_ENUM(JwtCryptoAlgorithm, {{JwtCryptoAlgorithm::RS256, "RS256"}});
00023 
00024   struct JwtHeader
00025   {
00026     JwtCryptoAlgorithm alg;
00027     std::string kid;
00028   };
00029 
00030 
00031 
00032   class JwtVerifier
00033   {
00034   public:
00035     struct Token
00036     {
00037       nlohmann::json header;
00038       JwtHeader header_typed;
00039       nlohmann::json payload;
00040       std::vector<uint8_t> signature;
00041       std::string_view signed_content;
00042     };
00043 
00044     static bool parse_auth_scheme(
00045       std::string_view& auth_header_value, std::string& error_reason)
00046     {
00047       auto next_space = auth_header_value.find(" ");
00048       if (next_space == std::string::npos)
00049       {
00050         error_reason = "Authorization header only contains one field";
00051         return false;
00052       }
00053       auto auth_scheme = auth_header_value.substr(0, next_space);
00054       if (auth_scheme != auth::BEARER_AUTH_SCHEME)
00055       {
00056         error_reason = fmt::format(
00057           "Authorization header does not have {} scheme",
00058           auth::BEARER_AUTH_SCHEME);
00059         return false;
00060       }
00061       auth_header_value = auth_header_value.substr(next_space + 1);
00062       return true;
00063     }
00064 
00065     static std::optional<Token> parse_token(
00066       std::string_view& token, std::string& error_reason)
00067     {
00068       constexpr char separator = '.';
00069       size_t first_dot = token.find(separator);
00070       size_t second_dot = std::string::npos;
00071       if (first_dot != std::string::npos)
00072       {
00073         second_dot = token.find(separator, first_dot + 1);
00074       }
00075       size_t extra_dot = std::string::npos;
00076       if (second_dot != std::string::npos)
00077       {
00078         extra_dot = token.find(separator, second_dot + 1);
00079       }
00080       if (
00081         first_dot == std::string::npos || second_dot == std::string::npos ||
00082         extra_dot != std::string::npos)
00083       {
00084         error_reason = "Malformed JWT: must contain exactly 3 parts";
00085         return std::nullopt;
00086       }
00087       size_t header_size = first_dot;
00088       size_t payload_size = second_dot - first_dot - 1;
00089       std::string_view header_b64url = token.substr(0, header_size);
00090       std::string_view payload_b64url =
00091         token.substr(first_dot + 1, payload_size);
00092       std::string_view signature_b64url = token.substr(second_dot + 1);
00093       auto header_raw = tls::raw_from_b64url(header_b64url);
00094       auto payload_raw = tls::raw_from_b64url(payload_b64url);
00095       auto signature_raw = tls::raw_from_b64url(signature_b64url);
00096       auto signed_content = token.substr(0, second_dot);
00097       nlohmann::json header;
00098       nlohmann::json payload;
00099       try
00100       {
00101         header = nlohmann::json::parse(header_raw);
00102         payload = nlohmann::json::parse(payload_raw);
00103       }
00104       catch (const nlohmann::json::parse_error& e)
00105       {
00106         error_reason =
00107           fmt::format("JWT header or payload is not valid JSON: {}", e.what());
00108         return std::nullopt;
00109       }
00110       if (!header.is_object() || !payload.is_object())
00111       {
00112         error_reason = "JWT header or payload is not an object";
00113         return std::nullopt;
00114       }
00115       JwtHeader header_typed;
00116       try
00117       {
00118         header_typed = header.get<JwtHeader>();
00119       }
00120       catch (const nlohmann::json::exception& e)
00121       {
00122         error_reason =
00123           fmt::format("JWT header does not follow schema: {}", e.what());
00124         return std::nullopt;
00125       }
00126       Token parsed = {
00127         header, header_typed, payload, signature_raw, signed_content};
00128       return parsed;
00129     }
00130 
00131     static std::optional<Token> extract_token(
00132       const http::HeaderMap& headers, std::string& error_reason)
00133     {
00134       const auto auth_it = headers.find(headers::AUTHORIZATION);
00135       if (auth_it == headers.end())
00136       {
00137         error_reason = fmt::format("Missing {} header", headers::AUTHORIZATION);
00138         return std::nullopt;
00139       }
00140       std::string_view token = auth_it->second;
00141       if (!parse_auth_scheme(token, error_reason))
00142       {
00143         return std::nullopt;
00144       }
00145       auto parsed = parse_token(token, error_reason);
00146       return parsed;
00147     }
00148 
00149     static bool validate_token_signature(
00150       const Token& token, std::vector<uint8_t> cert_der)
00151     {
00152       auto verifier = tls::make_unique_verifier(cert_der);
00153       bool valid = verifier->verify(
00154         (uint8_t*)token.signed_content.data(),
00155         token.signed_content.size(),
00156         token.signature.data(),
00157         token.signature.size(),
00158         MBEDTLS_MD_SHA256);
00159       return valid;
00160     }
00161   };
00162 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_jwt.h...
Preprocessing /data/git/CCF/src/http/http_parser.h...
#include enclave/tls_endpoint.h: not found! skipping...
#include http_builder.h: already included! skipping...
#include http_proc.h: already included! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include queue: not found! skipping...
#include regex: not found! skipping...
#include string: not found! skipping...
#include string_view: not found! skipping...
Preprocessor output (size: 10657 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 namespace http
00019 {
00020   static uint8_t hex_char_to_int(char c)
00021   {
00022     if (c <= '9')
00023     {
00024       return c - '0';
00025     }
00026     else if (c <= 'F')
00027     {
00028       return c - 'A' + 10;
00029     }
00030     else if (c <= 'f')
00031     {
00032       return c - 'a' + 10;
00033     }
00034     return c;
00035   }
00036 
00037   static std::string url_decode(const std::string_view& s_)
00038   {
00039     std::string s(s_);
00040     char const* src = s.c_str();
00041     char const* end = s.c_str() + s.size();
00042     char* dst = s.data();
00043 
00044     while (src < end)
00045     {
00046       char const c = *src++;
00047       if (c == '%' && (src + 1) < end && isxdigit(src[0]) && isxdigit(src[1]))
00048       {
00049         const auto a = hex_char_to_int(*src++);
00050         const auto b = hex_char_to_int(*src++);
00051         *dst++ = (a << 4) | b;
00052       }
00053       else if (c == '+')
00054       {
00055         *dst++ = ' ';
00056       }
00057       else
00058       {
00059         *dst++ = c;
00060       }
00061     }
00062 
00063     s.resize(dst - s.data());
00064     return s;
00065   }
00066 
00067   static bool status_success(http_status status)
00068   {
00069     return status >= 200 && status < 300;
00070   }
00071 
00072   struct SimpleRequestProcessor : public http::RequestProcessor
00073   {
00074   public:
00075     struct Request
00076     {
00077       llhttp_method method;
00078       std::string path;
00079       std::string query;
00080       std::string fragment;
00081       http::HeaderMap headers;
00082       std::vector<uint8_t> body;
00083     };
00084 
00085     std::queue<Request> received;
00086 
00087     virtual void handle_request(
00088       llhttp_method method,
00089       const std::string_view& path,
00090       const std::string& query,
00091       const std::string& fragment,
00092       http::HeaderMap&& headers,
00093       std::vector<uint8_t>&& body) override
00094     {
00095       received.emplace(Request{method,
00096                                std::string(path),
00097                                std::string(query),
00098                                std::string(fragment),
00099                                headers,
00100                                body});
00101     }
00102   };
00103 
00104   struct SimpleResponseProcessor : public http::ResponseProcessor
00105   {
00106   public:
00107     struct Response
00108     {
00109       http_status status;
00110       http::HeaderMap headers;
00111       std::vector<uint8_t> body;
00112     };
00113 
00114     std::queue<Response> received;
00115 
00116     virtual void handle_response(
00117       http_status status,
00118       http::HeaderMap&& headers,
00119       std::vector<uint8_t>&& body) override
00120     {
00121       received.emplace(Response{status, headers, body});
00122     }
00123   };
00124 
00125   enum State
00126   {
00127     DONE,
00128     IN_MESSAGE
00129   };
00130 
00131   static int on_msg_begin(llhttp_t* parser);
00132   static int on_url(llhttp_t* parser, const char* at, size_t length);
00133   static int on_header_field(llhttp_t* parser, const char* at, size_t length);
00134   static int on_header_value(llhttp_t* parser, const char* at, size_t length);
00135   static int on_headers_complete(llhttp_t* parser);
00136   static int on_body(llhttp_t* parser, const char* at, size_t length);
00137   static int on_msg_end(llhttp_t* parser);
00138 
00139   inline auto split_url_path(const std::string_view& url)
00140   {
00141     LOG_TRACE_FMT("Received url to parse: {}", std::string_view(url));
00142 
00143     const auto path_end = url.find('?');
00144     const auto query_start =
00145       path_end == std::string::npos ? url.size() : path_end + 1;
00146 
00147     const auto query_end = url.find('#', query_start);
00148     const auto fragment_start =
00149       query_end == std::string::npos ? url.size() : query_end + 1;
00150 
00151     return std::make_tuple(
00152       url.substr(0, path_end),
00153       url.substr(query_start, query_end - query_start),
00154       url.substr(fragment_start));
00155   }
00156 
00157   struct URL
00158   {
00159     std::string scheme;
00160     std::string host;
00161     std::string port;
00162     std::string path;
00163     std::string query;
00164     std::string fragment;
00165   };
00166 
00167   inline URL parse_url_full(const std::string& url)
00168   {
00169     LOG_TRACE_FMT("Received url to parse: {}", url);
00170 
00171     // From https://tools.ietf.org/html/rfc3986#appendix-B
00172     std::regex url_regex(
00173       "^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?");
00174 
00175     std::smatch match;
00176     if (!std::regex_match(url, match, url_regex))
00177     {
00178       throw std::invalid_argument(fmt::format("Unable to parse url: {}", url));
00179     }
00180 
00181     const auto host_port = match[4].str();
00182 
00183     // IPv6 hosts may contain colons, so only search for port after the closing
00184     // square bracket
00185     const auto closing_bracket = host_port.rfind(']');
00186     const auto port_delim_start =
00187       closing_bracket == std::string::npos ? 0 : closing_bracket;
00188     const auto port_delim = host_port.find(':', port_delim_start);
00189 
00190     URL u;
00191     u.scheme = match[2].str();
00192     u.host = host_port.substr(0, port_delim);
00193     if (port_delim != std::string::npos)
00194     {
00195       u.port = host_port.substr(port_delim + 1);
00196     }
00197     u.path = match[5].str();
00198     u.query = match[7].str();
00199     u.fragment = match[9].str();
00200     return u;
00201   }
00202 
00203   class Parser
00204   {
00205   protected:
00206     llhttp_t parser;
00207     llhttp_settings_t settings;
00208     State state = DONE;
00209 
00210     std::vector<uint8_t> body_buf;
00211     HeaderMap headers;
00212 
00213     std::pair<std::string, std::string> partial_parsed_header = {};
00214 
00215     void complete_header()
00216     {
00217       headers.emplace(partial_parsed_header);
00218       partial_parsed_header.first.clear();
00219       partial_parsed_header.second.clear();
00220     }
00221 
00222     Parser(llhttp_type_t type)
00223     {
00224       llhttp_settings_init(&settings);
00225 
00226       settings.on_message_begin = on_msg_begin;
00227       settings.on_header_field = on_header_field;
00228       settings.on_header_value = on_header_value;
00229       settings.on_headers_complete = on_headers_complete;
00230       settings.on_body = on_body;
00231       settings.on_message_complete = on_msg_end;
00232 
00233       llhttp_init(&parser, type, &settings);
00234       parser.data = this;
00235     }
00236 
00237   public:
00238     void execute(const uint8_t* data, size_t size)
00239     {
00240       auto err_no = llhttp_execute(&parser, (const char*)data, size);
00241 
00242       if (err_no == HPE_PAUSED_UPGRADE)
00243       {
00244         // Assume Upgrade requests will be handled by caller inspecting headers,
00245         // so we can instantly resume the parser.
00246         llhttp_resume_after_upgrade(&parser);
00247       }
00248       else if (err_no != HPE_OK)
00249       {
00250         throw std::runtime_error(fmt::format(
00251           "HTTP parsing failed: '{}: {}' while parsing fragment '{}'",
00252           llhttp_errno_name(err_no),
00253           llhttp_get_error_reason(&parser),
00254           std::string((char const*)data, size)));
00255       }
00256     }
00257 
00258     void append_body(const char* at, size_t length)
00259     {
00260       if (state == IN_MESSAGE)
00261       {
00262         LOG_TRACE_FMT("Appending chunk [{} bytes]", length);
00263         std::copy(at, at + length, std::back_inserter(body_buf));
00264       }
00265       else
00266       {
00267         throw std::runtime_error("Receiving content outside of message");
00268       }
00269     }
00270 
00271     virtual void new_message()
00272     {
00273       if (state == DONE)
00274       {
00275         LOG_TRACE_FMT("Entering new message");
00276         state = IN_MESSAGE;
00277         body_buf.clear();
00278         headers.clear();
00279       }
00280       else
00281       {
00282         throw std::runtime_error(
00283           "Entering new message when previous message isn't complete");
00284       }
00285     }
00286 
00287     virtual void handle_completed_message() = 0;
00288 
00289     void end_message()
00290     {
00291       if (state == IN_MESSAGE)
00292       {
00293         LOG_TRACE_FMT("Done with message");
00294         handle_completed_message();
00295         state = DONE;
00296       }
00297       else
00298       {
00299         throw std::runtime_error("Ending message, but not in a message");
00300       }
00301     }
00302 
00303     void header_field(const char* at, size_t length)
00304     {
00305       if (!partial_parsed_header.second.empty())
00306       {
00307         complete_header();
00308       }
00309 
00310       // HTTP headers are stored lowercase as it is easier to verify HTTP
00311       // signatures later on
00312       auto f = std::string(at, length);
00313       nonstd::to_lower(f);
00314       partial_parsed_header.first.append(f);
00315     }
00316 
00317     void header_value(const char* at, size_t length)
00318     {
00319       partial_parsed_header.second.append(at, length);
00320     }
00321 
00322     void headers_complete()
00323     {
00324       complete_header();
00325     }
00326   };
00327 
00328   static int on_msg_begin(llhttp_t* parser)
00329   {
00330     Parser* p = reinterpret_cast<Parser*>(parser->data);
00331     p->new_message();
00332     return HPE_OK;
00333   }
00334 
00335   static int on_header_field(llhttp_t* parser, const char* at, size_t length)
00336   {
00337     Parser* p = reinterpret_cast<Parser*>(parser->data);
00338     p->header_field(at, length);
00339     return HPE_OK;
00340   }
00341 
00342   static int on_header_value(llhttp_t* parser, const char* at, size_t length)
00343   {
00344     Parser* p = reinterpret_cast<Parser*>(parser->data);
00345     p->header_value(at, length);
00346     return HPE_OK;
00347   }
00348 
00349   static int on_headers_complete(llhttp_t* parser)
00350   {
00351     Parser* p = reinterpret_cast<Parser*>(parser->data);
00352     p->headers_complete();
00353     return HPE_OK;
00354   }
00355 
00356   static int on_body(llhttp_t* parser, const char* at, size_t length)
00357   {
00358     Parser* p = reinterpret_cast<Parser*>(parser->data);
00359     p->append_body(at, length);
00360     return HPE_OK;
00361   }
00362 
00363   static int on_msg_end(llhttp_t* parser)
00364   {
00365     Parser* p = reinterpret_cast<Parser*>(parser->data);
00366     p->end_message();
00367     return HPE_OK;
00368   }
00369 
00370   // Request-specific
00371   class RequestParser : public Parser
00372   {
00373   private:
00374     RequestProcessor& proc;
00375 
00376     std::string url = "";
00377 
00378   public:
00379     RequestParser(RequestProcessor& proc_) : Parser(HTTP_REQUEST), proc(proc_)
00380     {
00381       settings.on_url = on_url;
00382     }
00383 
00384     void append_url(const char* at, size_t length)
00385     {
00386       url.append(at, length);
00387     }
00388 
00389     void new_message() override
00390     {
00391       Parser::new_message();
00392       url.clear();
00393     }
00394 
00395     void handle_completed_message() override
00396     {
00397       if (url.empty())
00398       {
00399         proc.handle_request(
00400           llhttp_method(parser.method),
00401           {},
00402           {},
00403           {},
00404           std::move(headers),
00405           std::move(body_buf));
00406       }
00407       else
00408       {
00409         const auto [path, query, fragment] = split_url_path(url);
00410         const std::string decoded_query = url_decode(query);
00411         const std::string decoded_fragment = url_decode(fragment);
00412         proc.handle_request(
00413           llhttp_method(parser.method),
00414           path,
00415           decoded_query,
00416           decoded_fragment,
00417           std::move(headers),
00418           std::move(body_buf));
00419       }
00420     }
00421   };
00422 
00423   static int on_url(llhttp_t* parser, const char* at, size_t length)
00424   {
00425     RequestParser* p = reinterpret_cast<RequestParser*>(parser->data);
00426     p->append_url(at, length);
00427     return HPE_OK;
00428   }
00429 
00430   // Response-specific
00431   class ResponseParser : public Parser
00432   {
00433   private:
00434     ResponseProcessor& proc;
00435 
00436   public:
00437     ResponseParser(ResponseProcessor& proc_) :
00438       Parser(HTTP_RESPONSE),
00439       proc(proc_)
00440     {}
00441 
00442     void handle_completed_message() override
00443     {
00444       proc.handle_response(
00445         http_status(parser.status_code),
00446         std::move(headers),
00447         std::move(body_buf));
00448     }
00449   };
00450 }
00451 
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_parser.h...
Preprocessing /data/git/CCF/src/http/http_proc.h...
#include enclave/tls_endpoint.h: not found! skipping...
#include http_builder.h: already included! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include endian.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include map: not found! skipping...
#include queue: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 570 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace http
00017 {
00018   class RequestProcessor
00019   {
00020   public:
00021     virtual void handle_request(
00022       llhttp_method method,
00023       const std::string_view& path,
00024       const std::string& query,
00025       const std::string& fragment,
00026       HeaderMap&& headers,
00027       std::vector<uint8_t>&& body) = 0;
00028   };
00029 
00030   class ResponseProcessor
00031   {
00032   public:
00033     virtual void handle_response(
00034       http_status status, HeaderMap&& headers, std::vector<uint8_t>&& body) = 0;
00035   };
00036 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_proc.h...
Preprocessing /data/git/CCF/src/http/http_rpc_context.h...
#include enclave/rpc_context.h: not found! skipping...
#include http_parser.h: already included! skipping...
#include http_sig.h: already included! skipping...
#include node/rpc/error.h: not found! skipping...
#include ws_parser.h: already included! skipping...
#include ws_rpc_context.h: already included! skipping...
Preprocessor output (size: 10814 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace http
00013 {
00014   inline static std::optional<std::string> extract_actor(
00015     enclave::RpcContext& ctx)
00016   {
00017     const auto path = ctx.get_method();
00018 
00019     const auto first_slash = path.find_first_of('/');
00020     const auto second_slash = path.find_first_of('/', first_slash + 1);
00021 
00022     if (first_slash != 0 || second_slash == std::string::npos)
00023     {
00024       return std::nullopt;
00025     }
00026 
00027     const auto actor = path.substr(first_slash + 1, second_slash - 1);
00028     const auto remaining_path = path.substr(second_slash + 1);
00029 
00030     if (actor.empty() || remaining_path.empty())
00031     {
00032       return std::nullopt;
00033     }
00034 
00035     ctx.set_method(remaining_path);
00036     return actor;
00037   }
00038 
00039   inline std::vector<uint8_t> error(ccf::ErrorDetails&& error)
00040   {
00041     nlohmann::json body = ccf::ODataErrorResponse{
00042       ccf::ODataError{std::move(error.code), std::move(error.msg)}};
00043     const auto s = body.dump();
00044 
00045     std::vector<uint8_t> data(s.begin(), s.end());
00046     auto response = http::Response(error.status);
00047 
00048     response.set_header(
00049       http::headers::CONTENT_TYPE, http::headervalues::contenttype::JSON);
00050     response.set_body(&data);
00051 
00052     return response.build_response();
00053   }
00054 
00055   inline std::vector<uint8_t> error(
00056     http_status status, const std::string& code, std::string&& msg)
00057   {
00058     return error({status, code, std::move(msg)});
00059   }
00060 
00061   class HttpRpcContext : public enclave::RpcContext
00062   {
00063   private:
00064     size_t request_index;
00065 
00066     ccf::RESTVerb verb;
00067     std::string whole_path = {};
00068     std::string path = {};
00069     std::string query = {};
00070 
00071     http::HeaderMap request_headers = {};
00072 
00073     std::vector<uint8_t> request_body = {};
00074     enclave::PathParams path_params = {};
00075 
00076     std::vector<uint8_t> serialised_request = {};
00077 
00078     http::HeaderMap response_headers;
00079     std::vector<uint8_t> response_body = {};
00080     http_status response_status = HTTP_STATUS_OK;
00081 
00082     bool canonicalised = false;
00083 
00084     std::optional<bool> explicit_apply_writes = std::nullopt;
00085 
00086     void canonicalise()
00087     {
00088       if (!canonicalised)
00089       {
00090         // Build a canonical serialization of this request. If the request is
00091         // signed, then all unsigned headers must be removed
00092         const auto auth_it = request_headers.find(http::headers::AUTHORIZATION);
00093         if (auth_it != request_headers.end())
00094         {
00095           std::string_view authz_header = auth_it->second;
00096 
00097           if (http::HttpSignatureVerifier::parse_auth_scheme(authz_header))
00098           {
00099             auto parsed_sign_params =
00100               http::HttpSignatureVerifier::parse_signature_params(authz_header);
00101 
00102             if (!parsed_sign_params.has_value())
00103             {
00104               throw std::logic_error(fmt::format(
00105                 "Unable to parse signature params from: {}", authz_header));
00106             }
00107 
00108             // Keep all signed headers, and the auth header containing the
00109             // signature itself
00110             auto& signed_headers = parsed_sign_params->signed_headers;
00111             signed_headers.emplace_back(http::headers::AUTHORIZATION);
00112 
00113             auto it = request_headers.begin();
00114             while (it != request_headers.end())
00115             {
00116               if (
00117                 std::find(
00118                   signed_headers.begin(), signed_headers.end(), it->first) ==
00119                 signed_headers.end())
00120               {
00121                 it = request_headers.erase(it);
00122               }
00123               else
00124               {
00125                 ++it;
00126               }
00127             }
00128           }
00129         }
00130 
00131         const auto canonical_request_header = fmt::format(
00132           "{} {}{} HTTP/1.1\r\n"
00133           "{}"
00134           "\r\n",
00135           verb.c_str(),
00136           whole_path,
00137           query.empty() ? "" : fmt::format("?{}", query),
00138           http::get_header_string(request_headers));
00139 
00140         serialised_request.resize(
00141           canonical_request_header.size() + request_body.size());
00142         ::memcpy(
00143           serialised_request.data(),
00144           canonical_request_header.data(),
00145           canonical_request_header.size());
00146         if (!request_body.empty())
00147         {
00148           ::memcpy(
00149             serialised_request.data() + canonical_request_header.size(),
00150             request_body.data(),
00151             request_body.size());
00152         }
00153       }
00154 
00155       canonicalised = true;
00156     }
00157 
00158   public:
00159     HttpRpcContext(
00160       size_t request_index_,
00161       std::shared_ptr<enclave::SessionContext> s,
00162       llhttp_method verb_,
00163       const std::string_view& path_,
00164       const std::string_view& query_,
00165       const http::HeaderMap& headers_,
00166       const std::vector<uint8_t>& body_,
00167       const std::vector<uint8_t>& raw_request_ = {},
00168       const std::vector<uint8_t>& raw_bft_ = {}) :
00169       RpcContext(s, raw_bft_),
00170       request_index(request_index_),
00171       verb(verb_),
00172       path(path_),
00173       query(query_),
00174       request_headers(headers_),
00175       request_body(body_),
00176       serialised_request(raw_request_)
00177     {
00178       whole_path = path;
00179 
00180       if (!serialised_request.empty())
00181       {
00182         canonicalised = true;
00183       }
00184     }
00185 
00186     virtual enclave::FrameFormat frame_format() const override
00187     {
00188       return enclave::FrameFormat::http;
00189     }
00190 
00191     virtual size_t get_request_index() const override
00192     {
00193       return request_index;
00194     }
00195 
00196     virtual void set_seqno(kv::Version sn) override
00197     {
00198       set_response_header(http::headers::CCF_TX_SEQNO, fmt::format("{}", sn));
00199     }
00200 
00201     virtual void set_view(kv::Consensus::View v) override
00202     {
00203       set_response_header(http::headers::CCF_TX_VIEW, fmt::format("{}", v));
00204     }
00205 
00206     virtual void set_global_commit(kv::Version gc) override
00207     {
00208       set_response_header(
00209         http::headers::CCF_GLOBAL_COMMIT, fmt::format("{}", gc));
00210     }
00211 
00212     virtual const std::vector<uint8_t>& get_request_body() const override
00213     {
00214       return request_body;
00215     }
00216 
00217     virtual const std::string& get_request_query() const override
00218     {
00219       return query;
00220     }
00221 
00222     virtual enclave::PathParams& get_request_path_params() override
00223     {
00224       return path_params;
00225     }
00226 
00227     virtual const ccf::RESTVerb& get_request_verb() const override
00228     {
00229       return verb;
00230     }
00231 
00232     virtual std::string get_request_path() const override
00233     {
00234       return whole_path;
00235     }
00236 
00237     virtual const std::vector<uint8_t>& get_serialised_request() override
00238     {
00239       canonicalise();
00240       return serialised_request;
00241     }
00242 
00243     virtual std::string get_method() const override
00244     {
00245       return path;
00246     }
00247 
00248     virtual void set_method(const std::string_view& p) override
00249     {
00250       path = p;
00251     }
00252 
00253     virtual const http::HeaderMap& get_request_headers() const override
00254     {
00255       return request_headers;
00256     }
00257 
00258     virtual std::optional<std::string> get_request_header(
00259       const std::string_view& name) override
00260     {
00261       const auto it = request_headers.find(name);
00262       if (it != request_headers.end())
00263       {
00264         return it->second;
00265       }
00266 
00267       return std::nullopt;
00268     }
00269 
00270     virtual void set_response_body(const std::vector<uint8_t>& body) override
00271     {
00272       response_body = body;
00273     }
00274 
00275     virtual void set_response_body(std::vector<uint8_t>&& body) override
00276     {
00277       response_body = std::move(body);
00278     }
00279 
00280     virtual void set_response_body(std::string&& body) override
00281     {
00282       response_body = std::vector<uint8_t>(body.begin(), body.end());
00283       set_response_header(
00284         http::headers::CONTENT_TYPE, http::headervalues::contenttype::TEXT);
00285     }
00286 
00287     virtual void set_response_status(int status) override
00288     {
00289       response_status = (http_status)status;
00290     }
00291 
00292     virtual int get_response_status() const override
00293     {
00294       return response_status;
00295     }
00296 
00297     virtual void set_response_header(
00298       const std::string_view& name, const std::string_view& value) override
00299     {
00300       response_headers[std::string(name)] = value;
00301     }
00302 
00303     virtual void set_apply_writes(bool apply) override
00304     {
00305       explicit_apply_writes = apply;
00306     }
00307 
00308     virtual bool should_apply_writes() const override
00309     {
00310       if (explicit_apply_writes.has_value())
00311       {
00312         return explicit_apply_writes.value();
00313       }
00314 
00315       // Default is to apply any 2xx status
00316       return status_success(response_status);
00317     }
00318 
00319     virtual std::vector<uint8_t> serialise_response() const override
00320     {
00321       auto http_response = http::Response(response_status);
00322 
00323       for (const auto& [k, v] : response_headers)
00324       {
00325         http_response.set_header(k, v);
00326       }
00327 
00328       http_response.set_body(&response_body);
00329       return http_response.build_response();
00330     }
00331   };
00332 }
00333 
00334 // https://github.com/microsoft/CCF/issues/844
00335 namespace enclave
00336 {
00337   inline std::shared_ptr<RpcContext> make_rpc_context(
00338     std::shared_ptr<enclave::SessionContext> s,
00339     const std::vector<uint8_t>& packed,
00340     const std::vector<uint8_t>& raw_bft = {})
00341   {
00342     http::SimpleRequestProcessor processor;
00343     http::RequestParser parser(processor);
00344 
00345     parser.execute(packed.data(), packed.size());
00346 
00347     if (processor.received.size() != 1)
00348     {
00349       throw std::logic_error(fmt::format(
00350         "Expected packed to contain a single complete HTTP message. Actually "
00351         "parsed {} messages",
00352         processor.received.size()));
00353     }
00354 
00355     const auto& msg = processor.received.front();
00356 
00357     return std::make_shared<http::HttpRpcContext>(
00358       0,
00359       s,
00360       msg.method,
00361       msg.path,
00362       msg.query,
00363       msg.headers,
00364       msg.body,
00365       packed,
00366       raw_bft);
00367   }
00368 
00369   inline std::shared_ptr<enclave::RpcContext> make_fwd_rpc_context(
00370     std::shared_ptr<enclave::SessionContext> s,
00371     const std::vector<uint8_t>& packed,
00372     enclave::FrameFormat frame_format,
00373     const std::vector<uint8_t>& raw_bft = {})
00374   {
00375     switch (frame_format)
00376     {
00377       case enclave::FrameFormat::http:
00378       {
00379         return make_rpc_context(s, packed, raw_bft);
00380       }
00381       case enclave::FrameFormat::ws:
00382       {
00383         http::SimpleRequestProcessor processor;
00384         ws::RequestParser parser(processor);
00385 
00386         auto next_read = ws::INITIAL_READ;
00387         size_t index = 0;
00388         while (index < packed.size())
00389         {
00390           const auto next_next =
00391             parser.consume(packed.data() + index, next_read);
00392           index += next_read;
00393           next_read = next_next;
00394         }
00395 
00396         if (processor.received.size() != 1)
00397         {
00398           throw std::logic_error(fmt::format(
00399             "Expected packed to contain a single complete WS message. Actually "
00400             "parsed {} messages",
00401             processor.received.size()));
00402         }
00403 
00404         const auto& msg = processor.received.front();
00405 
00406         return std::make_shared<ws::WsRpcContext>(
00407           0, s, msg.path, msg.body, packed, raw_bft);
00408       }
00409       default:
00410         throw std::logic_error("Unknown Frame Format");
00411     }
00412   }
00413 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_rpc_context.h...
Preprocessing /data/git/CCF/src/http/http_sig.h...
#include http_consts.h: already included! skipping...
#include http_parser.h: already included! skipping...
#include node/client_signatures.h: not found! skipping...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 12060 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 #define FMT_HEADER_ONLY
00013 
00014 
00015 
00016 
00017 namespace http
00018 {
00019   inline std::optional<std::vector<uint8_t>> construct_raw_signed_string(
00020     std::string verb,
00021     const std::string_view& path,
00022     const std::string_view& query,
00023     const http::HeaderMap& headers,
00024     const std::vector<std::string_view>& headers_to_sign)
00025   {
00026     std::string signed_string = {};
00027     std::string value = {};
00028     bool first = true;
00029 
00030     for (const auto f : headers_to_sign)
00031     {
00032       if (f == auth::SIGN_HEADER_REQUEST_TARGET)
00033       {
00034         // Store verb as lowercase
00035         nonstd::to_lower(verb);
00036         value = fmt::format("{} {}", verb, path);
00037         if (!query.empty())
00038         {
00039           value.append(fmt::format("?{}", query));
00040         }
00041       }
00042       else
00043       {
00044         const auto h = headers.find(f);
00045         if (h == headers.end())
00046         {
00047           LOG_FAIL_FMT("Signed header '{}' does not exist", f);
00048           return std::nullopt;
00049         }
00050 
00051         value = h->second;
00052       }
00053 
00054       if (!first)
00055       {
00056         signed_string.append("\n");
00057       }
00058       first = false;
00059 
00060       signed_string.append(f);
00061       signed_string.append(": ");
00062       signed_string.append(value);
00063     }
00064 
00065     auto ret =
00066       std::vector<uint8_t>({signed_string.begin(), signed_string.end()});
00067     return ret;
00068   }
00069 
00070   struct SigningDetails
00071   {
00072     std::vector<uint8_t> to_sign;
00073     std::vector<uint8_t> signature;
00074   };
00075 
00076   inline void add_digest_header(http::Request& request)
00077   {
00078     // Ensure digest is present and up-to-date
00079     tls::HashBytes body_digest;
00080     tls::do_hash(
00081       request.get_content_data(),
00082       request.get_content_length(),
00083       body_digest,
00084       MBEDTLS_MD_SHA256);
00085     request.set_header(
00086       headers::DIGEST,
00087       fmt::format(
00088         "{}={}",
00089         "SHA-256",
00090         tls::b64_from_raw(body_digest.data(), body_digest.size())));
00091   }
00092 
00093   inline void sign_request(
00094     http::Request& request,
00095     const tls::KeyPairPtr& kp,
00096     const std::vector<std::string_view>& headers_to_sign,
00097     SigningDetails* details = nullptr)
00098   {
00099     add_digest_header(request);
00100 
00101     const auto to_sign = construct_raw_signed_string(
00102       llhttp_method_name(request.get_method()),
00103       request.get_path(),
00104       request.get_formatted_query(),
00105       request.get_headers(),
00106       headers_to_sign);
00107 
00108     if (!to_sign.has_value())
00109     {
00110       throw std::logic_error("Unable to sign HTTP request");
00111     }
00112 
00113     const auto signature = kp->sign(to_sign.value());
00114 
00115     // https://github.com/microsoft/CCF/issues/2018
00116     auto auth_value = fmt::format(
00117       "Signature "
00118       "keyId=\"ignored\",algorithm=\"{}\",headers=\"{}\",signature="
00119       "\"{}\"",
00120       auth::SIGN_ALGORITHM_HS_2019,
00121       fmt::format("{}", fmt::join(headers_to_sign, " ")),
00122       tls::b64_from_raw(signature.data(), signature.size()));
00123 
00124     request.set_header(headers::AUTHORIZATION, auth_value);
00125 
00126     if (details != nullptr)
00127     {
00128       details->to_sign = to_sign.value();
00129       details->signature = signature;
00130     }
00131   }
00132 
00133   inline void sign_request(
00134     http::Request& request,
00135     const tls::KeyPairPtr& kp,
00136     SigningDetails* details = nullptr)
00137   {
00138     std::vector<std::string_view> headers_to_sign;
00139     headers_to_sign.emplace_back(auth::SIGN_HEADER_REQUEST_TARGET);
00140     headers_to_sign.emplace_back(headers::DIGEST);
00141     headers_to_sign.emplace_back(headers::CONTENT_LENGTH);
00142 
00143     sign_request(request, kp, headers_to_sign, details);
00144   }
00145 
00146   // Implements verification of "Signature" scheme from
00147   // https://tools.ietf.org/html/draft-cavage-http-signatures-12
00148   //
00149   // Notes:
00150   //    - Only supports public key crytography (i.e. no HMAC)
00151   //    - Only supports SHA-256 as request digest algorithm
00152   //    - Only supports ecdsa-sha256 and hs2019 as signature algorithms
00153   //    - keyId can be set to a SHA-256 digest of a cert against which the
00154   //    signature verifies
00155   class HttpSignatureVerifier
00156   {
00157   public:
00158     struct SignatureParams
00159     {
00160       std::string_view signature = {};
00161       std::string_view signature_algorithm = {};
00162       std::vector<std::string_view> signed_headers;
00163       std::string key_id = {};
00164     };
00165 
00166     static bool parse_auth_scheme(std::string_view& auth_header_value)
00167     {
00168       auto next_space = auth_header_value.find(" ");
00169       if (next_space == std::string::npos)
00170       {
00171         LOG_FAIL_FMT("Authorization header only contains one field");
00172         return false;
00173       }
00174       auto auth_scheme = auth_header_value.substr(0, next_space);
00175       if (auth_scheme != auth::SIGN_AUTH_SCHEME)
00176       {
00177         return false;
00178       }
00179       auth_header_value = auth_header_value.substr(next_space + 1);
00180       return true;
00181     }
00182 
00183     static bool verify_digest(
00184       const http::HeaderMap& headers,
00185       const std::vector<uint8_t>& body,
00186       std::string& error_reason)
00187     {
00188       // First, retrieve digest from header
00189       auto digest = headers.find(headers::DIGEST);
00190       if (digest == headers.end())
00191       {
00192         error_reason = fmt::format("Missing {} header", headers::DIGEST);
00193         return false;
00194       }
00195 
00196       auto equal_pos = digest->second.find("=");
00197       if (equal_pos == std::string::npos)
00198       {
00199         error_reason =
00200           fmt::format("{} header does not contain key=value", headers::DIGEST);
00201         return false;
00202       }
00203 
00204       auto sha_key = digest->second.substr(0, equal_pos);
00205       if (sha_key != auth::DIGEST_SHA256)
00206       {
00207         error_reason = fmt::format(
00208           "Only {} for request digest is supported", auth::DIGEST_SHA256);
00209         return false;
00210       }
00211 
00212       auto raw_digest = tls::raw_from_b64(digest->second.substr(equal_pos + 1));
00213 
00214       // Then, hash the request body
00215       tls::HashBytes body_digest;
00216       tls::do_hash(body.data(), body.size(), body_digest, MBEDTLS_MD_SHA256);
00217 
00218       if (raw_digest != body_digest)
00219       {
00220         error_reason = fmt::format(
00221           "Request body does not match {} header, calculated body "
00222           "digest = {:02x}",
00223           headers::DIGEST,
00224           fmt::join(body_digest, ""));
00225         return false;
00226       }
00227 
00228       return true;
00229     }
00230 
00231     // Parses a delimited string with no delimiter at the end
00232     // (e.g. "foo,bar,baz") and returns a vector parsed string views (e.g.
00233     // ["foo", "bar", "baz"])
00234     static std::vector<std::string_view> parse_delimited_string(
00235       std::string_view& s, const std::string& delimiter)
00236     {
00237       std::vector<std::string_view> strings;
00238       bool last_string = false;
00239 
00240       auto next_delimiter = s.find(delimiter);
00241       while (next_delimiter != std::string::npos || !last_string)
00242       {
00243         auto token = s.substr(0, next_delimiter);
00244         if (next_delimiter == std::string::npos)
00245         {
00246           last_string = true;
00247         }
00248 
00249         strings.emplace_back(token);
00250 
00251         if (!last_string)
00252         {
00253           s = s.substr(next_delimiter + 1);
00254           next_delimiter = s.find(delimiter);
00255         }
00256       }
00257 
00258       return strings;
00259     }
00260 
00261     static std::optional<SignatureParams> parse_signature_params(
00262       std::string_view& auth_header_value)
00263     {
00264       SignatureParams sig_params = {};
00265 
00266       auto parsed_params =
00267         parse_delimited_string(auth_header_value, auth::SIGN_PARAMS_DELIMITER);
00268 
00269       for (auto& p : parsed_params)
00270       {
00271         auto eq_pos = p.find("=");
00272         if (eq_pos != std::string::npos)
00273         {
00274           auto k = p.substr(0, eq_pos);
00275           auto v = p.substr(eq_pos + 1);
00276 
00277           // Remove quotes around value, if present
00278           const bool begins_with_quote = v.front() == '"';
00279           const bool ends_with_quote = v.back() == '"';
00280           if (v.size() >= 2 && (begins_with_quote || ends_with_quote))
00281           {
00282             if (!(begins_with_quote && ends_with_quote))
00283             {
00284               LOG_FAIL_FMT("Unbalanced quotes in Authorization header: {}", p);
00285               return std::nullopt;
00286             }
00287 
00288             v = v.substr(1, v.size() - 2);
00289           }
00290 
00291           if (k == auth::SIGN_PARAMS_KEYID)
00292           {
00293             sig_params.key_id = v;
00294           }
00295           else if (k == auth::SIGN_PARAMS_ALGORITHM)
00296           {
00297             sig_params.signature_algorithm = v;
00298             if (
00299               v != auth::SIGN_ALGORITHM_ECDSA_SHA256 &&
00300               v != auth::SIGN_ALGORITHM_HS_2019)
00301             {
00302               LOG_FAIL_FMT("Signature algorithm {} is not supported", v);
00303               return std::nullopt;
00304             }
00305           }
00306           else if (k == auth::SIGN_PARAMS_SIGNATURE)
00307           {
00308             sig_params.signature = v;
00309           }
00310           else if (k == auth::SIGN_PARAMS_HEADERS)
00311           {
00312             auto parsed_signed_headers =
00313               parse_delimited_string(v, auth::SIGN_PARAMS_HEADERS_DELIMITER);
00314 
00315             if (parsed_signed_headers.size() == 0)
00316             {
00317               LOG_FAIL_FMT(
00318                 "No headers specified in {} field", auth::SIGN_PARAMS_HEADERS);
00319               return std::nullopt;
00320             }
00321 
00322             for (const auto& h : parsed_signed_headers)
00323             {
00324               sig_params.signed_headers.emplace_back(h);
00325             }
00326           }
00327         }
00328         else
00329         {
00330           LOG_FAIL_FMT("Authorization parameter {} does not contain \"=\"", p);
00331           return std::nullopt;
00332         }
00333       }
00334 
00335       return sig_params;
00336     }
00337 
00338     static std::optional<ccf::SignedReq> parse(
00339       const std::string& verb,
00340       const std::string_view& path,
00341       const std::string_view& query,
00342       const http::HeaderMap& headers,
00343       const std::vector<uint8_t>& body)
00344     {
00345       auto auth = headers.find(headers::AUTHORIZATION);
00346       if (auth != headers.end())
00347       {
00348         std::string_view authz_header = auth->second;
00349 
00350         if (!parse_auth_scheme(authz_header))
00351         {
00352           // The request does not have the correct authorization scheme
00353           return std::nullopt;
00354         }
00355 
00356         std::string verify_error_reason;
00357         if (!verify_digest(headers, body, verify_error_reason))
00358         {
00359           throw std::logic_error(fmt::format(
00360             "Error verifying HTTP {} header: {}",
00361             headers::DIGEST,
00362             verify_error_reason));
00363         }
00364 
00365         auto parsed_sign_params = parse_signature_params(authz_header);
00366         if (!parsed_sign_params.has_value())
00367         {
00368           throw std::logic_error(
00369             fmt::format("Error parsing {} fields", headers::AUTHORIZATION));
00370         }
00371 
00372         const auto& signed_headers = parsed_sign_params->signed_headers;
00373         std::vector<std::string> missing_required_headers;
00374         for (const auto& required_header : http::required_signature_headers)
00375         {
00376           const auto it = std::find(
00377             signed_headers.begin(), signed_headers.end(), required_header);
00378           if (it == signed_headers.end())
00379           {
00380             missing_required_headers.push_back(required_header);
00381           }
00382         }
00383 
00384         if (!missing_required_headers.empty())
00385         {
00386           throw std::logic_error(fmt::format(
00387             "HTTP signature does not cover required fields: {}",
00388             fmt::join(missing_required_headers, ", ")));
00389         }
00390 
00391         auto signed_raw = construct_raw_signed_string(
00392           verb, path, query, headers, signed_headers);
00393         if (!signed_raw.has_value())
00394         {
00395           throw std::logic_error(
00396             fmt::format("Error constructing signed string"));
00397         }
00398 
00399         auto sig_raw = tls::raw_from_b64(parsed_sign_params->signature);
00400 
00401         mbedtls_md_type_t signature_digest = MBEDTLS_MD_NONE;
00402         if (
00403           parsed_sign_params->signature_algorithm ==
00404           auth::SIGN_ALGORITHM_ECDSA_SHA256)
00405         {
00406           signature_digest = MBEDTLS_MD_SHA256;
00407         }
00408 
00409         ccf::SignedReq ret = {sig_raw,
00410                               signed_raw.value(),
00411                               body,
00412                               signature_digest,
00413                               parsed_sign_params->key_id};
00414         return ret;
00415       }
00416 
00417       // The request does not contain the Authorization header
00418       return std::nullopt;
00419     }
00420   };
00421 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/http_sig.h...
Preprocessing /data/git/CCF/src/http/http_status.h...
Preprocessor output (size: 486 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 /* Status Codes */
00006 #define HTTP_STATUS_MAP(XX) 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 
00065 
00066 
00067 enum http_status
00068 {
00069 #define XX(num, name, string) 
00070 
00071 
00072 };
00073 
00074 /* Returns a string version of the HTTP status code. */
00075 static inline const char* http_status_str(enum http_status s)
00076 {
00077   switch (s)
00078   {
00079 #define XX(num, name, string) 
00080 
00081 
00082 
00083 
00084     default:
00085       return "<unknown>";
00086   }
00087 }
00088 
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX 
---------
Parsing file /data/git/CCF/src/http/http_status.h...
Preprocessing /data/git/CCF/src/http/test/http_test.cpp...
#include ../http_builder.h: already included! skipping...
#include ../http_parser.h: already included! skipping...
#include ../http_sig.h: already included! skipping...
#include tls/key_pair.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include queue: not found! skipping...
#include string: not found! skipping...
#include fmt/format.h: not found! skipping...
Preprocessor output (size: 17061 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 #define DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 #define FMT_HEADER_ONLY
00014 
00015 
00016 constexpr auto request_0 = "{\"a_json_key\": \"a_json_value\"}";
00017 constexpr auto request_1 = "{\"another_json_key\": \"another_json_value\"}";
00018 
00019 std::vector<uint8_t> s_to_v(char const* s)
00020 {
00021   const auto d = (const uint8_t*)s;
00022   return std::vector<uint8_t>(d, d + strlen(s));
00023 }
00024 
00025 std::string to_lowercase(std::string s)
00026 {
00027   nonstd::to_lower(s);
00028   return s;
00029 }
00030 
00031 DOCTEST_TEST_CASE("Complete request")
00032 {
00033   for (const auto method : {HTTP_POST, HTTP_GET, HTTP_DELETE})
00034   {
00035     const std::vector<uint8_t> r = {0, 1, 2, 3};
00036     constexpr auto url = "/some/path/to/a/resource";
00037 
00038     http::SimpleRequestProcessor sp;
00039     http::RequestParser p(sp);
00040 
00041     auto request = http::Request(url, method);
00042     request.set_body(&r);
00043     auto req = request.build_request();
00044     p.execute(req.data(), req.size());
00045 
00046     DOCTEST_CHECK(!sp.received.empty());
00047     const auto& m = sp.received.front();
00048     DOCTEST_CHECK(m.method == method);
00049     DOCTEST_CHECK(m.path == url);
00050     DOCTEST_CHECK(m.body == r);
00051   }
00052 }
00053 
00054 DOCTEST_TEST_CASE("Complete response")
00055 {
00056   for (const auto status : {HTTP_STATUS_OK,
00057                             HTTP_STATUS_BAD_REQUEST,
00058                             HTTP_STATUS_INTERNAL_SERVER_ERROR})
00059   {
00060     const std::vector<uint8_t> r = {0, 1, 2, 3};
00061 
00062     http::SimpleResponseProcessor sp;
00063     http::ResponseParser p(sp);
00064 
00065     auto response = http::Response(status);
00066     response.set_body(&r);
00067     auto res = response.build_response();
00068     p.execute(res.data(), res.size());
00069 
00070     DOCTEST_CHECK(!sp.received.empty());
00071     const auto& m = sp.received.front();
00072     DOCTEST_CHECK(m.status == status);
00073     DOCTEST_CHECK(m.body == r);
00074   }
00075 }
00076 
00077 DOCTEST_TEST_CASE("Parsing error")
00078 {
00079   std::vector<uint8_t> r;
00080 
00081   http::SimpleRequestProcessor sp;
00082   http::RequestParser p(sp);
00083 
00084   auto req = http::build_post_request(r);
00085   req[6] = '\n';
00086 
00087   bool threw_with = false;
00088   try
00089   {
00090     p.execute(req.data(), req.size());
00091   }
00092   catch (std::exception& e)
00093   {
00094     threw_with = strstr(e.what(), "HPE_INVALID_HEADER_TOKEN") != nullptr;
00095   }
00096 
00097   DOCTEST_CHECK(threw_with);
00098   DOCTEST_CHECK(sp.received.empty());
00099 }
00100 
00101 DOCTEST_TEST_CASE("Partial request")
00102 {
00103   http::SimpleRequestProcessor sp;
00104   http::RequestParser p(sp);
00105 
00106   const auto r0 = s_to_v(request_0);
00107   auto req = http::build_post_request(r0);
00108   size_t offset = 10;
00109 
00110   p.execute(req.data(), req.size() - offset);
00111   p.execute(req.data() + req.size() - offset, offset);
00112 
00113   DOCTEST_CHECK(!sp.received.empty());
00114   const auto& m = sp.received.front();
00115   DOCTEST_CHECK(m.method == HTTP_POST);
00116   DOCTEST_CHECK(m.body == r0);
00117 }
00118 
00119 DOCTEST_TEST_CASE("Partial body")
00120 {
00121   http::SimpleRequestProcessor sp;
00122   http::RequestParser p(sp);
00123 
00124   const auto r0 = s_to_v(request_0);
00125   auto req = http::build_post_request(r0);
00126   size_t offset = http::build_post_header(r0).size() + r0.size() / 3;
00127 
00128   p.execute(req.data(), req.size() - offset);
00129   p.execute(req.data() + req.size() - offset, offset);
00130 
00131   DOCTEST_CHECK(!sp.received.empty());
00132   const auto& m = sp.received.front();
00133   DOCTEST_CHECK(m.method == HTTP_POST);
00134   DOCTEST_CHECK(m.body == r0);
00135 }
00136 
00137 DOCTEST_TEST_CASE("Multiple requests")
00138 {
00139   http::SimpleRequestProcessor sp;
00140   http::RequestParser p(sp);
00141 
00142   const auto r0 = s_to_v(request_0);
00143   auto req = http::build_post_request(r0);
00144   const auto r1 = s_to_v(request_1);
00145   auto req1 = http::build_post_request(r1);
00146   std::copy(req1.begin(), req1.end(), std::back_inserter(req));
00147 
00148   DOCTEST_SUBCASE("All at once")
00149   {
00150     p.execute(req.data(), req.size());
00151   }
00152 
00153   DOCTEST_SUBCASE("In chunks")
00154   {
00155     constexpr auto chunks = 7;
00156     const auto chunk_size = req.size() / chunks;
00157     auto remaining = req.size();
00158     auto next_data = req.data();
00159 
00160     while (remaining > 0)
00161     {
00162       const auto next = std::min(remaining, chunk_size);
00163       p.execute(next_data, next);
00164       next_data += next;
00165       remaining -= next;
00166     }
00167   }
00168 
00169   DOCTEST_SUBCASE("Byte-by-byte")
00170   {
00171     constexpr size_t next = 1;
00172     for (size_t i = 0; i < req.size(); ++i)
00173     {
00174       p.execute(req.data() + i, next);
00175     }
00176   }
00177 
00178   {
00179     DOCTEST_CHECK(!sp.received.empty());
00180     const auto& m = sp.received.front();
00181     DOCTEST_CHECK(m.method == HTTP_POST);
00182     DOCTEST_CHECK(m.body == r0);
00183   }
00184 
00185   sp.received.pop();
00186 
00187   {
00188     DOCTEST_CHECK(!sp.received.empty());
00189     const auto& m = sp.received.front();
00190     DOCTEST_CHECK(m.method == HTTP_POST);
00191     DOCTEST_CHECK(m.body == r1);
00192   }
00193 }
00194 
00195 DOCTEST_TEST_CASE("Method parsing")
00196 {
00197   http::SimpleRequestProcessor sp;
00198   http::RequestParser p(sp);
00199 
00200   bool choice = false;
00201   for (const auto method : {HTTP_DELETE, HTTP_GET, HTTP_POST, HTTP_PUT})
00202   {
00203     const auto r = s_to_v(choice ? request_0 : request_1);
00204     auto req = http::build_request(method, r);
00205     p.execute(req.data(), req.size());
00206 
00207     DOCTEST_CHECK(!sp.received.empty());
00208     const auto& m = sp.received.front();
00209     DOCTEST_CHECK(m.method == method);
00210     DOCTEST_CHECK(m.body == r);
00211 
00212     sp.received.pop();
00213     choice = !choice;
00214   }
00215 }
00216 
00217 DOCTEST_TEST_CASE("URL parsing")
00218 {
00219   http::SimpleRequestProcessor sp;
00220   http::RequestParser p(sp);
00221 
00222   const auto path = "/foo/123";
00223 
00224   http::Request r(path);
00225   r.set_query_param("balance", "42");
00226   r.set_query_param("id", "100");
00227 
00228   const auto body = s_to_v(request_0);
00229   r.set_body(&body);
00230   auto req = r.build_request();
00231 
00232   p.execute(req.data(), req.size());
00233 
00234   DOCTEST_CHECK(!sp.received.empty());
00235   const auto& m = sp.received.front();
00236   DOCTEST_CHECK(m.method == HTTP_POST);
00237   DOCTEST_CHECK(m.body == body);
00238   DOCTEST_CHECK(m.path == path);
00239   DOCTEST_CHECK(m.query.find("balance=42") != std::string::npos);
00240   DOCTEST_CHECK(m.query.find("id=100") != std::string::npos);
00241   DOCTEST_CHECK(m.query.find("&") != std::string::npos);
00242 }
00243 
00244 DOCTEST_TEST_CASE("Pessimal transport")
00245 {
00246   logger::config::level() = logger::INFO;
00247 
00248   const http::HeaderMap h1 = {{"foo", "bar"}, {"baz", "42"}};
00249   const http::HeaderMap h2 = {{"foo", "barbar"},
00250                               {"content-type", "application/json"},
00251                               {"x-custom-header", "custom user data"},
00252                               {"x-MixedCASE", "DontCARE"}};
00253 
00254   http::SimpleRequestProcessor sp;
00255   http::RequestParser p(sp);
00256 
00257   // Use the same processor and test repeatedly to make sure headers are for
00258   // only the current request
00259   for (const auto& headers : {{}, h1, h2, h1, h2, h2, h1})
00260   {
00261     auto builder =
00262       http::Request("/path/which/will/be/spliced/during/transport", HTTP_POST);
00263     for (const auto& it : headers)
00264     {
00265       builder.set_header(it.first, it.second);
00266     }
00267 
00268     const auto r0 = s_to_v(request_0);
00269     builder.set_body(&r0);
00270     auto req = builder.build_request();
00271 
00272     size_t done = 0;
00273     while (done < req.size())
00274     {
00275       // Simulate dreadful transport - send 1 byte at a time
00276       size_t next = 1;
00277       next = std::min(next, req.size() - done);
00278       p.execute(req.data() + done, next);
00279       done += next;
00280     }
00281 
00282     DOCTEST_CHECK(!sp.received.empty());
00283     const auto& m = sp.received.front();
00284     DOCTEST_CHECK(m.method == HTTP_POST);
00285     DOCTEST_CHECK(m.body == r0);
00286 
00287     // Check each specified header is present and matches. May include other
00288     // auto-inserted headers - these are ignored
00289     for (const auto& it : headers)
00290     {
00291       const auto found = m.headers.find(to_lowercase(it.first));
00292       DOCTEST_CHECK(found != m.headers.end());
00293       DOCTEST_CHECK(found->second == it.second);
00294     }
00295 
00296     sp.received.pop();
00297   }
00298 }
00299 
00300 DOCTEST_TEST_CASE("Escaping")
00301 {
00302   {
00303     const std::string unescaped =
00304       "This has many@many+many \\% \" AWKWARD :;-=?!& ++ characters %20%20";
00305     const std::string escaped =
00306       "This+has+many%40many%2Bmany+%5C%25+%22+AWKWARD+%3A%3B-%3D%3F%21%26+%2B%"
00307       "2b+"
00308       "characters+%2520%2520";
00309 
00310     std::string s = http::url_decode(escaped);
00311     DOCTEST_REQUIRE(s == unescaped);
00312   }
00313 
00314   {
00315     const std::string request =
00316       "GET "
00317       "/foo/"
00318       "bar?this=that&awkward=escaped+string+%3A%3B-%3D%3F%21%22%25%23#"
00319       "AndThisFragment+%3A%3B-%3D%3F%21%22%25%23 "
00320       "HTTP/1.1\r\n\r\n";
00321 
00322     http::SimpleRequestProcessor sp;
00323     http::RequestParser p(sp);
00324 
00325     const std::vector<uint8_t> req(request.begin(), request.end());
00326     p.execute(req.data(), req.size());
00327 
00328     DOCTEST_CHECK(!sp.received.empty());
00329     const auto& m = sp.received.front();
00330     DOCTEST_CHECK(m.method == HTTP_GET);
00331     DOCTEST_CHECK(m.path == "/foo/bar");
00332     DOCTEST_CHECK(m.query == "this=that&awkward=escaped string :;-=?!\"%#");
00333     DOCTEST_CHECK(m.fragment == "AndThisFragment :;-=?!\"%#");
00334   }
00335 
00336   {
00337     const std::string request =
00338       "GET "
00339       "/hello%20world?hello%20world=hello%20world&saluton%20mondo=saluton%"
00340       "20mondo HTTP/1.1\r\n\r\n";
00341 
00342     http::SimpleRequestProcessor sp;
00343     http::RequestParser p(sp);
00344 
00345     const std::vector<uint8_t> req(request.begin(), request.end());
00346     p.execute(req.data(), req.size());
00347 
00348     DOCTEST_CHECK(!sp.received.empty());
00349     const auto& m = sp.received.front();
00350     DOCTEST_CHECK(m.method == HTTP_GET);
00351     DOCTEST_CHECK(m.path == "/hello%20world");
00352     DOCTEST_CHECK(
00353       m.query == "hello world=hello world&saluton mondo=saluton mondo");
00354   }
00355 }
00356 
00357 DOCTEST_TEST_CASE("URL parser")
00358 {
00359   // Test cases taken from https://tools.ietf.org/html/rfc3986
00360   {
00361     constexpr auto url_s = "http://www.ietf.org/rfc/rfc2396.txt";
00362     const auto url = http::parse_url_full(url_s);
00363     DOCTEST_CHECK(url.scheme == "http");
00364     DOCTEST_CHECK(url.host == "www.ietf.org");
00365     DOCTEST_CHECK(url.port.empty());
00366     DOCTEST_CHECK(url.path == "/rfc/rfc2396.txt");
00367     DOCTEST_CHECK(url.query.empty());
00368     DOCTEST_CHECK(url.fragment.empty());
00369   }
00370 
00371   {
00372     constexpr auto url_s = "ftp://ftp.is.co.za/rfc/rfc1808.txt";
00373     const auto url = http::parse_url_full(url_s);
00374     DOCTEST_CHECK(url.scheme == "ftp");
00375     DOCTEST_CHECK(url.host == "ftp.is.co.za");
00376     DOCTEST_CHECK(url.port.empty());
00377     DOCTEST_CHECK(url.path == "/rfc/rfc1808.txt");
00378     DOCTEST_CHECK(url.query.empty());
00379     DOCTEST_CHECK(url.fragment.empty());
00380   }
00381 
00382   {
00383     constexpr auto url_s = "foo://example.com";
00384     const auto url = http::parse_url_full(url_s);
00385     DOCTEST_CHECK(url.scheme == "foo");
00386     DOCTEST_CHECK(url.host == "example.com");
00387     DOCTEST_CHECK(url.port.empty());
00388     DOCTEST_CHECK(url.path.empty());
00389     DOCTEST_CHECK(url.query.empty());
00390     DOCTEST_CHECK(url.fragment.empty());
00391   }
00392 
00393   {
00394     constexpr auto url_s = "foo://example.com:8042/over/there?name=ferret#nose";
00395     const auto url = http::parse_url_full(url_s);
00396     DOCTEST_CHECK(url.scheme == "foo");
00397     DOCTEST_CHECK(url.host == "example.com");
00398     DOCTEST_CHECK(url.port == "8042");
00399     DOCTEST_CHECK(url.path == "/over/there");
00400     DOCTEST_CHECK(url.query == "name=ferret");
00401     DOCTEST_CHECK(url.fragment == "nose");
00402   }
00403 
00404   {
00405     constexpr auto url_s =
00406       "https://[2001:0db8:0000:0000:0000::1428:57ab]:8042/over/there#nose";
00407     const auto url = http::parse_url_full(url_s);
00408     DOCTEST_CHECK(url.scheme == "https");
00409     DOCTEST_CHECK(url.host == "[2001:0db8:0000:0000:0000::1428:57ab]");
00410     DOCTEST_CHECK(url.port == "8042");
00411     DOCTEST_CHECK(url.path == "/over/there");
00412     DOCTEST_CHECK(url.query.empty());
00413     DOCTEST_CHECK(url.fragment == "nose");
00414   }
00415 
00416   {
00417     constexpr auto url_s = "http://[::ffff:0c22:384e]/";
00418     const auto url = http::parse_url_full(url_s);
00419     DOCTEST_CHECK(url.scheme == "http");
00420     DOCTEST_CHECK(url.host == "[::ffff:0c22:384e]");
00421     DOCTEST_CHECK(url.port.empty());
00422     DOCTEST_CHECK(url.path == "/");
00423     DOCTEST_CHECK(url.query.empty());
00424     DOCTEST_CHECK(url.fragment.empty());
00425   }
00426 }
00427 
00428 struct SignedRequestProcessor : public http::SimpleRequestProcessor
00429 {
00430   std::queue<ccf::SignedReq> signed_reqs;
00431 
00432   virtual void handle_request(
00433     llhttp_method method,
00434     const std::string_view& path,
00435     const std::string& query,
00436     const std::string& fragment,
00437     http::HeaderMap&& headers,
00438     std::vector<uint8_t>&& body) override
00439   {
00440     const auto signed_req = http::HttpSignatureVerifier::parse(
00441       llhttp_method_name(method), path, query, headers, body);
00442     DOCTEST_REQUIRE(signed_req.has_value());
00443 
00444     signed_reqs.push(signed_req.value());
00445 
00446     http::SimpleRequestProcessor::handle_request(
00447       method, path, query, fragment, std::move(headers), std::move(body));
00448   }
00449 };
00450 
00451 DOCTEST_TEST_CASE("Signatures")
00452 {
00453   // Produce signed requests with some formatting variations, ensure we can
00454   // parse them
00455   auto kp = tls::make_key_pair();
00456 
00457   http::Request request("/foo", HTTP_POST);
00458   request.set_query_param("param", "value");
00459   request.set_query_param("pet", "dog");
00460   request.set_header("Host", "example.com");
00461   request.set_header("Date", "Sun, 05 Jan 2014 21:31:40 GMT");
00462   request.set_header("Content-Type", "application/json");
00463 
00464   const std::string body_s("{\"hello\": \"world\"}");
00465   const std::vector<uint8_t> body_v(body_s.begin(), body_s.end());
00466 
00467   request.set_body(body_v.data(), body_v.size());
00468 
00469   http::add_digest_header(request);
00470 
00471   {
00472     const auto& headers = request.get_headers();
00473     const auto it = headers.find(http::headers::DIGEST);
00474     DOCTEST_REQUIRE(it != headers.end());
00475 
00476     constexpr auto expected_digest_value =
00477       "SHA-256=X48E9qOokqqrvdts8nOJRJN3OWDUoyWxBf7kbu9DBPE=";
00478     DOCTEST_REQUIRE(it->second == expected_digest_value);
00479   }
00480 
00481   DOCTEST_SUBCASE("Some headers")
00482   {
00483     std::vector<std::string_view> headers_to_sign;
00484     headers_to_sign.emplace_back(http::auth::SIGN_HEADER_REQUEST_TARGET);
00485     headers_to_sign.emplace_back(http::headers::DIGEST);
00486 
00487     http::sign_request(request, kp, headers_to_sign);
00488 
00489     const auto serial_request = request.build_request();
00490 
00491     SignedRequestProcessor sp;
00492     http::RequestParser p(sp);
00493 
00494     p.execute(serial_request.data(), serial_request.size());
00495     DOCTEST_REQUIRE(!sp.signed_reqs.empty());
00496   }
00497 
00498   DOCTEST_SUBCASE("All headers")
00499   {
00500     std::vector<std::string_view> headers_to_sign;
00501     headers_to_sign.emplace_back(http::auth::SIGN_HEADER_REQUEST_TARGET);
00502     for (const auto& header_it : request.get_headers())
00503     {
00504       headers_to_sign.emplace_back(header_it.first);
00505     }
00506 
00507     // Try all permutations to test order-independence
00508     std::sort(headers_to_sign.begin(), headers_to_sign.end());
00509     while (true)
00510     {
00511       http::sign_request(request, kp, headers_to_sign);
00512 
00513       const auto serial_request = request.build_request();
00514 
00515       SignedRequestProcessor sp;
00516       http::RequestParser p(sp);
00517 
00518       p.execute(serial_request.data(), serial_request.size());
00519       DOCTEST_REQUIRE(sp.signed_reqs.size() == 1);
00520 
00521       sp.signed_reqs.pop();
00522 
00523       const bool was_last_permutation =
00524         !std::next_permutation(headers_to_sign.begin(), headers_to_sign.end());
00525       if (was_last_permutation)
00526       {
00527         break;
00528       }
00529     }
00530   }
00531 
00532   DOCTEST_SUBCASE("Unquoted auth values")
00533   {
00534     std::vector<std::string_view> headers_to_sign;
00535     headers_to_sign.emplace_back(http::auth::SIGN_HEADER_REQUEST_TARGET);
00536     for (const auto& header_it : request.get_headers())
00537     {
00538       headers_to_sign.emplace_back(header_it.first);
00539     }
00540 
00541     http::sign_request(request, kp, headers_to_sign);
00542 
00543     const auto& headers = request.get_headers();
00544     const auto auth_it = headers.find(http::headers::AUTHORIZATION);
00545     DOCTEST_REQUIRE(auth_it != headers.end());
00546 
00547     DOCTEST_SUBCASE("Unbalanced quotes")
00548     {
00549       std::string original = auth_it->second;
00550 
00551       std::string missing_first_quote = original;
00552       const auto first_quote = missing_first_quote.find_first_of('"');
00553       missing_first_quote.erase(missing_first_quote.begin() + first_quote);
00554 
00555       {
00556         request.set_header(http::headers::AUTHORIZATION, missing_first_quote);
00557         const auto serial_request = request.build_request();
00558 
00559         SignedRequestProcessor sp;
00560         http::RequestParser p(sp);
00561         DOCTEST_REQUIRE_THROWS(
00562           p.execute(serial_request.data(), serial_request.size()));
00563       }
00564 
00565       std::string missing_second_quote = original;
00566       const auto second_quote =
00567         missing_second_quote.find_first_of('"', first_quote + 1);
00568       missing_second_quote.erase(missing_second_quote.begin() + second_quote);
00569 
00570       {
00571         request.set_header(http::headers::AUTHORIZATION, missing_second_quote);
00572         const auto serial_request = request.build_request();
00573 
00574         SignedRequestProcessor sp;
00575         http::RequestParser p(sp);
00576         DOCTEST_REQUIRE_THROWS(
00577           p.execute(serial_request.data(), serial_request.size()));
00578       }
00579     }
00580 
00581     DOCTEST_SUBCASE("No quotes")
00582     {
00583       std::string auth_value = auth_it->second;
00584       const auto new_end =
00585         std::remove(auth_value.begin(), auth_value.end(), '"');
00586       auth_value.erase(new_end, auth_value.end());
00587 
00588       request.set_header(http::headers::AUTHORIZATION, auth_value);
00589 
00590       const auto serial_request = request.build_request();
00591 
00592       SignedRequestProcessor sp;
00593       http::RequestParser p(sp);
00594       p.execute(serial_request.data(), serial_request.size());
00595       DOCTEST_REQUIRE(sp.signed_reqs.size() == 1);
00596     }
00597   }
00598 }
00599 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN HTTP_STATUS_MAP XX FMT_HEADER_ONLY DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES 
---------
Parsing file /data/git/CCF/src/http/test/http_test.cpp...
Preprocessing /data/git/CCF/src/http/ws_builder.h...
#include ../ds/serialized.h: already included! skipping...
#include ../kv/kv_types.h: already included! skipping...
#include ws_parser.h: already included! skipping...
#include arpa/inet.h: not found! skipping...
Preprocessor output (size: 2110 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ws
00012 {
00013   static std::vector<uint8_t> make_frame(size_t frame_size)
00014   {
00015     size_t sz_size = 0;
00016     if (frame_size > 125)
00017     {
00018       sz_size = frame_size > std::numeric_limits<uint16_t>::max() ? 8 : 2;
00019     }
00020 
00021     size_t ws_h_size = ws::INITIAL_READ + sz_size;
00022     std::vector<uint8_t> msg(ws_h_size + frame_size);
00023     msg[0] = 0x82;
00024     switch (sz_size)
00025     {
00026       case 0:
00027       {
00028         msg[1] = frame_size;
00029         break;
00030       }
00031       case 2:
00032       {
00033         msg[1] = 0x7e;
00034         *((uint16_t*)&msg[2]) = htons(frame_size);
00035         break;
00036       }
00037       case 8:
00038       {
00039         msg[1] = 0x7f;
00040         *((uint64_t*)&msg[2]) = htobe64(frame_size);
00041         break;
00042       }
00043       default:
00044         throw std::logic_error(fmt::format("Invalid sz_size: {}", sz_size));
00045     }
00046 
00047     return msg;
00048   };
00049 
00050   static std::vector<uint8_t> make_in_frame(
00051     const std::string& path, const std::vector<uint8_t>& body)
00052   {
00053     size_t in_frame_size = ws::in_header_size(path) + body.size();
00054     auto frame = make_frame(in_frame_size);
00055     size_t ws_h_size = frame.size() - in_frame_size;
00056 
00057     uint8_t* p = frame.data() + ws_h_size;
00058     size_t s = frame.size() - ws_h_size;
00059     serialized::write_lps(p, s, path);
00060     assert(s == body.size());
00061     ::memcpy(p, body.data(), s);
00062     return frame;
00063   }
00064 
00065   static std::vector<uint8_t> make_out_frame(
00066     size_t code,
00067     kv::Version seqno,
00068     kv::Consensus::View view,
00069     kv::Version global_commit,
00070     const std::vector<uint8_t>& body)
00071   {
00072     size_t out_frame_size = ws::OUT_CCF_HEADER_SIZE + body.size();
00073     auto frame = make_frame(out_frame_size);
00074     size_t ws_h_size = frame.size() - out_frame_size;
00075 
00076     uint8_t* p = frame.data() + ws_h_size;
00077     size_t s = frame.size() - ws_h_size;
00078     serialized::write<uint16_t>(p, s, code);
00079     serialized::write<size_t>(p, s, seqno);
00080     serialized::write<size_t>(p, s, view);
00081     serialized::write<size_t>(p, s, global_commit);
00082     assert(s == body.size());
00083     ::memcpy(p, body.data(), s);
00084     return frame;
00085   }
00086 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/ws_builder.h...
Preprocessing /data/git/CCF/src/http/ws_consts.h...
#include cstddef: not found! skipping...
Preprocessor output (size: 394 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace ws
00008 {
00009   static constexpr size_t INITIAL_READ = 2;
00010   static constexpr size_t OUT_CCF_HEADER_SIZE =
00011     sizeof(uint16_t) /* return code */ + sizeof(size_t) /* seqno */ +
00012     sizeof(size_t) /* view */ + sizeof(size_t) /* global_commit */;
00013 
00014   enum Verb
00015   {
00016     WEBSOCKET = -1
00017   };
00018 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/http/ws_consts.h...
Preprocessing /data/git/CCF/src/http/ws_parser.h...
#include enclave/tls_endpoint.h: not found! skipping...
#include http_proc.h: already included! skipping...
#include ws_consts.h: already included! skipping...
#include algorithm: not found! skipping...
#include cctype: not found! skipping...
#include endian.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 5363 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ws
00015 {
00016   static size_t in_header_size(const std::string& path)
00017   {
00018     return sizeof(uint16_t) + path.size();
00019   };
00020 
00021   enum ParserState
00022   {
00023     INIT,
00024     READ_SLEN,
00025     READ_LLEN,
00026     READ_BODY
00027   };
00028 
00029   class Parser
00030   {
00031   public:
00032     virtual size_t consume(const uint8_t*, size_t) = 0;
00033   };
00034 
00035   class ResponseParser : public Parser
00036   {
00037   private:
00038     http::ResponseProcessor& proc;
00039     uint64_t size = 0;
00040     ParserState state = INIT;
00041 
00042   public:
00043     ResponseParser(http::ResponseProcessor& proc_) : proc(proc_) {}
00044 
00045     size_t consume(const uint8_t* data, size_t s) override
00046     {
00047       switch (state)
00048       {
00049         case INIT:
00050         {
00051           assert(s == INITIAL_READ);
00052 
00053           bool fin = data[0] & 0x80;
00054           if (!fin)
00055           {
00056             LOG_FAIL_FMT("Fragment messages aren't supported.");
00057             return 0;
00058           }
00059           else
00060           {
00061             if (data[0] == 0x82)
00062             {
00063               if (data[1] & 0x80)
00064               {
00065                 LOG_FAIL_FMT("Masked messages aren't supported.");
00066                 return 0;
00067               }
00068               size = data[1] & 0x7f;
00069               switch (size)
00070               {
00071                 case 0x7f:
00072                 {
00073                   state = READ_LLEN;
00074                   return 8;
00075                 }
00076                 case 0x7e:
00077                 {
00078                   state = READ_SLEN;
00079                   return 2;
00080                 }
00081                 default:
00082                 {
00083                   state = READ_BODY;
00084                   return size;
00085                 }
00086               }
00087             }
00088             else
00089             {
00090               LOG_FAIL_FMT("Only binary messages are supported.");
00091               return 0;
00092             }
00093           }
00094         }
00095         case READ_SLEN:
00096         {
00097           assert(s == 2);
00098 
00099           size = be16toh(*(uint16_t*)data);
00100           state = READ_BODY;
00101           return size;
00102         }
00103         case READ_LLEN:
00104         {
00105           assert(s == 8);
00106 
00107           size = be64toh(*(uint64_t*)data);
00108           state = READ_BODY;
00109           return size;
00110         }
00111         case READ_BODY:
00112         {
00113           assert(s == size);
00114 
00115           auto status = serialized::read<uint16_t>(data, s);
00116           auto seqno = serialized::read<size_t>(data, s);
00117           auto view = serialized::read<size_t>(data, s);
00118           auto global_commit = serialized::read<size_t>(data, s);
00119 
00120           std::vector<uint8_t> body(data, data + s);
00121 
00122           proc.handle_response(
00123             (http_status)status,
00124             {{http::headers::CCF_TX_SEQNO, fmt::format("{}", seqno)},
00125              {http::headers::CCF_TX_VIEW, fmt::format("{}", view)},
00126              {http::headers::CCF_GLOBAL_COMMIT,
00127               fmt::format("{}", global_commit)}},
00128             std::move(body));
00129           state = INIT;
00130           return INITIAL_READ;
00131         }
00132         default:
00133         {
00134           throw std::logic_error("Unknown state");
00135         }
00136       }
00137     }
00138   };
00139 
00140   class RequestParser : public Parser
00141   {
00142   private:
00143     http::RequestProcessor& proc;
00144     uint64_t size = 0;
00145     ParserState state = INIT;
00146 
00147   public:
00148     RequestParser(http::RequestProcessor& proc_) : proc(proc_) {}
00149 
00150     size_t consume(const uint8_t* data, size_t s) override
00151     {
00152       switch (state)
00153       {
00154         case INIT:
00155         {
00156           assert(s == INITIAL_READ);
00157 
00158           bool fin = data[0] & 0x80;
00159           if (!fin)
00160           {
00161             LOG_FAIL_FMT("Fragment messages aren't supported.");
00162             return 0;
00163           }
00164           else
00165           {
00166             if (data[0] == 0x82)
00167             {
00168               if (data[1] & 0x80)
00169               {
00170                 LOG_FAIL_FMT("Masked messages aren't supported.");
00171                 return 0;
00172               }
00173               size = data[1] & 0x7f;
00174               switch (size)
00175               {
00176                 case 0x7f:
00177                 {
00178                   state = READ_LLEN;
00179                   return 8;
00180                 }
00181                 case 0x7e:
00182                 {
00183                   state = READ_SLEN;
00184                   return 2;
00185                 }
00186                 default:
00187                 {
00188                   state = READ_BODY;
00189                   return size;
00190                 }
00191               }
00192             }
00193             else
00194             {
00195               LOG_FAIL_FMT("Only binary messages are supported.");
00196               return 0;
00197             }
00198           }
00199         }
00200         case READ_SLEN:
00201         {
00202           assert(s == 2);
00203 
00204           size = be16toh(*(uint16_t*)data);
00205           state = READ_BODY;
00206           return size;
00207         }
00208         case READ_LLEN:
00209         {
00210           assert(s == 8);
00211 
00212           size = be64toh(*(uint64_t*)data);
00213           state = READ_BODY;
00214           return size;
00215         }
00216         case READ_BODY:
00217         {
00218           assert(s == size);
00219 
00220           auto path = serialized::read_lpsv(data, s);
00221           std::vector<uint8_t> body(data, data + s);
00222 
00223           proc.handle_request(
00224             llhttp_method::HTTP_POST,
00225             path,
00226             {},
00227             {},
00228             {{"Content-type", "application/json"}},
00229             std::move(body));
00230           state = INIT;
00231           return INITIAL_READ;
00232         }
00233         default:
00234         {
00235           throw std::logic_error("Unknown state");
00236         }
00237       }
00238     }
00239   };
00240 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/ws_parser.h...
Preprocessing /data/git/CCF/src/http/ws_rpc_context.h...
#include ../ds/serialized.h: already included! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include http_parser.h: already included! skipping...
#include http_sig.h: already included! skipping...
#include node/rpc/error.h: not found! skipping...
#include ws_builder.h: already included! skipping...
Preprocessor output (size: 4986 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ws
00013 {
00014   static std::vector<uint8_t> serialise(
00015     size_t code,
00016     const std::vector<uint8_t>& body,
00017     kv::Version seqno = kv::NoVersion,
00018     kv::Consensus::View view = ccf::VIEW_UNKNOWN,
00019     kv::Version global_commit = kv::NoVersion)
00020   {
00021     return make_out_frame(code, seqno, view, global_commit, body);
00022   };
00023 
00024   inline std::vector<uint8_t> error(ccf::ErrorDetails&& error)
00025   {
00026     nlohmann::json body = ccf::ODataErrorResponse{
00027       ccf::ODataError{std::move(error.code), std::move(error.msg)}};
00028     const auto s = body.dump();
00029 
00030     std::vector<uint8_t> data(s.begin(), s.end());
00031     return serialise(error.status, data);
00032   }
00033 
00034   inline std::vector<uint8_t> error(
00035     http_status status, const std::string& code, std::string&& msg)
00036   {
00037     return error({status, code, std::move(msg)});
00038   }
00039 
00040   class WsRpcContext : public enclave::RpcContext
00041   {
00042   private:
00043     size_t request_index;
00044 
00045     ccf::RESTVerb verb = ws::Verb::WEBSOCKET;
00046 
00047     std::string path = {};
00048     std::string method = {};
00049 
00050     http::HeaderMap request_headers = {};
00051 
00052     std::vector<uint8_t> request_body = {};
00053     enclave::PathParams path_params = {};
00054 
00055     std::vector<uint8_t> serialised_request = {};
00056 
00057     std::string query = {};
00058 
00059     std::vector<uint8_t> response_body = {};
00060     http_status response_status = HTTP_STATUS_OK;
00061     std::optional<bool> explicit_apply_writes = std::nullopt;
00062 
00063     size_t seqno = 0;
00064     size_t view = 0;
00065     size_t global_commit = 0;
00066 
00067   public:
00068     WsRpcContext(
00069       size_t request_index_,
00070       std::shared_ptr<enclave::SessionContext> s,
00071       const std::string_view& path_,
00072       const std::vector<uint8_t>& body_,
00073       const std::vector<uint8_t>& raw_request_ = {},
00074       const std::vector<uint8_t>& raw_bft_ = {}) :
00075       RpcContext(s, raw_bft_),
00076       request_index(request_index_),
00077       path(path_),
00078       method(path_),
00079       request_body(body_),
00080       serialised_request(raw_request_)
00081     {}
00082 
00083     virtual enclave::FrameFormat frame_format() const override
00084     {
00085       return enclave::FrameFormat::ws;
00086     }
00087 
00088     virtual size_t get_request_index() const override
00089     {
00090       return request_index;
00091     }
00092 
00093     virtual const std::vector<uint8_t>& get_request_body() const override
00094     {
00095       return request_body;
00096     }
00097 
00098     virtual const std::string& get_request_query() const override
00099     {
00100       return query;
00101     }
00102 
00103     virtual enclave::PathParams& get_request_path_params() override
00104     {
00105       return path_params;
00106     }
00107 
00108     virtual const ccf::RESTVerb& get_request_verb() const override
00109     {
00110       return verb;
00111     }
00112 
00113     virtual std::string get_request_path() const override
00114     {
00115       return method;
00116     }
00117 
00118     virtual const std::vector<uint8_t>& get_serialised_request() override
00119     {
00120       if (serialised_request.empty())
00121       {
00122         auto sr = make_in_frame(path, request_body);
00123         serialised_request.swap(sr);
00124       }
00125       return serialised_request;
00126     }
00127 
00128     virtual std::string get_method() const override
00129     {
00130       return method;
00131     }
00132 
00133     virtual void set_method(const std::string_view& p) override
00134     {
00135       method = p;
00136     }
00137 
00138     virtual const http::HeaderMap& get_request_headers() const override
00139     {
00140       return request_headers;
00141     }
00142 
00143     virtual std::optional<std::string> get_request_header(
00144       const std::string_view&) override
00145     {
00146       return std::nullopt;
00147     }
00148 
00149     virtual void set_response_body(const std::vector<uint8_t>& body) override
00150     {
00151       response_body = body;
00152     }
00153 
00154     virtual void set_response_body(std::vector<uint8_t>&& body) override
00155     {
00156       response_body = std::move(body);
00157     }
00158 
00159     virtual void set_response_body(std::string&& body) override
00160     {
00161       response_body = std::vector<uint8_t>(body.begin(), body.end());
00162     }
00163 
00164     virtual void set_response_status(int status) override
00165     {
00166       response_status = (http_status)status;
00167     }
00168 
00169     virtual int get_response_status() const override
00170     {
00171       return response_status;
00172     }
00173 
00174     virtual void set_response_header(
00175       const std::string_view&, const std::string_view&) override
00176     {}
00177 
00178     virtual void set_seqno(kv::Version sn) override
00179     {
00180       seqno = sn;
00181     }
00182 
00183     virtual void set_view(kv::Consensus::View t) override
00184     {
00185       view = t;
00186     }
00187 
00188     virtual void set_global_commit(kv::Version gc) override
00189     {
00190       global_commit = gc;
00191     }
00192 
00193     virtual void set_apply_writes(bool apply) override
00194     {
00195       explicit_apply_writes = apply;
00196     }
00197 
00198     virtual bool should_apply_writes() const override
00199     {
00200       if (explicit_apply_writes.has_value())
00201       {
00202         return explicit_apply_writes.value();
00203       }
00204 
00205       // Default is to apply any 2xx status
00206       return http::status_success(response_status);
00207     }
00208 
00209     virtual std::vector<uint8_t> serialise_response() const override
00210     {
00211       return serialise(
00212         response_status, response_body, seqno, view, global_commit);
00213     }
00214   };
00215 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/ws_rpc_context.h...
Preprocessing /data/git/CCF/src/http/ws_upgrade.h...
#include http_parser.h: already included! skipping...
#include tls/base64.h: not found! skipping...
#include tls/hash.h: not found! skipping...
#include optional: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 2573 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace http
00013 {
00014   class WebSocketUpgrader
00015   {
00016   private:
00017     // Constructs base64 acccept string (as per
00018     // https://tools.ietf.org/html/rfc6455#section-1.3)
00019     static std::optional<std::string> construct_accept_string(
00020       const std::string& client_key)
00021     {
00022       const auto string_to_hash =
00023         fmt::format("{}{}", client_key, WEBSOCKET_HANDSHAKE_GUID);
00024 
00025       const auto data = reinterpret_cast<const uint8_t*>(string_to_hash.data());
00026       const auto size = string_to_hash.size();
00027 
00028       tls::HashBytes accept_string_hash;
00029       tls::do_hash(data, size, accept_string_hash, MBEDTLS_MD_SHA1);
00030 
00031       return tls::b64_from_raw(
00032         accept_string_hash.data(), accept_string_hash.size());
00033     }
00034 
00035   public:
00036     // All HTTP headers are expected to be lowercase
00037     static constexpr auto HTTP_HEADER_UPGRADE = "upgrade";
00038     static constexpr auto HTTP_HEADER_CONNECTION = "connection";
00039     static constexpr auto HTTP_HEADER_WEBSOCKET_KEY = "sec-websocket-key";
00040     static constexpr auto HTTP_HEADER_WEBSOCKET_ACCEPT = "sec-websocket-accept";
00041 
00042     static constexpr auto UPGRADE_HEADER_WEBSOCKET = "websocket";
00043     static constexpr auto CONNECTION_HEADER_UPGRADE = "Upgrade";
00044 
00045     static constexpr auto WEBSOCKET_HANDSHAKE_GUID =
00046       "258EAFA5-E914-47DA-95CA-C5AB0DC85B11";
00047 
00048     WebSocketUpgrader() {}
00049 
00050     static std::optional<std::vector<uint8_t>> upgrade_if_necessary(
00051       const http::HeaderMap& headers)
00052     {
00053       auto const upgrade_header = headers.find(HTTP_HEADER_UPGRADE);
00054       if (upgrade_header != headers.end())
00055       {
00056         auto const header_key = headers.find(HTTP_HEADER_WEBSOCKET_KEY);
00057         if (header_key == headers.end())
00058         {
00059           throw std::logic_error(fmt::format(
00060             "{} header missing from upgrade request",
00061             HTTP_HEADER_WEBSOCKET_KEY));
00062         }
00063 
00064         auto accept_string = construct_accept_string(header_key->second);
00065         if (!accept_string.has_value())
00066         {
00067           throw std::logic_error(fmt::format(
00068             "Error constructing {} header", HTTP_HEADER_WEBSOCKET_ACCEPT));
00069         }
00070 
00071         auto r = Response(HTTP_STATUS_SWITCHING_PROTOCOLS);
00072         r.set_header(HTTP_HEADER_UPGRADE, UPGRADE_HEADER_WEBSOCKET);
00073         r.set_header(HTTP_HEADER_CONNECTION, CONNECTION_HEADER_UPGRADE);
00074         r.set_header(HTTP_HEADER_WEBSOCKET_ACCEPT, accept_string.value());
00075 
00076         return r.build_response();
00077       }
00078       else
00079       {
00080         return {};
00081       }
00082     }
00083   };
00084 }
---------
Macros accessible in this file:
---------
HTTP_STATUS_MAP XX FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/http/ws_upgrade.h...
Preprocessing /data/git/CCF/src/kv/change_set.h...
#include ds/champ_map.h: not found! skipping...
#include ds/hash.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include map: not found! skipping...
Preprocessor output (size: 2212 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace kv
00011 {
00012   template <typename V>
00013   using VersionV = champ::VersionV<V>;
00014   template <typename K, typename V, typename H>
00015   using State = champ::Map<K, VersionV<V>, H>;
00016   template <typename K, typename V, typename H>
00017   using Snapshot = champ::Snapshot<K, VersionV<V>, H>;
00018 
00019   template <typename K>
00020   using Read = std::map<K, Version>;
00021 
00022   // nullopt values represent deletions
00023   template <typename K, typename V>
00024   using Write = std::map<K, std::optional<V>>;
00025 
00026   // This is a container for a write-set + dependencies. It can be applied to a
00027   // given state, or used to track a set of operations on a state
00028   template <typename K, typename V, typename H>
00029   struct ChangeSet : public AbstractChangeSet
00030   {
00031   protected:
00032     ChangeSet() {}
00033 
00034   public:
00035     const size_t rollback_counter = {};
00036     const State<K, V, H> state = {};
00037     const State<K, V, H> committed = {};
00038     const Version start_version = {};
00039 
00040     Version read_version = NoVersion;
00041     Read<K> reads = {};
00042     Write<K, V> writes = {};
00043 
00044     ChangeSet(
00045       size_t rollbacks,
00046       State<K, V, H>& current_state,
00047       State<K, V, H>& committed_state,
00048       Version current_version) :
00049       rollback_counter(rollbacks),
00050       state(current_state),
00051       committed(committed_state),
00052       start_version(current_version)
00053     {}
00054 
00055     ChangeSet(ChangeSet&) = delete;
00056 
00057     bool has_writes() const override
00058     {
00059       return !writes.empty();
00060     }
00061   };
00062 
00063   // This is a container for a snapshot. It has no dependencies as the snapshot
00064   // obliterates the current state.
00065   template <typename K, typename V, typename H>
00066   struct SnapshotChangeSet : public ChangeSet<K, V, H>
00067   {
00068     const State<K, V, H> state;
00069     const Version version;
00070 
00071     SnapshotChangeSet(State<K, V, H>&& snapshot_state, Version version_) :
00072       state(std::move(snapshot_state)),
00073       version(version_)
00074     {}
00075 
00076     SnapshotChangeSet(SnapshotChangeSet&) = delete;
00077 
00078     bool has_writes() const override
00079     {
00080       return true;
00081     }
00082   };
00083 
00084   /// Signature for transaction commit handlers
00085   template <typename W>
00086   using CommitHook = std::function<void(Version, const W&)>;
00087 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/change_set.h...
Preprocessing /data/git/CCF/src/kv/encryptor.h...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
Preprocessor output (size: 6198 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv
00010 {
00011   class TxEncryptor : public kv::AbstractTxEncryptor
00012   {
00013   public:
00014     struct KeyInfo
00015     {
00016       kv::Version version;
00017 
00018       // This is unfortunate. Because the encryptor updates the ledger secrets
00019       // on global hook, we need easy access to the raw secrets.
00020       std::vector<uint8_t> raw_key;
00021     };
00022 
00023   private:
00024     SpinLock lock;
00025 
00026     virtual void set_iv(
00027       crypto::GcmHeader<crypto::GCM_SIZE_IV>& gcm_hdr,
00028       kv::Version version,
00029       bool is_snapshot = false)
00030     {
00031       // Warning: The same IV will get re-used on rollback!
00032       gcm_hdr.set_iv_seq(version);
00033       gcm_hdr.set_iv_id(iv_id);
00034       gcm_hdr.set_iv_snapshot(is_snapshot);
00035     }
00036 
00037     const crypto::KeyAesGcm& get_encryption_key(kv::Version version)
00038     {
00039       std::lock_guard<SpinLock> guard(lock);
00040 
00041       // Encryption key for a given version is the one with the highest version
00042       // that is lower than the given version (e.g. if encryption_keys contains
00043       // two keys for version 0 and 10 then the key associated with version 0
00044       // is used for version [0..9] and version 10 for versions 10+)
00045       auto search = std::upper_bound(
00046         encryption_keys.rbegin(),
00047         encryption_keys.rend(),
00048         version,
00049         [](kv::Version a, EncryptionKey const& b) { return b.version <= a; });
00050 
00051       if (search == encryption_keys.rend())
00052       {
00053         throw std::logic_error(fmt::format(
00054           "TxEncryptor: encrypt version is not valid: {}", version));
00055       }
00056 
00057       return search->key;
00058     }
00059 
00060   protected:
00061     // Encryption keys are set when TxEncryptor object is created and are used
00062     // to determine which key to use for encryption/decryption when
00063     // committing/deserialising depending on the version
00064 
00065     struct EncryptionKey : KeyInfo
00066     {
00067       crypto::KeyAesGcm key;
00068     };
00069 
00070     std::list<EncryptionKey> encryption_keys;
00071     size_t iv_id = 0;
00072 
00073     virtual void record_compacted_keys(const std::list<KeyInfo>&){};
00074 
00075   public:
00076     TxEncryptor(const std::list<KeyInfo>& existing_keys)
00077     {
00078       // Create map of existing encryption keys from the recorded ledger secrets
00079       for (auto const& s : existing_keys)
00080       {
00081         encryption_keys.emplace_back(TxEncryptor::EncryptionKey{
00082           {s.version, s.raw_key}, crypto::KeyAesGcm(s.raw_key)});
00083       }
00084     }
00085 
00086     /**
00087      * Encrypt data and return serialised GCM header and cipher.
00088      *
00089      * @param[in]   plain             Plaintext to encrypt
00090      * @param[in]   additional_data   Additional data to tag
00091      * @param[out]  serialised_header Serialised header (iv + tag)
00092      * @param[out]  cipher            Encrypted ciphertext
00093      * @param[in]   version           Version used to retrieve the corresponding
00094      * encryption key
00095      * @param[in]   is_snapshot       Indicates that the entry is a snapshot (to
00096      * avoid IV re-use)
00097      */
00098     void encrypt(
00099       const std::vector<uint8_t>& plain,
00100       const std::vector<uint8_t>& additional_data,
00101       std::vector<uint8_t>& serialised_header,
00102       std::vector<uint8_t>& cipher,
00103       kv::Version version,
00104       bool is_snapshot = false) override
00105     {
00106       crypto::GcmHeader<crypto::GCM_SIZE_IV> gcm_hdr;
00107       cipher.resize(plain.size());
00108 
00109       set_iv(gcm_hdr, version, is_snapshot);
00110 
00111       get_encryption_key(version).encrypt(
00112         gcm_hdr.get_iv(), plain, additional_data, cipher.data(), gcm_hdr.tag);
00113 
00114       serialised_header = gcm_hdr.serialise();
00115     }
00116 
00117     /**
00118      * Decrypt cipher and return plaintext.
00119      *
00120      * @param[in]   cipher            Cipher to decrypt
00121      * @param[in]   additional_data   Additional data to verify tag
00122      * @param[in]   serialised_header Serialised header (iv + tag)
00123      * @param[out]  plain             Decrypted plaintext
00124      * @param[in]   version           Version used to retrieve the corresponding
00125      * encryption key
00126      *
00127      * @return Boolean status indicating success of decryption.
00128      */
00129     bool decrypt(
00130       const std::vector<uint8_t>& cipher,
00131       const std::vector<uint8_t>& additional_data,
00132       const std::vector<uint8_t>& serialised_header,
00133       std::vector<uint8_t>& plain,
00134       kv::Version version) override
00135     {
00136       crypto::GcmHeader<crypto::GCM_SIZE_IV> gcm_hdr;
00137       gcm_hdr.deserialise(serialised_header);
00138       plain.resize(cipher.size());
00139 
00140       auto ret = get_encryption_key(version).decrypt(
00141         gcm_hdr.get_iv(), gcm_hdr.tag, cipher, additional_data, plain.data());
00142 
00143       if (!ret)
00144       {
00145         plain.resize(0);
00146       }
00147 
00148       return ret;
00149     }
00150 
00151     void set_iv_id(size_t id) override
00152     {
00153       iv_id = id;
00154     }
00155 
00156     /**
00157      * Return length of serialised header.
00158      *
00159      * @return size_t length of serialised header
00160      */
00161     size_t get_header_length() override
00162     {
00163       return crypto::GcmHeader<crypto::GCM_SIZE_IV>::RAW_DATA_SIZE;
00164     }
00165 
00166     void update_encryption_key(
00167       kv::Version version, const std::vector<uint8_t>& raw_ledger_key) override
00168     {
00169       std::lock_guard<SpinLock> guard(lock);
00170 
00171       encryption_keys.emplace_back(EncryptionKey{
00172         {version, raw_ledger_key}, crypto::KeyAesGcm(raw_ledger_key)});
00173     }
00174 
00175     void rollback(kv::Version version) override
00176     {
00177       std::lock_guard<SpinLock> guard(lock);
00178 
00179       while (encryption_keys.size() > 1)
00180       {
00181         auto k = encryption_keys.end();
00182         std::advance(k, -1);
00183 
00184         if (k->version <= version)
00185         {
00186           break;
00187         }
00188 
00189         encryption_keys.pop_back();
00190       }
00191     }
00192 
00193     void compact(kv::Version version) override
00194     {
00195       std::lock_guard<SpinLock> guard(lock);
00196       std::list<KeyInfo> compacted_keys;
00197 
00198       // Remove keys that have been superseded by a newer key.
00199       while (encryption_keys.size() > 1)
00200       {
00201         auto k = encryption_keys.begin();
00202 
00203         if (std::next(k)->version > version)
00204         {
00205           break;
00206         }
00207 
00208         compacted_keys.emplace_back(
00209           KeyInfo{std::next(k)->version, std::next(k)->raw_key});
00210 
00211         if (k->version < version)
00212         {
00213           encryption_keys.pop_front();
00214         }
00215       }
00216 
00217       record_compacted_keys(compacted_keys);
00218     }
00219   };
00220 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/encryptor.h...
Preprocessing /data/git/CCF/src/kv/generic_serialise_wrapper.h...
#include ds/buffer.h: not found! skipping...
#include kv_types.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include small_vector/SmallVector.h: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 12022 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 # 7 "/data/git/CCF/src/kv/generic_serialise_wrapper.h" 2
00008 
00009 
00010 
00011 namespace kv
00012 {
00013   using SerialisedKey = kv::serialisers::SerialisedEntry;
00014   using SerialisedValue = kv::serialisers::SerialisedEntry;
00015 
00016   enum class KvOperationType : uint32_t
00017   {
00018     KOT_NOT_SUPPORTED = 0,
00019     KOT_SET_VERSION = (1 << 0),
00020     KOT_MAP_START_INDICATOR = (1 << 1),
00021     KOT_ENTRY_VERSION = (1 << 2),
00022     KOT_READ = (1 << 3),
00023     KOT_WRITE_VERSION = (1 << 4),
00024     KOT_WRITE = (1 << 5),
00025     KOT_REMOVE_VERSION = (1 << 6),
00026     KOT_REMOVE = (1 << 7),
00027   };
00028 
00029   typedef std::underlying_type<KvOperationType>::type KotBase;
00030 
00031   inline KvOperationType operator&(
00032     const KvOperationType& a, const KvOperationType& b)
00033   {
00034     return static_cast<KvOperationType>(
00035       static_cast<KotBase>(a) & static_cast<KotBase>(b));
00036   }
00037 
00038   inline KvOperationType operator|(
00039     const KvOperationType& a, const KvOperationType& b)
00040   {
00041     return static_cast<KvOperationType>(
00042       static_cast<KotBase>(a) | static_cast<KotBase>(b));
00043   }
00044 
00045   template <typename W>
00046   class GenericSerialiseWrapper
00047   {
00048   private:
00049     W public_writer;
00050     W private_writer;
00051     W* current_writer;
00052     Version version;
00053     bool is_snapshot;
00054 
00055     std::shared_ptr<AbstractTxEncryptor> crypto_util;
00056 
00057     // must only be set by set_current_domain, since it affects current_writer
00058     SecurityDomain current_domain;
00059 
00060     template <typename T>
00061     void serialise_internal(T&& t)
00062     {
00063       current_writer->append(std::forward<T>(t));
00064     }
00065 
00066     template <typename T>
00067     void serialise_internal_pre_serialised(const T& raw)
00068     {
00069       current_writer->template append_pre_serialised<T>(raw);
00070     }
00071 
00072     void set_current_domain(SecurityDomain domain)
00073     {
00074       switch (domain)
00075       {
00076         case SecurityDomain::PRIVATE:
00077           current_writer = &private_writer;
00078           current_domain = SecurityDomain::PRIVATE;
00079           break;
00080         case SecurityDomain::PUBLIC:
00081           current_writer = &public_writer;
00082           current_domain = SecurityDomain::PUBLIC;
00083           break;
00084         default:
00085           break;
00086       }
00087     }
00088 
00089   public:
00090     GenericSerialiseWrapper(
00091       std::shared_ptr<AbstractTxEncryptor> e,
00092       const Version& version_,
00093       bool is_snapshot_ = false) :
00094       version(version_),
00095       is_snapshot(is_snapshot_),
00096       crypto_util(e)
00097     {
00098       set_current_domain(SecurityDomain::PUBLIC);
00099       serialise_internal(is_snapshot);
00100       serialise_internal(version);
00101     }
00102 
00103     void start_map(const std::string& name, SecurityDomain domain)
00104     {
00105       if (domain == SecurityDomain::PRIVATE && !crypto_util)
00106       {
00107         throw KvSerialiserException(fmt::format(
00108           "Private map {} cannot be serialised without an encryptor", name));
00109       }
00110 
00111       if (domain != current_domain)
00112         set_current_domain(domain);
00113 
00114       serialise_internal(KvOperationType::KOT_MAP_START_INDICATOR);
00115       serialise_internal(name);
00116     }
00117 
00118     void serialise_raw(const std::vector<uint8_t>& raw)
00119     {
00120       serialise_internal_pre_serialised(raw);
00121     }
00122 
00123     void serialise_view_history(const std::vector<Version>& view_history)
00124     {
00125       serialise_internal(view_history);
00126     }
00127 
00128     template <class Version>
00129     void serialise_entry_version(const Version& version)
00130     {
00131       serialise_internal(version);
00132     }
00133 
00134     void serialise_count_header(uint64_t ctr)
00135     {
00136       serialise_internal(ctr);
00137     }
00138 
00139     void serialise_read(const SerialisedKey& k, const Version& version)
00140     {
00141       serialise_internal_pre_serialised(k);
00142       serialise_internal(version);
00143     }
00144 
00145     void serialise_write(const SerialisedKey& k, const SerialisedValue& v)
00146     {
00147       serialise_internal_pre_serialised(k);
00148       serialise_internal_pre_serialised(v);
00149     }
00150 
00151     void serialise_write_version(
00152       const SerialisedKey& k, const SerialisedValue& v, const Version& version)
00153     {
00154       serialise_internal(KvOperationType::KOT_WRITE_VERSION);
00155       serialise_internal_pre_serialised(k);
00156       serialise_internal_pre_serialised(v);
00157       serialise_internal(version);
00158     }
00159 
00160     void serialise_remove_version(const SerialisedKey& k)
00161     {
00162       serialise_internal(KvOperationType::KOT_REMOVE_VERSION);
00163       serialise_internal_pre_serialised(k);
00164     }
00165 
00166     void serialise_remove(const SerialisedKey& k)
00167     {
00168       serialise_internal_pre_serialised(k);
00169     }
00170 
00171     std::vector<uint8_t> get_raw_data()
00172     {
00173       // make sure the private buffer is empty when we return
00174       auto writer_guard_func = [](W* writer) { writer->clear(); };
00175       std::unique_ptr<decltype(private_writer), decltype(writer_guard_func)>
00176         writer_guard(&private_writer, writer_guard_func);
00177 
00178       auto serialised_public_domain = public_writer.get_raw_data();
00179 
00180       // If no crypto util is set, all maps have been serialised by the public
00181       // writer.
00182       if (!crypto_util)
00183       {
00184         return serialised_public_domain;
00185       }
00186 
00187       auto serialised_private_domain = private_writer.get_raw_data();
00188 
00189       return serialise_domains(
00190         serialised_public_domain, serialised_private_domain);
00191     }
00192 
00193     std::vector<uint8_t> serialise_domains(
00194       const std::vector<uint8_t>& serialised_public_domain,
00195       const std::vector<uint8_t>& serialised_private_domain =
00196         std::vector<uint8_t>())
00197     {
00198       std::vector<uint8_t> serialised_tx;
00199       std::vector<uint8_t> serialised_hdr;
00200       std::vector<uint8_t> encrypted_private_domain(
00201         serialised_private_domain.size());
00202 
00203       crypto_util->encrypt(
00204         serialised_private_domain,
00205         serialised_public_domain,
00206         serialised_hdr,
00207         encrypted_private_domain,
00208         version,
00209         is_snapshot);
00210 
00211       // Serialise entire tx
00212       // Format: gcm hdr (iv + tag) + len of public domain + public domain +
00213       // encrypted privated domain
00214       auto space = serialised_hdr.size() + sizeof(size_t) +
00215         serialised_public_domain.size() + encrypted_private_domain.size();
00216       serialised_tx.resize(space);
00217       auto data_ = serialised_tx.data();
00218 
00219       serialized::write(
00220         data_, space, serialised_hdr.data(), serialised_hdr.size());
00221       serialized::write(data_, space, serialised_public_domain.size());
00222       serialized::write(
00223         data_,
00224         space,
00225         serialised_public_domain.data(),
00226         serialised_public_domain.size());
00227       if (encrypted_private_domain.size() > 0)
00228       {
00229         serialized::write(
00230           data_,
00231           space,
00232           encrypted_private_domain.data(),
00233           encrypted_private_domain.size());
00234       }
00235 
00236       return serialised_tx;
00237     }
00238   };
00239 
00240   template <typename R>
00241   class GenericDeserialiseWrapper
00242   {
00243   private:
00244     R public_reader;
00245     R private_reader;
00246     R* current_reader;
00247     std::vector<uint8_t> decrypted_buffer;
00248     KvOperationType unhandled_op;
00249     bool is_snapshot;
00250     Version version;
00251     std::shared_ptr<AbstractTxEncryptor> crypto_util;
00252     std::optional<SecurityDomain> domain_restriction;
00253 
00254     bool try_read_op(KvOperationType type)
00255     {
00256       return try_read_op(type, *current_reader);
00257     }
00258 
00259     bool try_read_op(KvOperationType type, R& reader)
00260     {
00261       return try_read_op_flag(type, reader) == type;
00262     }
00263 
00264     KvOperationType try_read_op_flag(KvOperationType type)
00265     {
00266       return try_read_op_flag(type, *current_reader);
00267     }
00268 
00269     KvOperationType try_read_op_flag(KvOperationType type, R& reader)
00270     {
00271       if (unhandled_op != KvOperationType::KOT_NOT_SUPPORTED)
00272       {
00273         auto curr_type = (type & unhandled_op);
00274         if (curr_type != KvOperationType::KOT_NOT_SUPPORTED)
00275         {
00276           // clear cached op header
00277           unhandled_op = KvOperationType::KOT_NOT_SUPPORTED;
00278         }
00279         return curr_type;
00280       }
00281 
00282       auto next_op = reader.template read_next<KvOperationType>();
00283       if ((type & next_op) == next_op)
00284       {
00285         return next_op;
00286       }
00287 
00288       unhandled_op = next_op;
00289       return KvOperationType::KOT_NOT_SUPPORTED;
00290     }
00291 
00292     // Should only be called once, once the GCM header and length of public
00293     // domain have been read
00294     void read_public_header()
00295     {
00296       is_snapshot = public_reader.template read_next<bool>();
00297       version = public_reader.template read_next<Version>();
00298     }
00299 
00300   public:
00301     GenericDeserialiseWrapper(
00302       std::shared_ptr<AbstractTxEncryptor> e,
00303       std::optional<SecurityDomain> domain_restriction = std::nullopt) :
00304       unhandled_op(KvOperationType::KOT_NOT_SUPPORTED),
00305       crypto_util(e),
00306       domain_restriction(domain_restriction)
00307     {}
00308 
00309     std::optional<Version> init(const uint8_t* data, size_t size)
00310     {
00311       current_reader = &public_reader;
00312       auto data_ = data;
00313       auto size_ = size;
00314 
00315       // If the kv store has no encryptor, assume that the serialised tx is
00316       // public only with no header
00317       if (!crypto_util)
00318       {
00319         public_reader.init(data, size);
00320         read_public_header();
00321         return version;
00322       }
00323 
00324       // Skip gcm hdr and read length of public domain
00325       serialized::skip(data_, size_, crypto_util->get_header_length());
00326       auto public_domain_length = serialized::read<size_t>(data_, size_);
00327 
00328       // Set public reader
00329       auto data_public = data_;
00330       public_reader.init(data_public, public_domain_length);
00331 
00332       read_public_header();
00333 
00334       // If the domain is public only, skip the decryption and only return the
00335       // public data
00336       if (
00337         domain_restriction.has_value() &&
00338         domain_restriction.value() == SecurityDomain::PUBLIC)
00339       {
00340         return version;
00341       }
00342 
00343       // Go to start of private domain
00344       serialized::skip(data_, size_, public_domain_length);
00345       decrypted_buffer.resize(size_);
00346 
00347       if (!crypto_util->decrypt(
00348             {data_, data_ + size_},
00349             {data_public, data_public + public_domain_length},
00350             {data, data + crypto_util->get_header_length()},
00351             decrypted_buffer,
00352             version))
00353       {
00354         return std::nullopt;
00355       }
00356 
00357       // Set private reader
00358       private_reader.init(decrypted_buffer.data(), decrypted_buffer.size());
00359       return version;
00360     }
00361 
00362     std::optional<std::string> start_map()
00363     {
00364       if (current_reader->is_eos())
00365       {
00366         if (current_reader == &public_reader && !private_reader.is_eos())
00367           current_reader = &private_reader;
00368         else
00369           return {};
00370       }
00371 
00372       if (!try_read_op(KvOperationType::KOT_MAP_START_INDICATOR))
00373       {
00374         return {};
00375       }
00376 
00377       return std::optional<std::string>{
00378         current_reader->template read_next<std::string>()};
00379     }
00380 
00381     Version deserialise_entry_version()
00382     {
00383       return current_reader->template read_next<Version>();
00384     }
00385 
00386     uint64_t deserialise_read_header()
00387     {
00388       return current_reader->template read_next<uint64_t>();
00389     }
00390 
00391     std::tuple<SerialisedKey, Version> deserialise_read()
00392     {
00393       return {
00394         current_reader->template read_next_pre_serialised<SerialisedKey>(),
00395         current_reader->template read_next<Version>()};
00396     }
00397 
00398     uint64_t deserialise_write_header()
00399     {
00400       return current_reader->template read_next<uint64_t>();
00401     }
00402 
00403     std::tuple<SerialisedKey, SerialisedValue> deserialise_write()
00404     {
00405       return {
00406         current_reader->template read_next_pre_serialised<SerialisedKey>(),
00407         current_reader->template read_next_pre_serialised<SerialisedValue>()};
00408     }
00409 
00410     std::vector<uint8_t> deserialise_raw()
00411     {
00412       return current_reader
00413         ->template read_next_pre_serialised<std::vector<uint8_t>>();
00414     }
00415 
00416     std::vector<Version> deserialise_view_history()
00417     {
00418       return current_reader->template read_next<std::vector<Version>>();
00419     }
00420 
00421     uint64_t deserialise_remove_header()
00422     {
00423       return current_reader->template read_next<uint64_t>();
00424     }
00425 
00426     SerialisedKey deserialise_remove()
00427     {
00428       return current_reader->template read_next_pre_serialised<SerialisedKey>();
00429     }
00430 
00431     bool end()
00432     {
00433       return current_reader->is_eos() && public_reader.is_eos();
00434     }
00435   };
00436 }
00437 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/generic_serialise_wrapper.h...
Preprocessing /data/git/CCF/src/kv/kv_serialiser.h...
#include kv/msgpack_serialise.h: not found! skipping...
Preprocessor output (size: 111 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/kv_serialiser.h...
Preprocessing /data/git/CCF/src/kv/kv_types.h...
#include crypto/hash.h: not found! skipping...
#include ds/nonstd.h: not found! skipping...
#include enclave/consensus_type.h: not found! skipping...
#include serialiser_declare.h: already included! skipping...
#include tls/pem.h: not found! skipping...
#include array: not found! skipping...
#include chrono: not found! skipping...
#include functional: not found! skipping...
#include limits: not found! skipping...
#include memory: not found! skipping...
#include string: not found! skipping...
#include unordered_set: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 14631 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 namespace ccf
00021 {
00022   struct PrimarySignature;
00023 }
00024 
00025 namespace kv
00026 {
00027   // Version indexes modifications to the local kv store. Negative values
00028   // indicate deletion
00029   using Version = int64_t;
00030   static const Version NoVersion = std::numeric_limits<Version>::min();
00031 
00032   static bool is_deleted(Version version)
00033   {
00034     return version < 0;
00035   }
00036 
00037   // Term describes an epoch of Versions. It is incremented when global kv's
00038   // writer(s) changes. Term and Version combined give a unique identifier for
00039   // all accepted kv modifications. Terms are handled by Consensus via the
00040   // TermHistory
00041   using Term = int64_t;
00042   using NodeId = uint64_t;
00043 
00044   struct TxID
00045   {
00046     Term term = 0;
00047     Version version = 0;
00048     MSGPACK_DEFINE(term, version);
00049   };
00050   DECLARE_JSON_TYPE(TxID);
00051 
00052 
00053   using BatchVector = std::vector<
00054     std::tuple<kv::Version, std::shared_ptr<std::vector<uint8_t>>, bool>>;
00055 
00056   enum CommitSuccess
00057   {
00058     OK,
00059     CONFLICT,
00060     NO_REPLICATE
00061   };
00062 
00063   enum SecurityDomain
00064   {
00065     PUBLIC, // Public domain indicates the version and always appears first
00066     PRIVATE,
00067     SECURITY_DOMAIN_MAX
00068   };
00069 
00070   enum AccessCategory
00071   {
00072     INTERNAL,
00073     GOVERNANCE,
00074     APPLICATION
00075   };
00076 
00077   constexpr auto public_domain_prefix = "public:";
00078 
00079   static inline SecurityDomain get_security_domain(const std::string& name)
00080   {
00081     if (nonstd::starts_with(name, public_domain_prefix))
00082     {
00083       return SecurityDomain::PUBLIC;
00084     }
00085 
00086     return SecurityDomain::PRIVATE;
00087   }
00088 
00089   static inline std::pair<SecurityDomain, AccessCategory> parse_map_name(
00090     const std::string& name)
00091   {
00092     constexpr auto internal_category_prefix = "ccf.internal.";
00093     constexpr auto governance_category_prefix = "ccf.gov.";
00094     constexpr auto reserved_category_prefix = "ccf.";
00095 
00096     auto security_domain = SecurityDomain::PRIVATE;
00097     const auto core_name = nonstd::remove_prefix(name, public_domain_prefix);
00098     if (core_name != name)
00099     {
00100       security_domain = SecurityDomain::PUBLIC;
00101     }
00102 
00103     auto access_category = AccessCategory::APPLICATION;
00104     if (nonstd::starts_with(core_name, internal_category_prefix))
00105     {
00106       access_category = AccessCategory::INTERNAL;
00107     }
00108     else if (nonstd::starts_with(core_name, governance_category_prefix))
00109     {
00110       access_category = AccessCategory::GOVERNANCE;
00111     }
00112     else if (nonstd::starts_with(core_name, reserved_category_prefix))
00113     {
00114       throw std::logic_error(fmt::format(
00115         "Map name '{}' includes disallowed reserved prefix '{}'",
00116         name,
00117         reserved_category_prefix));
00118     }
00119 
00120     return {security_domain, access_category};
00121   }
00122 
00123   // Note that failed = 0, and all other values are variants of PASS, which
00124   // allows DeserialiseSuccess to be used as a boolean in code that does not
00125   // need any detail about what happened on success
00126   enum DeserialiseSuccess
00127   {
00128     FAILED = 0,
00129     PASS = 1,
00130     PASS_SIGNATURE = 2,
00131     PASS_BACKUP_SIGNATURE = 3,
00132     PASS_BACKUP_SIGNATURE_SEND_ACK = 4,
00133     PASS_NONCES = 5,
00134     PASS_NEW_VIEW = 6,
00135     PASS_SNAPSHOT_EVIDENCE = 7
00136   };
00137 
00138   enum ReplicateType
00139   {
00140     ALL = 0,
00141     NONE,
00142     SOME
00143   };
00144 
00145   class KvSerialiserException : public std::exception
00146   {
00147   private:
00148     std::string msg;
00149 
00150   public:
00151     KvSerialiserException(const std::string& msg_) : msg(msg_) {}
00152 
00153     virtual const char* what() const throw()
00154     {
00155       return msg.c_str();
00156     }
00157   };
00158 
00159   class Syncable
00160   {
00161   public:
00162     virtual void rollback(Version v) = 0;
00163     virtual void compact(Version v) = 0;
00164   };
00165 
00166   class TxHistory : public Syncable
00167   {
00168   public:
00169     using RequestID = std::tuple<
00170       size_t /* Client Session ID */,
00171       size_t /* Request sequence number */>;
00172 
00173     struct RequestCallbackArgs
00174     {
00175       RequestID rid;
00176       std::vector<uint8_t> request;
00177       std::vector<uint8_t> caller_cert;
00178       uint8_t frame_format;
00179     };
00180 
00181     struct ResultCallbackArgs
00182     {
00183       RequestID rid;
00184       Version version;
00185       crypto::Sha256Hash replicated_state_merkle_root;
00186     };
00187 
00188     struct ResponseCallbackArgs
00189     {
00190       RequestID rid;
00191       std::vector<uint8_t> response;
00192     };
00193 
00194     enum class Result
00195     {
00196       FAIL = 0,
00197       OK,
00198       SEND_SIG_RECEIPT_ACK,
00199       SEND_REPLY_AND_NONCE
00200     };
00201 
00202     using ResultCallbackHandler = std::function<bool(ResultCallbackArgs)>;
00203     using ResponseCallbackHandler = std::function<bool(ResponseCallbackArgs)>;
00204 
00205     virtual ~TxHistory() {}
00206     virtual void append(const std::vector<uint8_t>& replicated) = 0;
00207     virtual void append(const uint8_t* replicated, size_t replicated_size) = 0;
00208     virtual Result verify_and_sign(
00209       ccf::PrimarySignature& signature, Term* term = nullptr) = 0;
00210     virtual bool verify(
00211       Term* term = nullptr, ccf::PrimarySignature* sig = nullptr) = 0;
00212     virtual void try_emit_signature() = 0;
00213     virtual void emit_signature() = 0;
00214     virtual crypto::Sha256Hash get_replicated_state_root() = 0;
00215     virtual std::vector<uint8_t> get_receipt(Version v) = 0;
00216     virtual bool verify_receipt(const std::vector<uint8_t>& receipt) = 0;
00217     virtual bool init_from_snapshot(
00218       const std::vector<uint8_t>& hash_at_snapshot) = 0;
00219     virtual std::vector<uint8_t> get_raw_leaf(uint64_t index) = 0;
00220 
00221     virtual bool add_request(
00222       kv::TxHistory::RequestID id,
00223       const std::vector<uint8_t>& caller_cert,
00224       const std::vector<uint8_t>& request,
00225       uint8_t frame_format) = 0;
00226     virtual void add_result(
00227       RequestID id,
00228       kv::Version version,
00229       const std::vector<uint8_t>& replicated) = 0;
00230     virtual void add_pending(
00231       RequestID id,
00232       kv::Version version,
00233       std::shared_ptr<std::vector<uint8_t>> replicated) = 0;
00234     virtual void flush_pending() = 0;
00235     virtual void add_result(
00236       RequestID id,
00237       kv::Version version,
00238       const uint8_t* replicated,
00239       size_t replicated_size) = 0;
00240     virtual void add_result(RequestID id, kv::Version version) = 0;
00241     virtual void add_response(
00242       RequestID id, const std::vector<uint8_t>& response) = 0;
00243     virtual void register_on_result(ResultCallbackHandler func) = 0;
00244     virtual void register_on_response(ResponseCallbackHandler func) = 0;
00245     virtual void clear_on_result() = 0;
00246     virtual void clear_on_response() = 0;
00247   };
00248 
00249   class Consensus
00250   {
00251   protected:
00252     enum State
00253     {
00254       Primary,
00255       Backup,
00256       Candidate
00257     };
00258 
00259     State state;
00260     NodeId local_id;
00261 
00262   public:
00263     // SeqNo indexes transactions processed by the consensus protocol providing
00264     // ordering
00265     using SeqNo = int64_t;
00266     // View describes an epoch of SeqNos. View is incremented when Consensus's
00267     // primary changes
00268     using View = int64_t;
00269 
00270     struct Configuration
00271     {
00272       struct NodeInfo
00273       {
00274         std::string hostname;
00275         std::string port;
00276         tls::Pem cert = {};
00277 
00278         NodeInfo() = default;
00279 
00280         NodeInfo(
00281           const std::string& hostname_,
00282           const std::string& port_,
00283           const tls::Pem& cert_ = {}) :
00284           hostname(hostname_),
00285           port(port_),
00286           cert(cert_)
00287         {}
00288       };
00289 
00290       using Nodes = std::unordered_map<NodeId, NodeInfo>;
00291 
00292       SeqNo idx;
00293       Nodes nodes;
00294     };
00295 
00296     Consensus(NodeId id) : state(Backup), local_id(id) {}
00297     virtual ~Consensus() {}
00298 
00299     virtual NodeId id()
00300     {
00301       return local_id;
00302     }
00303 
00304     virtual bool is_primary()
00305     {
00306       return state == Primary;
00307     }
00308 
00309     virtual bool is_backup()
00310     {
00311       return state == Backup;
00312     }
00313 
00314     virtual void force_become_primary()
00315     {
00316       state = Primary;
00317     }
00318 
00319     virtual void force_become_primary(
00320       SeqNo, View, const std::vector<SeqNo>&, SeqNo)
00321     {
00322       state = Primary;
00323     }
00324 
00325     virtual void init_as_backup(SeqNo, View, const std::vector<SeqNo>&)
00326     {
00327       state = Backup;
00328     }
00329 
00330     virtual bool replicate(const BatchVector& entries, View view) = 0;
00331     virtual std::pair<View, SeqNo> get_committed_txid() = 0;
00332     virtual std::optional<std::pair<View, SeqNo>> get_signable_txid() = 0;
00333 
00334     virtual View get_view(SeqNo seqno) = 0;
00335     virtual View get_view() = 0;
00336     virtual std::vector<SeqNo> get_view_history(SeqNo) = 0;
00337     virtual void initialise_view_history(const std::vector<SeqNo>&) = 0;
00338     virtual SeqNo get_committed_seqno() = 0;
00339     virtual NodeId primary() = 0;
00340     virtual std::set<NodeId> active_nodes() = 0;
00341 
00342     virtual void recv_message(OArray&& oa) = 0;
00343     virtual void add_configuration(
00344       SeqNo seqno, const Configuration::Nodes& conf) = 0;
00345     virtual Configuration::Nodes get_latest_configuration() const = 0;
00346 
00347     virtual bool on_request(const kv::TxHistory::RequestCallbackArgs&)
00348     {
00349       return true;
00350     }
00351 
00352     virtual void periodic(std::chrono::milliseconds) {}
00353     virtual void periodic_end() {}
00354 
00355     struct Statistics
00356     {
00357       uint32_t time_spent = 0;
00358       uint32_t count_num_samples = 0;
00359       uint32_t tx_count = 0;
00360     };
00361     virtual Statistics get_statistics()
00362     {
00363       return Statistics();
00364     }
00365     virtual void enable_all_domains() {}
00366 
00367     virtual uint32_t node_count() = 0;
00368     virtual void emit_signature() = 0;
00369     virtual ConsensusType type() = 0;
00370   };
00371 
00372   struct PendingTxInfo
00373   {
00374     CommitSuccess success;
00375     TxHistory::RequestID reqid;
00376     std::vector<uint8_t> data;
00377 
00378     PendingTxInfo(
00379       CommitSuccess success_,
00380       TxHistory::RequestID reqid_,
00381       std::vector<uint8_t>&& data_) :
00382       success(success_),
00383       reqid(std::move(reqid_)),
00384       data(std::move(data_))
00385     {}
00386   };
00387 
00388   using PendingTx = std::function<PendingTxInfo()>;
00389 
00390   class MovePendingTx
00391   {
00392   private:
00393     std::vector<uint8_t> data;
00394     kv::TxHistory::RequestID req_id;
00395 
00396   public:
00397     MovePendingTx(
00398       std::vector<uint8_t>&& data_, kv::TxHistory::RequestID&& req_id_) :
00399       data(std::move(data_)),
00400       req_id(std::move(req_id_))
00401     {}
00402 
00403     PendingTxInfo operator()()
00404     {
00405       return PendingTxInfo(
00406         CommitSuccess::OK, std::move(req_id), std::move(data));
00407     }
00408   };
00409 
00410   class AbstractTxEncryptor : public Syncable
00411   {
00412   public:
00413     virtual ~AbstractTxEncryptor() {}
00414     virtual void encrypt(
00415       const std::vector<uint8_t>& plain,
00416       const std::vector<uint8_t>& additional_data,
00417       std::vector<uint8_t>& serialised_header,
00418       std::vector<uint8_t>& cipher,
00419       kv::Version version,
00420       bool is_snapshot = false) = 0;
00421     virtual bool decrypt(
00422       const std::vector<uint8_t>& cipher,
00423       const std::vector<uint8_t>& additional_data,
00424       const std::vector<uint8_t>& serialised_header,
00425       std::vector<uint8_t>& plain,
00426       kv::Version version) = 0;
00427     virtual void set_iv_id(size_t id) = 0;
00428     virtual size_t get_header_length() = 0;
00429     virtual void update_encryption_key(
00430       Version version, const std::vector<uint8_t>& raw_ledger_key) = 0;
00431   };
00432 
00433   using EncryptorPtr = std::shared_ptr<AbstractTxEncryptor>;
00434 
00435   class AbstractChangeSet
00436   {
00437   public:
00438     virtual ~AbstractChangeSet() = default;
00439 
00440     virtual bool has_writes() const = 0;
00441   };
00442 
00443   class AbstractCommitter
00444   {
00445   public:
00446     virtual ~AbstractCommitter() = default;
00447 
00448     virtual bool has_writes() = 0;
00449     virtual bool prepare() = 0;
00450     virtual void commit(Version v) = 0;
00451     virtual void post_commit() = 0;
00452   };
00453 
00454   class AbstractTxView
00455   {
00456   public:
00457     virtual ~AbstractTxView() = default;
00458   };
00459 
00460   struct NamedMap
00461   {
00462   protected:
00463     std::string name;
00464 
00465   public:
00466     NamedMap(const std::string& s) : name(s) {}
00467     virtual ~NamedMap() = default;
00468 
00469     const std::string& get_name() const
00470     {
00471       return name;
00472     }
00473   };
00474 
00475   class AbstractStore;
00476   class AbstractMap : public std::enable_shared_from_this<AbstractMap>,
00477                       public NamedMap
00478   {
00479   public:
00480     class Snapshot
00481     {
00482     public:
00483       virtual ~Snapshot() = default;
00484       virtual void serialise(KvStoreSerialiser& s) = 0;
00485       virtual SecurityDomain get_security_domain() = 0;
00486     };
00487 
00488     using NamedMap::NamedMap;
00489     virtual ~AbstractMap() {}
00490     virtual bool operator==(const AbstractMap& that) const = 0;
00491     virtual bool operator!=(const AbstractMap& that) const = 0;
00492 
00493     virtual std::unique_ptr<AbstractCommitter> create_committer(
00494       AbstractChangeSet* changes) = 0;
00495 
00496     virtual AbstractStore* get_store() = 0;
00497     virtual void serialise_changes(
00498       const AbstractChangeSet* changes,
00499       KvStoreSerialiser& s,
00500       bool include_reads) = 0;
00501     virtual void compact(Version v) = 0;
00502     virtual std::unique_ptr<Snapshot> snapshot(Version v) = 0;
00503     virtual void post_compact() = 0;
00504     virtual void rollback(Version v) = 0;
00505     virtual void lock() = 0;
00506     virtual void unlock() = 0;
00507     virtual SecurityDomain get_security_domain() = 0;
00508     virtual bool is_replicated() = 0;
00509     virtual void clear() = 0;
00510 
00511     virtual AbstractMap* clone(AbstractStore* store) = 0;
00512     virtual void swap(AbstractMap* map) = 0;
00513   };
00514 
00515   class AbstractStore
00516   {
00517   public:
00518     class AbstractSnapshot
00519     {
00520     public:
00521       virtual ~AbstractSnapshot() = default;
00522       virtual Version get_version() const = 0;
00523       virtual std::vector<uint8_t> serialise(
00524         std::shared_ptr<AbstractTxEncryptor> encryptor) = 0;
00525     };
00526 
00527     virtual ~AbstractStore() {}
00528 
00529     virtual void lock() = 0;
00530     virtual void unlock() = 0;
00531 
00532     virtual Version next_version() = 0;
00533     virtual TxID next_txid() = 0;
00534 
00535     virtual Version current_version() = 0;
00536     virtual TxID current_txid() = 0;
00537 
00538     virtual Version commit_version() = 0;
00539 
00540     virtual std::shared_ptr<AbstractMap> get_map(
00541       kv::Version v, const std::string& map_name) = 0;
00542     virtual void add_dynamic_map(
00543       kv::Version v, const std::shared_ptr<AbstractMap>& map) = 0;
00544     virtual bool is_map_replicated(const std::string& map_name) = 0;
00545 
00546     virtual std::shared_ptr<Consensus> get_consensus() = 0;
00547     virtual std::shared_ptr<TxHistory> get_history() = 0;
00548     virtual EncryptorPtr get_encryptor() = 0;
00549     virtual DeserialiseSuccess deserialise(
00550       const std::vector<uint8_t>& data,
00551       bool public_only = false,
00552       kv::Term* term = nullptr) = 0;
00553     virtual void compact(Version v) = 0;
00554     virtual void rollback(Version v, std::optional<Term> t = std::nullopt) = 0;
00555     virtual void set_term(Term t) = 0;
00556     virtual CommitSuccess commit(
00557       const TxID& txid, PendingTx&& pending_tx, bool globally_committable) = 0;
00558 
00559     virtual std::unique_ptr<AbstractSnapshot> snapshot(Version v) = 0;
00560     virtual std::vector<uint8_t> serialise_snapshot(
00561       std::unique_ptr<AbstractSnapshot> snapshot) = 0;
00562     virtual DeserialiseSuccess deserialise_snapshot(
00563       const std::vector<uint8_t>& data,
00564       std::vector<Version>* view_history = nullptr,
00565       bool public_only = false) = 0;
00566 
00567     virtual size_t commit_gap() = 0;
00568   };
00569 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/kv_types.h...
Preprocessing /data/git/CCF/src/kv/map.h...
#include kv_types.h: already included! skipping...
#include ds/nonstd.h: not found! skipping...
#include serialised_entry.h: already included! skipping...
#include serialised_entry.h: already included! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include serialised_entry.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include kv/untyped_map.h: not found! skipping...
#include kv/untyped_tx_view.h: not found! skipping...
#include kv_types.h: already included! skipping...
Preprocessor output (size: 2505 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/kv/map.h" 2
00007 # 7 "/data/git/CCF/src/kv/map.h" 2
00008 # 8 "/data/git/CCF/src/kv/map.h" 2
00009 # 9 "/data/git/CCF/src/kv/map.h" 2
00010 
00011 namespace kv
00012 {
00013   template <typename K, typename V, typename KSerialiser, typename VSerialiser>
00014   class TypedMap : public NamedMap
00015   {
00016   protected:
00017     using This = TypedMap<K, V, KSerialiser, VSerialiser>;
00018 
00019   public:
00020     // Expose correct public aliases of types
00021     using VersionV = VersionV<V>;
00022 
00023     using Write = std::map<K, std::optional<V>>;
00024 
00025     using CommitHook = CommitHook<Write>;
00026 
00027     using ReadOnlyTxView = kv::ReadOnlyTxView<K, V, KSerialiser, VSerialiser>;
00028     using TxView = kv::TxView<K, V, KSerialiser, VSerialiser>;
00029 
00030     using KeySerialiser = KSerialiser;
00031     using ValueSerialiser = VSerialiser;
00032 
00033     using NamedMap::NamedMap;
00034 
00035     static kv::untyped::Map::CommitHook wrap_commit_hook(const CommitHook& hook)
00036     {
00037       return [hook](Version v, const kv::untyped::Write& w) {
00038         Write typed_writes;
00039         for (const auto& [uk, opt_uv] : w)
00040         {
00041           if (!opt_uv.has_value())
00042           {
00043             // Deletions are indicated by nullopt. We cannot deserialise them,
00044             // they are deletions here as well
00045             typed_writes[KSerialiser::from_serialised(uk)] = std::nullopt;
00046           }
00047           else
00048           {
00049             typed_writes[KSerialiser::from_serialised(uk)] =
00050               VSerialiser::from_serialised(opt_uv.value());
00051           }
00052         }
00053 
00054         hook(v, typed_writes);
00055       };
00056     }
00057   };
00058 
00059   template <
00060     typename K,
00061     typename V,
00062     template <typename>
00063     typename KSerialiser,
00064     template <typename> typename VSerialiser = KSerialiser>
00065   using MapSerialisedWith = TypedMap<K, V, KSerialiser<K>, VSerialiser<V>>;
00066 
00067   template <typename K, typename V>
00068   using JsonSerialisedMap =
00069     MapSerialisedWith<K, V, kv::serialisers::JsonSerialiser>;
00070 
00071   template <typename K, typename V>
00072   using RawCopySerialisedMap = TypedMap<
00073     K,
00074     V,
00075     kv::serialisers::BlitSerialiser<K>,
00076     kv::serialisers::BlitSerialiser<V>>;
00077 
00078   template <typename K, typename V>
00079   using MsgPackSerialisedMap =
00080     MapSerialisedWith<K, V, kv::serialisers::MsgPackSerialiser>;
00081 
00082   /** Short name for default-serialised maps, using msgpack serialisers. Support
00083    * for custom types can be added through the MSGPACK_DEFINE macro
00084    */
00085   template <typename K, typename V>
00086   using Map = MsgPackSerialisedMap<K, V>;
00087 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/map.h...
Preprocessing /data/git/CCF/src/kv/msgpack_serialise.h...
#include ds/msgpack_adaptor_nlohmann.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include ds/buffer.h: not found! skipping...
#include kv_types.h: already included! skipping...
#include serialised_entry.h: already included! skipping...
#include optional: not found! skipping...
#include serialised_entry.h: already included! skipping...
#include iterator: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include sstream: not found! skipping...
#include type_traits: not found! skipping...
Preprocessor output (size: 3113 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 # 7 "/data/git/CCF/src/kv/msgpack_serialise.h" 2
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 MSGPACK_ADD_ENUM(kv::KvOperationType);
00017 MSGPACK_ADD_ENUM(kv::SecurityDomain);
00018 
00019 namespace kv
00020 {
00021   class MsgPackWriter
00022   {
00023   private:
00024     msgpack::sbuffer sb;
00025 
00026   public:
00027     template <typename T>
00028     void append(T&& t)
00029     {
00030       msgpack::pack(sb, std::forward<T>(t));
00031     }
00032 
00033     // Where we have pre-serialised data, we dump it length-prefixed into the
00034     // output buffer. If we call append, then pack will prefix the data with
00035     // some type information, potentially redundantly repacking already-packed
00036     // data. This means the output is no longer a stream of msgpack objects!
00037     // Parsers are expected to know the type of the Ks and Vs for the tables
00038     // they care about, and skip over any others
00039     template <typename T>
00040     void append_pre_serialised(const T& entry)
00041     {
00042       const uint64_t size = entry.size();
00043       sb.write(reinterpret_cast<char const*>(&size), sizeof(size));
00044       if (entry.size() > 0)
00045       {
00046         sb.write(reinterpret_cast<char const*>(entry.data()), entry.size());
00047       }
00048     }
00049 
00050     void clear()
00051     {
00052       sb.clear();
00053     }
00054 
00055     bool is_empty()
00056     {
00057       return sb.size() == 0;
00058     }
00059 
00060     std::vector<uint8_t> get_raw_data()
00061     {
00062       return {reinterpret_cast<uint8_t*>(sb.data()),
00063               reinterpret_cast<uint8_t*>(sb.data()) + sb.size()};
00064     }
00065   };
00066 
00067   class MsgPackReader
00068   {
00069   public:
00070     const char* data_ptr;
00071     size_t data_offset;
00072     size_t data_size;
00073     msgpack::object_handle msg;
00074 
00075   public:
00076     MsgPackReader(const MsgPackReader& other) = delete;
00077     MsgPackReader& operator=(const MsgPackReader& other) = delete;
00078 
00079     MsgPackReader(const uint8_t* data_in_ptr = nullptr, size_t data_in_size = 0)
00080     {
00081       init(data_in_ptr, data_in_size);
00082     }
00083 
00084     void init(const uint8_t* data_in_ptr, size_t data_in_size)
00085     {
00086       data_offset = 0;
00087       data_ptr = (const char*)data_in_ptr;
00088       data_size = data_in_size;
00089     }
00090 
00091     template <typename T>
00092     T read_next()
00093     {
00094       msgpack::unpack(msg, data_ptr, data_size, data_offset);
00095       return msg->as<T>();
00096     }
00097 
00098     template <typename T>
00099     T read_next_pre_serialised()
00100     {
00101       auto remainder = data_size - data_offset;
00102       auto data = reinterpret_cast<const uint8_t*>(data_ptr + data_offset);
00103       const auto entry_size = serialized::read<uint64_t>(data, remainder);
00104 
00105       if (remainder < entry_size)
00106       {
00107         throw std::runtime_error(fmt::format(
00108           "Expected {} byte entry, found only {}", entry_size, remainder));
00109       }
00110 
00111       const auto bytes_read = data_size - data_offset - remainder;
00112       data_offset += bytes_read;
00113 
00114       const auto before_offset = data_offset;
00115       data_offset += entry_size;
00116       return {data_ptr + before_offset, data_ptr + data_offset};
00117     }
00118 
00119     bool is_eos()
00120     {
00121       return data_offset >= data_size;
00122     }
00123   };
00124 
00125   using KvStoreSerialiser = GenericSerialiseWrapper<MsgPackWriter>;
00126   using KvStoreDeserialiser = GenericDeserialiseWrapper<MsgPackReader>;
00127 }
00128 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/msgpack_serialise.h...
Preprocessing /data/git/CCF/src/kv/nljson_serialise.h...
#include ds/json.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include generic_serialise_wrapper.h: already included! skipping...
#include iterator: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include sstream: not found! skipping...
#include type_traits: not found! skipping...
Preprocessor output (size: 1556 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace kv
00015 {
00016   class JsonWriter
00017   {
00018   private:
00019     nlohmann::json arr;
00020 
00021   public:
00022     template <typename T>
00023     void append(T&& t)
00024     {
00025       nlohmann::json obj = t;
00026       arr.push_back(obj);
00027     }
00028 
00029     void clear()
00030     {
00031       arr.clear();
00032     }
00033 
00034     bool is_empty()
00035     {
00036       return arr.empty();
00037     }
00038 
00039     std::vector<uint8_t> get_raw_data()
00040     {
00041       return nlohmann::json::to_msgpack(arr);
00042     }
00043   };
00044 
00045   class JsonReader
00046   {
00047   public:
00048     nlohmann::json arr;
00049     size_t data_offset;
00050 
00051   public:
00052     JsonReader(const JsonReader& other) = delete;
00053     JsonReader& operator=(const JsonReader& other) = delete;
00054 
00055     JsonReader(const uint8_t* data_in_ptr = nullptr, size_t data_in_size = 0)
00056     {
00057       init(data_in_ptr, data_in_size);
00058     }
00059 
00060     void init(const uint8_t* data_in_ptr, size_t data_in_size)
00061     {
00062       data_offset = 0;
00063       if (data_in_ptr && data_in_size)
00064       {
00065         arr =
00066           nlohmann::json::from_msgpack(data_in_ptr, data_in_ptr + data_in_size);
00067       }
00068     }
00069 
00070     template <typename T>
00071     T read_next()
00072     {
00073       T ret = peek_next<T>();
00074       ++data_offset;
00075       return ret;
00076     }
00077 
00078     template <typename T>
00079     T peek_next()
00080     {
00081       T ret = arr[data_offset];
00082       return ret;
00083     }
00084 
00085     bool is_eos()
00086     {
00087       return data_offset >= arr.size();
00088     }
00089   };
00090 
00091   using KvStoreSerialiser = GenericSerialiseWrapper<JsonWriter>;
00092   using KvStoreDeserialiser = GenericDeserialiseWrapper<JsonReader>;
00093 }
00094 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/nljson_serialise.h...
Reading /data/git/CCF/src/kv/README.md...
Preprocessing /data/git/CCF/src/kv/serialise_entry_blit.h...
#include ds/nonstd.h: not found! skipping...
#include serialised_entry.h: already included! skipping...
Preprocessor output (size: 1704 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace kv::serialisers
00009 {
00010   template <typename T>
00011   struct BlitSerialiser
00012   {
00013     static SerialisedEntry to_serialised(const T& t)
00014     {
00015       if constexpr (std::is_same_v<T, std::vector<uint8_t>>)
00016       {
00017         return SerialisedEntry(t.begin(), t.end());
00018       }
00019       else if constexpr (nonstd::is_std_array<T>::value)
00020       {
00021         return SerialisedEntry(t.begin(), t.end());
00022       }
00023       else if constexpr (std::is_integral_v<T>)
00024       {
00025         SerialisedEntry s(sizeof(t));
00026         std::memcpy(s.data(), (uint8_t*)&t, sizeof(t));
00027         return s;
00028       }
00029       else if constexpr (std::is_same_v<T, std::string>)
00030       {
00031         return SerialisedEntry(t.begin(), t.end());
00032       }
00033       else
00034       {
00035         static_assert(
00036           nonstd::dependent_false<T>::value, "Can't serialise this type");
00037       }
00038     }
00039 
00040     static T from_serialised(const SerialisedEntry& rep)
00041     {
00042       if constexpr (std::is_same_v<T, std::vector<uint8_t>>)
00043       {
00044         return T(rep.begin(), rep.end());
00045       }
00046       else if constexpr (nonstd::is_std_array<T>::value)
00047       {
00048         return T(rep.begin(), rep.end());
00049       }
00050       else if constexpr (std::is_integral_v<T>)
00051       {
00052         if (rep.size() != sizeof(T))
00053         {
00054           throw std::logic_error("Wrong size for deserialising");
00055         }
00056         return *(T*)rep.data();
00057       }
00058       else if constexpr (std::is_same_v<T, std::string>)
00059       {
00060         return T(rep.begin(), rep.end());
00061       }
00062       else
00063       {
00064         static_assert(
00065           nonstd::dependent_false<T>::value, "Can't deserialise this type");
00066       }
00067     }
00068   };
00069 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/serialise_entry_blit.h...
Preprocessing /data/git/CCF/src/kv/serialise_entry_json.h...
#include serialised_entry.h: already included! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 553 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv::serialisers
00010 {
00011   template <typename T>
00012   struct JsonSerialiser
00013   {
00014     static SerialisedEntry to_serialised(const T& t)
00015     {
00016       const nlohmann::json j = t;
00017       const auto dumped = j.dump();
00018       return SerialisedEntry(dumped.begin(), dumped.end());
00019     }
00020 
00021     static T from_serialised(const SerialisedEntry& rep)
00022     {
00023       const auto j = nlohmann::json::parse(rep.begin(), rep.end());
00024       return j.get<T>();
00025     }
00026   };
00027 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/serialise_entry_json.h...
Preprocessing /data/git/CCF/src/kv/serialise_entry_msgpack.h...
#include serialised_entry.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 824 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv::serialisers
00010 {
00011   namespace detail
00012   {
00013     struct SerialisedEntryWriter
00014     {
00015       SerialisedEntry& entry;
00016 
00017       void write(const char* d, size_t n)
00018       {
00019         entry.insert(entry.end(), d, d + n);
00020       }
00021     };
00022   }
00023 
00024   template <typename T>
00025   struct MsgPackSerialiser
00026   {
00027     static SerialisedEntry to_serialised(const T& t)
00028     {
00029       SerialisedEntry e;
00030       detail::SerialisedEntryWriter w{e};
00031       msgpack::pack(w, t);
00032       return e;
00033     }
00034 
00035     static T from_serialised(const SerialisedEntry& rep)
00036     {
00037       msgpack::object_handle oh =
00038         msgpack::unpack(reinterpret_cast<const char*>(rep.data()), rep.size());
00039       auto object = oh.get();
00040       return object.as<T>();
00041     }
00042   };
00043 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/serialise_entry_msgpack.h...
Preprocessing /data/git/CCF/src/kv/serialised_entry.h...
#include msgpack/msgpack.hpp: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include small_vector/SmallVector.h: not found! skipping...
Preprocessor output (size: 205 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv::serialisers
00010 {
00011   using SerialisedEntry = llvm_vecsmall::SmallVector<uint8_t, 8>;
00012 }
00013 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/serialised_entry.h...
Preprocessing /data/git/CCF/src/kv/serialiser_declare.h...
Preprocessor output (size: 722 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 namespace kv
00006 {
00007   // This awkward forward declaration allows the <K,V>-templated serialisers to
00008   // depend on kv_types.h, and removes the reverse dependency. Once these
00009   // serialisers work purely with pre-serialised byte-vectors, we can create
00010   // replace this with an AbstractTxSerialiser pattern.
00011   template <typename W>
00012   class GenericSerialiseWrapper;
00013 
00014   template <typename W>
00015   class GenericDeserialiseWrapper;
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024   class MsgPackWriter;
00025   using KvStoreSerialiser = GenericSerialiseWrapper<MsgPackWriter>;
00026 
00027   class MsgPackReader;
00028   using KvStoreDeserialiser = GenericDeserialiseWrapper<MsgPackReader>;
00029 
00030 }
00031 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/serialiser_declare.h...
Preprocessing /data/git/CCF/src/kv/snapshot.h...
#include kv/kv_types.h: not found! skipping...
Preprocessor output (size: 1691 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace kv
00008 {
00009   class StoreSnapshot : public AbstractStore::AbstractSnapshot
00010   {
00011   private:
00012     Version version;
00013 
00014     std::vector<std::unique_ptr<kv::AbstractMap::Snapshot>> snapshots;
00015     std::optional<std::vector<uint8_t>> hash_at_snapshot = std::nullopt;
00016     std::optional<std::vector<Version>> view_history = std::nullopt;
00017 
00018   public:
00019     StoreSnapshot(Version version_) : version(version_) {}
00020 
00021     void add_map_snapshot(std::unique_ptr<kv::AbstractMap::Snapshot> snapshot)
00022     {
00023       snapshots.push_back(std::move(snapshot));
00024     }
00025 
00026     void add_hash_at_snapshot(std::vector<uint8_t>&& hash_at_snapshot_)
00027     {
00028       hash_at_snapshot = std::move(hash_at_snapshot_);
00029     }
00030 
00031     void add_view_history(std::vector<Version>&& view_history_)
00032     {
00033       view_history = std::move(view_history_);
00034     }
00035 
00036     Version get_version() const
00037     {
00038       return version;
00039     }
00040 
00041     std::vector<uint8_t> serialise(
00042       std::shared_ptr<AbstractTxEncryptor> encryptor)
00043     {
00044       KvStoreSerialiser serialiser(encryptor, version, true);
00045 
00046       if (hash_at_snapshot.has_value())
00047       {
00048         serialiser.serialise_raw(hash_at_snapshot.value());
00049       }
00050 
00051       if (view_history.has_value())
00052       {
00053         serialiser.serialise_view_history(view_history.value());
00054       }
00055 
00056       for (auto domain : {SecurityDomain::PUBLIC, SecurityDomain::PRIVATE})
00057       {
00058         for (const auto& it : snapshots)
00059         {
00060           if (it->get_security_domain() == domain)
00061           {
00062             it->serialise(serialiser);
00063           }
00064         }
00065       }
00066 
00067       return serialiser.get_raw_data();
00068     }
00069   };
00070 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/snapshot.h...
Preprocessing /data/git/CCF/src/kv/store.h...
#include ds/ccf_exception.h: not found! skipping...
#include kv/msgpack_serialise.h: not found! skipping...
#include kv_types.h: already included! skipping...
#include kv_types.h: already included! skipping...
#include serialise_entry_blit.h: already included! skipping...
#include serialise_entry_json.h: already included! skipping...
#include serialise_entry_msgpack.h: already included! skipping...
#include tx_view.h: already included! skipping...
#include node/entities.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include node/signatures.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include kv_serialiser.h: already included! skipping...
#include kv_types.h: already included! skipping...
#include map.h: already included! skipping...
  #include kv_types.h: already included! skipping...
#include functional: not found! skipping...
#include map: not found! skipping...
#include list: not found! skipping...
#include view_containers.h: already included! skipping...
#include fmt/format.h: not found! skipping...
Preprocessor output (size: 35238 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/kv/store.h" 2
00007 
00008 # 8 "/data/git/CCF/src/kv/store.h" 2
00009 
00010 
00011 
00012 # 12 "/data/git/CCF/src/kv/store.h" 2
00013 # 13 "/data/git/CCF/src/kv/store.h" 2
00014 
00015 
00016 
00017 
00018 namespace kv
00019 {
00020   class StoreState
00021   {
00022   protected:
00023     // All collections of Map must be ordered so that we lock their contained
00024     // maps in a stable order. The order here is by map name. The version
00025     // indicates the version at which the Map was created.
00026     using Maps = std::
00027       map<std::string, std::pair<kv::Version, std::shared_ptr<untyped::Map>>>;
00028     SpinLock maps_lock;
00029     Maps maps;
00030 
00031     SpinLock version_lock;
00032     Version version = 0;
00033     Version compacted = 0;
00034     Term term = 0;
00035     Version last_replicated = 0;
00036     Version last_committable = 0;
00037     Version rollback_count = 0;
00038 
00039     std::unordered_map<Version, std::pair<PendingTx, bool>> pending_txs;
00040 
00041   public:
00042     void clear()
00043     {
00044       std::lock_guard<SpinLock> mguard(maps_lock);
00045       std::lock_guard<SpinLock> vguard(version_lock);
00046 
00047       maps.clear();
00048       pending_txs.clear();
00049 
00050       version = 0;
00051       compacted = 0;
00052       term = 0;
00053 
00054       last_replicated = 0;
00055       last_committable = 0;
00056       rollback_count = 0;
00057     }
00058   };
00059 
00060   class Store : public AbstractStore, public StoreState
00061   {
00062   private:
00063     using Hooks = std::map<std::string, kv::untyped::Map::CommitHook>;
00064     Hooks local_hooks;
00065     Hooks global_hooks;
00066 
00067     std::shared_ptr<Consensus> consensus = nullptr;
00068     std::shared_ptr<TxHistory> history = nullptr;
00069     std::shared_ptr<ccf::ProgressTracker> progress_tracker = nullptr;
00070     EncryptorPtr encryptor = nullptr;
00071 
00072     kv::ReplicateType replicate_type = kv::ReplicateType::ALL;
00073     std::unordered_set<std::string> replicated_tables;
00074 
00075     // Generally we will only accept deserialised views if they are contiguous -
00076     // at Version N we reject everything but N+1. The exception is when a Store
00077     // is used for historical queries, where it may deserialise arbitrary
00078     // transactions. In this case the Store is a useful container for a set of
00079     // Tables, but its versioning invariants are ignored.
00080     const bool strict_versions = true;
00081 
00082     DeserialiseSuccess commit_deserialised(
00083       OrderedChanges& changes, Version& v, const MapCollection& new_maps)
00084     {
00085       auto c = apply_changes(
00086         changes, [v]() { return v; }, new_maps);
00087       if (!c.has_value())
00088       {
00089         LOG_FAIL_FMT("Failed to commit deserialised Tx at version {}", v);
00090         return DeserialiseSuccess::FAILED;
00091       }
00092       {
00093         std::lock_guard<SpinLock> vguard(version_lock);
00094         version = v;
00095         last_replicated = version;
00096       }
00097       return DeserialiseSuccess::PASS;
00098     }
00099 
00100     bool has_map_internal(const std::string& name)
00101     {
00102       auto search = maps.find(name);
00103       if (search != maps.end())
00104         return true;
00105 
00106       return false;
00107     }
00108 
00109   public:
00110     Store(bool strict_versions_ = true) : strict_versions(strict_versions_) {}
00111 
00112     Store(
00113       const ReplicateType& replicate_type_,
00114       const std::unordered_set<std::string>& replicated_tables_) :
00115       replicate_type(replicate_type_),
00116       replicated_tables(replicated_tables_)
00117     {}
00118 
00119     Store(std::shared_ptr<Consensus> consensus_) : consensus(consensus_) {}
00120 
00121     Store(const Store& that) = delete;
00122 
00123     std::shared_ptr<Consensus> get_consensus() override
00124     {
00125       return consensus;
00126     }
00127 
00128     void set_consensus(std::shared_ptr<Consensus> consensus_)
00129     {
00130       consensus = consensus_;
00131     }
00132 
00133     std::shared_ptr<TxHistory> get_history() override
00134     {
00135       return history;
00136     }
00137 
00138     void set_history(std::shared_ptr<TxHistory> history_)
00139     {
00140       history = history_;
00141     }
00142 
00143     std::shared_ptr<ccf::ProgressTracker> get_progress_tracker()
00144     {
00145       return progress_tracker;
00146     }
00147 
00148     void set_progress_tracker(
00149       std::shared_ptr<ccf::ProgressTracker> progress_tracker_)
00150     {
00151       progress_tracker = progress_tracker_;
00152     }
00153 
00154     void set_encryptor(const EncryptorPtr& encryptor_)
00155     {
00156       encryptor = encryptor_;
00157     }
00158 
00159     EncryptorPtr get_encryptor() override
00160     {
00161       return encryptor;
00162     }
00163 
00164     /** Get a map by name, iff it exists at the given version.
00165      *
00166      * This means a prior transaction must have created the map, and
00167      * successfully committed at a version <= v. If this has not happened (the
00168      * map has never been created, or never been committed, or committed at a
00169      * later version) this will return nullptr.
00170      *
00171      * @param v Version at which the map must exist
00172      * @param map_name Name of requested map
00173      *
00174      * @return Abstract shared-owning pointer to requested map, or nullptr if no
00175      * such map exists
00176      */
00177     std::shared_ptr<AbstractMap> get_map(
00178       kv::Version v, const std::string& map_name) override
00179     {
00180       return get_map_internal(v, map_name);
00181     }
00182 
00183     std::shared_ptr<kv::untyped::Map> get_map_internal(
00184       kv::Version v, const std::string& map_name)
00185     {
00186       auto search = maps.find(map_name);
00187       if (search != maps.end())
00188       {
00189         const auto& [map_creation_version, map_ptr] = search->second;
00190         if (v >= map_creation_version || map_creation_version == NoVersion)
00191         {
00192           return map_ptr;
00193         }
00194       }
00195 
00196       return nullptr;
00197     }
00198 
00199     /** Transfer ownership of a dynamically created map to this Store.
00200      *
00201      * Should be called as part of the commit process, once a transaction is
00202      * known to be conflict-free and has been assigned a unique Version. This
00203      * publishes dynamically created Maps so they can be retrieved via get_map
00204      * in future transactions.
00205      *
00206      * @param v Version at which map is being committed/created
00207      * @param map Map to add
00208      */
00209     void add_dynamic_map(
00210       kv::Version v, const std::shared_ptr<AbstractMap>& map_) override
00211     {
00212       auto map = std::dynamic_pointer_cast<kv::untyped::Map>(map_);
00213       if (map == nullptr)
00214       {
00215         throw std::logic_error(fmt::format(
00216           "Can't add dynamic map - {} is not of expected type",
00217           map_->get_name()));
00218       }
00219 
00220       const auto map_name = map->get_name();
00221       if (get_map(v, map_name) != nullptr)
00222       {
00223         throw std::logic_error(fmt::format(
00224           "Can't add dynamic map - already have a map named {}", map_name));
00225       }
00226 
00227       LOG_DEBUG_FMT("Adding newly created map '{}' at version {}", map_name, v);
00228       maps[map_name] = std::make_pair(v, map);
00229 
00230       {
00231         // If we have any hooks for the given map name, set them on this new map
00232         const auto local_it = local_hooks.find(map_name);
00233         if (local_it != local_hooks.end())
00234         {
00235           map->set_local_hook(local_it->second);
00236         }
00237 
00238         const auto global_it = global_hooks.find(map_name);
00239         if (global_it != global_hooks.end())
00240         {
00241           map->set_global_hook(global_it->second);
00242         }
00243       }
00244     }
00245 
00246     bool is_map_replicated(const std::string& name) override
00247     {
00248       switch (replicate_type)
00249       {
00250         case (kv::ReplicateType::ALL):
00251         {
00252           return true;
00253         }
00254 
00255         case (kv::ReplicateType::NONE):
00256         {
00257           return false;
00258         }
00259 
00260         case (kv::ReplicateType::SOME):
00261         {
00262           return replicated_tables.find(name) != replicated_tables.end();
00263         }
00264 
00265         default:
00266         {
00267           throw std::logic_error("Unhandled ReplicateType value");
00268         }
00269       }
00270     }
00271 
00272     std::unique_ptr<AbstractSnapshot> snapshot(Version v) override
00273     {
00274       if (v < commit_version())
00275       {
00276         throw std::logic_error(fmt::format(
00277           "Cannot snapshot at version {} which is earlier than committed "
00278           "version {} ",
00279           v,
00280           commit_version()));
00281       }
00282 
00283       if (v > current_version())
00284       {
00285         throw std::logic_error(fmt::format(
00286           "Cannot snapshot at version {} which is later than current "
00287           "version {} ",
00288           v,
00289           current_version()));
00290       }
00291 
00292       auto snapshot = std::make_unique<StoreSnapshot>(v);
00293 
00294       {
00295         std::lock_guard<SpinLock> mguard(maps_lock);
00296 
00297         for (auto& it : maps)
00298         {
00299           auto& [_, map] = it.second;
00300           map->lock();
00301         }
00302 
00303         for (auto& it : maps)
00304         {
00305           auto& [_, map] = it.second;
00306           snapshot->add_map_snapshot(map->snapshot(v));
00307         }
00308 
00309         auto h = get_history();
00310         if (h)
00311         {
00312           snapshot->add_hash_at_snapshot(h->get_raw_leaf(v));
00313         }
00314 
00315         auto c = get_consensus();
00316         if (c)
00317         {
00318           snapshot->add_view_history(c->get_view_history(v));
00319         }
00320 
00321         for (auto& it : maps)
00322         {
00323           auto& [_, map] = it.second;
00324           map->unlock();
00325         }
00326       }
00327 
00328       return snapshot;
00329     }
00330 
00331     std::vector<uint8_t> serialise_snapshot(
00332       std::unique_ptr<AbstractSnapshot> snapshot) override
00333     {
00334       auto e = get_encryptor();
00335       return snapshot->serialise(e);
00336     }
00337 
00338     DeserialiseSuccess deserialise_snapshot(
00339       const std::vector<uint8_t>& data,
00340       std::vector<Version>* view_history = nullptr,
00341       bool public_only = false) override
00342     {
00343       auto e = get_encryptor();
00344       auto d = KvStoreDeserialiser(
00345         e,
00346         public_only ? kv::SecurityDomain::PUBLIC :
00347                       std::optional<kv::SecurityDomain>());
00348 
00349       auto v_ = d.init(data.data(), data.size());
00350       if (!v_.has_value())
00351       {
00352         LOG_FAIL_FMT("Initialisation of deserialise object failed");
00353         return DeserialiseSuccess::FAILED;
00354       }
00355       auto v = v_.value();
00356 
00357       std::lock_guard<SpinLock> mguard(maps_lock);
00358 
00359       for (auto& it : maps)
00360       {
00361         auto& [_, map] = it.second;
00362         map->lock();
00363       }
00364 
00365       std::vector<uint8_t> hash_at_snapshot;
00366       auto h = get_history();
00367       if (h)
00368       {
00369         hash_at_snapshot = d.deserialise_raw();
00370       }
00371 
00372       std::vector<Version> view_history_;
00373       if (view_history)
00374       {
00375         view_history_ = d.deserialise_view_history();
00376       }
00377 
00378       OrderedChanges changes;
00379       MapCollection new_maps;
00380 
00381       for (auto r = d.start_map(); r.has_value(); r = d.start_map())
00382       {
00383         const auto map_name = r.value();
00384 
00385         std::shared_ptr<kv::untyped::Map> map = nullptr;
00386 
00387         auto search = maps.find(map_name);
00388         if (search == maps.end())
00389         {
00390           map = std::make_shared<kv::untyped::Map>(
00391             this,
00392             map_name,
00393             get_security_domain(map_name),
00394             is_map_replicated(map_name));
00395           new_maps[map_name] = map;
00396           LOG_DEBUG_FMT(
00397             "Creating map {} while deserialising snapshot at version {}",
00398             map_name,
00399             v);
00400         }
00401         else
00402         {
00403           map = search->second.second;
00404         }
00405 
00406         auto changes_search = changes.find(map_name);
00407         if (changes_search != changes.end())
00408         {
00409           LOG_FAIL_FMT("Failed to deserialise snapshot at version {}", v);
00410           LOG_DEBUG_FMT("Multiple writes on map {}", map_name);
00411           return DeserialiseSuccess::FAILED;
00412         }
00413 
00414         auto deserialised_snapshot_changes =
00415           map->deserialise_snapshot_changes(d);
00416 
00417         // Take ownership of the produced change set, store it to be committed
00418         // later
00419         changes[map_name] = {map, std::move(deserialised_snapshot_changes)};
00420       }
00421 
00422       for (auto& it : maps)
00423       {
00424         auto& [_, map] = it.second;
00425         map->unlock();
00426       }
00427 
00428       if (!d.end())
00429       {
00430         LOG_FAIL_FMT("Unexpected content in snapshot at version {}", v);
00431         return DeserialiseSuccess::FAILED;
00432       }
00433 
00434       // Each map is committed at a different version, independently of the
00435       // overall snapshot version. The commit versions for each map are
00436       // contained in the snapshot and applied when the snapshot is committed.
00437       auto r = apply_changes(
00438         changes, []() { return NoVersion; }, new_maps);
00439       if (!r.has_value())
00440       {
00441         LOG_FAIL_FMT("Failed to commit deserialised snapshot at version {}", v);
00442         return DeserialiseSuccess::FAILED;
00443       }
00444 
00445       {
00446         std::lock_guard<SpinLock> vguard(version_lock);
00447         version = v;
00448         last_replicated = v;
00449         last_committable = v;
00450       }
00451 
00452       if (h)
00453       {
00454         if (!h->init_from_snapshot(hash_at_snapshot))
00455         {
00456           return DeserialiseSuccess::FAILED;
00457         }
00458       }
00459 
00460       if (view_history)
00461       {
00462         *view_history = std::move(view_history_);
00463       }
00464 
00465       return DeserialiseSuccess::PASS;
00466     }
00467 
00468     void compact(Version v) override
00469     {
00470       // This is called when the store will never be rolled back to any
00471       // state before the specified version.
00472       // No transactions can be prepared or committed during compaction.
00473       std::lock_guard<SpinLock> mguard(maps_lock);
00474 
00475       if (v > current_version())
00476       {
00477         return;
00478       }
00479 
00480       for (auto& it : maps)
00481       {
00482         auto& [_, map] = it.second;
00483         map->lock();
00484       }
00485 
00486       for (auto& it : maps)
00487       {
00488         auto& [_, map] = it.second;
00489         map->compact(v);
00490       }
00491 
00492       for (auto& it : maps)
00493       {
00494         auto& [_, map] = it.second;
00495         map->unlock();
00496       }
00497 
00498       {
00499         std::lock_guard<SpinLock> vguard(version_lock);
00500         compacted = v;
00501 
00502         auto h = get_history();
00503         if (h)
00504         {
00505           h->compact(v);
00506         }
00507 
00508         auto e = get_encryptor();
00509         if (e)
00510         {
00511           e->compact(v);
00512         }
00513       }
00514 
00515       for (auto& it : maps)
00516       {
00517         auto& [_, map] = it.second;
00518         map->post_compact();
00519       }
00520     }
00521 
00522     void rollback(Version v, std::optional<Term> t = std::nullopt) override
00523     {
00524       // This is called to roll the store back to the state it was in
00525       // at the specified version.
00526       // No transactions can be prepared or committed during rollback.
00527       std::lock_guard<SpinLock> mguard(maps_lock);
00528 
00529       {
00530         std::lock_guard<SpinLock> vguard(version_lock);
00531         // The term should always be updated on rollback() when passed
00532         // regardless of whether version needs to be updated or not
00533         if (t.has_value())
00534           term = t.value();
00535         if (v >= version)
00536           return;
00537       }
00538 
00539       if (v < commit_version())
00540       {
00541         throw std::logic_error(fmt::format(
00542           "Attempting rollback to {}, earlier than commit version {}",
00543           v,
00544           commit_version()));
00545       }
00546 
00547       for (auto& it : maps)
00548       {
00549         auto& [_, map] = it.second;
00550         map->lock();
00551       }
00552 
00553       auto it = maps.begin();
00554       while (it != maps.end())
00555       {
00556         auto& [map_creation_version, map] = it->second;
00557         // Rollback this map whether we're forgetting about it or not. Anyone
00558         // else still holding it should see it has rolled back
00559         map->rollback(v);
00560         if (map_creation_version > v)
00561         {
00562           // Map was created more recently; its creation is being forgotten.
00563           // Erase our knowledge of it
00564           map->unlock();
00565           it = maps.erase(it);
00566         }
00567         else
00568         {
00569           ++it;
00570         }
00571       }
00572 
00573       for (auto& it : maps)
00574       {
00575         auto& [_, map] = it.second;
00576         map->unlock();
00577       }
00578 
00579       std::lock_guard<SpinLock> vguard(version_lock);
00580       version = v;
00581       last_replicated = v;
00582       last_committable = v;
00583       rollback_count++;
00584       pending_txs.clear();
00585       auto h = get_history();
00586       if (h)
00587         h->rollback(v);
00588       auto e = get_encryptor();
00589       if (e)
00590         e->rollback(v);
00591     }
00592 
00593     void set_term(Term t) override
00594     {
00595       std::lock_guard<SpinLock> vguard(version_lock);
00596       term = t;
00597     }
00598 
00599     DeserialiseSuccess deserialise_views(
00600       const std::vector<uint8_t>& data,
00601       bool public_only = false,
00602       Term* term_ = nullptr,
00603       Version* index_ = nullptr,
00604       AbstractChangeContainer* tx = nullptr,
00605       ccf::PrimarySignature* sig = nullptr)
00606     {
00607       // If we pass in a transaction we don't want to commit, just deserialise
00608       // and put the views into that transaction.
00609       // Tread carefully here: at the moment passing in a transaction assumes we
00610       // are using bft as the consensus
00611       auto commit = (tx == nullptr);
00612 
00613       // This will return FAILED if the serialised transaction is being
00614       // applied out of order.
00615       // Processing transactions locally and also deserialising to the
00616       // same store will result in a store version mismatch and
00617       // deserialisation will then fail.
00618       auto e = get_encryptor();
00619 
00620       auto d = KvStoreDeserialiser(
00621         e,
00622         public_only ? kv::SecurityDomain::PUBLIC :
00623                       std::optional<kv::SecurityDomain>());
00624 
00625       auto v_ = d.init(data.data(), data.size());
00626       if (!v_.has_value())
00627       {
00628         LOG_FAIL_FMT("Initialisation of deserialise object failed");
00629         return DeserialiseSuccess::FAILED;
00630       }
00631       auto v = v_.value();
00632 
00633       // Throw away any local commits that have not propagated via the
00634       // consensus.
00635       rollback(v - 1);
00636 
00637       if (strict_versions)
00638       {
00639         // Make sure this is the next transaction.
00640         auto cv = current_version();
00641         if (cv != (v - 1))
00642         {
00643           LOG_FAIL_FMT(
00644             "Tried to deserialise {} but current_version is {}", v, cv);
00645           return DeserialiseSuccess::FAILED;
00646         }
00647       }
00648 
00649       // Deserialised transactions express read dependencies as versions,
00650       // rather than with the actual value read. As a result, they don't
00651       // need snapshot isolation on the map state, and so do not need to
00652       // lock each of the maps before creating the transaction.
00653       std::lock_guard<SpinLock> mguard(maps_lock);
00654       OrderedChanges changes;
00655       MapCollection new_maps;
00656 
00657       for (auto r = d.start_map(); r.has_value(); r = d.start_map())
00658       {
00659         const auto map_name = r.value();
00660 
00661         auto map = get_map_internal(v, map_name);
00662         if (map == nullptr)
00663         {
00664           auto new_map = std::make_shared<kv::untyped::Map>(
00665             this,
00666             map_name,
00667             get_security_domain(map_name),
00668             is_map_replicated(map_name));
00669           map = new_map;
00670           new_maps[map_name] = new_map;
00671           LOG_DEBUG_FMT(
00672             "Creating map {} while deserialising transaction at version {}",
00673             map_name,
00674             v);
00675         }
00676 
00677         auto change_search = changes.find(map_name);
00678         if (change_search != changes.end())
00679         {
00680           LOG_FAIL_FMT("Failed to deserialise transaction at version {}", v);
00681           LOG_DEBUG_FMT("Multiple writes on map {}", map_name);
00682           return DeserialiseSuccess::FAILED;
00683         }
00684 
00685         auto deserialised_changes = map->deserialise_changes(d, v);
00686 
00687         // Take ownership of the produced change set, store it to be applied
00688         // later
00689         changes[map_name] =
00690           kv::MapChanges{map, std::move(deserialised_changes)};
00691       }
00692 
00693       if (!d.end())
00694       {
00695         LOG_FAIL_FMT("Unexpected content in transaction at version {}", v);
00696         return DeserialiseSuccess::FAILED;
00697       }
00698 
00699       auto success = DeserialiseSuccess::PASS;
00700 
00701       if (commit)
00702       {
00703         success = commit_deserialised(changes, v, new_maps);
00704         if (success == DeserialiseSuccess::FAILED)
00705         {
00706           return success;
00707         }
00708 
00709         auto h = get_history();
00710 
00711         auto search = changes.find(ccf::Tables::SIGNATURES);
00712         if (search != changes.end())
00713         {
00714           // Transactions containing a signature must only contain
00715           // a signature and must be verified
00716           if (changes.size() > 1)
00717           {
00718             LOG_FAIL_FMT("Failed to deserialise");
00719             LOG_DEBUG_FMT("Unexpected contents in signature transaction {}", v);
00720             return DeserialiseSuccess::FAILED;
00721           }
00722 
00723           if (h)
00724           {
00725             if (!h->verify(term_))
00726             {
00727               LOG_FAIL_FMT("Failed to deserialise");
00728               LOG_DEBUG_FMT("Signature in transaction {} failed to verify", v);
00729               return DeserialiseSuccess::FAILED;
00730             }
00731           }
00732           success = DeserialiseSuccess::PASS_SIGNATURE;
00733         }
00734 
00735         search = changes.find(ccf::Tables::SNAPSHOT_EVIDENCE);
00736         if (search != changes.end())
00737         {
00738           success = DeserialiseSuccess::PASS_SNAPSHOT_EVIDENCE;
00739         }
00740 
00741         if (h)
00742         {
00743           h->append(data.data(), data.size());
00744         }
00745       }
00746       else
00747       {
00748         // BFT Transactions should only write to 1 table
00749         if (changes.size() != 1)
00750         {
00751           LOG_FAIL_FMT("Failed to deserialise");
00752           LOG_DEBUG_FMT(
00753             "Unexpected contents in bft transaction {}, size:{}",
00754             v,
00755             changes.size());
00756           return DeserialiseSuccess::FAILED;
00757         }
00758 
00759         if (changes.find(ccf::Tables::SIGNATURES) != changes.end())
00760         {
00761           success = commit_deserialised(changes, v, new_maps);
00762           if (success == DeserialiseSuccess::FAILED)
00763           {
00764             return success;
00765           }
00766 
00767           auto h = get_history();
00768           bool result = true;
00769           if (sig != nullptr)
00770           {
00771             auto r = h->verify_and_sign(*sig, term_);
00772             if (
00773               r != kv::TxHistory::Result::OK &&
00774               r != kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK)
00775             {
00776               result = false;
00777             }
00778           }
00779           else
00780           {
00781             result = h->verify(term_);
00782           }
00783 
00784           if (!result)
00785           {
00786             LOG_FAIL_FMT("Failed to deserialise");
00787             LOG_DEBUG_FMT("Signature in transaction {} failed to verify", v);
00788             throw std::logic_error(
00789               "Failed to verify signature, view-changes not implemented");
00790             return DeserialiseSuccess::FAILED;
00791           }
00792           h->append(data.data(), data.size());
00793           success = DeserialiseSuccess::PASS_SIGNATURE;
00794         }
00795         else if (changes.find(ccf::Tables::BACKUP_SIGNATURES) != changes.end())
00796         {
00797           success = commit_deserialised(changes, v, new_maps);
00798           if (success == DeserialiseSuccess::FAILED)
00799           {
00800             return success;
00801           }
00802 
00803           kv::TxID tx_id;
00804 
00805           auto r = progress_tracker->receive_backup_signatures(
00806             tx_id, consensus->node_count(), consensus->is_primary());
00807           if (r == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK)
00808           {
00809             success = DeserialiseSuccess::PASS_BACKUP_SIGNATURE_SEND_ACK;
00810           }
00811           else if (r == kv::TxHistory::Result::OK)
00812           {
00813             success = DeserialiseSuccess::PASS_BACKUP_SIGNATURE;
00814           }
00815           else
00816           {
00817             LOG_FAIL_FMT("receive_backup_signatures Failed");
00818             LOG_DEBUG_FMT("Signature in transaction {} failed to verify", v);
00819             throw std::logic_error(
00820               "Failed to verify signature, view-changes not implemented");
00821             return DeserialiseSuccess::FAILED;
00822           }
00823 
00824           *term_ = tx_id.term;
00825           *index_ = tx_id.version;
00826 
00827           auto h = get_history();
00828           h->append(data.data(), data.size());
00829         }
00830         else if (changes.find(ccf::Tables::NONCES) != changes.end())
00831         {
00832           success = commit_deserialised(changes, v, new_maps);
00833           if (success == DeserialiseSuccess::FAILED)
00834           {
00835             return success;
00836           }
00837 
00838           auto r = progress_tracker->receive_nonces();
00839           if (r != kv::TxHistory::Result::OK)
00840           {
00841             LOG_FAIL_FMT("receive_nonces Failed");
00842             throw std::logic_error(
00843               "Failed to verify nonces, view-changes not implemented");
00844             return DeserialiseSuccess::FAILED;
00845           }
00846 
00847           auto h = get_history();
00848           h->append(data.data(), data.size());
00849           success = DeserialiseSuccess::PASS_NONCES;
00850         }
00851         else if (changes.find(ccf::Tables::NEW_VIEWS) != changes.end())
00852         {
00853           LOG_INFO_FMT("Applying new view");
00854           success = commit_deserialised(changes, v, new_maps);
00855           if (success == DeserialiseSuccess::FAILED)
00856           {
00857             return success;
00858           }
00859 
00860           if (!progress_tracker->apply_new_view(
00861                 consensus->primary(), consensus->node_count(), *term_, *index_))
00862           {
00863             LOG_FAIL_FMT("apply_new_view Failed");
00864             LOG_DEBUG_FMT("NewView in transaction {} failed to verify", v);
00865             return DeserialiseSuccess::FAILED;
00866           }
00867 
00868           auto h = get_history();
00869           h->append(data.data(), data.size());
00870           success = DeserialiseSuccess::PASS_NEW_VIEW;
00871         }
00872         else if (changes.find(ccf::Tables::AFT_REQUESTS) == changes.end())
00873         {
00874           // we have deserialised an entry that didn't belong to the bft
00875           // requests nor the signatures table
00876           LOG_FAIL_FMT(
00877             "Request contains unexpected table - {}", changes.begin()->first);
00878           CCF_ASSERT_FMT_FAIL(
00879             "Request contains unexpected table - {}", changes.begin()->first);
00880         }
00881       }
00882 
00883       if (tx)
00884       {
00885         tx->set_change_list(std::move(changes), term);
00886       }
00887 
00888       return success;
00889     }
00890 
00891     DeserialiseSuccess deserialise(
00892       const std::vector<uint8_t>& data,
00893       bool public_only = false,
00894       Term* term = nullptr) override
00895     {
00896       return deserialise_views(data, public_only, term);
00897     }
00898 
00899     bool operator==(const Store& that) const
00900     {
00901       // Only used for debugging, not thread safe.
00902       if (version != that.version)
00903         return false;
00904 
00905       if (maps.size() != that.maps.size())
00906         return false;
00907 
00908       for (auto it = maps.begin(); it != maps.end(); ++it)
00909       {
00910         auto search = that.maps.find(it->first);
00911 
00912         if (search == that.maps.end())
00913           return false;
00914 
00915         auto& [this_v, this_map] = it->second;
00916         auto& [that_v, that_map] = search->second;
00917 
00918         if (this_v != that_v)
00919           return false;
00920 
00921         if (*this_map != *that_map)
00922           return false;
00923       }
00924 
00925       return true;
00926     }
00927 
00928     bool operator!=(const Store& that) const
00929     {
00930       // Only used for debugging, not thread safe.
00931       return !(*this == that);
00932     }
00933 
00934     Version current_version() override
00935     {
00936       // Must lock in case the version or term is being incremented.
00937       std::lock_guard<SpinLock> vguard(version_lock);
00938       return version;
00939     }
00940 
00941     TxID current_txid() override
00942     {
00943       // Must lock in case the version is being incremented.
00944       std::lock_guard<SpinLock> vguard(version_lock);
00945       return {term, version};
00946     }
00947 
00948     Version commit_version() override
00949     {
00950       // Must lock in case the store is being compacted.
00951       std::lock_guard<SpinLock> vguard(version_lock);
00952       return compacted;
00953     }
00954 
00955     CommitSuccess commit(
00956       const TxID& txid,
00957       PendingTx&& pending_tx,
00958       bool globally_committable) override
00959     {
00960       auto c = get_consensus();
00961       if (!c)
00962       {
00963         return CommitSuccess::OK;
00964       }
00965 
00966       LOG_DEBUG_FMT(
00967         "Store::commit {}{}",
00968         txid.version,
00969         (globally_committable ? " globally_committable" : ""));
00970 
00971       BatchVector batch;
00972       Version previous_last_replicated = 0;
00973       Version next_last_replicated = 0;
00974       Version previous_rollback_count = 0;
00975       kv::Consensus::View replication_view = 0;
00976 
00977       {
00978         std::lock_guard<SpinLock> vguard(version_lock);
00979         if (txid.term != term)
00980         {
00981           // This can happen when a transaction started before a view change,
00982           // but tries to commit after the view change is complete.
00983           LOG_DEBUG_FMT(
00984             "Want to commit for term {} but term is {}", txid.term, term);
00985 
00986           return CommitSuccess::NO_REPLICATE;
00987         }
00988 
00989         if (globally_committable && txid.version > last_committable)
00990           last_committable = txid.version;
00991 
00992         pending_txs.insert(
00993           {txid.version,
00994            std::make_pair(std::move(pending_tx), globally_committable)});
00995 
00996         auto h = get_history();
00997         auto c = get_consensus();
00998 
00999         for (Version offset = 1; true; ++offset)
01000         {
01001           auto search = pending_txs.find(last_replicated + offset);
01002           if (search == pending_txs.end())
01003             break;
01004 
01005           auto& [pending_tx_, committable_] = search->second;
01006           auto [success_, reqid, data_] = pending_tx_();
01007           auto data_shared =
01008             std::make_shared<std::vector<uint8_t>>(std::move(data_));
01009 
01010           // NB: this cannot happen currently. Regular Tx only make it here if
01011           // they did succeed, and signatures cannot conflict because they
01012           // execute in order with a read_version that's version - 1, so even
01013           // two contiguous signatures are fine
01014           if (success_ != CommitSuccess::OK)
01015             LOG_DEBUG_FMT("Failed Tx commit {}", last_replicated + offset);
01016 
01017           if (h)
01018           {
01019             h->add_pending(reqid, txid.version, data_shared);
01020           }
01021 
01022           LOG_DEBUG_FMT(
01023             "Batching {} ({})", last_replicated + offset, data_shared->size());
01024 
01025           batch.emplace_back(
01026             last_replicated + offset, data_shared, committable_);
01027           pending_txs.erase(search);
01028         }
01029 
01030         if (batch.size() == 0)
01031           return CommitSuccess::OK;
01032 
01033         previous_rollback_count = rollback_count;
01034         previous_last_replicated = last_replicated;
01035         next_last_replicated = last_replicated + batch.size();
01036 
01037         replication_view = term;
01038       }
01039 
01040       if (c->replicate(batch, replication_view))
01041       {
01042         std::lock_guard<SpinLock> vguard(version_lock);
01043         if (
01044           last_replicated == previous_last_replicated &&
01045           previous_rollback_count == rollback_count)
01046         {
01047           last_replicated = next_last_replicated;
01048         }
01049         return CommitSuccess::OK;
01050       }
01051       else
01052       {
01053         LOG_DEBUG_FMT("Failed to replicate");
01054         return CommitSuccess::NO_REPLICATE;
01055       }
01056     }
01057 
01058     void lock() override
01059     {
01060       maps_lock.lock();
01061     }
01062 
01063     void unlock() override
01064     {
01065       maps_lock.unlock();
01066     }
01067 
01068     Version next_version() override
01069     {
01070       std::lock_guard<SpinLock> vguard(version_lock);
01071 
01072       // Get the next global version. If we would go negative, wrap to 0.
01073       ++version;
01074 
01075       if (version < 0)
01076         version = 0;
01077 
01078       return version;
01079     }
01080 
01081     TxID next_txid() override
01082     {
01083       std::lock_guard<SpinLock> vguard(version_lock);
01084 
01085       // Get the next global version. If we would go negative, wrap to 0.
01086       ++version;
01087       if (version < 0)
01088         version = 0;
01089 
01090       return {term, version};
01091     }
01092 
01093     size_t commit_gap() override
01094     {
01095       std::lock_guard<SpinLock> vguard(version_lock);
01096       return version - last_committable;
01097     }
01098 
01099     /** This is only safe in very restricted circumstances, and is only
01100      * meant to be used during catastrophic recovery, between a KV
01101      * with public-state only and a KV with full state, to swap in the
01102      * private state from the latter into the former.
01103      *
01104      * It's also important to note that swapping in private state
01105      * may result in previously uncompacted writes becoming effectively
01106      * compacted, from a user's perspective (they would not be internally
01107      * compacted until the next compact() however). So it is important to
01108      * make sure that the private state being swapped in is fully compacted
01109      * before the swap.
01110      **/
01111     void swap_private_maps(Store& store)
01112     {
01113       {
01114         const auto source_version = store.current_version();
01115         const auto target_version = current_version();
01116         if (source_version > target_version)
01117         {
01118           throw std::runtime_error(fmt::format(
01119             "Invalid call to swap_private_maps. Source is at version {} while "
01120             "target is at {}",
01121             source_version,
01122             target_version));
01123         }
01124       }
01125 
01126       std::lock_guard<SpinLock> this_maps_guard(maps_lock);
01127       std::lock_guard<SpinLock> other_maps_guard(store.maps_lock);
01128 
01129       // Each entry is (Name, MyMap, TheirMap)
01130       using MapEntry = std::tuple<std::string, AbstractMap*, AbstractMap*>;
01131       std::vector<MapEntry> entries;
01132 
01133       // Get the list of private maps from the source store
01134       for (auto& [name, pair] : store.maps)
01135       {
01136         auto& [_, map] = pair;
01137         if (map->get_security_domain() == SecurityDomain::PRIVATE)
01138         {
01139           map->lock();
01140           entries.emplace_back(name, nullptr, map.get());
01141         }
01142       }
01143 
01144       // For each source map, either create it or, where it already exists,
01145       // confirm it is PRIVATE. Lock it and store it in entries
01146       auto entry = entries.begin();
01147       while (entry != entries.end())
01148       {
01149         const auto& [name, _, their_map] = *entry;
01150         std::shared_ptr<AbstractMap> map = nullptr;
01151         const auto it = maps.find(name);
01152         if (it == maps.end())
01153         {
01154           // NB: We lose the creation version from the original map, but assume
01155           // it is irrelevant - its creation should no longer be at risk of
01156           // rollback
01157           auto new_map = std::make_pair(
01158             NoVersion,
01159             std::make_shared<kv::untyped::Map>(
01160               this, name, SecurityDomain::PRIVATE, is_map_replicated(name)));
01161           maps[name] = new_map;
01162           map = new_map.second;
01163         }
01164         else
01165         {
01166           map = it->second.second;
01167           if (map->get_security_domain() != SecurityDomain::PRIVATE)
01168           {
01169             throw std::logic_error(fmt::format(
01170               "Swap mismatch - map {} is private in source but not in target",
01171               name));
01172           }
01173         }
01174 
01175         std::get<1>(*entry) = map.get();
01176         map->lock();
01177         ++entry;
01178       }
01179 
01180       for (auto& [name, lhs, rhs] : entries)
01181       {
01182         lhs->swap(rhs);
01183       }
01184 
01185       for (auto& [name, lhs, rhs] : entries)
01186       {
01187         lhs->unlock();
01188         rhs->unlock();
01189       }
01190     }
01191 
01192     void set_local_hook(
01193       const std::string& map_name, const kv::untyped::Map::CommitHook& hook)
01194     {
01195       local_hooks[map_name] = hook;
01196 
01197       const auto it = maps.find(map_name);
01198       if (it != maps.end())
01199       {
01200         it->second.second->set_local_hook(hook);
01201       }
01202     }
01203 
01204     void unset_local_hook(const std::string& map_name)
01205     {
01206       local_hooks.erase(map_name);
01207 
01208       const auto it = maps.find(map_name);
01209       if (it != maps.end())
01210       {
01211         it->second.second->unset_local_hook();
01212       }
01213     }
01214 
01215     void set_global_hook(
01216       const std::string& map_name, const kv::untyped::Map::CommitHook& hook)
01217     {
01218       global_hooks[map_name] = hook;
01219 
01220       const auto it = maps.find(map_name);
01221       if (it != maps.end())
01222       {
01223         it->second.second->set_global_hook(hook);
01224       }
01225     }
01226 
01227     void unset_global_hook(const std::string& map_name)
01228     {
01229       global_hooks.erase(map_name);
01230 
01231       const auto it = maps.find(map_name);
01232       if (it != maps.end())
01233       {
01234         it->second.second->unset_global_hook();
01235       }
01236     }
01237 
01238     ReadOnlyTx create_read_only_tx()
01239     {
01240       return ReadOnlyTx(this);
01241     }
01242 
01243     Tx create_tx()
01244     {
01245       return Tx(this);
01246     }
01247 
01248     ReservedTx create_reserved_tx(Version v)
01249     {
01250       return ReservedTx(this, v);
01251     }
01252   };
01253 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/store.h...
Preprocessing /data/git/CCF/src/kv/test/kv_bench.cpp...
#include kv/store.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/encryptor.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 7293 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 using KeyType = kv::serialisers::SerialisedEntry;
00015 using ValueType = kv::serialisers::SerialisedEntry;
00016 using MapType = kv::untyped::Map;
00017 
00018 inline void clobber_memory()
00019 {
00020   asm volatile("" : : : "memory");
00021 }
00022 
00023 KeyType gen_key(size_t i, const std::string& suf = "")
00024 {
00025   const auto s = "key" + std::to_string(i) + suf;
00026   msgpack::sbuffer buf;
00027   msgpack::pack(buf, s);
00028   const auto raw = reinterpret_cast<const uint8_t*>(buf.data());
00029   return KeyType(raw, raw + buf.size());
00030 }
00031 
00032 ValueType gen_value(size_t i)
00033 {
00034   const auto s = "value" + std::to_string(i);
00035   msgpack::sbuffer buf;
00036   msgpack::pack(buf, s);
00037   const auto raw = reinterpret_cast<const uint8_t*>(buf.data());
00038   return ValueType(raw, raw + buf.size());
00039 }
00040 
00041 // Helper functions to use a dummy encryption key
00042 std::shared_ptr<ccf::LedgerSecrets> create_ledger_secrets()
00043 {
00044   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00045   auto new_secret = ccf::LedgerSecret();
00046   secrets->init();
00047 
00048   return secrets;
00049 }
00050 
00051 std::string build_map_name(const std::string& core_name, kv::SecurityDomain sd)
00052 {
00053   if (sd == kv::SecurityDomain::PUBLIC)
00054   {
00055     return fmt::format("{}{}", kv::public_domain_prefix, core_name);
00056   }
00057 
00058   return core_name;
00059 }
00060 
00061 // Test functions
00062 template <kv::SecurityDomain SD>
00063 static void serialise(picobench::state& s)
00064 {
00065   logger::config::level() = logger::INFO;
00066 
00067   kv::Store kv_store;
00068   auto secrets = create_ledger_secrets();
00069   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00070   encryptor->set_iv_id(1);
00071   kv_store.set_encryptor(encryptor);
00072 
00073   auto map0 = build_map_name("map0", SD);
00074   auto map1 = build_map_name("map1", SD);
00075 
00076   auto tx = kv_store.create_tx();
00077   auto [tx0, tx1] = tx.get_view<MapType, MapType>(map0, map1);
00078 
00079   for (int i = 0; i < s.iterations(); i++)
00080   {
00081     const auto key = gen_key(i);
00082     const auto value = gen_value(i);
00083     tx0->put(key, value);
00084     tx1->put(key, value);
00085   }
00086 
00087   s.start_timer();
00088   auto rc = tx.commit();
00089   if (rc != kv::CommitSuccess::OK)
00090     throw std::logic_error("Transaction commit failed: " + std::to_string(rc));
00091   s.stop_timer();
00092 }
00093 
00094 template <kv::SecurityDomain SD>
00095 static void deserialise(picobench::state& s)
00096 {
00097   logger::config::level() = logger::INFO;
00098 
00099   auto consensus = std::make_shared<kv::StubConsensus>();
00100   kv::Store kv_store(consensus);
00101   kv::Store kv_store2;
00102 
00103   auto secrets = create_ledger_secrets();
00104   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00105   encryptor->set_iv_id(1);
00106   kv_store.set_encryptor(encryptor);
00107   kv_store2.set_encryptor(encryptor);
00108 
00109   auto map0 = build_map_name("map0", SD);
00110   auto map1 = build_map_name("map1", SD);
00111 
00112   auto tx = kv_store.create_tx();
00113   auto [tx0, tx1] = tx.get_view<MapType, MapType>(map0, map1);
00114 
00115   for (int i = 0; i < s.iterations(); i++)
00116   {
00117     const auto key = gen_key(i);
00118     const auto value = gen_value(i);
00119     tx0->put(key, value);
00120     tx1->put(key, value);
00121   }
00122   tx.commit();
00123 
00124   s.start_timer();
00125   auto rc = kv_store2.deserialise(consensus->get_latest_data().value());
00126   if (rc != kv::DeserialiseSuccess::PASS)
00127     throw std::logic_error(
00128       "Transaction deserialisation failed: " + std::to_string(rc));
00129   s.stop_timer();
00130 }
00131 
00132 template <size_t S>
00133 static void commit_latency(picobench::state& s)
00134 {
00135   logger::config::level() = logger::INFO;
00136 
00137   kv::Store kv_store;
00138   auto secrets = create_ledger_secrets();
00139   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00140   encryptor->set_iv_id(1);
00141   kv_store.set_encryptor(encryptor);
00142 
00143   auto map0 = "map0";
00144   auto map1 = "map1";
00145 
00146   for (int i = 0; i < s.iterations(); i++)
00147   {
00148     auto tx = kv_store.create_tx();
00149     auto [tx0, tx1] = tx.get_view<MapType, MapType>(map0, map1);
00150     for (int iTx = 0; iTx < S; iTx++)
00151     {
00152       const auto key = gen_key(i, std::to_string(iTx));
00153       const auto value = gen_value(i);
00154       tx0->put(key, value);
00155       tx1->put(key, value);
00156     }
00157 
00158     auto rc = tx.commit();
00159     if (rc != kv::CommitSuccess::OK)
00160     {
00161       throw std::logic_error(
00162         "Transaction commit failed: " + std::to_string(rc));
00163     }
00164   }
00165   s.start_timer();
00166   kv_store.compact(kv_store.current_version());
00167   s.stop_timer();
00168 }
00169 
00170 template <size_t KEY_COUNT>
00171 static void ser_snap(picobench::state& s)
00172 {
00173   logger::config::level() = logger::INFO;
00174 
00175   kv::Store kv_store;
00176   auto secrets = create_ledger_secrets();
00177   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00178   encryptor->set_iv_id(1);
00179   kv_store.set_encryptor(encryptor);
00180 
00181   auto tx = kv_store.create_tx();
00182   for (int i = 0; i < s.iterations(); i++)
00183   {
00184     auto view = tx.get_view<MapType>(fmt::format("map{}", i));
00185     for (int j = 0; j < KEY_COUNT; j++)
00186     {
00187       const auto key = gen_key(j);
00188       const auto value = gen_value(j);
00189 
00190       view->put(key, value);
00191     }
00192   }
00193 
00194   auto rc = tx.commit();
00195   if (rc != kv::CommitSuccess::OK)
00196     throw std::logic_error("Transaction commit failed: " + std::to_string(rc));
00197 
00198   s.start_timer();
00199   auto snap = kv_store.snapshot(tx.commit_version());
00200   kv_store.serialise_snapshot(std::move(snap));
00201   s.stop_timer();
00202 }
00203 
00204 template <size_t KEY_COUNT>
00205 static void des_snap(picobench::state& s)
00206 {
00207   logger::config::level() = logger::INFO;
00208 
00209   kv::Store kv_store;
00210   kv::Store kv_store2;
00211   auto secrets = create_ledger_secrets();
00212   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00213   encryptor->set_iv_id(1);
00214   kv_store.set_encryptor(encryptor);
00215   kv_store2.set_encryptor(encryptor);
00216 
00217   auto tx = kv_store.create_tx();
00218   for (int i = 0; i < s.iterations(); i++)
00219   {
00220     auto view = tx.get_view<MapType>(fmt::format("map{}", i));
00221     for (int j = 0; j < KEY_COUNT; j++)
00222     {
00223       const auto key = gen_key(j);
00224       const auto value = gen_value(j);
00225 
00226       view->put(key, value);
00227     }
00228   }
00229 
00230   auto rc = tx.commit();
00231   if (rc != kv::CommitSuccess::OK)
00232     throw std::logic_error("Transaction commit failed: " + std::to_string(rc));
00233 
00234   auto snap = kv_store.snapshot(tx.commit_version());
00235   auto serialised_snap = kv_store.serialise_snapshot(std::move(snap));
00236 
00237   s.start_timer();
00238   kv_store2.deserialise_snapshot(serialised_snap);
00239   s.stop_timer();
00240 }
00241 
00242 const std::vector<int> tx_count = {10, 100, 1000};
00243 const uint32_t sample_size = 100;
00244 
00245 using SD = kv::SecurityDomain;
00246 
00247 PICOBENCH_SUITE("commit_latency");
00248 PICOBENCH(commit_latency<10>).iterations(tx_count).samples(10).baseline();
00249 PICOBENCH(commit_latency<100>).iterations(tx_count).samples(10);
00250 
00251 PICOBENCH_SUITE("serialise");
00252 
00253   .iterations(tx_count)
00254   .samples(sample_size)
00255   .baseline();
00256 PICOBENCH(serialise<SD::PRIVATE>).iterations(tx_count).samples(sample_size);
00257 
00258 PICOBENCH_SUITE("deserialise");
00259 
00260   .iterations(tx_count)
00261   .samples(sample_size)
00262   .baseline();
00263 PICOBENCH(deserialise<SD::PRIVATE>).iterations(tx_count).samples(sample_size);
00264 
00265 const uint32_t snapshot_sample_size = 10;
00266 const std::vector<int> map_count = {20, 100};
00267 
00268 PICOBENCH_SUITE("serialise_snapshot");
00269 
00270   .iterations(map_count)
00271   .samples(snapshot_sample_size)
00272   .baseline();
00273 PICOBENCH(ser_snap<1000>).iterations(map_count).samples(snapshot_sample_size);
00274 
00275 PICOBENCH_SUITE("deserialise_snapshot");
00276 
00277   .iterations(map_count)
00278   .samples(snapshot_sample_size)
00279   .baseline();
00280 PICOBENCH(des_snap<1000>).iterations(map_count).samples(snapshot_sample_size);
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/kv/test/kv_bench.cpp...
Preprocessing /data/git/CCF/src/kv/test/kv_contention.cpp...
#include ds/logger.h: not found! skipping...
#include kv/kv_serialiser.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 5353 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 #define DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES
00011 
00012 
00013 
00014 
00015 
00016 
00017 {
00018   logger::config::level() = logger::INFO;
00019 
00020   // Multiple threads write random entries into random tables, and attempt to
00021   // commit them. A single thread continually compacts the kv to the latest
00022   // entry. The goal is for these commits and compactions to avoid deadlock
00023   kv::Store kv_store;
00024 
00025   using MapType = kv::Map<size_t, size_t>;
00026   constexpr size_t max_k = 32;
00027 
00028   constexpr size_t thread_count = 16;
00029   std::thread tx_threads[thread_count] = {};
00030 
00031   constexpr size_t tx_count = 100;
00032   constexpr size_t tx_size = 100;
00033 
00034   // Keep atomic count of running threads
00035   std::atomic<size_t> active_tx_threads(thread_count);
00036 
00037   struct ThreadArgs
00038   {
00039     std::vector<MapType> maps;
00040     kv::Store* kv_store;
00041     std::atomic<size_t>* counter;
00042   };
00043   ThreadArgs args[thread_count] = {};
00044 
00045   srand(42);
00046   constexpr size_t map_count = 8;
00047   for (size_t i = 0u; i < map_count; ++i)
00048   {
00049     const auto name = fmt::format("public:{}", i);
00050     MapType map(name);
00051 
00052     // Every thread gets the first map, and a random half of the others
00053     for (size_t j = 0u; j < thread_count; ++j)
00054     {
00055       if (i == 0u || rand() % 2)
00056       {
00057         args[j].maps.push_back(map);
00058       }
00059     }
00060   }
00061 
00062   auto thread_fn = [](void* a) {
00063     auto args = static_cast<ThreadArgs*>(a);
00064 
00065     for (size_t i = 0u; i < tx_count; ++i)
00066     {
00067       // Generate a set of random reads and writes across our maps
00068       std::vector<std::tuple<size_t, size_t, size_t, size_t>> writes;
00069       for (size_t j = 0u; j < tx_size; ++j)
00070       {
00071         writes.push_back({rand() % args->maps.size(),
00072                           rand() % max_k,
00073                           rand() % args->maps.size(),
00074                           rand() % max_k});
00075       }
00076 
00077       // Keep trying until you're able to commit it
00078       while (true)
00079       {
00080         try
00081         {
00082           // Start a transaction over selected maps
00083           auto tx = args->kv_store->create_tx();
00084 
00085           std::vector<MapType::TxView*> views;
00086           for (const auto& map : args->maps)
00087           {
00088             views.push_back(tx.get_view(map));
00089           }
00090 
00091           for (const auto& [from_map, from_k, to_map, to_k] : writes)
00092           {
00093             auto from_view = views[from_map];
00094             const auto v = from_view->get(from_k).value_or(from_k);
00095 
00096             auto to_view = views[to_map];
00097             to_view->put(to_k, v);
00098           }
00099 
00100           // Yield now, to increase the chance of conflicts
00101           std::this_thread::yield();
00102 
00103           // Try to commit
00104           const auto result = tx.commit();
00105           if (result == kv::CommitSuccess::OK)
00106           {
00107             break;
00108           }
00109         }
00110         catch (const kv::CompactedVersionConflict& e)
00111         {
00112           // Retry on conflict
00113           continue;
00114         }
00115       }
00116     }
00117 
00118     // Notify that this thread has finished
00119     --*args->counter;
00120   };
00121 
00122   // Start a thread which continually compacts at the latest version, until all
00123   // tx_threads have finished
00124   std::thread compact_thread;
00125   enum CompacterState
00126   {
00127     NotStarted,
00128     Running,
00129     Done
00130   };
00131   std::atomic<CompacterState> compact_state(NotStarted);
00132 
00133   struct CompactArgs
00134   {
00135     kv::Store* kv_store;
00136     std::atomic<size_t>* tx_counter;
00137     decltype(compact_state)* compact_state;
00138   } ca{&kv_store, &active_tx_threads, &compact_state};
00139 
00140   // Start compact thread
00141   {
00142     compact_thread = std::thread(
00143       [](void* a) {
00144         auto ca = static_cast<CompactArgs*>(a);
00145         auto& store = *ca->kv_store;
00146 
00147         ca->compact_state->store(Running);
00148 
00149         while (ca->tx_counter->load() > 0)
00150         {
00151           store.compact(store.current_version());
00152         }
00153 
00154         // Ensure store is compacted one last time _after_ all threads have
00155         // finished
00156         store.compact(store.current_version());
00157 
00158         ca->compact_state->store(Done);
00159       },
00160       &ca);
00161   }
00162 
00163   const auto initial_version = kv_store.commit_version();
00164 
00165   // Start tx threads
00166   for (size_t i = 0u; i < thread_count; ++i)
00167   {
00168     args[i].kv_store = &kv_store;
00169     args[i].counter = &active_tx_threads;
00170 
00171     tx_threads[i] = std::thread(thread_fn, &args[i]);
00172   }
00173 
00174   // Wait for the compact thread to start
00175   while (compact_state.load() == NotStarted)
00176   {
00177     std::this_thread::sleep_for(std::chrono::milliseconds(100));
00178   }
00179 
00180   // Wait for the compact thread to finish, with an overall timeout to detect
00181   // deadlock
00182   using Clock = std::chrono::system_clock;
00183   const auto start = Clock::now();
00184   const auto timeout = std::chrono::seconds(30);
00185   while (compact_state.load() == Running)
00186   {
00187     const auto elapsed = Clock::now() - start;
00188     DOCTEST_REQUIRE(elapsed < timeout);
00189     std::this_thread::sleep_for(std::chrono::milliseconds(100));
00190   }
00191 
00192   DOCTEST_REQUIRE(compact_state.load() == Done);
00193 
00194   // Sanity check that all transactions were compacted
00195   const auto now_compacted = kv_store.commit_version();
00196   DOCTEST_REQUIRE(now_compacted > initial_version);
00197   const auto expected = initial_version + (tx_count * thread_count);
00198   DOCTEST_REQUIRE(now_compacted == expected);
00199 
00200   // Wait for tx threads to complete
00201   for (size_t i = 0u; i < thread_count; ++i)
00202   {
00203     tx_threads[i].join();
00204   }
00205 
00206   // Wait for compact thread to complete
00207   {
00208     compact_thread.join();
00209   }
00210 }
00211 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES 
---------
Parsing file /data/git/CCF/src/kv/test/kv_contention.cpp...
Preprocessing /data/git/CCF/src/kv/test/kv_dynamic_tables.cpp...
#include kv/store.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 16525 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 struct MapTypes
00010 {
00011   using StringString = kv::Map<std::string, std::string>;
00012   using NumNum = kv::Map<size_t, size_t>;
00013   using NumString = kv::Map<size_t, std::string>;
00014   using StringNum = kv::Map<std::string, size_t>;
00015 };
00016 
00017 
00018 {
00019   kv::Store kv_store;
00020 
00021   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00022   kv_store.set_encryptor(encryptor);
00023 
00024   constexpr auto map_name = "mapA";
00025 
00026   INFO("Dynamically created maps can be used like normal maps");
00027 
00028   {
00029     auto tx = kv_store.create_tx();
00030 
00031     auto view = tx.get_view<MapTypes::StringString>(map_name);
00032     view->put("foo", "bar");
00033 
00034     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00035   }
00036 
00037   {
00038     INFO("New style access");
00039     auto tx = kv_store.create_tx();
00040 
00041     auto view = tx.get_view<MapTypes::StringString>(map_name);
00042     const auto it = view->get("foo");
00043     REQUIRE(it.has_value());
00044     REQUIRE(it.value() == "bar");
00045   }
00046 
00047   {
00048     INFO("Dynamic tables remain through compaction");
00049     kv_store.compact(kv_store.current_version());
00050 
00051     auto tx = kv_store.create_tx();
00052 
00053     auto view = tx.get_view<MapTypes::StringString>(map_name);
00054     const auto it = view->get("foo");
00055     REQUIRE(it.has_value());
00056     REQUIRE(it.value() == "bar");
00057   }
00058 
00059   const auto version_before = kv_store.current_version();
00060 
00061   constexpr auto new_map1 = "new_map1";
00062   constexpr auto new_map2 = "new_map2";
00063   constexpr auto new_map3 = "new_map3";
00064 
00065   {
00066     INFO("Multiple dynamic tables can be created in a single tx");
00067     auto tx = kv_store.create_tx();
00068 
00069     auto [v1, v2] = tx.get_view<MapTypes::StringString, MapTypes::StringNum>(
00070       new_map1, new_map2);
00071     auto [v2a, v3] =
00072       tx.get_view<MapTypes::StringNum, MapTypes::NumString>(new_map2, new_map3);
00073 
00074     REQUIRE(v2 == v2a);
00075 
00076     v1->put("foo", "bar");
00077     v3->put(42, "hello");
00078 
00079     auto va = tx.get_view<MapTypes::StringString>(map_name);
00080     va->put("foo", "baz");
00081 
00082     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00083 
00084     {
00085       auto check_tx = kv_store.create_tx();
00086       auto check_va = check_tx.get_view<MapTypes::StringString>(map_name);
00087       const auto v = check_va->get("foo");
00088       REQUIRE(v.has_value());
00089       REQUIRE(v.value() == "baz");
00090     }
00091   }
00092 
00093   {
00094     INFO("Rollback can delete dynamic tables");
00095     kv_store.rollback(version_before);
00096 
00097     {
00098       auto tx = kv_store.create_tx();
00099       auto [v1, v2, v3] = tx.get_view<
00100         MapTypes::StringString,
00101         MapTypes::StringNum,
00102         MapTypes::NumString>(new_map1, new_map2, new_map3);
00103 
00104       REQUIRE(!v1->has("foo"));
00105       REQUIRE(!v2->has("foo"));
00106       REQUIRE(!v3->has(42));
00107     }
00108 
00109     {
00110       INFO("Retained dynamic maps have their state rolled back");
00111       auto check_tx = kv_store.create_tx();
00112       auto check_va = check_tx.get_view<MapTypes::StringString>(map_name);
00113       const auto v = check_va->get("foo");
00114       REQUIRE(v.has_value());
00115       REQUIRE(v.value() == "bar");
00116     }
00117   }
00118 }
00119 
00120 
00121 {
00122   kv::Store kv_store;
00123 
00124   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00125   kv_store.set_encryptor(encryptor);
00126 
00127   constexpr auto map_name = "dynamic_map";
00128 
00129   auto tx1 = kv_store.create_tx();
00130   auto tx2 = kv_store.create_tx();
00131 
00132   auto view1 = tx1.get_view<MapTypes::StringString>(map_name);
00133   view1->put("foo", "bar");
00134   REQUIRE(view1->get("foo").value() == "bar");
00135 
00136   auto view2 = tx2.get_view<MapTypes::StringString>(map_name);
00137   view2->put("foo", "baz");
00138   REQUIRE(view2->get("foo").value() == "baz");
00139 
00140   {
00141     INFO("First transaction commits successfully");
00142     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00143   }
00144 
00145   {
00146     INFO("Committed transaction results are persisted");
00147     auto txx = kv_store.create_tx();
00148     auto view = txx.get_view<MapTypes::StringString>(map_name);
00149     const auto v = view->get("foo");
00150     REQUIRE(v.has_value());
00151     REQUIRE(v.value() == "bar");
00152   }
00153 
00154   {
00155     INFO("Second transaction conflicts");
00156     REQUIRE(tx2.commit() == kv::CommitSuccess::CONFLICT);
00157   }
00158 
00159   {
00160     INFO("Conflicting transaction can be rerun, on existing map");
00161     auto tx3 = kv_store.create_tx();
00162     auto view3 = tx3.get_view<MapTypes::StringString>(map_name);
00163     const auto v = view3->get("foo");
00164     REQUIRE(v.has_value());
00165     view3->put("foo", "baz");
00166     REQUIRE(view3->get("foo").value() == "baz");
00167 
00168     REQUIRE(tx3.commit() == kv::CommitSuccess::OK);
00169   }
00170 
00171   {
00172     INFO("Subsequent transactions over dynamic map are persisted");
00173     auto tx4 = kv_store.create_tx();
00174     auto view4 = tx4.get_view<MapTypes::StringString>(map_name);
00175     const auto v = view4->get("foo");
00176     REQUIRE(v.has_value());
00177     REQUIRE(v.value() == "baz");
00178   }
00179 }
00180 
00181 TEST_CASE(
00182   "Dynamic table visibility by version" * doctest::test_suite("dynamic"))
00183 {
00184   kv::Store kv_store;
00185 
00186   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00187   kv_store.set_encryptor(encryptor);
00188 
00189   constexpr auto map_name = "dynamic_map";
00190   constexpr auto other_map = "other_map";
00191 
00192   auto tx1 = kv_store.create_tx();
00193   auto tx2 = kv_store.create_tx();
00194   auto tx3 = kv_store.create_tx();
00195   auto tx4 = kv_store.create_tx();
00196 
00197   auto view1 = tx1.get_view<MapTypes::StringString>(map_name);
00198   view1->put("foo", "bar");
00199 
00200   // Map created in tx1 is not visible
00201   auto view2 = tx2.get_view<MapTypes::StringString>(map_name);
00202   REQUIRE(!view2->get("foo").has_value());
00203 
00204   // tx3 takes a read dependency at an early version, before the map is visible
00205   auto view3_static = tx3.get_view<MapTypes::StringString>(other_map);
00206 
00207   REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00208 
00209   // Even after commit, the new map is not visible to tx3 because it is reading
00210   // from an earlier version
00211   auto view3 = tx3.get_view<MapTypes::StringString>(map_name);
00212   REQUIRE(!view3->get("foo").has_value());
00213 
00214   // Map created in tx1 is visible, because tx4 first _reads_ (creates a
00215   // view) after tx1 has committed
00216   auto view4 = tx4.get_view<MapTypes::StringString>(map_name);
00217   REQUIRE(view4->get("foo").has_value());
00218 }
00219 
00220 
00221 {
00222   kv::Store kv_store;
00223 
00224   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00225   kv_store.set_encryptor(encryptor);
00226 
00227   constexpr auto dynamic_map_a = "dynamic_map_a";
00228   constexpr auto dynamic_map_b = "dynamic_map_b";
00229 
00230   {
00231     auto tx = kv_store.create_read_only_tx();
00232     auto va = tx.get_read_only_view<MapTypes::StringString>(dynamic_map_a);
00233     auto [vaa, vb, vbb] = tx.get_read_only_view<
00234       MapTypes::StringString,
00235       MapTypes::StringString,
00236       MapTypes::StringString>(dynamic_map_a, dynamic_map_b, dynamic_map_b);
00237 
00238     REQUIRE(va != nullptr);
00239     REQUIRE(vaa != nullptr);
00240     REQUIRE(vb != nullptr);
00241     REQUIRE(vbb != nullptr);
00242 
00243     REQUIRE(va == vaa);
00244     REQUIRE(vb == vbb);
00245 
00246     REQUIRE(!va->get("foo").has_value());
00247     REQUIRE(!vb->get("foo").has_value());
00248 
00249     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00250   }
00251 
00252   {
00253     auto tx = kv_store.create_tx();
00254     auto [va, vb] = tx.get_view<MapTypes::StringString, MapTypes::StringString>(
00255       dynamic_map_a, dynamic_map_b);
00256 
00257     va->put("foo", "bar");
00258     vb->put("foo", "baz");
00259 
00260     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00261   }
00262 
00263   {
00264     auto tx = kv_store.create_read_only_tx();
00265     auto [va, vb] =
00266       tx.get_read_only_view<MapTypes::StringString, MapTypes::StringString>(
00267         dynamic_map_a, dynamic_map_b);
00268 
00269     const auto foo_a = va->get("foo");
00270     REQUIRE(foo_a.has_value());
00271     REQUIRE(*foo_a == "bar");
00272 
00273     const auto foo_b = vb->get("foo");
00274     REQUIRE(foo_b.has_value());
00275     REQUIRE(*foo_b == "baz");
00276   }
00277 }
00278 
00279 
00280 {
00281   kv::Store kv_store;
00282 
00283   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00284   kv_store.set_encryptor(encryptor);
00285 
00286   constexpr auto key = "foo";
00287 
00288   MapTypes::StringString prior_map("prior_map");
00289   {
00290     auto tx = kv_store.create_tx();
00291     auto view = tx.get_view(prior_map);
00292     view->put(key, "bar");
00293     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00294   }
00295 
00296   constexpr auto dynamic_map_a = "dynamic_map_a";
00297   constexpr auto dynamic_map_b = "dynamic_map_b";
00298 
00299   SUBCASE("Parallel independent map creation")
00300   {
00301     auto tx1 = kv_store.create_tx();
00302     auto tx2 = kv_store.create_tx();
00303 
00304     auto view1 = tx1.get_view<MapTypes::NumString>(dynamic_map_a);
00305     auto view2 = tx2.get_view<MapTypes::StringNum>(dynamic_map_b);
00306 
00307     view1->put(42, "hello");
00308     view2->put("hello", 42);
00309 
00310     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00311     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00312   }
00313 
00314   SUBCASE("Map creation blocked by standard conflict")
00315   {
00316     auto tx1 = kv_store.create_tx();
00317     {
00318       auto view1 = tx1.get_view(prior_map);
00319       const auto v = view1->get(key); // Introduce read-dependency
00320       view1->put(key, "bar");
00321       auto dynamic_view = tx1.get_view<MapTypes::NumString>(dynamic_map_a);
00322       dynamic_view->put(42, "hello world");
00323     }
00324 
00325     auto tx2 = kv_store.create_tx();
00326     {
00327       auto view2 = tx2.get_view(prior_map);
00328       const auto v = view2->get(key); // Introduce read-dependency
00329       view2->put(key, "bar");
00330       auto dynamic_view = tx2.get_view<MapTypes::StringNum>(dynamic_map_b);
00331       dynamic_view->put("hello world", 42);
00332     }
00333 
00334     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00335     REQUIRE(tx2.commit() == kv::CommitSuccess::CONFLICT);
00336 
00337     {
00338       auto tx3 = kv_store.create_tx();
00339 
00340       auto [view1, view2] =
00341         tx3.get_view<MapTypes::NumString, MapTypes::StringNum>(
00342           dynamic_map_a, dynamic_map_b);
00343 
00344       const auto v1 = view1->get(42);
00345       REQUIRE(v1.has_value());
00346       REQUIRE(v1.value() == "hello world");
00347 
00348       const auto v2 = view2->get("hello world");
00349       REQUIRE_FALSE(v2.has_value());
00350     }
00351   }
00352 }
00353 
00354 
00355 {
00356   auto consensus = std::make_shared<kv::StubConsensus>();
00357   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00358 
00359   kv::Store kv_store(consensus);
00360   kv_store.set_encryptor(encryptor);
00361 
00362   kv::Store kv_store_target;
00363   kv_store_target.set_encryptor(encryptor);
00364 
00365   const auto map_name = "new_map";
00366   const auto key = "foo";
00367   const auto value = "bar";
00368 
00369   {
00370     INFO("Commit a map creation in source store");
00371     auto tx = kv_store.create_tx();
00372     auto view = tx.get_view<MapTypes::StringString>(map_name);
00373     view->put(key, value);
00374     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00375   }
00376 
00377   {
00378     INFO("Deserialise transaction in target store");
00379     const auto latest_data = consensus->get_latest_data();
00380     REQUIRE(latest_data.has_value());
00381 
00382     REQUIRE(
00383       kv_store_target.deserialise(latest_data.value()) ==
00384       kv::DeserialiseSuccess::PASS);
00385 
00386     auto tx_target = kv_store_target.create_tx();
00387     auto view_target = tx_target.get_view<MapTypes::StringString>(map_name);
00388     const auto v = view_target->get(key);
00389     REQUIRE(v.has_value());
00390     REQUIRE(v.value() == value);
00391   }
00392 }
00393 
00394 
00395 {
00396   kv::Store store;
00397   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00398   store.set_encryptor(encryptor);
00399 
00400   constexpr auto map_name = "string_map";
00401 
00402   kv::Version snapshot_version;
00403   INFO("Create maps in original store");
00404   {
00405     auto tx1 = store.create_tx();
00406     auto view_1 = tx1.get_view<MapTypes::StringString>(map_name);
00407     view_1->put("foo", "foo");
00408     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00409 
00410     auto tx2 = store.create_tx();
00411     auto view_2 = tx2.get_view<MapTypes::StringString>(map_name);
00412     view_2->put("bar", "bar");
00413     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00414 
00415     snapshot_version = tx2.commit_version();
00416   }
00417 
00418   INFO("Create snapshot of original store");
00419   auto snapshot = store.snapshot(snapshot_version);
00420   auto serialised_snapshot = store.serialise_snapshot(std::move(snapshot));
00421 
00422   INFO("Apply snapshot to create maps in new store");
00423   {
00424     kv::Store new_store;
00425     new_store.set_encryptor(encryptor);
00426     new_store.deserialise_snapshot(serialised_snapshot);
00427 
00428     auto tx = new_store.create_tx();
00429     auto view = tx.get_view<MapTypes::StringString>(map_name);
00430 
00431     const auto foo_v = view->get("foo");
00432     REQUIRE(foo_v.has_value());
00433     REQUIRE(foo_v.value() == "foo");
00434 
00435     const auto bar_v = view->get("bar");
00436     REQUIRE(bar_v.has_value());
00437     REQUIRE(bar_v.value() == "bar");
00438   }
00439 }
00440 
00441 
00442 {
00443   kv::Store kv_store;
00444 
00445   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00446   kv_store.set_encryptor(encryptor);
00447 
00448   constexpr auto map_name = "my_new_map";
00449 
00450   const auto version_before = kv_store.current_version();
00451 
00452   {
00453     auto tx = kv_store.create_tx();
00454 
00455     auto view = tx.get_view<MapTypes::StringString>(map_name);
00456     view->put("foo", "bar");
00457 
00458     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00459   }
00460 
00461   {
00462     auto tx = kv_store.create_tx();
00463     auto view = tx.get_view<MapTypes::StringString>(map_name);
00464     const auto v_0 = view->get("foo");
00465     REQUIRE(v_0.has_value());
00466     REQUIRE(v_0.value() == "bar");
00467 
00468     // Rollbacks may happen while a tx is executing, and these can delete the
00469     // maps this tx is executing over
00470     kv_store.rollback(version_before);
00471 
00472     const auto v_1 = view->get("foo");
00473     REQUIRE(v_0.has_value());
00474     REQUIRE(v_0.value() == "bar");
00475 
00476     auto view_after = tx.get_view<MapTypes::StringString>(map_name);
00477     REQUIRE(view_after == view);
00478 
00479     view->put("foo", "baz");
00480 
00481     const auto result = tx.commit();
00482     REQUIRE(result == kv::CommitSuccess::CONFLICT);
00483   }
00484 }
00485 
00486 TEST_CASE(
00487   "Security domain is determined by map name" * doctest::test_suite("dynamic"))
00488 {
00489   kv::Store kv_store;
00490 
00491   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00492   kv_store.set_encryptor(encryptor);
00493 
00494   {
00495     auto tx = kv_store.create_tx();
00496     auto view = tx.get_view<MapTypes::StringString>("public:foo");
00497     view->put("foo", "bar");
00498 
00499     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00500   }
00501 
00502   {
00503     auto tx = kv_store.create_tx();
00504     auto view = tx.get_view<MapTypes::StringString>("foo");
00505     view->put("hello", "world");
00506 
00507     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00508   }
00509 
00510   {
00511     auto tx = kv_store.create_tx();
00512     auto [public_view, private_view] =
00513       tx.get_view<MapTypes::StringString, MapTypes::StringString>(
00514         "public:foo", "foo");
00515 
00516     // These are _different views_ over _different maps_
00517     REQUIRE(public_view != private_view);
00518 
00519     const auto pub_v = public_view->get("foo");
00520     REQUIRE(pub_v.has_value());
00521     REQUIRE(pub_v.value() == "bar");
00522 
00523     const auto priv_v = private_view->get("hello");
00524     REQUIRE(priv_v.has_value());
00525     REQUIRE(priv_v.value() == "world");
00526   }
00527 }
00528 
00529 
00530 {
00531   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00532 
00533   kv::Store s1;
00534   s1.set_encryptor(encryptor);
00535 
00536   {
00537     auto tx = s1.create_tx();
00538     auto [v0, v1] =
00539       tx.get_view<MapTypes::StringString, MapTypes::NumString>("foo", "bar");
00540     v0->put("hello", "world");
00541     v1->put(42, "everything");
00542     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00543   }
00544 
00545   {
00546     auto tx = s1.create_tx();
00547     auto [v0, v1] =
00548       tx.get_view<MapTypes::StringString, MapTypes::StringNum>("foo", "baz");
00549     v0->put("hello", "goodbye");
00550     v1->put("saluton", 100);
00551     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00552   }
00553 
00554   {
00555     // Create _public_ state in source store
00556     auto tx = s1.create_tx();
00557     auto v0 = tx.get_view<MapTypes::StringString>("public:source_state");
00558     v0->put("store", "source");
00559     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00560   }
00561 
00562   kv::Store s2;
00563   s2.set_encryptor(encryptor);
00564 
00565   // Ensure source store is at _at least_ the same version as source store
00566   while (s2.current_version() < s1.current_version())
00567   {
00568     // Create public state in target store, to confirm it is unaffected
00569     auto tx = s2.create_tx();
00570     auto v0 = tx.get_view<MapTypes::StringString>("public:target_state");
00571     v0->put("store", "target");
00572     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00573   }
00574 
00575   s1.compact(s1.current_version());
00576 
00577   s2.swap_private_maps(s1);
00578 
00579   {
00580     INFO("Private state is transferred");
00581     auto tx = s2.create_tx();
00582 
00583     auto [v0, v1, v2] = tx.get_view<
00584       MapTypes::StringString,
00585       MapTypes::NumString,
00586       MapTypes::StringNum>("foo", "bar", "baz");
00587 
00588     const auto val0 = v0->get("hello");
00589     REQUIRE(val0.has_value());
00590     REQUIRE(val0.value() == "goodbye");
00591 
00592     const auto val1 = v1->get(42);
00593     REQUIRE(val1.has_value());
00594     REQUIRE(val1.value() == "everything");
00595 
00596     const auto val2 = v2->get("saluton");
00597     REQUIRE(val2.has_value());
00598     REQUIRE(val2.value() == 100);
00599   }
00600 
00601   {
00602     INFO("Public state is untouched");
00603     auto tx = s2.create_tx();
00604 
00605     auto [v0, v1] = tx.get_view<MapTypes::StringString, MapTypes::StringString>(
00606       "public:source_state", "public:target_state");
00607 
00608     const auto val0 = v0->get("store");
00609     REQUIRE_FALSE(val0.has_value());
00610 
00611     const auto val1 = v1->get("store");
00612     REQUIRE(val1.has_value());
00613     REQUIRE(val1.value() == "target");
00614   }
00615 }
00616 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/test/kv_dynamic_tables.cpp...
Preprocessing /data/git/CCF/src/kv/test/kv_serialisation.cpp...
#include ds/logger.h: not found! skipping...
#include kv/encryptor.h: not found! skipping...
#include kv/kv_serialiser.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 19790 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 struct MapTypes
00017 {
00018   using StringString = kv::Map<std::string, std::string>;
00019   using NumNum = kv::Map<size_t, size_t>;
00020   using NumString = kv::Map<size_t, std::string>;
00021   using StringNum = kv::Map<std::string, size_t>;
00022 };
00023 
00024 TEST_CASE(
00025   "Serialise/deserialise public map only" *
00026   doctest::test_suite("serialisation"))
00027 {
00028   // No need for an encryptor here as all maps are public. Both serialisation
00029   // and deserialisation should succeed.
00030   auto consensus = std::make_shared<kv::StubConsensus>();
00031 
00032   kv::Store kv_store(consensus);
00033 
00034   kv::Store kv_store_target;
00035 
00036   INFO("Commit to public map in source store");
00037   {
00038     auto tx = kv_store.create_tx();
00039     auto view0 = tx.get_view<MapTypes::StringString>("public:pub_map");
00040     view0->put("pubk1", "pubv1");
00041     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00042   }
00043 
00044   INFO("Deserialise transaction in target store");
00045   {
00046     const auto latest_data = consensus->get_latest_data();
00047     REQUIRE(latest_data.has_value());
00048     REQUIRE(!latest_data.value().empty());
00049     REQUIRE(
00050       kv_store_target.deserialise(latest_data.value()) ==
00051       kv::DeserialiseSuccess::PASS);
00052 
00053     auto tx_target = kv_store_target.create_tx();
00054     auto view_target =
00055       tx_target.get_view<MapTypes::StringString>("public:pub_map");
00056     REQUIRE(view_target->get("pubk1") == "pubv1");
00057   }
00058 }
00059 
00060 TEST_CASE(
00061   "Serialise/deserialise private map only" *
00062   doctest::test_suite("serialisation"))
00063 {
00064   auto consensus = std::make_shared<kv::StubConsensus>();
00065   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00066 
00067   kv::Store kv_store(consensus);
00068 
00069   kv::Store kv_store_target;
00070   kv_store_target.set_encryptor(encryptor);
00071 
00072   SUBCASE(
00073     "Commit a private transaction without an encryptor throws an exception")
00074   {
00075     auto tx = kv_store.create_tx();
00076     auto view0 = tx.get_view<MapTypes::StringString>("priv_map");
00077     view0->put("privk1", "privv1");
00078     REQUIRE_THROWS_AS(tx.commit(), kv::KvSerialiserException);
00079   }
00080 
00081   SUBCASE("Commit private transaction with encryptor")
00082   {
00083     kv_store.set_encryptor(encryptor);
00084     INFO("Commit to private map in source store");
00085     {
00086       auto tx = kv_store.create_tx();
00087       auto view0 = tx.get_view<MapTypes::StringString>("priv_map");
00088       view0->put("privk1", "privv1");
00089       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00090     }
00091 
00092     INFO("Deserialise transaction in target store");
00093     {
00094       const auto latest_data = consensus->get_latest_data();
00095       REQUIRE(latest_data.has_value());
00096       REQUIRE(
00097         kv_store_target.deserialise(latest_data.value()) ==
00098         kv::DeserialiseSuccess::PASS);
00099 
00100       auto tx_target = kv_store_target.create_tx();
00101       auto view_target = tx_target.get_view<MapTypes::StringString>("priv_map");
00102       REQUIRE(view_target->get("privk1") == "privv1");
00103     }
00104   }
00105 }
00106 
00107 TEST_CASE(
00108   "Serialise/deserialise private map and public maps" *
00109   doctest::test_suite("serialisation"))
00110 {
00111   auto consensus = std::make_shared<kv::StubConsensus>();
00112   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00113 
00114   kv::Store kv_store(consensus);
00115   kv_store.set_encryptor(encryptor);
00116 
00117   constexpr auto priv_map = "priv_map";
00118   constexpr auto pub_map = "public:pub_map";
00119 
00120   kv::Store kv_store_target;
00121   kv_store_target.set_encryptor(encryptor);
00122 
00123   INFO("Commit to public and private map in source store");
00124   {
00125     auto tx = kv_store.create_tx();
00126     auto [view_priv, view_pub] =
00127       tx.get_view<MapTypes::StringString, MapTypes::StringString>(
00128         priv_map, pub_map);
00129 
00130     view_priv->put("privk1", "privv1");
00131     view_pub->put("pubk1", "pubv1");
00132 
00133     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00134   }
00135 
00136   INFO("Deserialise transaction in target store");
00137   {
00138     const auto latest_data = consensus->get_latest_data();
00139     REQUIRE(latest_data.has_value());
00140     REQUIRE(
00141       kv_store_target.deserialise(latest_data.value()) !=
00142       kv::DeserialiseSuccess::FAILED);
00143 
00144     auto tx_target = kv_store_target.create_tx();
00145     auto [view_priv, view_pub] =
00146       tx_target.get_view<MapTypes::StringString, MapTypes::StringString>(
00147         priv_map, pub_map);
00148 
00149     REQUIRE(view_priv->get("privk1") == "privv1");
00150     REQUIRE(view_pub->get("pubk1") == "pubv1");
00151   }
00152 }
00153 
00154 TEST_CASE(
00155   "Serialise/deserialise removed keys" * doctest::test_suite("serialisation"))
00156 {
00157   auto consensus = std::make_shared<kv::StubConsensus>();
00158   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00159 
00160   kv::Store kv_store(consensus);
00161   kv_store.set_encryptor(encryptor);
00162 
00163   kv::Store kv_store_target;
00164   kv_store_target.set_encryptor(encryptor);
00165 
00166   INFO("Commit a new key in source store and deserialise in target store");
00167   {
00168     auto tx = kv_store.create_tx();
00169     auto view_priv = tx.get_view<MapTypes::StringString>("priv_map");
00170     view_priv->put("privk1", "privv1");
00171     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00172 
00173     const auto latest_data = consensus->get_latest_data();
00174     REQUIRE(latest_data.has_value());
00175     REQUIRE(
00176       kv_store_target.deserialise(latest_data.value()) !=
00177       kv::DeserialiseSuccess::FAILED);
00178 
00179     auto tx_target = kv_store_target.create_tx();
00180     auto view_priv_target =
00181       tx_target.get_view<MapTypes::StringString>("priv_map");
00182     REQUIRE(view_priv_target->get("privk1") == "privv1");
00183   }
00184 
00185   INFO("Commit key removal in source store and deserialise in target store");
00186   {
00187     auto tx = kv_store.create_tx();
00188     auto view_priv = tx.get_view<MapTypes::StringString>("priv_map");
00189     view_priv->remove("privk1");
00190     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00191 
00192     // Make sure it has been marked as deleted in source store
00193     auto tx2 = kv_store.create_tx();
00194     auto view_priv2 = tx2.get_view<MapTypes::StringString>("priv_map");
00195     REQUIRE(view_priv2->get("privk1").has_value() == false);
00196 
00197     const auto latest_data = consensus->get_latest_data();
00198     REQUIRE(latest_data.has_value());
00199     REQUIRE(
00200       kv_store_target.deserialise(latest_data.value()) !=
00201       kv::DeserialiseSuccess::FAILED);
00202 
00203     auto tx_target = kv_store_target.create_tx();
00204     auto view_priv_target =
00205       tx_target.get_view<MapTypes::StringString>("priv_map");
00206     REQUIRE(view_priv_target->get("privk1").has_value() == false);
00207   }
00208 }
00209 
00210 // SNIPPET_START: CustomClass definition
00211 struct CustomClass
00212 {
00213   std::string s;
00214   size_t n;
00215 
00216   // This macro allows the default msgpack serialiser to be used
00217   MSGPACK_DEFINE(s, n);
00218 };
00219 // SNIPPET_END: CustomClass definition
00220 
00221 // These macros allow the default nlohmann JSON serialiser to be used
00222 DECLARE_JSON_TYPE(CustomClass);
00223 DECLARE_JSON_REQUIRED_FIELDS(CustomClass, s, n);
00224 
00225 // Not really intended to be extended, but lets us use the BlitSerialiser for
00226 // this specific type
00227 namespace kv::serialisers
00228 {
00229   template <>
00230   struct BlitSerialiser<CustomClass>
00231   {
00232     static SerialisedEntry to_serialised(const CustomClass& cc)
00233     {
00234       // Don't encode size, entire remainder of buffer is string
00235       const auto s_size = cc.s.size();
00236       const auto total_size = sizeof(cc.n) + s_size;
00237       SerialisedEntry s(total_size);
00238 
00239       uint8_t* data = s.data();
00240       size_t remaining = s.size();
00241 
00242       memcpy(data, (void*)&cc.n, sizeof(cc.n));
00243       data += sizeof(cc.n);
00244       remaining -= sizeof(cc.n);
00245 
00246       memcpy(data, (void*)cc.s.c_str(), remaining);
00247 
00248       return s;
00249     }
00250 
00251     static CustomClass from_serialised(const SerialisedEntry& s)
00252     {
00253       CustomClass cc;
00254       const uint8_t* data = s.data();
00255       size_t remaining = s.size();
00256 
00257       cc.n = *(decltype(cc.n)*)data;
00258       data += sizeof(cc.n);
00259       remaining -= sizeof(cc.n);
00260 
00261       cc.s.assign(data, data + remaining);
00262 
00263       return cc;
00264     }
00265   };
00266 }
00267 
00268 // SNIPPET_START: CustomSerialiser definition
00269 struct CustomSerialiser
00270 {
00271   /**
00272    * Format:
00273    * [ 8 bytes=n | 8 bytes=size_of_s | size_of_s bytes=s... ]
00274    */
00275 
00276   static constexpr auto size_of_n = 8;
00277   static constexpr auto size_of_size_of_s = 8;
00278   static kv::serialisers::SerialisedEntry to_serialised(const CustomClass& cc)
00279   {
00280     const auto s_size = cc.s.size();
00281     const auto total_size = size_of_n + size_of_size_of_s + s_size;
00282     kv::serialisers::SerialisedEntry serialised(total_size);
00283     uint8_t* data = serialised.data();
00284     memcpy(data, (const uint8_t*)&cc.n, size_of_n);
00285     data += size_of_n;
00286     memcpy(data, (const uint8_t*)&s_size, size_of_size_of_s);
00287     data += size_of_size_of_s;
00288     memcpy(data, (const uint8_t*)cc.s.data(), s_size);
00289     return serialised;
00290   }
00291 
00292   static CustomClass from_serialised(
00293     const kv::serialisers::SerialisedEntry& ser)
00294   {
00295     CustomClass cc;
00296     const uint8_t* data = ser.data();
00297     cc.n = *(const uint64_t*)data;
00298     data += size_of_n;
00299     const auto s_size = *(const uint64_t*)data;
00300     data += size_of_size_of_s;
00301     cc.s.resize(s_size);
00302     std::memcpy(cc.s.data(), data, s_size);
00303     return cc;
00304   }
00305 };
00306 // SNIPPET_END: CustomSerialiser definition
00307 
00308 struct CustomJsonSerialiser
00309 {
00310   using Bytes = kv::serialisers::SerialisedEntry;
00311 
00312   static Bytes to_serialised(const CustomClass& c)
00313   {
00314     nlohmann::json j = nlohmann::json::object();
00315     j["s"] = c.s;
00316     j["n"] = c.n;
00317     const auto s = j.dump();
00318     return Bytes(s.begin(), s.end());
00319   }
00320 
00321   static CustomClass from_serialised(const Bytes& b)
00322   {
00323     const auto j = nlohmann::json::parse(b.begin(), b.end());
00324     CustomClass c;
00325     c.s = j["s"];
00326     c.n = j["n"];
00327     return c;
00328   }
00329 };
00330 
00331 struct KPrefix
00332 {
00333   static constexpr auto prefix = "This is a key:";
00334 };
00335 
00336 struct VPrefix
00337 {
00338   static constexpr auto prefix = "Here follows a value:";
00339 };
00340 
00341 template <typename T>
00342 struct CustomVerboseDumbSerialiser
00343 {
00344   using Bytes = kv::serialisers::SerialisedEntry;
00345 
00346   static Bytes to_serialised(const CustomClass& c)
00347   {
00348     const auto verbose = fmt::format("{}\ns={}\nn={}", T::prefix, c.s, c.n);
00349     return Bytes(verbose.begin(), verbose.end());
00350   }
00351 
00352   static CustomClass from_serialised(const Bytes& b)
00353   {
00354     std::string s(b.begin(), b.end());
00355     const auto prefix_start = s.find(T::prefix);
00356     if (prefix_start != 0)
00357     {
00358       throw std::logic_error("Missing expected prefix");
00359     }
00360 
00361     CustomClass c;
00362     const auto first_linebreak = s.find('\n');
00363     const auto last_linebreak = s.rfind('\n');
00364     const auto seg_a = s.substr(0, first_linebreak);
00365     const auto seg_b =
00366       s.substr(first_linebreak + 1, last_linebreak - first_linebreak - 1);
00367     const auto seg_c = s.substr(last_linebreak + 1);
00368 
00369     c.s = seg_b.substr(strlen("s="));
00370     const auto n_str = seg_c.substr(strlen("n="));
00371     c.n = strtoul(n_str.c_str(), nullptr, 10);
00372     return c;
00373   }
00374 };
00375 
00376 using DefaultSerialisedMap = kv::Map<CustomClass, CustomClass>;
00377 using JsonSerialisedMap = kv::JsonSerialisedMap<CustomClass, CustomClass>;
00378 using RawCopySerialisedMap = kv::RawCopySerialisedMap<CustomClass, CustomClass>;
00379 using MixSerialisedMapA = kv::TypedMap<
00380   CustomClass,
00381   CustomClass,
00382   kv::serialisers::MsgPackSerialiser<CustomClass>,
00383   kv::serialisers::JsonSerialiser<CustomClass>>;
00384 using MixSerialisedMapB = kv::TypedMap<
00385   CustomClass,
00386   CustomClass,
00387   kv::serialisers::JsonSerialiser<CustomClass>,
00388   kv::serialisers::BlitSerialiser<CustomClass>>;
00389 using MixSerialisedMapC = kv::TypedMap<
00390   CustomClass,
00391   CustomClass,
00392   kv::serialisers::BlitSerialiser<CustomClass>,
00393   kv::serialisers::MsgPackSerialiser<CustomClass>>;
00394 
00395 // SNIPPET_START: CustomSerialisedMap definition
00396 using CustomSerialisedMap =
00397   kv::TypedMap<CustomClass, CustomClass, CustomSerialiser, CustomSerialiser>;
00398 // SNIPPET_END: CustomSerialisedMap definition
00399 
00400 using CustomJsonMap = kv::TypedMap<
00401   CustomClass,
00402   CustomClass,
00403   CustomJsonSerialiser,
00404   CustomJsonSerialiser>;
00405 using VerboseSerialisedMap = kv::TypedMap<
00406   CustomClass,
00407   CustomClass,
00408   CustomVerboseDumbSerialiser<KPrefix>,
00409   CustomVerboseDumbSerialiser<VPrefix>>;
00410 
00411 TEST_CASE_TEMPLATE(
00412   "Custom type serialisation test" * doctest::test_suite("serialisation"),
00413   MapType,
00414   DefaultSerialisedMap,
00415   JsonSerialisedMap,
00416   RawCopySerialisedMap,
00417   MixSerialisedMapA,
00418   MixSerialisedMapB,
00419   MixSerialisedMapC,
00420   CustomSerialisedMap,
00421   CustomJsonMap,
00422   VerboseSerialisedMap)
00423 {
00424   kv::Store kv_store;
00425 
00426   MapType map("public:map");
00427 
00428   CustomClass k1{"hello", 42};
00429   CustomClass v1{"world", 43};
00430 
00431   CustomClass k2{"saluton", 100};
00432   CustomClass v2{"mondo", 1024};
00433 
00434   INFO("Serialise/Deserialise 2 kv stores");
00435   {
00436     kv::Store kv_store2;
00437     MapType map2("public:map");
00438 
00439     auto tx = kv_store.create_reserved_tx(kv_store.next_version());
00440     auto view = tx.get_view(map);
00441     view->put(k1, v1);
00442     view->put(k2, v2);
00443 
00444     auto [success, reqid, data] = tx.commit_reserved();
00445     REQUIRE(success == kv::CommitSuccess::OK);
00446     kv_store.compact(kv_store.current_version());
00447 
00448     REQUIRE(kv_store2.deserialise(data) == kv::DeserialiseSuccess::PASS);
00449     auto tx2 = kv_store2.create_tx();
00450     auto view2 = tx2.get_view(map2);
00451 
00452     // operator== does not need to be defined for custom types. In this case it
00453     // is not, and we check each member manually
00454     auto va = view2->get(k1);
00455     REQUIRE(va.has_value());
00456     REQUIRE(va->s == v1.s);
00457     REQUIRE(va->n == v1.n);
00458 
00459     auto vb = view2->get(k2);
00460     REQUIRE(vb.has_value());
00461     REQUIRE(vb->s == v2.s);
00462     REQUIRE(vb->n == v2.n);
00463   }
00464 }
00465 
00466 bool corrupt_serialised_tx(
00467   std::vector<uint8_t>& serialised_tx, std::vector<uint8_t>& value_to_corrupt)
00468 {
00469   // This utility function corrupts a serialised transaction by changing one
00470   // byte of the public domain as specified by value_to_corrupt.
00471   std::vector<uint8_t> match_buffer;
00472   for (auto& i : serialised_tx)
00473   {
00474     if (i == value_to_corrupt[match_buffer.size()])
00475     {
00476       match_buffer.push_back(i);
00477       if (match_buffer.size() == value_to_corrupt.size())
00478       {
00479         i = 'X';
00480         LOG_DEBUG_FMT("Corrupting serialised public data");
00481         return true;
00482       }
00483     }
00484     else
00485     {
00486       match_buffer.clear();
00487     }
00488   }
00489   return false;
00490 }
00491 
00492 
00493 {
00494   SUBCASE("Public and Private")
00495   {
00496     auto consensus = std::make_shared<kv::StubConsensus>();
00497 
00498     // Here, a real encryptor is needed to protect the integrity of the
00499     // transactions
00500     std::list<kv::TxEncryptor::KeyInfo> keys;
00501     std::vector<uint8_t> raw_key(crypto::GCM_SIZE_KEY);
00502     for (size_t i = 0; i < raw_key.size(); ++i)
00503     {
00504       raw_key[i] = i;
00505     }
00506     keys.push_back({kv::Version(0), raw_key});
00507     auto encryptor = std::make_shared<kv::TxEncryptor>(keys);
00508     encryptor->set_iv_id(1);
00509 
00510     kv::Store kv_store(consensus);
00511     kv::Store kv_store_target;
00512     kv_store.set_encryptor(encryptor);
00513     kv_store_target.set_encryptor(encryptor);
00514 
00515     MapTypes::StringString public_map("public:public_map");
00516     MapTypes::StringString private_map("private_map");
00517 
00518     auto tx = kv_store.create_tx();
00519     auto [public_view, private_view] = tx.get_view(public_map, private_map);
00520     std::string pub_value = "pubv1";
00521     public_view->put("pubk1", pub_value);
00522     private_view->put("privk1", "privv1");
00523     auto rc = tx.commit();
00524 
00525     // Tamper with serialised public data
00526     auto latest_data = consensus->get_latest_data();
00527     REQUIRE(latest_data.has_value());
00528     std::vector<uint8_t> value_to_corrupt(pub_value.begin(), pub_value.end());
00529     REQUIRE(corrupt_serialised_tx(latest_data.value(), value_to_corrupt));
00530 
00531     REQUIRE(
00532       kv_store_target.deserialise(latest_data.value()) ==
00533       kv::DeserialiseSuccess::FAILED);
00534   }
00535 }
00536 
00537 TEST_CASE("nlohmann (de)serialisation" * doctest::test_suite("serialisation"))
00538 {
00539   const auto k0 = "abc";
00540   const auto v0 = 123;
00541 
00542   const std::vector<int> k1{4, 5, 6, 7};
00543   const std::string v1 = "xyz";
00544 
00545   SUBCASE("baseline")
00546   {
00547     auto consensus = std::make_shared<kv::StubConsensus>();
00548     using Table = kv::Map<std::vector<int>, std::string>;
00549     kv::Store s0(consensus), s1;
00550     Table t("public:t");
00551 
00552     auto tx = s0.create_tx();
00553     tx.get_view(t)->put(k1, v1);
00554     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00555 
00556     const auto latest_data = consensus->get_latest_data();
00557     REQUIRE(latest_data.has_value());
00558     REQUIRE(
00559       s1.deserialise(latest_data.value()) != kv::DeserialiseSuccess::FAILED);
00560   }
00561 
00562   SUBCASE("nlohmann")
00563   {
00564     auto consensus = std::make_shared<kv::StubConsensus>();
00565     using Table = kv::Map<nlohmann::json, nlohmann::json>;
00566     kv::Store s0(consensus), s1;
00567     Table t("public:t");
00568 
00569     auto tx = s0.create_tx();
00570     tx.get_view(t)->put(k0, v0);
00571     tx.get_view(t)->put(k1, v1);
00572     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00573 
00574     const auto latest_data = consensus->get_latest_data();
00575     REQUIRE(latest_data.has_value());
00576     REQUIRE(
00577       s1.deserialise(latest_data.value()) != kv::DeserialiseSuccess::FAILED);
00578   }
00579 }
00580 
00581 TEST_CASE(
00582   "Replicated and derived table serialisation" *
00583   doctest::test_suite("serialisation"))
00584 {
00585   using T = MapTypes::NumNum;
00586 
00587   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00588   constexpr auto data_replicated = "public:data_replicated";
00589   constexpr auto data_derived = "data_replicated";
00590   constexpr auto data_replicated_private = "public:data_replicated_private";
00591   constexpr auto data_derived_private = "data_replicated_private";
00592   std::unordered_set<std::string> replicated_tables = {data_replicated,
00593                                                        data_replicated_private};
00594 
00595   kv::Store store(kv::ReplicateType::SOME, replicated_tables);
00596   store.set_encryptor(encryptor);
00597 
00598   kv::Store kv_store_target(kv::ReplicateType::SOME, replicated_tables);
00599   kv_store_target.set_encryptor(encryptor);
00600 
00601   {
00602     auto tx = store.create_reserved_tx(store.next_version());
00603 
00604     auto [data_view_r, data_view_r_p, data_view_d, data_view_d_p] =
00605       tx.get_view<T, T, T, T>(
00606         data_replicated,
00607         data_replicated_private,
00608         data_derived,
00609         data_derived_private);
00610     data_view_r->put(44, 44);
00611     data_view_r_p->put(45, 45);
00612     data_view_d->put(46, 46);
00613     data_view_d_p->put(47, 47);
00614 
00615     auto [success, reqid, data] = tx.commit_reserved();
00616     REQUIRE(success == kv::CommitSuccess::OK);
00617     REQUIRE(store.deserialise(data) == kv::DeserialiseSuccess::PASS);
00618 
00619     INFO("check that second store derived data is not populated");
00620     {
00621       REQUIRE(
00622         kv_store_target.deserialise(data) == kv::DeserialiseSuccess::PASS);
00623       auto tx = kv_store_target.create_tx();
00624       auto [data_view_r, data_view_r_p, data_view_d, data_view_d_p] =
00625         tx.get_view<T, T, T, T>(
00626           data_replicated,
00627           data_replicated_private,
00628           data_derived,
00629           data_derived_private);
00630       auto dvr = data_view_r->get(44);
00631       REQUIRE(dvr.has_value());
00632       REQUIRE(dvr.value() == 44);
00633 
00634       auto dvrp = data_view_r_p->get(45);
00635       REQUIRE(dvrp.has_value());
00636       REQUIRE(dvrp.value() == 45);
00637 
00638       auto dvd = data_view_d->get(46);
00639       REQUIRE(!dvd.has_value());
00640       auto dvdp = data_view_d_p->get(47);
00641       REQUIRE(!dvdp.has_value());
00642     }
00643   }
00644 }
00645 
00646 struct NonSerialisable
00647 {};
00648 
00649 struct NonSerialiser
00650 {
00651   using Bytes = kv::serialisers::SerialisedEntry;
00652 
00653   static Bytes to_serialised(const NonSerialisable& ns)
00654   {
00655     throw std::runtime_error("Serialise failure");
00656   }
00657 
00658   static NonSerialisable from_serialised(const Bytes& b)
00659   {
00660     throw std::runtime_error("Deserialise failure");
00661   }
00662 };
00663 
00664 
00665 {
00666   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00667   auto consensus = std::make_shared<kv::StubConsensus>();
00668 
00669   kv::Store store(consensus);
00670   store.set_encryptor(encryptor);
00671 
00672   kv::TypedMap<
00673     NonSerialisable,
00674     size_t,
00675     NonSerialiser,
00676     kv::serialisers::MsgPackSerialiser<size_t>>
00677     bad_map_k("bad_map_k");
00678   kv::TypedMap<
00679     size_t,
00680     NonSerialisable,
00681     kv::serialisers::MsgPackSerialiser<size_t>,
00682     NonSerialiser>
00683     bad_map_v("bad_map_v");
00684 
00685   {
00686     auto tx = store.create_tx();
00687     auto bad_view = tx.get_view(bad_map_k);
00688     REQUIRE_THROWS(bad_view->put({}, 0));
00689   }
00690 
00691   {
00692     auto tx = store.create_tx();
00693     auto bad_view = tx.get_view(bad_map_v);
00694     REQUIRE_THROWS(bad_view->put(0, {}));
00695   }
00696 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/test/kv_serialisation.cpp...
Preprocessing /data/git/CCF/src/kv/test/kv_snapshot.cpp...
#include kv/kv_serialiser.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 6882 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 struct MapTypes
00012 {
00013   using StringString = kv::Map<std::string, std::string>;
00014   using NumNum = kv::Map<size_t, size_t>;
00015 };
00016 
00017 
00018 {
00019   kv::Store store;
00020   MapTypes::StringString string_map("public:string_map");
00021   MapTypes::NumNum num_map("public:num_map");
00022 
00023   kv::Version first_snapshot_version = kv::NoVersion;
00024   kv::Version second_snapshot_version = kv::NoVersion;
00025 
00026   INFO("Apply transactions to original store");
00027   {
00028     auto tx1 = store.create_tx();
00029     auto view_1 = tx1.get_view<MapTypes::StringString>("public:string_map");
00030     view_1->put("foo", "bar");
00031     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00032     first_snapshot_version = tx1.commit_version();
00033 
00034     auto tx2 = store.create_tx();
00035     auto view_2 = tx2.get_view(num_map);
00036     view_2->put(42, 123);
00037     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00038     second_snapshot_version = tx2.commit_version();
00039 
00040     auto tx3 = store.create_tx();
00041     auto view_3 = tx1.get_view<MapTypes::StringString>("public:string_map");
00042     view_3->put("uncommitted", "not committed");
00043     // Do not commit tx3
00044   }
00045 
00046   auto first_snapshot = store.snapshot(first_snapshot_version);
00047   auto first_serialised_snapshot =
00048     store.serialise_snapshot(std::move(first_snapshot));
00049 
00050   INFO("Apply snapshot at 1 to new store");
00051   {
00052     kv::Store new_store;
00053 
00054     REQUIRE_EQ(
00055       new_store.deserialise_snapshot(first_serialised_snapshot),
00056       kv::DeserialiseSuccess::PASS);
00057     REQUIRE_EQ(new_store.current_version(), 1);
00058 
00059     auto tx1 = new_store.create_tx();
00060     auto view = tx1.get_view<MapTypes::StringString>("public:string_map");
00061     auto v = view->get("foo");
00062     REQUIRE(v.has_value());
00063     REQUIRE_EQ(v.value(), "bar");
00064 
00065     auto num_view = tx1.get_view<MapTypes::NumNum>("public:num_map");
00066     REQUIRE(!num_view->has(42));
00067 
00068     REQUIRE(!view->has("uncommitted"));
00069   }
00070 
00071   auto second_snapshot = store.snapshot(second_snapshot_version);
00072   auto second_serialised_snapshot =
00073     store.serialise_snapshot(std::move(second_snapshot));
00074 
00075   INFO("Apply snapshot at 2 to new store");
00076   {
00077     kv::Store new_store;
00078 
00079     new_store.deserialise_snapshot(second_serialised_snapshot);
00080     REQUIRE_EQ(new_store.current_version(), 2);
00081 
00082     auto tx1 = new_store.create_tx();
00083     auto view = tx1.get_view<MapTypes::StringString>("public:string_map");
00084 
00085     auto v = view->get("foo");
00086     REQUIRE(v.has_value());
00087     REQUIRE_EQ(v.value(), "bar");
00088 
00089     auto num_view = tx1.get_view<MapTypes::NumNum>("public:num_map");
00090     auto num_v = num_view->get(42);
00091     REQUIRE(num_v.has_value());
00092     REQUIRE_EQ(num_v.value(), 123);
00093 
00094     REQUIRE(!view->has("uncommitted"));
00095   }
00096 }
00097 
00098 TEST_CASE(
00099   "Commit transaction while applying snapshot" *
00100   doctest::test_suite("snapshot"))
00101 {
00102   kv::Store store;
00103   MapTypes::StringString string_map("public:string_map");
00104 
00105   kv::Version snapshot_version = kv::NoVersion;
00106   INFO("Apply transactions to original store");
00107   {
00108     auto tx1 = store.create_tx();
00109     auto view_1 = tx1.get_view<MapTypes::StringString>("public:string_map");
00110     view_1->put("foo", "foo");
00111     REQUIRE(tx1.commit() == kv::CommitSuccess::OK); // Committed at 1
00112 
00113     auto tx2 = store.create_tx();
00114     auto view_2 = tx2.get_view<MapTypes::StringString>("public:string_map");
00115     view_2->put("bar", "bar");
00116     REQUIRE(tx2.commit() == kv::CommitSuccess::OK); // Committed at 2
00117     snapshot_version = tx2.commit_version();
00118   }
00119 
00120   auto snapshot = store.snapshot(snapshot_version);
00121   auto serialised_snapshot = store.serialise_snapshot(std::move(snapshot));
00122 
00123   INFO("Apply snapshot while committing a transaction");
00124   {
00125     kv::Store new_store;
00126 
00127     auto tx = new_store.create_tx();
00128     auto view = tx.get_view<MapTypes::StringString>("public:string_map");
00129     view->put("in", "flight");
00130     // tx is not committed until the snapshot is deserialised
00131 
00132     new_store.deserialise_snapshot(serialised_snapshot);
00133 
00134     // Transaction conflicts as snapshot was applied while transaction was in
00135     // flight
00136     REQUIRE(tx.commit() == kv::CommitSuccess::CONFLICT);
00137 
00138     // Try again
00139     auto tx2 = new_store.create_tx();
00140     auto view2 = tx2.get_view<MapTypes::StringString>("public:string_map");
00141     view2->put("baz", "baz");
00142     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00143   }
00144 }
00145 
00146 
00147 {
00148   kv::Store store;
00149   constexpr auto string_map = "public:string_map";
00150 
00151   kv::Version snapshot_version = kv::NoVersion;
00152   INFO("Apply transactions to original store");
00153   {
00154     auto tx1 = store.create_tx();
00155     auto view_1 = tx1.get_view<MapTypes::StringString>(string_map);
00156     view_1->put("foo", "foo");
00157     view_1->put("bar", "bar");
00158     REQUIRE(tx1.commit() == kv::CommitSuccess::OK); // Committed at 1
00159 
00160     // New transaction, deleting content from the previous transaction
00161     auto tx2 = store.create_tx();
00162     auto view_2 = tx2.get_view<MapTypes::StringString>(string_map);
00163     view_2->put("baz", "baz");
00164     view_2->remove("bar");
00165     REQUIRE(tx2.commit() == kv::CommitSuccess::OK); // Committed at 2
00166     snapshot_version = tx2.commit_version();
00167   }
00168 
00169   auto snapshot = store.snapshot(snapshot_version);
00170   auto serialised_snapshot = store.serialise_snapshot(std::move(snapshot));
00171 
00172   INFO("Apply snapshot with local hook on target store");
00173   {
00174     kv::Store new_store;
00175 
00176     MapTypes::StringString new_string_map(string_map);
00177 
00178     using Write = MapTypes::StringString::Write;
00179     std::vector<Write> local_writes;
00180     std::vector<Write> global_writes;
00181 
00182     INFO("Set hooks on target store");
00183     {
00184       auto local_hook = [&](kv::Version v, const Write& w) {
00185         local_writes.push_back(w);
00186       };
00187       auto global_hook = [&](kv::Version v, const Write& w) {
00188         global_writes.push_back(w);
00189       };
00190 
00191       new_store.set_local_hook(
00192         string_map, new_string_map.wrap_commit_hook(local_hook));
00193       new_store.set_global_hook(
00194         string_map, new_string_map.wrap_commit_hook(global_hook));
00195     }
00196 
00197     new_store.deserialise_snapshot(serialised_snapshot);
00198 
00199     INFO("Verify content of snapshot");
00200     {
00201       auto tx = new_store.create_tx();
00202       auto view = tx.get_view<MapTypes::StringString>(string_map);
00203       REQUIRE(view->get("foo").has_value());
00204       REQUIRE(!view->get("bar").has_value());
00205       REQUIRE(view->get("baz").has_value());
00206     }
00207 
00208     INFO("Verify local hook execution");
00209     {
00210       REQUIRE_EQ(local_writes.size(), 1);
00211       auto writes = local_writes.at(0);
00212       REQUIRE_EQ(writes.at("foo"), "foo");
00213       REQUIRE_EQ(writes.find("bar"), writes.end());
00214       REQUIRE_EQ(writes.at("baz"), "baz");
00215     }
00216 
00217     INFO("Verify global hook execution after compact");
00218     {
00219       new_store.compact(snapshot_version);
00220 
00221       REQUIRE_EQ(global_writes.size(), 1);
00222       auto writes = global_writes.at(0);
00223       REQUIRE_EQ(writes.at("foo"), "foo");
00224       REQUIRE_EQ(writes.find("bar"), writes.end());
00225       REQUIRE_EQ(writes.at("baz"), "baz");
00226     }
00227   }
00228 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/test/kv_snapshot.cpp...
Preprocessing /data/git/CCF/src/kv/test/kv_test.cpp...
#include ds/logger.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include kv/kv_serialiser.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/history.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include set: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 39140 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00012 
00013 
00014 
00015 
00016 
00017 
00018 struct MapTypes
00019 {
00020   using StringString = kv::Map<std::string, std::string>;
00021   using NumNum = kv::Map<size_t, size_t>;
00022   using NumString = kv::Map<size_t, std::string>;
00023   using StringNum = kv::Map<std::string, size_t>;
00024 };
00025 
00026 TEST_CASE("Map name parsing")
00027 {
00028   using SD = kv::SecurityDomain;
00029   using AC = kv::AccessCategory;
00030 
00031   auto parse = kv::parse_map_name;
00032   auto mp = std::make_pair<SD, AC>;
00033 
00034   REQUIRE(parse("foo") == mp(SD::PRIVATE, AC::APPLICATION));
00035   REQUIRE(parse("public:foo") == mp(SD::PUBLIC, AC::APPLICATION));
00036   REQUIRE(parse("ccf.gov.foo") == mp(SD::PRIVATE, AC::GOVERNANCE));
00037   REQUIRE(parse("public:ccf.gov.foo") == mp(SD::PUBLIC, AC::GOVERNANCE));
00038   REQUIRE(parse("ccf.internal.foo") == mp(SD::PRIVATE, AC::INTERNAL));
00039   REQUIRE(parse("public:ccf.internal.foo") == mp(SD::PUBLIC, AC::INTERNAL));
00040 
00041   REQUIRE_THROWS(parse("ccf.foo"));
00042   REQUIRE_THROWS(parse("public:ccf.foo"));
00043 
00044   // Typos may lead to unexpected behaviour!
00045   REQUIRE(parse("publik:ccf.gov.foo") == mp(SD::PRIVATE, AC::APPLICATION));
00046   REQUIRE(parse("PUBLIC:ccf.gov.foo") == mp(SD::PRIVATE, AC::APPLICATION));
00047   REQUIRE(parse("public:Ccf.gov.foo") == mp(SD::PUBLIC, AC::APPLICATION));
00048 
00049   REQUIRE(parse("ccf_foo") == mp(SD::PRIVATE, AC::APPLICATION));
00050   REQUIRE(parse("public:ccf_foo") == mp(SD::PUBLIC, AC::APPLICATION));
00051 }
00052 
00053 TEST_CASE("Reads/writes and deletions")
00054 {
00055   kv::Store kv_store;
00056 
00057   MapTypes::StringString map("public:map");
00058 
00059   constexpr auto k = "key";
00060   constexpr auto invalid_key = "invalid_key";
00061   constexpr auto v1 = "value1";
00062 
00063   INFO("Start empty transaction");
00064   {
00065     auto tx = kv_store.create_tx();
00066     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00067     REQUIRE_THROWS_AS(tx.commit(), std::logic_error);
00068   }
00069 
00070   INFO("Read own writes");
00071   {
00072     auto tx = kv_store.create_tx();
00073     auto view = tx.get_view(map);
00074     REQUIRE(!view->has(k));
00075     auto v = view->get(k);
00076     REQUIRE(!v.has_value());
00077     view->put(k, v1);
00078     REQUIRE(view->has(k));
00079     auto va = view->get(k);
00080     REQUIRE(va.has_value());
00081     REQUIRE(va.value() == v1);
00082     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00083   }
00084 
00085   INFO("Read previous writes");
00086   {
00087     auto tx = kv_store.create_tx();
00088     auto view = tx.get_view(map);
00089     REQUIRE(view->has(k));
00090     auto v = view->get(k);
00091     REQUIRE(v.has_value());
00092     REQUIRE(v.value() == v1);
00093     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00094   }
00095 
00096   INFO("Remove keys");
00097   {
00098     {
00099       auto tx = kv_store.create_tx();
00100       auto view = tx.get_view(map);
00101       view->put(k, v1);
00102 
00103       REQUIRE(!view->has(invalid_key));
00104       REQUIRE(!view->remove(invalid_key));
00105       REQUIRE(view->remove(k));
00106       REQUIRE(!view->has(k));
00107       auto va = view->get(k);
00108       REQUIRE(!va.has_value());
00109 
00110       view->put(k, v1);
00111       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00112     }
00113 
00114     {
00115       auto tx2 = kv_store.create_tx();
00116       auto view2 = tx2.get_view(map);
00117       REQUIRE(view2->has(k));
00118       REQUIRE(view2->remove(k));
00119     }
00120   }
00121 
00122   INFO("Remove key that was deleted from state");
00123   {
00124     {
00125       auto tx = kv_store.create_tx();
00126       auto view = tx.get_view(map);
00127       view->put(k, v1);
00128       auto va = view->get_globally_committed(k);
00129       REQUIRE(!va.has_value());
00130       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00131     }
00132 
00133     {
00134       auto tx2 = kv_store.create_tx();
00135       auto view2 = tx2.get_view(map);
00136       REQUIRE(view2->has(k));
00137       REQUIRE(view2->remove(k));
00138       REQUIRE(!view2->has(k));
00139       REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00140     }
00141 
00142     {
00143       auto tx3 = kv_store.create_tx();
00144       auto view3 = tx3.get_view(map);
00145       REQUIRE(!view3->has(k));
00146       auto vc = view3->get(k);
00147       REQUIRE(!vc.has_value());
00148     }
00149   }
00150 }
00151 
00152 TEST_CASE("foreach")
00153 {
00154   kv::Store kv_store;
00155   MapTypes::StringString map("public:map");
00156 
00157   std::map<std::string, std::string> iterated_entries;
00158 
00159   auto store_iterated =
00160     [&iterated_entries](const auto& key, const auto& value) {
00161       auto it = iterated_entries.find(key);
00162       REQUIRE(it == iterated_entries.end());
00163       iterated_entries[key] = value;
00164       return true;
00165     };
00166 
00167   SUBCASE("Empty map")
00168   {
00169     auto tx = kv_store.create_tx();
00170     auto view = tx.get_view(map);
00171     view->foreach(store_iterated);
00172     REQUIRE(iterated_entries.empty());
00173   }
00174 
00175   SUBCASE("Reading own writes")
00176   {
00177     auto tx = kv_store.create_tx();
00178     auto view = tx.get_view(map);
00179     view->put("key1", "value1");
00180     view->put("key2", "value2");
00181     view->foreach(store_iterated);
00182     REQUIRE(iterated_entries.size() == 2);
00183     REQUIRE(iterated_entries["key1"] == "value1");
00184     REQUIRE(iterated_entries["key2"] == "value2");
00185 
00186     iterated_entries.clear();
00187 
00188     INFO("Uncommitted writes from other txs are not visible");
00189     auto tx2 = kv_store.create_tx();
00190     auto view2 = tx2.get_view(map);
00191     view2->foreach(store_iterated);
00192     REQUIRE(iterated_entries.empty());
00193   }
00194 
00195   SUBCASE("Reading committed writes")
00196   {
00197     auto tx = kv_store.create_tx();
00198     auto view = tx.get_view(map);
00199     view->put("key1", "value1");
00200     view->put("key2", "value2");
00201     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00202 
00203     auto tx2 = kv_store.create_tx();
00204     auto view2 = tx2.get_view(map);
00205     view2->foreach(store_iterated);
00206     REQUIRE(iterated_entries.size() == 2);
00207     REQUIRE(iterated_entries["key1"] == "value1");
00208     REQUIRE(iterated_entries["key2"] == "value2");
00209   }
00210 
00211   SUBCASE("Mix of committed and own writes")
00212   {
00213     auto tx = kv_store.create_tx();
00214     auto view = tx.get_view(map);
00215     view->put("key1", "value1");
00216     view->put("key2", "value2");
00217     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00218 
00219     auto tx2 = kv_store.create_tx();
00220     auto view2 = tx2.get_view(map);
00221     view2->put("key2", "replaced2");
00222     view2->put("key3", "value3");
00223     view2->foreach(store_iterated);
00224     REQUIRE(iterated_entries.size() == 3);
00225     REQUIRE(iterated_entries["key1"] == "value1");
00226     REQUIRE(iterated_entries["key2"] == "replaced2");
00227     REQUIRE(iterated_entries["key3"] == "value3");
00228   }
00229 
00230   SUBCASE("Deletions")
00231   {
00232     {
00233       auto tx = kv_store.create_tx();
00234       auto view = tx.get_view(map);
00235       view->put("key1", "value1");
00236       view->put("key2", "value2");
00237       view->put("key3", "value3");
00238       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00239     }
00240 
00241     {
00242       auto tx = kv_store.create_tx();
00243       auto view = tx.get_view(map);
00244       view->remove("key1");
00245       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00246     }
00247 
00248     {
00249       auto tx = kv_store.create_tx();
00250       auto view = tx.get_view(map);
00251       view->foreach(store_iterated);
00252       REQUIRE(iterated_entries.size() == 2);
00253       REQUIRE(iterated_entries["key2"] == "value2");
00254       REQUIRE(iterated_entries["key3"] == "value3");
00255 
00256       iterated_entries.clear();
00257 
00258       view->remove("key2");
00259       view->foreach(store_iterated);
00260       REQUIRE(iterated_entries.size() == 1);
00261       REQUIRE(iterated_entries["key3"] == "value3");
00262 
00263       iterated_entries.clear();
00264 
00265       view->put("key1", "value1");
00266       view->put("key2", "value2");
00267       view->foreach(store_iterated);
00268       REQUIRE(iterated_entries.size() == 3);
00269       REQUIRE(iterated_entries["key1"] == "value1");
00270       REQUIRE(iterated_entries["key2"] == "value2");
00271       REQUIRE(iterated_entries["key3"] == "value3");
00272     }
00273   }
00274 
00275   SUBCASE("Early termination")
00276   {
00277     {
00278       auto tx = kv_store.create_tx();
00279       auto view = tx.get_view(map);
00280       view->put("key1", "value1");
00281       view->put("key2", "value2");
00282       view->put("key3", "value3");
00283       size_t ctr = 0;
00284       view->foreach([&ctr](const auto& key, const auto& value) {
00285         ++ctr;
00286         return ctr < 2; // Continue after the first, but not the second (so
00287                         // never see the third)
00288       });
00289       REQUIRE(ctr == 2);
00290       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00291     }
00292 
00293     {
00294       auto tx = kv_store.create_tx();
00295       auto view = tx.get_view(map);
00296       view->put("key4", "value4");
00297       view->put("key5", "value5");
00298 
00299       {
00300         size_t ctr = 0;
00301         view->foreach([&ctr](const auto&, const auto&) {
00302           ++ctr;
00303           return ctr < 2; //< See only committed state
00304         });
00305         REQUIRE(ctr == 2);
00306       }
00307 
00308       {
00309         size_t ctr = 0;
00310         view->foreach([&ctr](const auto&, const auto&) {
00311           ++ctr;
00312           return ctr < 4; //< See mix of old state and new writes
00313         });
00314         REQUIRE(ctr == 4);
00315       }
00316 
00317       {
00318         size_t ctr = 0;
00319         view->foreach([&ctr](const auto&, const auto&) {
00320           ++ctr;
00321           return ctr < 100; //< See as much as possible
00322         });
00323         REQUIRE(ctr == 5);
00324       }
00325     }
00326   }
00327 }
00328 
00329 TEST_CASE("Modifications during foreach iteration")
00330 {
00331   kv::Store kv_store;
00332   MapTypes::NumString map("public:map");
00333 
00334   const auto value1 = "foo";
00335   const auto value2 = "bar";
00336 
00337   std::set<size_t> keys;
00338   {
00339     INFO("Insert initial keys");
00340 
00341     auto tx = kv_store.create_tx();
00342     auto view = tx.get_view(map);
00343     for (size_t i = 0; i < 60; ++i)
00344     {
00345       keys.insert(i);
00346       view->put(i, value1);
00347     }
00348 
00349     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00350   }
00351 
00352   auto tx = kv_store.create_tx();
00353   auto view = tx.get_view(map);
00354 
00355   // 5 types of key:
00356   // 1) previously committed and unmodified
00357   const auto initial_keys_size = keys.size();
00358   const auto keys_per_category = keys.size() / 3;
00359   // We do nothing to the first keys_per_category keys
00360 
00361   // 2) previously committed and had their values changed
00362   for (size_t i = keys_per_category; i < 2 * keys_per_category; ++i)
00363   {
00364     keys.insert(i);
00365     view->put(i, value2);
00366   }
00367 
00368   // 3) previously committed and now removed
00369   for (size_t i = 2 * keys_per_category; i < initial_keys_size; ++i)
00370   {
00371     keys.erase(i);
00372     view->remove(i);
00373   }
00374 
00375   // 4) newly written
00376   for (size_t i = initial_keys_size; i < initial_keys_size + keys_per_category;
00377        ++i)
00378   {
00379     keys.insert(i);
00380     view->put(i, value2);
00381   }
00382 
00383   // 5) newly written and then removed
00384   for (size_t i = initial_keys_size + keys_per_category;
00385        i < initial_keys_size + 2 * keys_per_category;
00386        ++i)
00387   {
00388     keys.insert(i);
00389     view->put(i, value2);
00390 
00391     keys.erase(i);
00392     view->remove(i);
00393   }
00394 
00395   size_t keys_seen = 0;
00396   const auto expected_keys_seen = keys.size();
00397 
00398   SUBCASE("Removing current key while iterating")
00399   {
00400     auto should_remove = [](size_t n) { return n % 3 == 0 || n % 5 == 0; };
00401 
00402     view->foreach(
00403       [&view, &keys, &keys_seen, should_remove](const auto& k, const auto&) {
00404         ++keys_seen;
00405         const auto it = keys.find(k);
00406         REQUIRE(it != keys.end());
00407 
00408         // Remove a 'random' set of keys while iterating
00409         if (should_remove(k))
00410         {
00411           view->remove(k);
00412           keys.erase(it);
00413         }
00414 
00415         return true;
00416       });
00417 
00418     REQUIRE(keys_seen == expected_keys_seen);
00419 
00420     // Check all expected keys are still there...
00421     view->foreach([&keys, should_remove](const auto& k, const auto&) {
00422       REQUIRE(!should_remove(k));
00423       const auto it = keys.find(k);
00424       REQUIRE(it != keys.end());
00425       keys.erase(it);
00426       return true;
00427     });
00428 
00429     // ...and nothing else
00430     REQUIRE(keys.empty());
00431   }
00432 
00433   SUBCASE("Removing other keys while iterating")
00434   {
00435     auto should_remove = [](size_t n) { return n % 3 == 0 || n % 5 == 0; };
00436 
00437     std::optional<size_t> removal_trigger = std::nullopt;
00438 
00439     view->foreach([&view, &keys, &keys_seen, &removal_trigger, should_remove](
00440                     const auto& k, const auto&) {
00441       ++keys_seen;
00442 
00443       // The first time we find a removable, remove _all the others_ (not
00444       // ourself!)
00445       if (should_remove(k) && !removal_trigger.has_value())
00446       {
00447         REQUIRE(!removal_trigger.has_value());
00448         removal_trigger = k;
00449 
00450         auto remove_it = keys.begin();
00451         while (remove_it != keys.end())
00452         {
00453           const auto n = *remove_it;
00454           if (should_remove(n) && n != k)
00455           {
00456             view->remove(n);
00457             remove_it = keys.erase(remove_it);
00458           }
00459           else
00460           {
00461             ++remove_it;
00462           }
00463         }
00464       }
00465 
00466       return true;
00467     });
00468 
00469     REQUIRE(keys_seen == expected_keys_seen);
00470 
00471     REQUIRE(removal_trigger.has_value());
00472 
00473     // Check all expected keys are still there...
00474     view->foreach(
00475       [&keys, removal_trigger, should_remove](const auto& k, const auto&) {
00476         const auto should_be_here =
00477           !should_remove(k) || k == removal_trigger.value();
00478         REQUIRE(should_be_here);
00479         const auto it = keys.find(k);
00480         REQUIRE(it != keys.end());
00481         keys.erase(it);
00482         return true;
00483       });
00484 
00485     // ...and nothing else
00486     REQUIRE(keys.empty());
00487   }
00488 
00489   static constexpr auto value3 = "baz";
00490 
00491   SUBCASE("Modifying and adding other keys while iterating")
00492   {
00493     auto should_modify = [](size_t n) { return n % 3 == 0 || n % 5 == 0; };
00494 
00495     std::set<size_t> updated_keys;
00496 
00497     view->foreach([&view, &keys, &keys_seen, &updated_keys, should_modify](
00498                     const auto& k, const auto& v) {
00499       ++keys_seen;
00500 
00501       if (should_modify(k))
00502       {
00503         // Modify ourselves
00504         view->put(k, value3);
00505         updated_keys.insert(k);
00506 
00507         // Modify someone else ('before' and 'after' are guesses - iteration
00508         // order is undefined!)
00509         const auto before = k / 2;
00510         view->put(before, value3);
00511         keys.insert(before);
00512         updated_keys.insert(before);
00513 
00514         const auto after = k * 2;
00515         view->put(after, value3);
00516         keys.insert(after);
00517         updated_keys.insert(after);
00518 
00519         // Note discrepancy with externally visible value
00520         const auto visible_v = view->get(k);
00521         REQUIRE(visible_v.has_value());
00522         REQUIRE(visible_v.value() == value3);
00523         REQUIRE(visible_v.value() != v); // !!
00524       }
00525 
00526       return true;
00527     });
00528 
00529     REQUIRE(keys_seen == expected_keys_seen);
00530 
00531     // Check all expected keys are still there...
00532     view->foreach([&keys, &updated_keys](const auto& k, const auto& v) {
00533       const auto updated_it = updated_keys.find(k);
00534       if (updated_it != updated_keys.end())
00535       {
00536         REQUIRE(v == value3);
00537         updated_keys.erase(updated_it);
00538       }
00539       else
00540       {
00541         REQUIRE(v != value3);
00542       }
00543 
00544       const auto it = keys.find(k);
00545       if (it != keys.end())
00546       {
00547         keys.erase(it);
00548       }
00549 
00550       return true;
00551     });
00552 
00553     // ...and nothing else
00554     REQUIRE(keys.empty());
00555     REQUIRE(updated_keys.empty());
00556   }
00557 
00558   SUBCASE("Rewriting to new keys")
00559   {
00560     // Rewrite map, placing each value at a new key
00561     view->foreach([&view, &keys_seen](const auto& k, const auto& v) {
00562       ++keys_seen;
00563 
00564       view->remove(k);
00565 
00566       const auto new_key = k + 1000;
00567       REQUIRE(!view->has(new_key));
00568       view->put(new_key, v);
00569 
00570       return true;
00571     });
00572 
00573     REQUIRE(keys_seen == expected_keys_seen);
00574 
00575     // Check map contains only new keys, and the same count
00576     keys_seen = 0;
00577     view->foreach([&view, &keys, &keys_seen](const auto& k, const auto& v) {
00578       ++keys_seen;
00579 
00580       REQUIRE(keys.find(k) == keys.end());
00581 
00582       return true;
00583     });
00584 
00585     REQUIRE(keys_seen == expected_keys_seen);
00586   }
00587 }
00588 
00589 TEST_CASE("Read-only tx")
00590 {
00591   kv::Store kv_store;
00592   MapTypes::StringString map("public:map");
00593 
00594   constexpr auto k = "key";
00595   constexpr auto invalid_key = "invalid_key";
00596   constexpr auto v1 = "value1";
00597 
00598   INFO("Write some keys");
00599   {
00600     auto tx = kv_store.create_tx();
00601     auto view = tx.get_view(map);
00602     auto v = view->get(k);
00603     REQUIRE(!v.has_value());
00604     view->put(k, v1);
00605     auto va = view->get(k);
00606     REQUIRE(va.has_value());
00607     REQUIRE(va.value() == v1);
00608     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00609   }
00610 
00611   INFO("Do only reads with an overpowered Tx");
00612   {
00613     auto tx = kv_store.create_tx();
00614     auto view = tx.get_read_only_view(map);
00615     REQUIRE(view->has(k));
00616     const auto v = view->get(k);
00617     REQUIRE(v.has_value());
00618     REQUIRE(v.value() == v1);
00619 
00620     REQUIRE(!view->has(invalid_key));
00621     const auto invalid_v = view->get(invalid_key);
00622     REQUIRE(!invalid_v.has_value());
00623 
00624     // The following won't compile:
00625     // view->put(k, v1);
00626     // view->remove(k);
00627   }
00628 
00629   INFO("Read with read-only tx");
00630   {
00631     auto tx = kv_store.create_read_only_tx();
00632     auto view = tx.get_read_only_view(map);
00633     REQUIRE(view->has(k));
00634     const auto v = view->get(k);
00635     REQUIRE(v.has_value());
00636     REQUIRE(v.value() == v1);
00637 
00638     REQUIRE(!view->has(invalid_key));
00639     const auto invalid_v = view->get(invalid_key);
00640     REQUIRE(!invalid_v.has_value());
00641 
00642     // The following won't compile:
00643     // view->put(k, v1);
00644     // view->remove(k);
00645   }
00646 }
00647 
00648 TEST_CASE("Rollback and compact")
00649 {
00650   kv::Store kv_store;
00651   MapTypes::StringString map("public:map");
00652 
00653   constexpr auto k = "key";
00654   constexpr auto v1 = "value1";
00655 
00656   INFO("Do not read transactions that have been rolled back");
00657   {
00658     auto tx = kv_store.create_tx();
00659     auto tx2 = kv_store.create_tx();
00660     auto view = tx.get_view(map);
00661     view->put(k, v1);
00662     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00663 
00664     kv_store.rollback(0);
00665     auto view2 = tx2.get_view(map);
00666     auto v = view2->get(k);
00667     REQUIRE(!v.has_value());
00668     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00669   }
00670 
00671   INFO("Read committed key");
00672   {
00673     auto tx = kv_store.create_tx();
00674     auto tx2 = kv_store.create_tx();
00675     auto view = tx.get_view(map);
00676     view->put(k, v1);
00677     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00678     kv_store.compact(kv_store.current_version());
00679 
00680     auto view2 = tx2.get_view(map);
00681     auto va = view2->get_globally_committed(k);
00682     REQUIRE(va.has_value());
00683     REQUIRE(va.value() == v1);
00684   }
00685 
00686   INFO("Read deleted committed key");
00687   {
00688     auto tx = kv_store.create_tx();
00689     auto tx2 = kv_store.create_tx();
00690     auto view = tx.get_view(map);
00691     REQUIRE(view->remove(k));
00692     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00693     kv_store.compact(kv_store.current_version());
00694 
00695     auto view2 = tx2.get_view(map);
00696     auto va = view2->get_globally_committed(k);
00697     REQUIRE(!va.has_value());
00698   }
00699 }
00700 
00701 TEST_CASE("Local commit hooks")
00702 {
00703   using Write = MapTypes::StringString::Write;
00704   std::vector<Write> local_writes;
00705   std::vector<Write> global_writes;
00706 
00707   auto local_hook = [&](kv::Version v, const Write& w) {
00708     local_writes.push_back(w);
00709   };
00710   auto global_hook = [&](kv::Version v, const Write& w) {
00711     global_writes.push_back(w);
00712   };
00713 
00714   kv::Store kv_store;
00715   constexpr auto map_name = "public:map";
00716   MapTypes::StringString map(map_name);
00717   kv_store.set_local_hook(map_name, map.wrap_commit_hook(local_hook));
00718   kv_store.set_global_hook(map_name, map.wrap_commit_hook(global_hook));
00719 
00720   INFO("Write with hooks");
00721   {
00722     auto tx = kv_store.create_tx();
00723     auto view = tx.get_view(map);
00724     view->put("key1", "value1");
00725     view->put("key2", "value2");
00726     view->remove("key2");
00727     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00728 
00729     REQUIRE(global_writes.size() == 0);
00730     REQUIRE(local_writes.size() == 1);
00731     const auto& latest_writes = local_writes.front();
00732     REQUIRE(latest_writes.at("key1").has_value());
00733     REQUIRE(latest_writes.at("key1").value() == "value1");
00734     INFO("Local removals are not seen");
00735     REQUIRE(latest_writes.find("key2") == latest_writes.end());
00736     REQUIRE(latest_writes.size() == 1);
00737 
00738     local_writes.clear();
00739   }
00740 
00741   INFO("Write without hooks");
00742   {
00743     kv_store.unset_local_hook(map_name);
00744     kv_store.unset_global_hook(map_name);
00745 
00746     auto tx = kv_store.create_tx();
00747     auto view = tx.get_view(map);
00748     view->put("key2", "value2");
00749     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00750 
00751     REQUIRE(local_writes.size() == 0);
00752     REQUIRE(global_writes.size() == 0);
00753   }
00754 
00755   INFO("Write with hook again");
00756   {
00757     kv_store.set_local_hook(map_name, map.wrap_commit_hook(local_hook));
00758     kv_store.set_global_hook(map_name, map.wrap_commit_hook(global_hook));
00759 
00760     auto tx = kv_store.create_tx();
00761     auto view = tx.get_view(map);
00762     view->remove("key2");
00763     view->put("key3", "value3");
00764     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00765 
00766     REQUIRE(global_writes.size() == 0);
00767     REQUIRE(local_writes.size() == 1);
00768     const auto& latest_writes = local_writes.front();
00769     INFO("Old writes are not included");
00770     REQUIRE(latest_writes.find("key1") == latest_writes.end());
00771     INFO("Visible removals are included");
00772     const auto it2 = latest_writes.find("key2");
00773     REQUIRE(it2 != latest_writes.end());
00774     REQUIRE(!it2->second.has_value());
00775     const auto it3 = latest_writes.find("key3");
00776     REQUIRE(it3 != latest_writes.end());
00777     REQUIRE(it3->second.has_value());
00778     REQUIRE(it3->second.value() == "value3");
00779     REQUIRE(latest_writes.size() == 2);
00780 
00781     local_writes.clear();
00782   }
00783 }
00784 
00785 TEST_CASE("Global commit hooks")
00786 {
00787   using Write = MapTypes::StringString::Write;
00788 
00789   struct GlobalHookInput
00790   {
00791     kv::Version version;
00792     Write writes;
00793   };
00794 
00795   std::vector<GlobalHookInput> global_writes;
00796 
00797   auto global_hook = [&](kv::Version v, const Write& w) {
00798     global_writes.emplace_back(GlobalHookInput({v, w}));
00799   };
00800 
00801   kv::Store kv_store;
00802   using MapT = kv::Map<std::string, std::string>;
00803   MapT map_with_hook("public:map_with_hook");
00804   kv_store.set_global_hook(
00805     map_with_hook.get_name(), map_with_hook.wrap_commit_hook(global_hook));
00806 
00807   MapT map_no_hook("public:map_no_hook");
00808 
00809   INFO("Compact an empty store");
00810   {
00811     kv_store.compact(0);
00812 
00813     REQUIRE(global_writes.size() == 0);
00814   }
00815 
00816   SUBCASE("Compact one transaction")
00817   {
00818     auto tx1 = kv_store.create_tx();
00819     auto view_hook = tx1.get_view(map_with_hook);
00820     view_hook->put("key1", "value1");
00821     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00822 
00823     kv_store.compact(1);
00824 
00825     REQUIRE(global_writes.size() == 1);
00826     const auto& latest_writes = global_writes.front();
00827     REQUIRE(latest_writes.version == 1);
00828     const auto it1 = latest_writes.writes.find("key1");
00829     REQUIRE(it1 != latest_writes.writes.end());
00830     REQUIRE(it1->second.has_value());
00831     REQUIRE(it1->second.value() == "value1");
00832   }
00833 
00834   SUBCASE("Compact beyond the last map version")
00835   {
00836     auto tx1 = kv_store.create_tx();
00837     auto tx2 = kv_store.create_tx();
00838     auto tx3 = kv_store.create_tx();
00839     auto view_hook = tx1.get_view(map_with_hook);
00840     view_hook->put("key1", "value1");
00841     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00842 
00843     view_hook = tx2.get_view(map_with_hook);
00844     view_hook->put("key2", "value2");
00845     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00846 
00847     const auto compact_version = kv_store.current_version();
00848 
00849     // This does not affect map_with_hook but still increments the current
00850     // version of the store
00851     auto view_no_hook = tx3.get_view(map_no_hook);
00852     view_no_hook->put("key3", "value3");
00853     REQUIRE(tx3.commit() == kv::CommitSuccess::OK);
00854 
00855     kv_store.compact(compact_version);
00856 
00857     // Only the changes made to map_with_hook should be passed to the global
00858     // hook
00859     REQUIRE(global_writes.size() == 2);
00860     REQUIRE(global_writes.at(0).version == 1);
00861     const auto it1 = global_writes.at(0).writes.find("key1");
00862     REQUIRE(it1 != global_writes.at(0).writes.end());
00863     REQUIRE(it1->second.has_value());
00864     REQUIRE(it1->second.value() == "value1");
00865     const auto it2 = global_writes.at(1).writes.find("key2");
00866     REQUIRE(it2 != global_writes.at(1).writes.end());
00867     REQUIRE(it2->second.has_value());
00868     REQUIRE(it2->second.value() == "value2");
00869   }
00870 
00871   SUBCASE("Compact in between two map versions")
00872   {
00873     auto tx1 = kv_store.create_tx();
00874     auto tx2 = kv_store.create_tx();
00875     auto tx3 = kv_store.create_tx();
00876     auto view_hook = tx1.get_view(map_with_hook);
00877     view_hook->put("key1", "value1");
00878     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00879 
00880     // This does not affect map_with_hook but still increments the current
00881     // version of the store
00882     auto view_no_hook = tx2.get_view(map_no_hook);
00883     view_no_hook->put("key2", "value2");
00884     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00885 
00886     const auto compact_version = kv_store.current_version();
00887 
00888     view_hook = tx3.get_view(map_with_hook);
00889     view_hook->put("key3", "value3");
00890     REQUIRE(tx3.commit() == kv::CommitSuccess::OK);
00891 
00892     kv_store.compact(compact_version);
00893 
00894     // Only the changes made to map_with_hook should be passed to the global
00895     // hook
00896     REQUIRE(global_writes.size() == 1);
00897     REQUIRE(global_writes.at(0).version == 1);
00898     const auto it1 = global_writes.at(0).writes.find("key1");
00899     REQUIRE(it1 != global_writes.at(0).writes.end());
00900     REQUIRE(it1->second.has_value());
00901     REQUIRE(it1->second.value() == "value1");
00902   }
00903 
00904   SUBCASE("Compact twice")
00905   {
00906     auto tx1 = kv_store.create_tx();
00907     auto tx2 = kv_store.create_tx();
00908     auto view_hook = tx1.get_view(map_with_hook);
00909     view_hook->put("key1", "value1");
00910     REQUIRE(tx1.commit() == kv::CommitSuccess::OK);
00911 
00912     kv_store.compact(kv_store.current_version());
00913     global_writes.clear();
00914 
00915     view_hook = tx2.get_view(map_with_hook);
00916     view_hook->put("key2", "value2");
00917     REQUIRE(tx2.commit() == kv::CommitSuccess::OK);
00918 
00919     kv_store.compact(kv_store.current_version());
00920 
00921     // Only writes since the last compact are passed to the global hook
00922     REQUIRE(global_writes.size() == 1);
00923     REQUIRE(global_writes.at(0).version == 2);
00924     const auto it2 = global_writes.at(0).writes.find("key2");
00925     REQUIRE(it2 != global_writes.at(0).writes.end());
00926     REQUIRE(it2->second.has_value());
00927     REQUIRE(it2->second.value() == "value2");
00928   }
00929 }
00930 
00931 TEST_CASE("Deserialising from other Store")
00932 {
00933   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00934   kv::Store store;
00935   store.set_encryptor(encryptor);
00936 
00937   MapTypes::NumString public_map("public:public");
00938   MapTypes::NumString private_map("private");
00939   auto tx1 = store.create_reserved_tx(store.next_version());
00940   auto [view1, view2] = tx1.get_view(public_map, private_map);
00941   view1->put(42, "aardvark");
00942   view2->put(14, "alligator");
00943   auto [success, reqid, data] = tx1.commit_reserved();
00944   REQUIRE(success == kv::CommitSuccess::OK);
00945 
00946   kv::Store clone;
00947   clone.set_encryptor(encryptor);
00948 
00949   REQUIRE(clone.deserialise(data) == kv::DeserialiseSuccess::PASS);
00950 }
00951 
00952 TEST_CASE("Deserialise return status")
00953 {
00954   kv::Store store;
00955 
00956   ccf::Signatures signatures(ccf::Tables::SIGNATURES);
00957   ccf::Nodes nodes(ccf::Tables::NODES);
00958   MapTypes::NumNum data("public:data");
00959 
00960   auto kp = tls::make_key_pair();
00961 
00962   auto history = std::make_shared<ccf::NullTxHistory>(store, 0, *kp);
00963   store.set_history(history);
00964 
00965   {
00966     auto tx = store.create_reserved_tx(store.next_version());
00967     auto data_view = tx.get_view(data);
00968     data_view->put(42, 42);
00969     auto [success, reqid, data] = tx.commit_reserved();
00970     REQUIRE(success == kv::CommitSuccess::OK);
00971 
00972     REQUIRE(store.deserialise(data) == kv::DeserialiseSuccess::PASS);
00973   }
00974 
00975   {
00976     auto tx = store.create_reserved_tx(store.next_version());
00977     auto sig_view = tx.get_view(signatures);
00978     ccf::PrimarySignature sigv(0, 2);
00979     sig_view->put(0, sigv);
00980     auto [success, reqid, data] = tx.commit_reserved();
00981     REQUIRE(success == kv::CommitSuccess::OK);
00982 
00983     REQUIRE(store.deserialise(data) == kv::DeserialiseSuccess::PASS_SIGNATURE);
00984   }
00985 
00986   INFO("Signature transactions with additional contents should fail");
00987   {
00988     auto tx = store.create_reserved_tx(store.next_version());
00989     auto [sig_view, data_view] = tx.get_view(signatures, data);
00990     ccf::PrimarySignature sigv(0, 2);
00991     sig_view->put(0, sigv);
00992     data_view->put(43, 43);
00993     auto [success, reqid, data] = tx.commit_reserved();
00994     REQUIRE(success == kv::CommitSuccess::OK);
00995 
00996     REQUIRE(store.deserialise(data) == kv::DeserialiseSuccess::FAILED);
00997   }
00998 }
00999 
01000 TEST_CASE("Map swap between stores")
01001 {
01002   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
01003   kv::Store s1;
01004   s1.set_encryptor(encryptor);
01005 
01006   kv::Store s2;
01007   s2.set_encryptor(encryptor);
01008 
01009   MapTypes::NumNum d("data");
01010   MapTypes::NumNum pd("public:data");
01011 
01012   {
01013     auto tx = s1.create_tx();
01014     auto v = tx.get_view(d);
01015     v->put(42, 42);
01016     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01017   }
01018 
01019   {
01020     auto tx = s1.create_tx();
01021     auto v = tx.get_view(pd);
01022     v->put(14, 14);
01023     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01024   }
01025 
01026   const auto target_version = s1.current_version();
01027   while (s2.current_version() < target_version)
01028   {
01029     auto tx = s2.create_tx();
01030     auto v = tx.get_view(d);
01031     v->put(41, 41);
01032     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01033   }
01034 
01035   s2.swap_private_maps(s1);
01036 
01037   {
01038     auto tx = s1.create_tx();
01039     auto v = tx.get_view(d);
01040     auto val = v->get(41);
01041     REQUIRE_FALSE(v->get(42).has_value());
01042     REQUIRE(val.has_value());
01043     REQUIRE(val.value() == 41);
01044   }
01045 
01046   {
01047     auto tx = s1.create_tx();
01048     auto v = tx.get_view(pd);
01049     auto val = v->get(14);
01050     REQUIRE(val.has_value());
01051     REQUIRE(val.value() == 14);
01052   }
01053 
01054   {
01055     auto tx = s2.create_tx();
01056     auto v = tx.get_view(d);
01057     auto val = v->get(42);
01058     REQUIRE_FALSE(v->get(41).has_value());
01059     REQUIRE(val.has_value());
01060     REQUIRE(val.value() == 42);
01061   }
01062 
01063   {
01064     auto tx = s2.create_tx();
01065     auto v = tx.get_view(pd);
01066     REQUIRE_FALSE(v->get(14).has_value());
01067   }
01068 }
01069 
01070 TEST_CASE("Private recovery map swap")
01071 {
01072   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
01073   kv::Store s1;
01074   s1.set_encryptor(encryptor);
01075   MapTypes::NumNum priv1("private");
01076   MapTypes::NumString pub1("public:data");
01077 
01078   kv::Store s2;
01079   s2.set_encryptor(encryptor);
01080   MapTypes::NumNum priv2("private");
01081   MapTypes::NumString pub2("public:data");
01082 
01083   INFO("Populate s1 with public entries");
01084   // We compact twice, deliberately. A public KV during recovery
01085   // would have compacted some number of times.
01086   {
01087     auto tx = s1.create_tx();
01088     auto v = tx.get_view(pub1);
01089     v->put(42, "42");
01090     tx.commit();
01091   }
01092   {
01093     auto tx = s1.create_tx();
01094     auto v = tx.get_view(pub1);
01095     v->put(42, "43");
01096     tx.commit();
01097   }
01098   s1.compact(s1.current_version());
01099   {
01100     auto tx = s1.create_tx();
01101     auto v = tx.get_view(pub1);
01102     v->put(44, "44");
01103     tx.commit();
01104   }
01105   s1.compact(s1.current_version());
01106   {
01107     auto tx = s1.create_tx();
01108     auto v = tx.get_view(pub1);
01109     v->put(45, "45");
01110     tx.commit();
01111   }
01112 
01113   INFO("Populate s2 with private entries");
01114   // We compact only once, at a lower index than we did for the public
01115   // KV, which is what we expect during recovery of the private KV. We do expect
01116   // that the _entire_ private state is compacted
01117   {
01118     auto tx = s2.create_tx();
01119     auto v = tx.get_view(priv2);
01120     v->put(12, 12);
01121     tx.commit();
01122   }
01123   {
01124     auto tx = s2.create_tx();
01125     auto v = tx.get_view(priv2);
01126     v->put(13, 13);
01127     tx.commit();
01128   }
01129   s2.compact(s2.current_version());
01130   {
01131     auto tx = s2.create_tx();
01132     auto v = tx.get_view(priv2);
01133     v->put(14, 14);
01134     tx.commit();
01135   }
01136   {
01137     auto tx = s2.create_tx();
01138     auto v = tx.get_view(priv2);
01139     v->put(15, 15);
01140     tx.commit();
01141   }
01142 
01143   INFO("Swap in private maps");
01144   REQUIRE(s1.current_version() == s2.current_version());
01145   REQUIRE_NOTHROW(s1.swap_private_maps(s2));
01146 
01147   INFO("Check state looks as expected in s1");
01148   {
01149     auto tx = s1.create_tx();
01150     auto [priv, pub] = tx.get_view(priv1, pub1);
01151     {
01152       auto val = pub->get(42);
01153       REQUIRE(val.has_value());
01154       REQUIRE(val.value() == "43");
01155 
01156       val = pub->get(44);
01157       REQUIRE(val.has_value());
01158       REQUIRE(val.value() == "44");
01159 
01160       val = pub->get(45);
01161       REQUIRE(val.has_value());
01162       REQUIRE(val.value() == "45");
01163 
01164       REQUIRE(s1.commit_version() == 3);
01165     }
01166     {
01167       for (size_t i : {12, 13, 14, 15})
01168       {
01169         auto val = priv->get(i);
01170         REQUIRE(val.has_value());
01171         REQUIRE(val.value() == i);
01172       }
01173     }
01174   }
01175 
01176   INFO("Check committed state looks as expected in s1");
01177   {
01178     auto tx = s1.create_tx();
01179     auto [priv, pub] = tx.get_view(priv1, pub1);
01180     {
01181       auto val = pub->get_globally_committed(42);
01182       REQUIRE(val.has_value());
01183       REQUIRE(val.value() == "43");
01184 
01185       val = pub->get_globally_committed(44);
01186       REQUIRE(val.has_value());
01187       REQUIRE(val.value() == "44");
01188 
01189       val = pub->get_globally_committed(45);
01190       REQUIRE_FALSE(val.has_value());
01191     }
01192     {
01193       auto val = priv->get_globally_committed(12);
01194       REQUIRE(val.has_value());
01195       REQUIRE(val.value() == 12);
01196 
01197       val = priv->get_globally_committed(13);
01198       REQUIRE(val.has_value());
01199       REQUIRE(val.value() == 13);
01200 
01201       // Uncompacted state is visible, which is expected, but isn't
01202       // something that would happen in recovery (only compacted state
01203       // would be swapped in). There is deliberately no check for compacted
01204       // state later than the compact level on the public KV, as this is
01205       // impossible during recovery.
01206     }
01207   }
01208 }
01209 
01210 TEST_CASE("Conflict resolution")
01211 {
01212   kv::Store kv_store;
01213   MapTypes::StringString map("public:map");
01214 
01215   {
01216     // Ensure this map already exists, by making a prior write to it
01217     auto tx = kv_store.create_tx();
01218     auto view = tx.get_view(map);
01219     view->put("foo", "initial");
01220     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01221   }
01222 
01223   auto try_write = [&](kv::Tx& tx, const std::string& s) {
01224     auto view = tx.get_view(map);
01225 
01226     // Introduce read-dependency
01227     view->get("foo");
01228     view->put("foo", s);
01229 
01230     view->put(s, s);
01231   };
01232 
01233   auto confirm_state = [&](
01234                          const std::vector<std::string>& present,
01235                          const std::vector<std::string>& missing) {
01236     auto tx = kv_store.create_tx();
01237     auto view = tx.get_view(map);
01238 
01239     for (const auto& s : present)
01240     {
01241       const auto it = view->get(s);
01242       REQUIRE(it.has_value());
01243       REQUIRE(view->has(s));
01244       REQUIRE(it.value() == s);
01245     }
01246 
01247     for (const auto& s : missing)
01248     {
01249       const auto it = view->get(s);
01250       REQUIRE(!it.has_value());
01251       REQUIRE(!view->has(s));
01252     }
01253   };
01254 
01255   // Simulate parallel execution by interleaving tx steps
01256   auto tx1 = kv_store.create_tx();
01257   auto tx2 = kv_store.create_tx();
01258 
01259   // First transaction tries to write a value, depending on initial version
01260   try_write(tx1, "bar");
01261 
01262   {
01263     // A second transaction is committed, conflicting with the first
01264     try_write(tx2, "baz");
01265     const auto res2 = tx2.commit();
01266     REQUIRE(res2 == kv::CommitSuccess::OK);
01267 
01268     confirm_state({"baz"}, {"bar"});
01269   }
01270 
01271   // Trying to commit first transaction produces a conflict
01272   auto res1 = tx1.commit();
01273   REQUIRE(res1 == kv::CommitSuccess::CONFLICT);
01274   confirm_state({"baz"}, {"bar"});
01275 
01276   // A third transaction just wants to read the value
01277   auto tx3 = kv_store.create_tx();
01278   auto view3 = tx3.get_view(map);
01279   REQUIRE(view3->has("foo"));
01280 
01281   // First transaction is rerun with same object, producing different result
01282   try_write(tx1, "buzz");
01283 
01284   // Expected results are committed
01285   res1 = tx1.commit();
01286   REQUIRE(res1 == kv::CommitSuccess::OK);
01287   confirm_state({"baz", "buzz"}, {"bar"});
01288 
01289   // Third transaction completes later, has no conflicts but reports the earlier
01290   // version it read
01291   auto res3 = tx3.commit();
01292   REQUIRE(res3 == kv::CommitSuccess::OK);
01293 
01294   REQUIRE(tx1.commit_version() > tx2.commit_version());
01295   REQUIRE(tx2.get_read_version() >= tx2.get_read_version());
01296 
01297   // Re-running a _committed_ transaction is exceptionally bad
01298   REQUIRE_THROWS(tx1.commit());
01299   REQUIRE_THROWS(tx2.commit());
01300 }
01301 
01302 TEST_CASE("Mid-tx compaction")
01303 {
01304   kv::Store kv_store;
01305   MapTypes::StringNum map_a("public:A");
01306   MapTypes::StringNum map_b("public:B");
01307 
01308   constexpr auto key_a = "a";
01309   constexpr auto key_b = "b";
01310 
01311   auto increment_vals = [&]() {
01312     auto tx = kv_store.create_tx();
01313     auto [view_a, view_b] = tx.get_view(map_a, map_b);
01314 
01315     auto a_opt = view_a->get(key_a);
01316     auto b_opt = view_b->get(key_b);
01317 
01318     REQUIRE(a_opt == b_opt);
01319 
01320     const auto new_val = a_opt.has_value() ? *a_opt + 1 : 0;
01321 
01322     view_a->put(key_a, new_val);
01323     view_b->put(key_b, new_val);
01324 
01325     const auto result = tx.commit();
01326     REQUIRE(result == kv::CommitSuccess::OK);
01327   };
01328 
01329   increment_vals();
01330 
01331   {
01332     INFO("Compaction before get_views");
01333     auto tx = kv_store.create_tx();
01334 
01335     increment_vals();
01336     kv_store.compact(kv_store.current_version());
01337 
01338     auto view_a = tx.get_view(map_a);
01339     auto view_b = tx.get_view(map_b);
01340 
01341     auto a_opt = view_a->get(key_a);
01342     auto b_opt = view_b->get(key_b);
01343 
01344     REQUIRE(a_opt == b_opt);
01345 
01346     const auto result = tx.commit();
01347     REQUIRE(result == kv::CommitSuccess::OK);
01348   }
01349 
01350   {
01351     INFO("Compaction after get_views");
01352     auto tx = kv_store.create_tx();
01353 
01354     auto view_a = tx.get_view(map_a);
01355     increment_vals();
01356     auto view_b = tx.get_view(map_b);
01357     kv_store.compact(kv_store.current_version());
01358 
01359     auto a_opt = view_a->get(key_a);
01360     auto b_opt = view_b->get(key_b);
01361 
01362     REQUIRE(a_opt == b_opt);
01363 
01364     const auto result = tx.commit();
01365     REQUIRE(result == kv::CommitSuccess::OK);
01366   }
01367 
01368   {
01369     INFO("Compaction between get_views");
01370     bool threw = false;
01371 
01372     try
01373     {
01374       auto tx = kv_store.create_tx();
01375 
01376       auto view_a = tx.get_view(map_a);
01377       // This transaction does something slow. Meanwhile...
01378 
01379       // ...another transaction commits...
01380       increment_vals();
01381       // ...and is compacted...
01382       kv_store.compact(kv_store.current_version());
01383 
01384       // ...then the original transaction proceeds, expecting to read a single
01385       // version
01386       // This should throw a CompactedVersionConflict error
01387       auto view_b = tx.get_view(map_b);
01388 
01389       auto a_opt = view_a->get(key_a);
01390       auto b_opt = view_b->get(key_b);
01391 
01392       REQUIRE(a_opt == b_opt);
01393 
01394       const auto result = tx.commit();
01395       REQUIRE(result == kv::CommitSuccess::OK);
01396     }
01397     catch (const kv::CompactedVersionConflict& e)
01398     {
01399       threw = true;
01400     }
01401 
01402     REQUIRE(threw);
01403     // In real operation, this transaction would be re-executed and hope to not
01404     // intersect a compaction
01405   }
01406 }
01407 
01408 TEST_CASE("Store clear")
01409 {
01410   kv::Store kv_store;
01411   kv_store.set_term(42);
01412 
01413   auto map_a_name = "public:A";
01414   auto map_b_name = "public:B";
01415   MapTypes::StringNum map_a(map_a_name);
01416   MapTypes::StringNum map_b(map_b_name);
01417 
01418   INFO("Apply transactions and compact store");
01419   {
01420     size_t tx_count = 10;
01421     for (int i = 0; i < tx_count; i++)
01422     {
01423       auto tx = kv_store.create_tx();
01424       auto [view_a, view_b] = tx.get_view(map_a, map_b);
01425 
01426       view_a->put("key" + std::to_string(i), 42);
01427       view_b->put("key" + std::to_string(i), 42);
01428       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01429     }
01430 
01431     auto current_version = kv_store.current_version();
01432     kv_store.compact(current_version);
01433 
01434     REQUIRE(kv_store.get_map(current_version, map_a_name) != nullptr);
01435     REQUIRE(kv_store.get_map(current_version, map_b_name) != nullptr);
01436 
01437     REQUIRE(kv_store.current_version() != 0);
01438     REQUIRE(kv_store.commit_version() != 0);
01439     auto tx_id = kv_store.current_txid();
01440     REQUIRE(tx_id.term != 0);
01441     REQUIRE(tx_id.version != 0);
01442   }
01443 
01444   INFO("Verify that store state is cleared");
01445   {
01446     kv_store.clear();
01447     auto current_version = kv_store.current_version();
01448 
01449     REQUIRE(kv_store.get_map(current_version, map_a_name) == nullptr);
01450     REQUIRE(kv_store.get_map(current_version, map_b_name) == nullptr);
01451 
01452     REQUIRE(kv_store.current_version() == 0);
01453     REQUIRE(kv_store.commit_version() == 0);
01454     auto tx_id = kv_store.current_txid();
01455     REQUIRE(tx_id.term == 0);
01456     REQUIRE(tx_id.version == 0);
01457   }
01458 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/kv/test/kv_test.cpp...
Preprocessing /data/git/CCF/src/kv/test/null_encryptor.h...
#include kv/kv_types.h: not found! skipping...
Preprocessor output (size: 1175 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace kv
00008 {
00009   // NullTxEncryptor does not decrypt or verify integrity
00010   class NullTxEncryptor : public kv::AbstractTxEncryptor
00011   {
00012   public:
00013     void encrypt(
00014       const std::vector<uint8_t>& plain,
00015       const std::vector<uint8_t>& additional_data,
00016       std::vector<uint8_t>& serialised_header,
00017       std::vector<uint8_t>& cipher,
00018       kv::Version version,
00019       bool is_snapshot = false) override
00020     {
00021       cipher = plain;
00022     }
00023 
00024     bool decrypt(
00025       const std::vector<uint8_t>& cipher,
00026       const std::vector<uint8_t>& additional_data,
00027       const std::vector<uint8_t>& serialised_header,
00028       std::vector<uint8_t>& plain,
00029       kv::Version version) override
00030     {
00031       plain = cipher;
00032       return true;
00033     }
00034 
00035     void set_iv_id(size_t id) override {}
00036 
00037     size_t get_header_length() override
00038     {
00039       return 0;
00040     }
00041 
00042     void update_encryption_key(
00043       kv::Version version, const std::vector<uint8_t>& raw_ledger_key) override
00044     {}
00045 
00046     void rollback(kv::Version version) override {}
00047     void compact(kv::Version version) override {}
00048   };
00049 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/test/null_encryptor.h...
Preprocessing /data/git/CCF/src/kv/test/stub_consensus.h...
#include consensus/aft/impl/state.h: not found! skipping...
#include crypto/symmetric_key.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include algorithm: not found! skipping...
#include iostream: not found! skipping...
Preprocessor output (size: 3624 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace kv
00013 {
00014   class StubConsensus : public Consensus
00015   {
00016   private:
00017     std::vector<kv::BatchVector::value_type> replica;
00018     ConsensusType consensus_type;
00019 
00020   public:
00021     aft::ViewHistory view_history;
00022 
00023     StubConsensus(ConsensusType consensus_type_ = ConsensusType::CFT) :
00024       Consensus(0),
00025       replica(),
00026       consensus_type(consensus_type_)
00027     {}
00028 
00029     bool replicate(const BatchVector& entries, View view) override
00030     {
00031       for (const auto& entry : entries)
00032       {
00033         replica.push_back(entry);
00034 
00035         // Simplification: all entries are replicated in the same term
00036         view_history.update(std::get<0>(entry), 2);
00037       }
00038       return true;
00039     }
00040 
00041     std::optional<std::vector<uint8_t>> get_latest_data()
00042     {
00043       if (!replica.empty())
00044       {
00045         return *std::get<1>(replica.back());
00046       }
00047       else
00048       {
00049         return std::nullopt;
00050       }
00051     }
00052 
00053     std::optional<std::vector<uint8_t>> pop_oldest_data()
00054     {
00055       if (!replica.empty())
00056       {
00057         auto data = *std::get<1>(replica.front());
00058         replica.erase(replica.begin());
00059         return data;
00060       }
00061       else
00062       {
00063         return std::nullopt;
00064       }
00065     }
00066 
00067     std::optional<kv::BatchVector::value_type> pop_oldest_entry()
00068     {
00069       if (!replica.empty())
00070       {
00071         auto entry = replica.front();
00072         replica.erase(replica.begin());
00073         return entry;
00074       }
00075       else
00076       {
00077         return std::nullopt;
00078       }
00079     }
00080 
00081     size_t number_of_replicas()
00082     {
00083       return replica.size();
00084     }
00085 
00086     void flush()
00087     {
00088       replica.clear();
00089     }
00090 
00091     std::pair<View, SeqNo> get_committed_txid() override
00092     {
00093       return {2, 0};
00094     }
00095 
00096     std::optional<std::pair<View, SeqNo>> get_signable_txid() override
00097     {
00098       return get_committed_txid();
00099     }
00100 
00101     SeqNo get_committed_seqno() override
00102     {
00103       return 0;
00104     }
00105 
00106     NodeId primary() override
00107     {
00108       return 1;
00109     }
00110 
00111     std::set<NodeId> active_nodes() override
00112     {
00113       return {};
00114     }
00115 
00116     NodeId id() override
00117     {
00118       return 0;
00119     }
00120 
00121     View get_view(SeqNo seqno) override
00122     {
00123       return 2;
00124     }
00125 
00126     View get_view() override
00127     {
00128       return 2;
00129     }
00130 
00131     std::vector<SeqNo> get_view_history(SeqNo seqno) override
00132     {
00133       return view_history.get_history_until(seqno);
00134     }
00135 
00136     void initialise_view_history(
00137       const std::vector<SeqNo>& view_history_) override
00138     {
00139       view_history.initialise(view_history_);
00140     }
00141 
00142     void recv_message(OArray&& oa) override {}
00143 
00144     void add_configuration(
00145       SeqNo seqno, const Configuration::Nodes& conf) override
00146     {}
00147 
00148     Configuration::Nodes get_latest_configuration() const override
00149     {
00150       return {};
00151     }
00152 
00153     uint32_t node_count() override
00154     {
00155       return 0;
00156     }
00157 
00158     void emit_signature() override
00159     {
00160       return;
00161     }
00162 
00163     ConsensusType type() override
00164     {
00165       return consensus_type;
00166     }
00167   };
00168 
00169   class BackupStubConsensus : public StubConsensus
00170   {
00171   public:
00172     BackupStubConsensus(ConsensusType consensus_type = ConsensusType::CFT) :
00173       StubConsensus(consensus_type)
00174     {}
00175 
00176     bool is_primary() override
00177     {
00178       return false;
00179     }
00180 
00181     bool replicate(const BatchVector& entries, View view) override
00182     {
00183       return false;
00184     }
00185   };
00186 
00187   class PrimaryStubConsensus : public StubConsensus
00188   {
00189   public:
00190     PrimaryStubConsensus(ConsensusType consensus_type = ConsensusType::CFT) :
00191       StubConsensus(consensus_type)
00192     {}
00193 
00194     bool is_primary() override
00195     {
00196       return true;
00197     }
00198   };
00199 }
00200 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/test/stub_consensus.h...
Preprocessing /data/git/CCF/src/kv/tx.h...
#include ds/ccf_assert.h: not found! skipping...
#include kv_serialiser.h: already included! skipping...
#include kv_types.h: already included! skipping...
#include map.h: already included! skipping...
#include view_containers.h: already included! skipping...
#include list: not found! skipping...
Preprocessor output (size: 16882 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace kv
00014 {
00015   class CompactedVersionConflict
00016   {
00017   private:
00018     std::string msg;
00019 
00020   public:
00021     CompactedVersionConflict(const std::string& s) : msg(s) {}
00022 
00023     char const* what() const
00024     {
00025       return msg.c_str();
00026     }
00027   };
00028 
00029   // Manages a collection of TxViews. Derived implementations call get_tuple to
00030   // retrieve views over target maps.
00031   class BaseTx : public AbstractChangeContainer
00032   {
00033   protected:
00034     AbstractStore* store;
00035 
00036     OrderedChanges all_changes;
00037 
00038     // NB: This exists only to maintain the old API, where this Tx stores
00039     // TxViews and returns raw pointers to them. It could be removed entirely
00040     // with a near-identical API if we return `shared_ptr`s, and assuming that
00041     // we don't actually care about returning the same View instance if
00042     // `get_view` is called multiple times
00043     using PossibleViews = std::list<std::unique_ptr<AbstractTxView>>;
00044     std::map<std::string, PossibleViews> all_views;
00045 
00046     bool committed = false;
00047     bool success = false;
00048     Version read_version = NoVersion;
00049     Version version = NoVersion;
00050     Term term = 0;
00051 
00052     kv::TxHistory::RequestID req_id;
00053 
00054     std::map<std::string, std::shared_ptr<AbstractMap>> created_maps;
00055 
00056     template <typename MapView>
00057     MapView* get_or_insert_view(
00058       untyped::ChangeSet& change_set, const std::string& name)
00059     {
00060       auto it = all_views.find(name);
00061       if (it == all_views.end())
00062       {
00063         PossibleViews views;
00064         auto typed_view = new MapView(change_set);
00065         views.emplace_back(std::unique_ptr<AbstractTxView>(typed_view));
00066         all_views[name] = std::move(views);
00067         return typed_view;
00068       }
00069       else
00070       {
00071         PossibleViews& views = it->second;
00072         for (auto& view : views)
00073         {
00074           auto typed_view = dynamic_cast<MapView*>(view.get());
00075           if (typed_view != nullptr)
00076           {
00077             return typed_view;
00078           }
00079         }
00080         auto typed_view = new MapView(change_set);
00081         views.emplace_back(std::unique_ptr<AbstractTxView>(typed_view));
00082         return typed_view;
00083       }
00084     }
00085 
00086     template <typename MapView>
00087     std::tuple<MapView*> check_and_store_change_set(
00088       std::unique_ptr<untyped::ChangeSet>&& change_set,
00089       const std::string& map_name,
00090       const std::shared_ptr<AbstractMap>& abstract_map)
00091     {
00092       if (change_set == nullptr)
00093       {
00094         throw CompactedVersionConflict(fmt::format(
00095           "Unable to retrieve state over map {} at {}",
00096           map_name,
00097           read_version));
00098       }
00099 
00100       auto typed_view = get_or_insert_view<MapView>(*change_set, map_name);
00101       all_changes[map_name] = {abstract_map, std::move(change_set)};
00102       return std::make_tuple(typed_view);
00103     }
00104 
00105     template <class MapView>
00106     std::tuple<MapView*> get_view_tuple_by_name(const std::string& map_name)
00107     {
00108       auto search = all_changes.find(map_name);
00109       if (search != all_changes.end())
00110       {
00111         auto view =
00112           get_or_insert_view<MapView>(*search->second.changeset, map_name);
00113         return std::make_tuple(view);
00114       }
00115 
00116       if (read_version == NoVersion)
00117       {
00118         // Grab opacity version that all Maps should be queried at.
00119         auto txid = store->current_txid();
00120         term = txid.term;
00121         read_version = txid.version;
00122       }
00123 
00124       auto abstract_map = store->get_map(read_version, map_name);
00125       if (abstract_map == nullptr)
00126       {
00127         // Store doesn't know this map yet - create it dynamically
00128         {
00129           const auto map_it = created_maps.find(map_name);
00130           if (map_it != created_maps.end())
00131           {
00132             throw std::logic_error("Created map without creating view over it");
00133           }
00134         }
00135 
00136         // NB: The created maps are always untyped. Only the views over them are
00137         // typed
00138         auto new_map = std::make_shared<kv::untyped::Map>(
00139           store,
00140           map_name,
00141           kv::get_security_domain(map_name),
00142           store->is_map_replicated(map_name));
00143         created_maps[map_name] = new_map;
00144 
00145         abstract_map = new_map;
00146       }
00147 
00148       auto untyped_map =
00149         std::dynamic_pointer_cast<kv::untyped::Map>(abstract_map);
00150       if (untyped_map == nullptr)
00151       {
00152         throw std::logic_error(
00153           fmt::format("Map {} has unexpected type", map_name));
00154       }
00155 
00156       auto change_set = untyped_map->create_change_set(read_version);
00157       return check_and_store_change_set<MapView>(
00158         std::move(change_set), map_name, abstract_map);
00159     }
00160 
00161     template <class M, class... Ms>
00162     std::tuple<typename M::TxView*, typename Ms::TxView*...>
00163     get_view_tuple_by_types(M& m, Ms&... ms)
00164     {
00165       if constexpr (sizeof...(Ms) == 0)
00166       {
00167         return get_view_tuple_by_name<typename M::TxView>(m.get_name());
00168       }
00169       else
00170       {
00171         return std::tuple_cat(
00172           get_view_tuple_by_name<typename M::TxView>(m.get_name()),
00173           get_view_tuple_by_types(ms...));
00174       }
00175     }
00176 
00177     template <class M, class... Ms, class... Ts>
00178     std::tuple<typename M::TxView*, typename Ms::TxView*...>
00179     get_view_tuple_by_names(const std::string& map_name, const Ts&... names)
00180     {
00181       if constexpr (sizeof...(Ts) == 0)
00182       {
00183         return get_view_tuple_by_name<typename M::TxView>(map_name);
00184       }
00185       else
00186       {
00187         return std::tuple_cat(
00188           get_view_tuple_by_name<typename M::TxView>(map_name),
00189           get_view_tuple_by_names<Ms...>(names...));
00190       }
00191     }
00192 
00193   public:
00194     BaseTx(AbstractStore* _store, bool known_null = false) : store(_store)
00195     {
00196       // For testing purposes, caller may opt-in to creation of an unsafe Tx by
00197       // passing (nullptr, true). Many operations on this Tx, including
00198       // commit(), will try to dereference this pointer, so the caller must not
00199       // call these.
00200       if (!known_null)
00201       {
00202         CCF_ASSERT(
00203           store != nullptr,
00204           "Transactions must be created with reference to real Store");
00205       }
00206     }
00207 
00208     BaseTx(const BaseTx& that) = delete;
00209 
00210     void set_change_list(OrderedChanges&& change_list_, Term term_) override
00211     {
00212       // if all_changes is not empty then any coinciding keys will not be
00213       // overwritten
00214       all_changes.merge(change_list_);
00215       term = term_;
00216     }
00217 
00218     void set_req_id(const kv::TxHistory::RequestID& req_id_)
00219     {
00220       req_id = req_id_;
00221     }
00222 
00223     const kv::TxHistory::RequestID& get_req_id()
00224     {
00225       return req_id;
00226     }
00227 
00228     /** Version for the transaction set
00229      *
00230      * @return Committed version, or `kv::NoVersion` otherwise
00231      */
00232     Version get_version()
00233     {
00234       return version;
00235     }
00236 
00237     Version get_read_version()
00238     {
00239       return read_version;
00240     }
00241 
00242     Version get_term()
00243     {
00244       return term;
00245     }
00246 
00247     /** Commit transaction
00248      *
00249      * A transaction can either succeed and replicate (`kv::CommitSuccess::OK`),
00250      * fail because of a conflict with other transactions
00251      * (`kv::CommitSuccess::CONFLICT`), or succeed locally, but fail to
00252      * replicate (`kv::CommitSuccess::NO_REPLICATE`).
00253      *
00254      * Transactions that fail are rolled back, no matter the reason.
00255      *
00256      * @return transaction outcome
00257      */
00258     CommitSuccess commit()
00259     {
00260       if (committed)
00261         throw std::logic_error("Transaction already committed");
00262 
00263       if (all_changes.empty())
00264       {
00265         committed = true;
00266         success = true;
00267         return CommitSuccess::OK;
00268       }
00269 
00270       auto store = all_changes.begin()->second.map->get_store();
00271 
00272       // If this transaction may create maps, ensure that commit gets a
00273       // consistent view of the existing maps
00274       if (!created_maps.empty())
00275         this->store->lock();
00276 
00277       auto c = apply_changes(
00278         all_changes, [store]() { return store->next_version(); }, created_maps);
00279 
00280       if (!created_maps.empty())
00281         this->store->unlock();
00282 
00283       success = c.has_value();
00284 
00285       if (!success)
00286       {
00287         // Conflicting views (and contained writes) and all version tracking are
00288         // discarded. They must be reconstructed at updated, non-conflicting
00289         // versions
00290         reset();
00291 
00292         LOG_TRACE_FMT("Could not commit transaction due to conflict");
00293         return CommitSuccess::CONFLICT;
00294       }
00295       else
00296       {
00297         committed = true;
00298         version = c.value();
00299 
00300         // From here, we have received a unique commit version and made
00301         // modifications to our local kv. If we fail in any way, we cannot
00302         // recover.
00303         try
00304         {
00305           auto data = serialise();
00306 
00307           if (data.empty())
00308           {
00309             auto h = store->get_history();
00310             if (h != nullptr)
00311             {
00312               // This tx does not have a write set, so this is a read only tx
00313               // because of this we are returning NoVersion
00314               h->add_result(req_id, NoVersion);
00315             }
00316             return CommitSuccess::OK;
00317           }
00318 
00319           return store->commit(
00320             {term, version},
00321             MovePendingTx(std::move(data), std::move(req_id)),
00322             false);
00323         }
00324         catch (const std::exception& e)
00325         {
00326           committed = false;
00327 
00328           LOG_FAIL_FMT("Error during serialisation");
00329           LOG_DEBUG_FMT("Error during serialisation: {}", e.what());
00330 
00331           // Discard original exception type, throw as now fatal
00332           // KvSerialiserException
00333           throw KvSerialiserException(e.what());
00334         }
00335       }
00336     }
00337 
00338     /** Commit version if committed
00339      *
00340      * @return Commit version
00341      */
00342     Version commit_version()
00343     {
00344       if (!committed)
00345         throw std::logic_error("Transaction not yet committed");
00346 
00347       if (!success)
00348         throw std::logic_error("Transaction aborted");
00349 
00350       return version;
00351     }
00352 
00353     /** Commit term if committed
00354      *
00355      * @return Commit term
00356      */
00357     Version commit_term()
00358     {
00359       if (!committed)
00360         throw std::logic_error("Transaction not yet committed");
00361 
00362       if (!success)
00363         throw std::logic_error("Transaction aborted");
00364 
00365       return term;
00366     }
00367 
00368     std::vector<uint8_t> serialise(bool include_reads = false)
00369     {
00370       if (!committed)
00371         throw std::logic_error("Transaction not yet committed");
00372 
00373       if (!success)
00374         throw std::logic_error("Transaction aborted");
00375 
00376       // If no transactions made changes, return a zero length vector.
00377       const bool any_changes =
00378         std::any_of(all_changes.begin(), all_changes.end(), [](const auto& it) {
00379           return it.second.changeset->has_writes();
00380         });
00381 
00382       if (!any_changes)
00383       {
00384         return {};
00385       }
00386 
00387       // Retrieve encryptor.
00388       auto map = all_changes.begin()->second.map;
00389       auto e = map->get_store()->get_encryptor();
00390 
00391       KvStoreSerialiser replicated_serialiser(e, version);
00392 
00393       // Process in security domain order
00394       for (auto domain : {SecurityDomain::PUBLIC, SecurityDomain::PRIVATE})
00395       {
00396         for (const auto& it : all_changes)
00397         {
00398           const auto& map = it.second.map;
00399           const auto& changeset = it.second.changeset;
00400           if (
00401             map->get_security_domain() == domain && map->is_replicated() &&
00402             changeset->has_writes())
00403           {
00404             map->serialise_changes(
00405               changeset.get(), replicated_serialiser, include_reads);
00406           }
00407         }
00408       }
00409 
00410       // Return serialised Tx.
00411       return replicated_serialiser.get_raw_data();
00412     }
00413 
00414     // Used by frontend for reserved transactions
00415     BaseTx(Version reserved) :
00416       committed(false),
00417       success(false),
00418       read_version(reserved - 1),
00419       version(reserved)
00420     {}
00421 
00422     // Used to clear the Tx to its initial state, to retry after a conflict
00423     void reset()
00424     {
00425       all_changes.clear();
00426       all_views.clear();
00427       created_maps.clear();
00428       committed = false;
00429       success = false;
00430       read_version = NoVersion;
00431       version = NoVersion;
00432       term = 0;
00433     }
00434   };
00435 
00436   class ReadOnlyTx : public BaseTx
00437   {
00438   public:
00439     using BaseTx::BaseTx;
00440 
00441     /** Get a read-only transaction view on a map.
00442      *
00443      * This adds the map to the transaction set if it is not yet present.
00444      *
00445      * @param m Map
00446      */
00447     template <class M>
00448     typename M::ReadOnlyTxView* get_read_only_view(M& m)
00449     {
00450       // NB: Always creates a (writeable) TxView, which is cast to
00451       // ReadOnlyTxView on return. This is so that other calls (before or after)
00452       // can retrieve writeable views over the same map.
00453       return std::get<0>(
00454         get_view_tuple_by_name<typename M::TxView>(m.get_name()));
00455     }
00456 
00457     /** Get a read-only transaction view on a map by name.
00458      *
00459      * This adds the map to the transaction set if it is not yet present, and
00460      * creates the map if it does not yet exist.
00461      *
00462      * @param map_name Name of map
00463      */
00464     template <class M>
00465     typename M::ReadOnlyTxView* get_read_only_view(const std::string& map_name)
00466     {
00467       return std::get<0>(get_view_tuple_by_name<typename M::TxView>(map_name));
00468     }
00469 
00470     /** Get read-only transaction views over multiple maps.
00471      *
00472      * @param m Map
00473      * @param ms Map
00474      */
00475     template <class M, class... Ms>
00476     std::tuple<typename M::ReadOnlyTxView*, typename Ms::ReadOnlyTxView*...>
00477     get_read_only_view(M& m, Ms&... ms)
00478     {
00479       return std::tuple_cat(
00480         get_view_tuple_by_name<typename M::TxView>(m.get_name()),
00481         get_view_tuple_by_types(ms...));
00482     }
00483 
00484     /** Get read-only transaction views over multiple maps by name. This will
00485      * create the maps if they do not exist.
00486      *
00487      * @param map_name Name of first map to retrieve
00488      * @param names Names of additional maps
00489      */
00490     template <class M, class... Ms, class... Ts>
00491     std::tuple<typename M::TxView*, typename Ms::TxView*...> get_read_only_view(
00492       const std::string& map_name, const Ts&... names)
00493     {
00494       return std::tuple_cat(
00495         get_view_tuple_by_name<typename M::TxView>(map_name),
00496         get_view_tuple_by_names<Ms...>(names...));
00497     }
00498   };
00499 
00500   class Tx : public ReadOnlyTx
00501   {
00502   public:
00503     using ReadOnlyTx::ReadOnlyTx;
00504 
00505     /** Get a transaction view on a map.
00506      *
00507      * This adds the map to the transaction set if it is not yet present.
00508      *
00509      * @param m Map
00510      */
00511     template <class M>
00512     typename M::TxView* get_view(M& m)
00513     {
00514       return std::get<0>(
00515         get_view_tuple_by_name<typename M::TxView>(m.get_name()));
00516     }
00517 
00518     /** Get a transaction view on a map by name
00519      *
00520      * This adds the map to the transaction set if it is not yet present, and
00521      * creates the map if it does not yet exist.
00522      *
00523      * @param map_name Name of map
00524      */
00525     template <class M>
00526     typename M::TxView* get_view(const std::string& map_name)
00527     {
00528       return std::get<0>(get_view_tuple_by_name<typename M::TxView>(map_name));
00529     }
00530 
00531     /** Get transaction views over multiple maps.
00532      *
00533      * @param m Map
00534      * @param ms Map
00535      */
00536     template <class M, class... Ms>
00537     std::tuple<typename M::TxView*, typename Ms::TxView*...> get_view(
00538       M& m, Ms&... ms)
00539     {
00540       return std::tuple_cat(
00541         get_view_tuple_by_name<typename M::TxView>(m.get_name()),
00542         get_view_tuple_by_types(ms...));
00543     }
00544 
00545     /** Get transaction views over multiple maps by name. This will create the
00546      * maps if they do not exist.
00547      *
00548      * @param map_name Name of first map to retrieve
00549      * @param names Names of additional maps
00550      */
00551     template <class M, class... Ms, class... Ts>
00552     std::tuple<typename M::TxView*, typename Ms::TxView*...> get_view(
00553       const std::string& map_name, const Ts&... names)
00554     {
00555       return std::tuple_cat(
00556         get_view_tuple_by_name<typename M::TxView>(map_name),
00557         get_view_tuple_by_names<Ms...>(names...));
00558     }
00559   };
00560 
00561   // Used by frontend for reserved transactions. These are constructed with a
00562   // pre-reserved Version, and _must succeed_ to fulfil this version, else
00563   // creating a hole in the history
00564   class ReservedTx : public Tx
00565   {
00566   public:
00567     ReservedTx(AbstractStore* _store, Version reserved) : Tx(_store)
00568     {
00569       committed = false;
00570       success = false;
00571       read_version = reserved - 1;
00572       version = reserved;
00573     }
00574 
00575     // Used by frontend to commit reserved transactions
00576     PendingTxInfo commit_reserved()
00577     {
00578       if (committed)
00579         throw std::logic_error("Transaction already committed");
00580 
00581       if (all_changes.empty())
00582         throw std::logic_error("Reserved transaction cannot be empty");
00583 
00584       auto c = apply_changes(
00585         all_changes, [this]() { return version; }, created_maps, version);
00586       success = c.has_value();
00587 
00588       if (!success)
00589         throw std::logic_error("Failed to commit reserved transaction");
00590 
00591       committed = true;
00592       return {CommitSuccess::OK, {0, 0}, serialise()};
00593     }
00594   };
00595 }
00596 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/tx.h...
Preprocessing /data/git/CCF/src/kv/tx_view.h...
#include kv/untyped_map.h: not found! skipping...
#include kv/untyped_tx_view.h: not found! skipping...
#include kv_types.h: already included! skipping...
Preprocessor output (size: 2096 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv
00010 {
00011   template <typename K, typename V, typename KSerialiser, typename VSerialiser>
00012   class ReadOnlyTxView : public AbstractTxView
00013   {
00014   protected:
00015     kv::untyped::TxView untyped_view;
00016 
00017   public:
00018     using KeyType = K;
00019     using ValueType = V;
00020 
00021     ReadOnlyTxView(kv::untyped::ChangeSet& changes) : untyped_view(changes) {}
00022 
00023     std::optional<V> get(const K& key)
00024     {
00025       const auto opt_v_rep = untyped_view.get(KSerialiser::to_serialised(key));
00026 
00027       if (opt_v_rep.has_value())
00028       {
00029         return VSerialiser::from_serialised(*opt_v_rep);
00030       }
00031 
00032       return std::nullopt;
00033     }
00034 
00035     std::optional<V> get_globally_committed(const K& key)
00036     {
00037       const auto opt_v_rep =
00038         untyped_view.get_globally_committed(KSerialiser::to_serialised(key));
00039 
00040       if (opt_v_rep.has_value())
00041       {
00042         return VSerialiser::from_serialised(*opt_v_rep);
00043       }
00044 
00045       return std::nullopt;
00046     }
00047 
00048     bool has(const K& key)
00049     {
00050       return untyped_view.has(KSerialiser::to_serialised(key));
00051     }
00052 
00053     template <class F>
00054     void foreach(F&& f)
00055     {
00056       auto g = [&](
00057                  const kv::serialisers::SerialisedEntry& k_rep,
00058                  const kv::serialisers::SerialisedEntry& v_rep) {
00059         return f(
00060           KSerialiser::from_serialised(k_rep),
00061           VSerialiser::from_serialised(v_rep));
00062       };
00063       untyped_view.foreach(g);
00064     }
00065   };
00066 
00067   template <typename K, typename V, typename KSerialiser, typename VSerialiser>
00068   class TxView : public ReadOnlyTxView<K, V, KSerialiser, VSerialiser>
00069   {
00070   protected:
00071     using ReadOnlyBase = ReadOnlyTxView<K, V, KSerialiser, VSerialiser>;
00072 
00073   public:
00074     using ReadOnlyBase::ReadOnlyBase;
00075 
00076     bool put(const K& key, const V& value)
00077     {
00078       return ReadOnlyBase::untyped_view.put(
00079         KSerialiser::to_serialised(key), VSerialiser::to_serialised(value));
00080     }
00081 
00082     bool remove(const K& key)
00083     {
00084       return ReadOnlyBase::untyped_view.remove(KSerialiser::to_serialised(key));
00085     }
00086   };
00087 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/tx_view.h...
Preprocessing /data/git/CCF/src/kv/untyped_map.h...
#include ds/dl_list.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include kv/kv_serialiser.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/untyped_tx_view.h: not found! skipping...
#include functional: not found! skipping...
#include optional: not found! skipping...
#include unordered_set: not found! skipping...
Preprocessor output (size: 20441 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace kv::untyped
00017 {
00018   namespace Check
00019   {
00020     struct No
00021     {};
00022 
00023     template <typename T, typename Arg>
00024     No operator!=(const T&, const Arg&)
00025     {
00026       return No();
00027     }
00028 
00029     template <typename T, typename Arg = T>
00030     struct Ne
00031     {
00032       enum
00033       {
00034         value = !std::is_same<decltype(*(T*)(0) != *(Arg*)(0)), No>::value
00035       };
00036     };
00037 
00038     template <class T>
00039     bool ne(std::enable_if_t<Ne<T>::value, const T&> a, const T& b)
00040     {
00041       return a != b;
00042     }
00043 
00044     template <class T>
00045     bool ne(std::enable_if_t<!Ne<T>::value, const T&>, const T&)
00046     {
00047       return false;
00048     }
00049   }
00050 
00051   struct LocalCommit
00052   {
00053     LocalCommit() = default;
00054     LocalCommit(Version v, State&& s, const Write& w) :
00055       version(v),
00056       state(std::move(s)),
00057       writes(w)
00058     {}
00059 
00060     Version version;
00061     State state;
00062     Write writes;
00063     LocalCommit* next = nullptr;
00064     LocalCommit* prev = nullptr;
00065   };
00066   using LocalCommits = snmalloc::DLList<LocalCommit, std::nullptr_t, true>;
00067 
00068   struct Roll
00069   {
00070     std::unique_ptr<LocalCommits> commits;
00071     size_t rollback_counter;
00072 
00073     LocalCommits empty_commits;
00074 
00075     void reset_commits()
00076     {
00077       commits->clear();
00078       commits->insert_back(create_new_local_commit(0, State(), Write()));
00079     }
00080 
00081     template <typename... Args>
00082     LocalCommit* create_new_local_commit(Args&&... args)
00083     {
00084       LocalCommit* c = empty_commits.pop();
00085       if (c == nullptr)
00086       {
00087         c = new LocalCommit(std::forward<Args>(args)...);
00088       }
00089       else
00090       {
00091         c->~LocalCommit();
00092         new (c) LocalCommit(std::forward<Args>(args)...);
00093       }
00094       return c;
00095     }
00096   };
00097 
00098   class Map : public AbstractMap
00099   {
00100   public:
00101     using K = SerialisedEntry;
00102     using V = SerialisedEntry;
00103     using H = SerialisedKeyHasher;
00104 
00105     using StateSnapshot = kv::Snapshot<K, V, H>;
00106 
00107     using CommitHook = CommitHook<Write>;
00108 
00109   private:
00110     AbstractStore* store;
00111     Roll roll;
00112     CommitHook local_hook = nullptr;
00113     CommitHook global_hook = nullptr;
00114     std::list<std::pair<Version, Write>> commit_deltas;
00115     SpinLock sl;
00116     const SecurityDomain security_domain;
00117     const bool replicated;
00118 
00119   public:
00120     class TxViewCommitter : public AbstractCommitter
00121     {
00122     protected:
00123       Map& map;
00124 
00125       ChangeSet& change_set;
00126 
00127       Version commit_version = NoVersion;
00128 
00129       bool changes = false;
00130       bool committed_writes = false;
00131 
00132     public:
00133       TxViewCommitter(Map& m, ChangeSet& change_set_) :
00134         map(m),
00135         change_set(change_set_)
00136       {}
00137 
00138       // Commit-related methods
00139       bool has_writes() override
00140       {
00141         return committed_writes || change_set.has_writes();
00142       }
00143 
00144       bool prepare() override
00145       {
00146         if (change_set.writes.empty())
00147           return true;
00148 
00149         auto& roll = map.get_roll();
00150 
00151         // If the parent map has rolled back since this transaction began, this
00152         // transaction must fail.
00153         if (change_set.rollback_counter != roll.rollback_counter)
00154           return false;
00155 
00156         // If we have iterated over the map, check for a global version match.
00157         auto current = roll.commits->get_tail();
00158 
00159         if (
00160           (change_set.read_version != NoVersion) &&
00161           (change_set.read_version != current->version))
00162         {
00163           LOG_DEBUG_FMT("Read version {} is invalid", change_set.read_version);
00164           return false;
00165         }
00166 
00167         // Check each key in our read set.
00168         for (auto it = change_set.reads.begin(); it != change_set.reads.end();
00169              ++it)
00170         {
00171           // Get the value from the current state.
00172           auto search = current->state.get(it->first);
00173 
00174           if (it->second == NoVersion)
00175           {
00176             // If we depend on the key not existing, it must be absent.
00177             if (search.has_value())
00178             {
00179               LOG_DEBUG_FMT("Read depends on non-existing entry");
00180               return false;
00181             }
00182           }
00183           else
00184           {
00185             // If we depend on the key existing, it must be present and have the
00186             // version that we expect.
00187             if (!search.has_value() || (it->second != search.value().version))
00188             {
00189               LOG_DEBUG_FMT("Read depends on invalid version of entry");
00190               return false;
00191             }
00192           }
00193         }
00194 
00195         return true;
00196       }
00197 
00198       void commit(Version v) override
00199       {
00200         if (change_set.writes.empty())
00201         {
00202           commit_version = change_set.start_version;
00203           return;
00204         }
00205 
00206         // Record our commit time.
00207         commit_version = v;
00208         committed_writes = true;
00209 
00210         auto& roll = map.get_roll();
00211         auto state = roll.commits->get_tail()->state;
00212 
00213         for (auto it = change_set.writes.begin(); it != change_set.writes.end();
00214              ++it)
00215         {
00216           if (it->second.has_value())
00217           {
00218             // Write the new value with the global version.
00219             changes = true;
00220             state = state.put(it->first, VersionV{v, it->second.value()});
00221           }
00222           else
00223           {
00224             // Write an empty value with the deleted global version only if
00225             // the key exists.
00226             auto search = state.get(it->first);
00227             if (search.has_value())
00228             {
00229               changes = true;
00230               state = state.put(it->first, VersionV{-v, {}});
00231             }
00232           }
00233         }
00234 
00235         if (changes)
00236         {
00237           map.roll.commits->insert_back(map.roll.create_new_local_commit(
00238             v, std::move(state), change_set.writes));
00239         }
00240       }
00241 
00242       void post_commit() override
00243       {
00244         // This is run separately from commit so that all commits in the Tx
00245         // have been applied before local hooks are run. The maps in the Tx
00246         // are still locked when post_commit is run.
00247         if (change_set.writes.empty())
00248           return;
00249 
00250         map.trigger_local_hook(commit_version, change_set.writes);
00251       }
00252 
00253       void set_commit_version(Version v)
00254       {
00255         commit_version = v;
00256       }
00257     };
00258 
00259     class Snapshot : public AbstractMap::Snapshot
00260     {
00261     private:
00262       const std::string name;
00263       const SecurityDomain security_domain;
00264       const kv::Version version;
00265 
00266       StateSnapshot map_snapshot;
00267 
00268     public:
00269       Snapshot(
00270         const std::string& name_,
00271         SecurityDomain security_domain_,
00272         kv::Version version_,
00273         StateSnapshot&& map_snapshot_) :
00274         name(name_),
00275         security_domain(security_domain_),
00276         version(version_),
00277         map_snapshot(std::move(map_snapshot_))
00278       {}
00279 
00280       void serialise(KvStoreSerialiser& s) override
00281       {
00282         s.start_map(name, security_domain);
00283         s.serialise_entry_version(version);
00284 
00285         std::vector<uint8_t> ret(map_snapshot.get_serialized_size());
00286         map_snapshot.serialize(ret.data());
00287         s.serialise_raw(ret);
00288       }
00289 
00290       SecurityDomain get_security_domain() override
00291       {
00292         return security_domain;
00293       }
00294     };
00295 
00296     // Public typedef for external consumption
00297     using TxView = kv::untyped::TxView;
00298 
00299     Map(
00300       AbstractStore* store_,
00301       const std::string& name_,
00302       SecurityDomain security_domain_,
00303       bool replicated_) :
00304       AbstractMap(name_),
00305       store(store_),
00306       roll{std::make_unique<LocalCommits>(), 0, {}},
00307       security_domain(security_domain_),
00308       replicated(replicated_)
00309     {
00310       roll.reset_commits();
00311     }
00312 
00313     Map(const Map& that) = delete;
00314 
00315     virtual AbstractMap* clone(AbstractStore* other) override
00316     {
00317       return new Map(other, name, security_domain, replicated);
00318     }
00319 
00320     void serialise_changes(
00321       const AbstractChangeSet* changes,
00322       KvStoreSerialiser& s,
00323       bool include_reads) override
00324     {
00325       const auto non_abstract =
00326         dynamic_cast<const kv::untyped::ChangeSet*>(changes);
00327       if (non_abstract == nullptr)
00328       {
00329         LOG_FAIL_FMT("Unable to serialise map due to type mismatch");
00330         return;
00331       }
00332 
00333       const auto& change_set = *non_abstract;
00334 
00335       s.start_map(name, security_domain);
00336 
00337       if (include_reads)
00338       {
00339         s.serialise_entry_version(change_set.read_version);
00340 
00341         s.serialise_count_header(change_set.reads.size());
00342         for (auto it = change_set.reads.begin(); it != change_set.reads.end();
00343              ++it)
00344         {
00345           s.serialise_read(it->first, it->second);
00346         }
00347       }
00348       else
00349       {
00350         s.serialise_entry_version(NoVersion);
00351         s.serialise_count_header(0);
00352       }
00353 
00354       uint64_t write_ctr = 0;
00355       uint64_t remove_ctr = 0;
00356       for (auto it = change_set.writes.begin(); it != change_set.writes.end();
00357            ++it)
00358       {
00359         if (it->second.has_value())
00360         {
00361           ++write_ctr;
00362         }
00363         else
00364         {
00365           auto search = roll.commits->get_tail()->state.get(it->first);
00366           if (search.has_value())
00367           {
00368             ++remove_ctr;
00369           }
00370         }
00371       }
00372 
00373       s.serialise_count_header(write_ctr);
00374       for (auto it = change_set.writes.begin(); it != change_set.writes.end();
00375            ++it)
00376       {
00377         if (it->second.has_value())
00378         {
00379           s.serialise_write(it->first, it->second.value());
00380         }
00381       }
00382 
00383       s.serialise_count_header(remove_ctr);
00384       for (auto it = change_set.writes.begin(); it != change_set.writes.end();
00385            ++it)
00386       {
00387         if (!it->second.has_value())
00388         {
00389           s.serialise_remove(it->first);
00390         }
00391       }
00392     }
00393 
00394     class SnapshotViewCommitter : public AbstractCommitter
00395     {
00396     private:
00397       Map& map;
00398 
00399       SnapshotChangeSet& change_set;
00400 
00401     public:
00402       SnapshotViewCommitter(Map& m, SnapshotChangeSet& change_set_) :
00403         map(m),
00404         change_set(change_set_)
00405       {}
00406 
00407       bool has_writes() override
00408       {
00409         return true;
00410       }
00411 
00412       bool prepare() override
00413       {
00414         // Snapshots never conflict
00415         return true;
00416       }
00417 
00418       void commit(Version) override
00419       {
00420         // Version argument is ignored. The version of the roll after the
00421         // snapshot is applied depends on the version of the map at which the
00422         // snapshot was taken.
00423         map.roll.reset_commits();
00424         map.roll.rollback_counter++;
00425 
00426         auto r = map.roll.commits->get_head();
00427 
00428         r->state = change_set.state;
00429         r->version = change_set.version;
00430 
00431         // Executing hooks from snapshot requires copying the entire snapshotted
00432         // state so only do it if there's an hook on the table
00433         if (map.local_hook || map.global_hook)
00434         {
00435           r->state.foreach([&r](const K& k, const VersionV& v) {
00436             if (!is_deleted(v.version))
00437             {
00438               r->writes[k] = v.value;
00439             }
00440             return true;
00441           });
00442         }
00443       }
00444 
00445       void post_commit() override
00446       {
00447         auto r = map.roll.commits->get_head();
00448         map.trigger_local_hook(change_set.version, r->writes);
00449       }
00450     };
00451 
00452     ChangeSetPtr deserialise_snapshot_changes(KvStoreDeserialiser& d)
00453     {
00454       // Create a new empty view, deserialising d's contents into it.
00455       auto v = d.deserialise_entry_version();
00456       auto map_snapshot = d.deserialise_raw();
00457 
00458       return std::make_unique<SnapshotChangeSet>(
00459         State::deserialize_map(map_snapshot), v);
00460     }
00461 
00462     ChangeSetPtr deserialise_changes(KvStoreDeserialiser& d, Version version)
00463     {
00464       return deserialise_internal(d, version);
00465     }
00466 
00467     ChangeSetPtr deserialise_internal(KvStoreDeserialiser& d, Version version)
00468     {
00469       // Create a new change set, and deserialise d's contents into it.
00470       auto change_set_ptr = create_change_set(version);
00471       if (change_set_ptr == nullptr)
00472       {
00473         LOG_FAIL_FMT(
00474           "Failed to create view over '{}' at {} - too early", name, version);
00475         throw std::logic_error("Can't create view");
00476       }
00477 
00478       auto& change_set = *change_set_ptr;
00479 
00480       uint64_t ctr;
00481 
00482       auto rv = d.deserialise_entry_version();
00483       if (rv != NoVersion)
00484       {
00485         change_set.read_version = rv;
00486       }
00487 
00488       ctr = d.deserialise_read_header();
00489       for (size_t i = 0; i < ctr; ++i)
00490       {
00491         auto r = d.deserialise_read();
00492         change_set.reads[std::get<0>(r)] = std::get<1>(r);
00493       }
00494 
00495       ctr = d.deserialise_write_header();
00496       for (size_t i = 0; i < ctr; ++i)
00497       {
00498         auto w = d.deserialise_write();
00499         change_set.writes[std::get<0>(w)] = std::get<1>(w);
00500       }
00501 
00502       ctr = d.deserialise_remove_header();
00503       for (size_t i = 0; i < ctr; ++i)
00504       {
00505         auto r = d.deserialise_remove();
00506         change_set.writes[r] = std::nullopt;
00507       }
00508 
00509       return change_set_ptr;
00510     }
00511 
00512     std::unique_ptr<AbstractCommitter> create_committer(
00513       AbstractChangeSet* changes) override
00514     {
00515       auto non_abstract = dynamic_cast<ChangeSet*>(changes);
00516       if (non_abstract == nullptr)
00517       {
00518         throw std::logic_error("Type confusion error");
00519       }
00520 
00521       auto snapshot_change_set = dynamic_cast<SnapshotChangeSet*>(non_abstract);
00522       if (snapshot_change_set != nullptr)
00523       {
00524         return std::make_unique<SnapshotViewCommitter>(
00525           *this, *snapshot_change_set);
00526       }
00527 
00528       return std::make_unique<TxViewCommitter>(*this, *non_abstract);
00529     }
00530 
00531     /** Get store that the map belongs to
00532      *
00533      * @return Pointer to `kv::AbstractStore`
00534      */
00535     AbstractStore* get_store() override
00536     {
00537       return store;
00538     }
00539 
00540     /** Set handler to be called on local transaction commit
00541      *
00542      * @param hook function to be called on local transaction commit
00543      */
00544     void set_local_hook(const CommitHook& hook)
00545     {
00546       local_hook = hook;
00547     }
00548 
00549     /** Reset local transaction commit handler
00550      */
00551     void unset_local_hook()
00552     {
00553       local_hook = nullptr;
00554     }
00555 
00556     /** Set handler to be called on global transaction commit
00557      *
00558      * @param hook function to be called on global transaction commit
00559      */
00560     void set_global_hook(const CommitHook& hook)
00561     {
00562       global_hook = hook;
00563     }
00564 
00565     /** Reset global transaction commit handler
00566      */
00567     void unset_global_hook()
00568     {
00569       global_hook = nullptr;
00570     }
00571 
00572     /** Get security domain of a Map
00573      *
00574      * @return Security domain of the map (affects serialisation)
00575      */
00576     virtual SecurityDomain get_security_domain() override
00577     {
00578       return security_domain;
00579     }
00580 
00581     /** Get Map replicability
00582      *
00583      * @return true if the map is to be replicated, false if it is to be derived
00584      */
00585     virtual bool is_replicated() override
00586     {
00587       return replicated;
00588     }
00589 
00590     bool operator==(const AbstractMap& that) const override
00591     {
00592       auto p = dynamic_cast<const Map*>(&that);
00593       if (p == nullptr)
00594         return false;
00595 
00596       if (name != p->name)
00597         return false;
00598 
00599       auto state1 = roll.commits->get_tail();
00600       auto state2 = p->roll.commits->get_tail();
00601 
00602       if (state1->version != state2->version)
00603         return false;
00604 
00605       size_t count = 0;
00606       state2->state.foreach([&count](const K&, const VersionV&) {
00607         count++;
00608         return true;
00609       });
00610 
00611       size_t i = 0;
00612       bool ok =
00613         state1->state.foreach([&state2, &i](const K& k, const VersionV& v) {
00614           auto search = state2->state.get(k);
00615 
00616           if (search.has_value())
00617           {
00618             auto& found = search.value();
00619             if (found.version != v.version)
00620             {
00621               return false;
00622             }
00623             else if (Check::ne(found.value, v.value))
00624             {
00625               return false;
00626             }
00627           }
00628           else
00629           {
00630             return false;
00631           }
00632 
00633           i++;
00634           return true;
00635         });
00636 
00637       if (i != count)
00638         ok = false;
00639 
00640       return ok;
00641     }
00642 
00643     bool operator!=(const AbstractMap& that) const override
00644     {
00645       return !(*this == that);
00646     }
00647 
00648     std::unique_ptr<AbstractMap::Snapshot> snapshot(Version v) override
00649     {
00650       // This takes a snapshot of the state of the map at the last entry
00651       // committed at or before this version. The Map expects to be locked while
00652       // taking the snapshot.
00653       auto r = roll.commits->get_head();
00654 
00655       for (auto current = roll.commits->get_tail(); current != nullptr;
00656            current = current->prev)
00657       {
00658         if (current->version <= v)
00659         {
00660           r = current;
00661           break;
00662         }
00663       }
00664 
00665       return std::make_unique<Snapshot>(
00666         name, security_domain, r->version, StateSnapshot(r->state));
00667     }
00668 
00669     void compact(Version v) override
00670     {
00671       // This discards available rollback state before version v, and populates
00672       // the commit_deltas to be passed to the global commit hook, if there is
00673       // one, up to version v. The Map expects to be locked during compaction.
00674       while (roll.commits->get_head() != roll.commits->get_tail())
00675       {
00676         auto r = roll.commits->get_head();
00677 
00678         // Globally committed but not discardable.
00679         if (r->version == v)
00680         {
00681           // We know that write set is not empty.
00682           if (global_hook)
00683           {
00684             commit_deltas.emplace_back(r->version, std::move(r->writes));
00685           }
00686           return;
00687         }
00688 
00689         // Discardable, so move to commit_deltas.
00690         if (global_hook && !r->writes.empty())
00691         {
00692           commit_deltas.emplace_back(r->version, std::move(r->writes));
00693         }
00694 
00695         // Stop if the next state may be rolled back or is the only state.
00696         // This ensures there is always a state present.
00697         if (r->next->version > v)
00698           return;
00699 
00700         auto c = roll.commits->pop();
00701         roll.empty_commits.insert(c);
00702       }
00703 
00704       // There is only one roll. We may need to call the commit hook.
00705       auto r = roll.commits->get_head();
00706 
00707       if (global_hook && !r->writes.empty())
00708       {
00709         commit_deltas.emplace_back(r->version, std::move(r->writes));
00710       }
00711     }
00712 
00713     void post_compact() override
00714     {
00715       if (global_hook)
00716       {
00717         for (auto& [version, writes] : commit_deltas)
00718         {
00719           global_hook(version, writes);
00720         }
00721       }
00722 
00723       commit_deltas.clear();
00724     }
00725 
00726     void rollback(Version v) override
00727     {
00728       // This rolls the current state back to version v.
00729       // The Map expects to be locked during rollback.
00730       bool advance = false;
00731 
00732       while (roll.commits->get_head() != roll.commits->get_tail())
00733       {
00734         auto r = roll.commits->get_tail();
00735 
00736         // The initial empty state has v = 0, so will not be discarded if it
00737         // is present.
00738         if (r->version <= v)
00739           break;
00740 
00741         advance = true;
00742         auto c = roll.commits->pop_tail();
00743         roll.empty_commits.insert(c);
00744       }
00745 
00746       if (advance)
00747         roll.rollback_counter++;
00748     }
00749 
00750     void clear() override
00751     {
00752       // This discards all entries in the roll and resets the rollback counter.
00753       // The Map expects to be locked before clearing it.
00754       roll.reset_commits();
00755       roll.rollback_counter = 0;
00756     }
00757 
00758     void lock() override
00759     {
00760       sl.lock();
00761     }
00762 
00763     void unlock() override
00764     {
00765       sl.unlock();
00766     }
00767 
00768     void swap(AbstractMap* map_) override
00769     {
00770       Map* map = dynamic_cast<Map*>(map_);
00771       if (map == nullptr)
00772         throw std::logic_error(
00773           "Attempted to swap maps with incompatible types");
00774 
00775       std::swap(roll, map->roll);
00776     }
00777 
00778     ChangeSetPtr create_change_set(Version version)
00779     {
00780       lock();
00781 
00782       ChangeSetPtr changes = nullptr;
00783 
00784       // Find the last entry committed at or before this version.
00785       for (auto current = roll.commits->get_tail(); current != nullptr;
00786            current = current->prev)
00787       {
00788         if (current->version <= version)
00789         {
00790           changes = std::make_unique<untyped::ChangeSet>(
00791             roll.rollback_counter,
00792             current->state,
00793             roll.commits->get_head()->state,
00794             current->version);
00795           break;
00796         }
00797       }
00798 
00799       // Returning nullptr is allowed, and indicates that we have no suitable
00800       // version - the version requested is _earlier_ than anything in the roll
00801 
00802       unlock();
00803       return changes;
00804     }
00805 
00806     Roll& get_roll()
00807     {
00808       return roll;
00809     }
00810 
00811     void trigger_local_hook(Version version, const Write& writes)
00812     {
00813       if (local_hook)
00814       {
00815         local_hook(version, writes);
00816       }
00817     }
00818   };
00819 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/untyped_map.h...
Preprocessing /data/git/CCF/src/kv/untyped_tx_view.h...
#include kv/change_set.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/serialised_entry.h: not found! skipping...
Preprocessor output (size: 8186 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace kv::untyped
00010 {
00011   using SerialisedEntry = kv::serialisers::SerialisedEntry;
00012   using SerialisedKeyHasher = std::hash<SerialisedEntry>;
00013 
00014   using VersionV = kv::VersionV<SerialisedEntry>;
00015   using State =
00016     kv::State<SerialisedEntry, SerialisedEntry, SerialisedKeyHasher>;
00017   using Read = kv::Read<SerialisedEntry>;
00018   using Write = kv::Write<SerialisedEntry, SerialisedEntry>;
00019   using ChangeSet =
00020     kv::ChangeSet<SerialisedEntry, SerialisedEntry, SerialisedKeyHasher>;
00021   using ChangeSetPtr = std::unique_ptr<ChangeSet>;
00022   using SnapshotChangeSet = kv::
00023     SnapshotChangeSet<SerialisedEntry, SerialisedEntry, SerialisedKeyHasher>;
00024 
00025   class TxView : public kv::AbstractTxView
00026   {
00027   public:
00028     // Expose these types so that other code can use them as MyTx::KeyType or
00029     // MyMap::TxView::KeyType, templated on the TxView or Map type
00030     using KeyType = SerialisedEntry;
00031     using ValueType = SerialisedEntry;
00032 
00033   protected:
00034     ChangeSet& tx_changes;
00035 
00036     /** Get pointer to current value if this key exists, else nullptr if it does
00037      * not exist or has been deleted. If non-null, points to something owned by
00038      * tx_changes - expect this is used/dereferenced immediately, and there is
00039      * no concurrent access which could invalidate it. Modifies read set if
00040      * appropriate to record read dependency on this key, at the version of the
00041      * returned data.
00042      */
00043     const ValueType* read_key(const KeyType& key)
00044     {
00045       // A write followed by a read doesn't introduce a read dependency.
00046       // If we have written, return the value without updating the read set.
00047       auto write = tx_changes.writes.find(key);
00048       if (write != tx_changes.writes.end())
00049       {
00050         if (write->second.has_value())
00051         {
00052           return &write->second.value();
00053         }
00054         else
00055         {
00056           return nullptr;
00057         }
00058       }
00059 
00060       // If the key doesn't exist, return empty and record that we depend on
00061       // the key not existing.
00062       const auto search = tx_changes.state.getp(key);
00063       if (search == nullptr)
00064       {
00065         tx_changes.reads.insert(std::make_pair(key, NoVersion));
00066         return nullptr;
00067       }
00068 
00069       // Record the version that we depend on.
00070       tx_changes.reads.insert(std::make_pair(key, search->version));
00071 
00072       // If the key has been deleted, return empty.
00073       if (is_deleted(search->version))
00074       {
00075         return nullptr;
00076       }
00077 
00078       // Return the value.
00079       return &search->value;
00080     }
00081 
00082   public:
00083     TxView(ChangeSet& cs) : tx_changes(cs) {}
00084 
00085     /** Get value for key
00086      *
00087      * This returns the value for the key inside the transaction. If the key
00088      * has been updated in the current transaction, that update will be
00089      * reflected in the return of this call.
00090      *
00091      * @param key Key
00092      *
00093      * @return optional containing value, empty if the key doesn't exist
00094      */
00095     std::optional<ValueType> get(const KeyType& key)
00096     {
00097       auto value_p = read_key(key);
00098       if (value_p == nullptr)
00099       {
00100         return std::nullopt;
00101       }
00102 
00103       return *value_p;
00104     }
00105 
00106     /** Get globally committed value for key
00107      *
00108      * This reads a globally replicated value for the specified key.
00109      * The value will have been the replicated value when the transaction
00110      * began, but the map may be compacted while the transaction is in
00111      * flight. If that happens, there may be a more recent committed
00112      * version. This is undetectable to the transaction.
00113      *
00114      * @param key Key
00115      *
00116      * @return optional containing value, empty if the key doesn't exist in
00117      * globally committed state
00118      */
00119     std::optional<ValueType> get_globally_committed(const KeyType& key)
00120     {
00121       // If there is no committed value, return empty.
00122       auto search = tx_changes.committed.get(key);
00123       if (!search.has_value())
00124       {
00125         return std::nullopt;
00126       }
00127 
00128       // If the key has been deleted, return empty.
00129       auto& found = search.value();
00130       if (is_deleted(found.version))
00131       {
00132         return std::nullopt;
00133       }
00134 
00135       // Return the value.
00136       return found.value;
00137     }
00138 
00139     /** Test if key is present
00140      *
00141      * This returns true if the key has a value inside the transaction. If the
00142      * key has been updated (written to or deleted) in the current transaction,
00143      * that update will be reflected in the return of this call.
00144      *
00145      * @param key Key
00146      *
00147      * @return bool true iff key exists
00148      */
00149     bool has(const KeyType& key)
00150     {
00151       auto value_p = read_key(key);
00152       return value_p != nullptr;
00153     }
00154 
00155     /** Write value at key
00156      *
00157      * If the key already exists, the value will be replaced.
00158      * This will fail if the transaction is already committed.
00159      *
00160      * @param key Key
00161      * @param value Value
00162      *
00163      * @return true if successful, false otherwise
00164      */
00165     bool put(const KeyType& key, const ValueType& value)
00166     {
00167       // Record in the write set.
00168       tx_changes.writes[key] = value;
00169       return true;
00170     }
00171 
00172     /** Remove key
00173      *
00174      * This will fail if the key does not exist, or if the transaction
00175      * is already committed.
00176      *
00177      * @param key Key
00178      *
00179      * @return true if successful, false otherwise
00180      */
00181     bool remove(const KeyType& key)
00182     {
00183       auto write = tx_changes.writes.find(key);
00184       auto search = tx_changes.state.get(key).has_value();
00185 
00186       if (write != tx_changes.writes.end())
00187       {
00188         if (!search)
00189         {
00190           // this key only exists locally, there is no reason to maintain and
00191           // serialise it
00192           tx_changes.writes.erase(key);
00193         }
00194         else
00195         {
00196           // If we have written, change the write set to indicate a remove.
00197           write->second = std::nullopt;
00198         }
00199 
00200         return true;
00201       }
00202 
00203       // If the key doesn't exist, return false.
00204       if (!search)
00205       {
00206         return false;
00207       }
00208 
00209       // Record in the write set.
00210       tx_changes.writes[key] = std::nullopt;
00211       return true;
00212     }
00213 
00214     /** Iterate over all entries in the map. There is no guarantee on the
00215      * iteration order.
00216      *
00217      * The set of key-value entries which will be iterated over is determined at
00218      * the point foreach is called, and does not include any modifications made
00219      * by the functor. This means:
00220      * - If the functor sets a value V at a new key K', the functor will not be
00221      * called for (K', V)
00222      * - If the functor changes the value at key K from V to V', the functor
00223      * will be called with the old value (K, V)
00224      * - If the functor removes K, the functor will still be called for (K, V)
00225      *
00226      * Calling `get` will always return the true latest state, this behaviour
00227      * only applies to the keys and values passed as functor arguments.
00228      *
00229      * @param F functor, taking a key and a value, return value determines
00230      * whether the iteration should continue (true) or stop (false)
00231      */
00232     template <class F>
00233     void foreach(F&& f)
00234     {
00235       // Record a global read dependency.
00236       tx_changes.read_version = tx_changes.start_version;
00237 
00238       // Take a snapshot copy of the writes. This is what we will iterate over,
00239       // while any additional modifications made by the functor will modify the
00240       // original tx_changes.writes, and be visible outside of the functor's
00241       // args
00242       auto w = tx_changes.writes;
00243       bool should_continue = true;
00244 
00245       tx_changes.state.foreach(
00246         [&w, &f, &should_continue](const KeyType& k, const VersionV& v) {
00247           auto write = w.find(k);
00248 
00249           if ((write == w.end()) && !is_deleted(v.version))
00250           {
00251             should_continue = f(k, v.value);
00252           }
00253 
00254           return should_continue;
00255         });
00256 
00257       if (should_continue)
00258       {
00259         for (auto write = w.begin(); write != w.end(); ++write)
00260         {
00261           if (write->second.has_value())
00262           {
00263             should_continue = f(write->first, write->second.value());
00264           }
00265 
00266           if (!should_continue)
00267           {
00268             break;
00269           }
00270         }
00271       }
00272     }
00273   };
00274 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/untyped_tx_view.h...
Preprocessing /data/git/CCF/src/kv/view_containers.h...
#include kv_types.h: already included! skipping...
#include functional: not found! skipping...
#include map: not found! skipping...
Preprocessor output (size: 4242 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace kv
00011 {
00012   struct MapChanges
00013   {
00014     // Shared ownership over source map
00015     std::shared_ptr<AbstractMap> map;
00016 
00017     // Owning pointer of ChangeSet over that map
00018     std::unique_ptr<untyped::ChangeSet> changeset;
00019   };
00020 
00021   // When a collection of Maps are locked, the locks must be acquired in a
00022   // stable order to avoid deadlocks. This ordered map will claim in name-order
00023   using OrderedChanges = std::map<std::string, MapChanges>;
00024 
00025   // All collections of Map must be ordered so that we lock their contained
00026   // maps in a stable order. The order here is by map name
00027   using MapCollection = std::map<std::string, std::shared_ptr<AbstractMap>>;
00028 
00029   struct AbstractChangeContainer
00030   {
00031     virtual ~AbstractChangeContainer() = default;
00032     virtual void set_change_list(OrderedChanges&& change_list, Term term) = 0;
00033   };
00034 
00035   // Atomically checks for conflicts then applies the writes in the given change
00036   // sets to their underlying Maps. Calls f() at most once, iff the writes are
00037   // applied, to retrieve a unique Version for the write set.
00038   static inline std::optional<Version> apply_changes(
00039     OrderedChanges& changes,
00040     std::function<Version()> f,
00041     const MapCollection& new_maps = {},
00042     const std::optional<Version>& new_maps_conflict_version = std::nullopt)
00043   {
00044     // All maps with pending writes are locked, transactions are prepared
00045     // and possibly committed, and then all maps with pending writes are
00046     // unlocked. This is to prevent transactions from being committed in an
00047     // interleaved fashion.
00048     Version version = 0;
00049     bool has_writes = false;
00050 
00051     std::map<std::string, std::unique_ptr<AbstractCommitter>> views;
00052     for (const auto& [map_name, mc] : changes)
00053     {
00054       views[map_name] = mc.map->create_committer(mc.changeset.get());
00055     }
00056 
00057     for (auto it = changes.begin(); it != changes.end(); ++it)
00058     {
00059       if (it->second.changeset->has_writes())
00060       {
00061         it->second.map->lock();
00062         has_writes = true;
00063       }
00064     }
00065 
00066     bool ok = true;
00067 
00068     for (auto it = views.begin(); it != views.end(); ++it)
00069     {
00070       if (!it->second->prepare())
00071       {
00072         ok = false;
00073         break;
00074       }
00075     }
00076 
00077     for (const auto& [map_name, map_ptr] : new_maps)
00078     {
00079       // Check that none of these pending maps have already been created.
00080       // It is possible for non-conflicting other transactions to commit here
00081       // and increment the version, so we may ask this question at different
00082       // versions. This is fine - none can create maps (ie - change their
00083       // conflict set with this operation) while we hold the store lock. Assume
00084       // that the caller is currently holding store->lock()
00085       auto store = map_ptr->get_store();
00086 
00087       // This is to avoid recursively locking version_lock by calling
00088       // current_version() in the commit_reserved case.
00089       kv::Version current_v;
00090       if (new_maps_conflict_version.has_value())
00091       {
00092         current_v = *new_maps_conflict_version;
00093       }
00094       else
00095       {
00096         current_v = store->current_version();
00097       }
00098 
00099       if (store->get_map(current_v, map_name) != nullptr)
00100       {
00101         ok = false;
00102         break;
00103       }
00104     }
00105 
00106     if (ok && has_writes)
00107     {
00108       // Get the version number to be used for this commit.
00109       version = f();
00110 
00111       // Transfer ownership of these new maps to their target stores, iff we
00112       // have writes to them
00113       for (const auto& [map_name, map_ptr] : new_maps)
00114       {
00115         const auto it = views.find(map_name);
00116         if (it != views.end() && it->second->has_writes())
00117         {
00118           map_ptr->get_store()->add_dynamic_map(version, map_ptr);
00119         }
00120       }
00121 
00122       for (auto it = views.begin(); it != views.end(); ++it)
00123       {
00124         it->second->commit(version);
00125       }
00126 
00127       for (auto it = views.begin(); it != views.end(); ++it)
00128       {
00129         it->second->post_commit();
00130       }
00131     }
00132 
00133     for (auto it = changes.begin(); it != changes.end(); ++it)
00134     {
00135       if (it->second.changeset->has_writes())
00136       {
00137         it->second.map->unlock();
00138       }
00139     }
00140 
00141     if (!ok)
00142     {
00143       return std::nullopt;
00144     }
00145 
00146     return version;
00147   }
00148 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/kv/view_containers.h...
Preprocessing /data/git/CCF/src/libmerklecpp/merklecpp.h...
#include array: not found! skipping...
#include cassert: not found! skipping...
#include cmath: not found! skipping...
#include cstddef: not found! skipping...
#include cstdint: not found! skipping...
#include cstring: not found! skipping...
#include functional: not found! skipping...
#include list: not found! skipping...
#include memory: not found! skipping...
#include sstream: not found! skipping...
#include stack: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 35984 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 #define MERKLECPP_TRACE(X)
00058 
00059 
00060 namespace merkle
00061 {
00062   void serialise_size_t(size_t size, std::vector<uint8_t>& bytes)
00063   {
00064     size_t size_be = htobe64(size);
00065     uint8_t* size_bytes = (uint8_t*)&size_be;
00066     for (size_t i = 0; i < sizeof(size_t); i++)
00067       bytes.push_back(size_bytes[i]);
00068   }
00069 
00070   size_t deserialise_size_t(const std::vector<uint8_t>& bytes, size_t& index)
00071   {
00072     size_t result = 0;
00073     uint8_t* result_bytes = (uint8_t*)&result;
00074     for (size_t i = 0; i < sizeof(size_t); i++)
00075       result_bytes[i] = bytes[index++];
00076     return be64toh(result);
00077   }
00078 
00079   template <size_t SIZE>
00080   struct HashT
00081   {
00082     uint8_t bytes[SIZE];
00083 
00084     HashT<SIZE>()
00085     {
00086       std::fill(bytes, bytes + SIZE, 0);
00087     }
00088 
00089     HashT<SIZE>(const uint8_t* bytes)
00090     {
00091       std::copy(bytes, bytes + SIZE, this->bytes);
00092     }
00093 
00094     HashT<SIZE>(const std::string& s)
00095     {
00096       if (s.length() != 2 * SIZE)
00097         throw std::runtime_error("invalid hash string");
00098       for (size_t i = 0; i < SIZE; i++)
00099       {
00100         int tmp;
00101         sscanf(s.c_str() + 2 * i, "%02x", &tmp);
00102         bytes[i] = tmp;
00103       }
00104     }
00105 
00106     HashT<SIZE>(const std::vector<uint8_t>& bytes)
00107     {
00108       if (bytes.size() < SIZE)
00109         throw std::runtime_error("not enough bytes");
00110       deserialise(bytes);
00111     }
00112 
00113     HashT<SIZE>(const std::vector<uint8_t>& bytes, size_t& position)
00114     {
00115       if (bytes.size() - position < SIZE)
00116         throw std::runtime_error("not enough bytes");
00117       deserialise(bytes, position);
00118     }
00119 
00120     HashT<SIZE>(const std::array<uint8_t, SIZE>& bytes)
00121     {
00122       std::copy(bytes.data(), bytes.data() + SIZE, this->bytes);
00123     }
00124 
00125     size_t size() const
00126     {
00127       return SIZE;
00128     }
00129 
00130     size_t serialised_size() const
00131     {
00132       return SIZE;
00133     }
00134 
00135     std::string to_string(size_t num_bytes = SIZE) const
00136     {
00137       size_t num_chars = 2 * num_bytes;
00138       std::string r(num_chars, '_');
00139       for (size_t i = 0; i < num_bytes; i++)
00140         snprintf(r.data() + 2 * i, num_chars + 1 - 2 * i, "%02X", bytes[i]);
00141       return r;
00142     }
00143 
00144     HashT<SIZE> operator=(const HashT<SIZE>& other)
00145     {
00146       std::copy(other.bytes, other.bytes + SIZE, bytes);
00147       return *this;
00148     }
00149 
00150     bool operator==(const HashT<SIZE>& other) const
00151     {
00152       return memcmp(bytes, other.bytes, SIZE) == 0;
00153     }
00154 
00155     bool operator!=(const HashT<SIZE>& other) const
00156     {
00157       return memcmp(bytes, other.bytes, SIZE) != 0;
00158     }
00159 
00160     void serialise(std::vector<uint8_t>& buffer) const
00161     {
00162       MERKLECPP_TRACE(MERKLECPP_TOUT << "> HashT::serialise " << std::endl);
00163       for (auto& b : bytes)
00164         buffer.push_back(b);
00165     }
00166 
00167     void deserialise(const std::vector<uint8_t>& buffer, size_t& position)
00168     {
00169       MERKLECPP_TRACE(MERKLECPP_TOUT << "> HashT::deserialise " << std::endl);
00170       if (buffer.size() - position < SIZE)
00171         throw std::runtime_error("not enough bytes");
00172       for (size_t i = 0; i < sizeof(bytes); i++)
00173         bytes[i] = buffer[position++];
00174     }
00175 
00176     void deserialise(const std::vector<uint8_t>& buffer)
00177     {
00178       size_t position = 0;
00179       deserialise(buffer, position);
00180     }
00181 
00182     operator std::vector<uint8_t>() const
00183     {
00184       std::vector<uint8_t> bytes;
00185       serialise(bytes);
00186       return bytes;
00187     }
00188   };
00189 
00190   template <
00191     size_t HASH_SIZE,
00192     void (*HASH_FUNCTION)(
00193       const HashT<HASH_SIZE>& l,
00194       const HashT<HASH_SIZE>& r,
00195       HashT<HASH_SIZE>& out)>
00196   class PathT
00197   {
00198   public:
00199     typedef enum
00200     {
00201       PATH_LEFT,
00202       PATH_RIGHT
00203     } Direction;
00204 
00205     typedef struct
00206     {
00207       HashT<HASH_SIZE> hash; // This is a copy; do we want a shared_ptr<HashT>?
00208       Direction direction;
00209     } Element;
00210 
00211     PathT(
00212       const HashT<HASH_SIZE>& leaf,
00213       size_t leaf_index,
00214       std::list<Element>&& elements,
00215       size_t max_index) :
00216       _leaf(leaf),
00217       _leaf_index(leaf_index),
00218       _max_index(max_index),
00219       elements(elements)
00220     {}
00221     PathT(const PathT& other)
00222     {
00223       _leaf = other._leaf;
00224       elements = other.elements;
00225     }
00226     PathT(PathT&& other)
00227     {
00228       _leaf = std::move(other._leaf);
00229       elements = std::move(other.elements);
00230     }
00231     PathT(const std::vector<uint8_t>& bytes)
00232     {
00233       deserialise(bytes);
00234     }
00235     PathT(const std::vector<uint8_t>& bytes, size_t& position)
00236     {
00237       deserialise(bytes, position);
00238     }
00239 
00240     bool verify(const HashT<HASH_SIZE>& root) const
00241     {
00242       HashT<HASH_SIZE> result = _leaf, tmp;
00243       MERKLECPP_TRACE(
00244         MERKLECPP_TOUT << "> PathT::verify " << _leaf.to_string(TRACE_HASH_SIZE)
00245                        << std::endl);
00246       for (const Element& e : elements)
00247       {
00248         if (e.direction == PATH_LEFT)
00249         {
00250           MERKLECPP_TRACE(
00251             MERKLECPP_TOUT << " - " << e.hash.to_string(TRACE_HASH_SIZE)
00252                            << " x " << result.to_string(TRACE_HASH_SIZE)
00253                            << std::endl);
00254           HASH_FUNCTION(e.hash, result, tmp);
00255         }
00256         else
00257         {
00258           MERKLECPP_TRACE(
00259             MERKLECPP_TOUT << " - " << result.to_string(TRACE_HASH_SIZE)
00260                            << " x " << e.hash.to_string(TRACE_HASH_SIZE)
00261                            << std::endl);
00262           HASH_FUNCTION(result, e.hash, tmp);
00263         }
00264         std::swap(result, tmp);
00265       }
00266       MERKLECPP_TRACE(
00267         MERKLECPP_TOUT << " = " << result.to_string(TRACE_HASH_SIZE)
00268                        << std::endl);
00269       return result == root;
00270     }
00271 
00272     void serialise(std::vector<uint8_t>& bytes) const
00273     {
00274       MERKLECPP_TRACE(MERKLECPP_TOUT << "> PathT::serialise " << std::endl);
00275       _leaf.serialise(bytes);
00276       serialise_size_t(_leaf_index, bytes);
00277       serialise_size_t(_max_index, bytes);
00278       serialise_size_t(elements.size(), bytes);
00279       for (auto& e : elements)
00280       {
00281         e.hash.serialise(bytes);
00282         bytes.push_back(e.direction == PATH_LEFT ? 1 : 0);
00283       }
00284     }
00285 
00286     void deserialise(const std::vector<uint8_t>& bytes, size_t& position)
00287     {
00288       MERKLECPP_TRACE(MERKLECPP_TOUT << "> PathT::deserialise " << std::endl);
00289       elements.clear();
00290       _leaf.deserialise(bytes, position);
00291       _leaf_index = deserialise_size_t(bytes, position);
00292       _max_index = deserialise_size_t(bytes, position);
00293       size_t num_elements = deserialise_size_t(bytes, position);
00294       for (size_t i = 0; i < num_elements; i++)
00295       {
00296         HashT<HASH_SIZE> hash(bytes, position);
00297         PathT::Direction direction =
00298           bytes[position++] != 0 ? PATH_LEFT : PATH_RIGHT;
00299         PathT::Element e;
00300         e.hash = hash;
00301         e.direction = direction;
00302         elements.push_back(std::move(e));
00303       }
00304     }
00305 
00306     void deserialise(const std::vector<uint8_t>& bytes)
00307     {
00308       size_t position = 0;
00309       deserialise(bytes, position);
00310     }
00311 
00312     operator std::vector<uint8_t>() const
00313     {
00314       std::vector<uint8_t> bytes;
00315       serialise(bytes);
00316       return bytes;
00317     }
00318 
00319     size_t size() const
00320     {
00321       return elements.size();
00322     }
00323 
00324     size_t serialised_size() const
00325     {
00326       return sizeof(_leaf) + elements.size() * sizeof(Element);
00327     }
00328 
00329     size_t leaf_index() const
00330     {
00331       return _leaf_index;
00332     }
00333 
00334     size_t max_index() const
00335     {
00336       return _max_index;
00337     }
00338 
00339     const HashT<HASH_SIZE>& operator[](size_t i) const
00340     {
00341       return *elements[i].hash;
00342     }
00343 
00344     typedef typename std::list<Element>::const_iterator const_iterator;
00345     const_iterator begin()
00346     {
00347       return elements.begin();
00348     }
00349     const_iterator end()
00350     {
00351       return elements.end();
00352     }
00353 
00354     std::string to_string(size_t num_bytes = HASH_SIZE) const
00355     {
00356       std::stringstream stream;
00357       stream << _leaf.to_string(num_bytes);
00358       for (auto& e : elements)
00359         stream << " " << e.hash.to_string(num_bytes)
00360                << (e.direction == PATH_LEFT ? "(L)" : "(R)");
00361       return stream.str();
00362     }
00363 
00364     const HashT<HASH_SIZE>& leaf() const
00365     {
00366       return _leaf;
00367     }
00368 
00369     bool operator==(const PathT<HASH_SIZE, HASH_FUNCTION>& other) const
00370     {
00371       if (_leaf != other._leaf || elements.size() != other.elements.size())
00372         return false;
00373       auto it = elements.begin();
00374       auto other_it = other.elements.begin();
00375       while (it != elements.end() && other_it != other.elements.end())
00376       {
00377         if (it->hash != other_it->hash || it->direction != other_it->direction)
00378           return false;
00379         it++;
00380         other_it++;
00381       }
00382       return true;
00383     }
00384 
00385     bool operator!=(const PathT<HASH_SIZE, HASH_FUNCTION>& other)
00386     {
00387       return !this->operator==(other);
00388     }
00389 
00390   protected:
00391     HashT<HASH_SIZE> _leaf;
00392     size_t _leaf_index, _max_index;
00393     std::list<Element> elements;
00394   };
00395 
00396   template <
00397     size_t HASH_SIZE,
00398     void (*HASH_FUNCTION)(
00399       const HashT<HASH_SIZE>& l,
00400       const HashT<HASH_SIZE>& r,
00401       HashT<HASH_SIZE>& out)>
00402   class TreeT
00403   {
00404   protected:
00405     struct Node
00406     {
00407       static Node* make(const HashT<HASH_SIZE>& hash)
00408       {
00409         auto r = new Node();
00410         r->left = r->right = nullptr;
00411         r->hash = hash;
00412         r->dirty = false;
00413         r->update_sizes();
00414         assert(r->invariant());
00415         return r;
00416       }
00417 
00418       static Node* make(Node* left, Node* right)
00419       {
00420         assert(left && right);
00421         auto r = new Node();
00422         r->left = left;
00423         r->right = right;
00424         r->dirty = true;
00425         r->update_sizes();
00426         r->left->parent = r->right->parent = r;
00427         assert(r->invariant());
00428         return r;
00429       }
00430 
00431       static Node* copy_node(
00432         const Node* from, std::vector<Node*>* leaf_nodes = nullptr)
00433       {
00434         if (from == nullptr)
00435           return nullptr;
00436 
00437         Node* r = make(from->hash);
00438         r->size = from->size;
00439         r->height = from->height;
00440         r->dirty = from->dirty;
00441         r->parent = nullptr;
00442         r->left = copy_node(from->left, leaf_nodes);
00443         r->right = copy_node(from->right, leaf_nodes);
00444         if (leaf_nodes && r->size == 1 && !r->left && !r->right)
00445           leaf_nodes->push_back(r);
00446         return r;
00447       }
00448 
00449       bool invariant()
00450       {
00451         bool c1 = !parent || parent->left == this || parent->right == this;
00452         bool c2 = (left && right) || (!left && !right);
00453         bool c3 = !left || !right || (size == left->size + right->size + 1);
00454         bool cl = !left || left->invariant();
00455         bool cr = !right || right->invariant();
00456         bool ch = height <= 64;
00457         bool r = c1 && c2 && c3 && cl && cr && ch;
00458         return r;
00459       }
00460 
00461       ~Node()
00462       {
00463         assert(invariant());
00464         parent = nullptr;
00465         // Potential future improvement: remove recursion
00466         delete (left);
00467         delete (right);
00468       }
00469 
00470       bool is_full() const
00471       {
00472         size_t max_size = (1 << height) - 1;
00473         assert(size <= max_size);
00474         return size == max_size;
00475       }
00476 
00477       void update_sizes()
00478       {
00479         if (left && right)
00480         {
00481           size = left->size + right->size + 1;
00482           height = std::max(left->height, right->height) + 1;
00483         }
00484         else
00485           size = height = 1;
00486       }
00487 
00488       HashT<HASH_SIZE> hash;
00489       Node* parent;
00490       Node *left, *right;
00491       size_t size;
00492       uint8_t height;
00493       bool dirty;
00494     };
00495 
00496   public:
00497     typedef HashT<HASH_SIZE> Hash;
00498     typedef PathT<HASH_SIZE, HASH_FUNCTION> Path;
00499     typedef TreeT<HASH_SIZE, HASH_FUNCTION> Tree;
00500 
00501     TreeT() {}
00502     TreeT(const TreeT& other)
00503     {
00504       *this = other;
00505     }
00506     TreeT(TreeT&& other) :
00507       leaf_nodes(std::move(other.leaf_nodes)),
00508       uninserted_leaf_nodes(std::move(other.uninserted_leaf_nodes)),
00509       _root(std::move(other._root)),
00510       num_flushed(other.num_flushed),
00511       insertion_stack(std::move(other.insertion_stack)),
00512       hashing_stack(std::move(other.hashing_stack)),
00513       walk_stack(std::move(other.walk_stack))
00514     {}
00515     TreeT(const std::vector<uint8_t>& bytes)
00516     {
00517       deserialise(bytes);
00518     }
00519     TreeT(const std::vector<uint8_t>& bytes, size_t& position)
00520     {
00521       deserialise(bytes, position);
00522     }
00523     TreeT(const Hash& root)
00524     {
00525       insert(root);
00526     }
00527     ~TreeT()
00528     {
00529       delete (_root);
00530       for (auto n : uninserted_leaf_nodes)
00531         delete (n);
00532     }
00533 
00534     bool invariant()
00535     {
00536       return _root ? _root->invariant() : true;
00537     }
00538 
00539     void insert(const uint8_t* hash)
00540     {
00541       insert(Hash(hash));
00542     }
00543 
00544     void insert(const Hash& hash)
00545     {
00546       MERKLECPP_TRACE(MERKLECPP_TOUT << "> insert "
00547                                      << hash.to_string(TRACE_HASH_SIZE)
00548                                      << std::endl;);
00549       uninserted_leaf_nodes.push_back(Node::make(hash));
00550       statistics.num_insert++;
00551     }
00552 
00553     void insert(const std::vector<Hash>& hashes)
00554     {
00555       for (auto hash : hashes)
00556         insert(hash);
00557     }
00558 
00559     void insert(const std::list<Hash>& hashes)
00560     {
00561       for (auto hash : hashes)
00562         insert(hash);
00563     }
00564 
00565     void flush_to(size_t index)
00566     {
00567       MERKLECPP_TRACE(MERKLECPP_TOUT << "> flush_to " << index << std::endl;);
00568       statistics.num_flush++;
00569 
00570       walk_to(index, false, [this](Node*& n, bool go_right) {
00571         if (go_right && n->left)
00572         {
00573           MERKLECPP_TRACE(MERKLECPP_TOUT
00574                             << " - conflate "
00575                             << n->left->hash.to_string(TRACE_HASH_SIZE)
00576                             << std::endl;);
00577           if (n->left && n->left->dirty)
00578             hash(n->left);
00579           delete (n->left->left);
00580           n->left->left = nullptr;
00581           delete (n->left->right);
00582           n->left->right = nullptr;
00583         }
00584         return true;
00585       });
00586 
00587       size_t num_newly_flushed = index - num_flushed;
00588       leaf_nodes.erase(
00589         leaf_nodes.begin(), leaf_nodes.begin() + num_newly_flushed);
00590       num_flushed += num_newly_flushed;
00591     }
00592 
00593     void retract_to(size_t index)
00594     {
00595       MERKLECPP_TRACE(MERKLECPP_TOUT << "> retract_to " << index << std::endl;);
00596       statistics.num_retract++;
00597 
00598       if (max_index() < index)
00599         return;
00600 
00601       if (index < min_index())
00602         throw std::runtime_error("leaf index out of bounds");
00603 
00604       if (index >= num_flushed + leaf_nodes.size())
00605       {
00606         size_t over = index - (num_flushed + leaf_nodes.size()) + 1;
00607         while (uninserted_leaf_nodes.size() > over)
00608         {
00609           delete (uninserted_leaf_nodes.back());
00610           uninserted_leaf_nodes.pop_back();
00611         }
00612         return;
00613       }
00614 
00615       Node* final = walk_to(index, true, [this](Node*& n, bool go_right) {
00616         bool go_left = !go_right;
00617         n->dirty = true;
00618         if (go_left && n->right)
00619         {
00620           MERKLECPP_TRACE(MERKLECPP_TOUT
00621                             << " - eliminate "
00622                             << n->right->hash.to_string(TRACE_HASH_SIZE)
00623                             << std::endl;);
00624           bool is_root = n == _root;
00625 
00626           Node* old_parent = n->parent;
00627           Node* old_left = n->left;
00628           delete (n->right);
00629           n->right = nullptr;
00630 
00631           *n = *old_left;
00632           n->parent = old_parent;
00633 
00634           old_left->left = old_left->right = nullptr;
00635           old_left->parent = nullptr;
00636           delete (old_left);
00637           old_left = nullptr;
00638 
00639           if (n->left && n->right)
00640           {
00641             n->left->parent = n;
00642             n->right->parent = n;
00643             n->dirty = true;
00644           }
00645 
00646           if (is_root)
00647           {
00648             MERKLECPP_TRACE(MERKLECPP_TOUT << " - new root: "
00649                                            << n->hash.to_string(TRACE_HASH_SIZE)
00650                                            << std::endl;);
00651             assert(n->parent == nullptr);
00652             assert(_root == n);
00653           }
00654 
00655           assert(n->invariant());
00656 
00657           MERKLECPP_TRACE(MERKLECPP_TOUT
00658                             << " - after elimination: " << std::endl
00659                             << to_string(TRACE_HASH_SIZE) << std::endl;);
00660           return false;
00661         }
00662         else
00663           return true;
00664       });
00665 
00666       // The leaf is now elsewhere, save the pointer.
00667       leaf_nodes[index - num_flushed] = final;
00668 
00669       size_t num_retracted = num_leaves() - index - 1;
00670       if (num_retracted < leaf_nodes.size())
00671         leaf_nodes.resize(leaf_nodes.size() - num_retracted);
00672       else
00673         leaf_nodes.clear();
00674 
00675       assert(num_leaves() == index + 1);
00676     }
00677 
00678     Tree& operator=(const Tree& other)
00679     {
00680       leaf_nodes.clear();
00681       uninserted_leaf_nodes.clear();
00682       insertion_stack.clear();
00683       hashing_stack.clear();
00684       walk_stack.clear();
00685 
00686       _root = Node::copy_node(other._root, &leaf_nodes);
00687       for (auto n : other.uninserted_leaf_nodes)
00688         uninserted_leaf_nodes.push_back(Node::copy_node(n));
00689       num_flushed = other.num_flushed;
00690       return *this;
00691     }
00692 
00693     const Tree split(size_t index)
00694     {
00695       MERKLECPP_TRACE(MERKLECPP_TOUT << "> split (slow) at " << index
00696                                      << std::endl;);
00697       Tree other = *this;
00698       if (index > num_flushed)
00699         other.retract_to(index - 1);
00700       this->flush_to(index);
00701       return other;
00702     }
00703 
00704     const Hash& root()
00705     {
00706       MERKLECPP_TRACE(MERKLECPP_TOUT << "> root" << std::endl;);
00707       statistics.num_root++;
00708       compute_root();
00709       assert(_root && !_root->dirty);
00710       MERKLECPP_TRACE(MERKLECPP_TOUT
00711                         << " - root: " << _root->hash.to_string(TRACE_HASH_SIZE)
00712                         << std::endl;);
00713       return _root->hash;
00714     }
00715 
00716     std::shared_ptr<Hash> past_root(size_t index)
00717     {
00718       MERKLECPP_TRACE(MERKLECPP_TOUT << "> past_root " << index << std::endl;);
00719       statistics.num_past_root++;
00720 
00721       auto p = path(index);
00722       auto result = std::make_shared<Hash>(p->leaf());
00723       MERKLECPP_TRACE(
00724         MERKLECPP_TOUT << " - " << p->to_string(TRACE_HASH_SIZE) << std::endl;
00725         MERKLECPP_TOUT << " - " << result->to_string(TRACE_HASH_SIZE)
00726                        << std::endl;);
00727       for (auto e : *p)
00728       {
00729         if (e.direction == Path::Direction::PATH_LEFT)
00730         {
00731           Hash tmp;
00732           HASH_FUNCTION(e.hash, *result, tmp);
00733           *result = tmp;
00734         }
00735       }
00736 
00737       return result;
00738     }
00739 
00740     Node* walk_to(
00741       size_t index, bool update, std::function<bool(Node*&, bool)> f)
00742     {
00743       if (index < min_index() || max_index() < index)
00744         throw std::runtime_error("invalid leaf index");
00745 
00746       compute_root();
00747 
00748       assert(index < _root->size);
00749 
00750       Node* cur = _root;
00751       size_t it = 0;
00752       if (_root->height > 1)
00753         it = index << (sizeof(index) * 8 - _root->height + 1);
00754       assert(walk_stack.empty());
00755 
00756       for (uint8_t height = _root->height; height > 1;)
00757       {
00758         assert(cur->invariant());
00759         bool go_right = (it >> (8 * sizeof(it) - 1)) & 0x01;
00760         if (update)
00761           walk_stack.push_back(cur);
00762         MERKLECPP_TRACE(MERKLECPP_TOUT
00763                           << " - at " << cur->hash.to_string(TRACE_HASH_SIZE)
00764                           << " (" << cur->size << "/" << (unsigned)cur->height
00765                           << ")"
00766                           << " (" << (go_right ? "R" : "L") << ")"
00767                           << std::endl;);
00768         if (cur->height == height)
00769         {
00770           if (!f(cur, go_right))
00771             continue;
00772           cur = (go_right ? cur->right : cur->left);
00773         }
00774         it <<= 1;
00775         height--;
00776       }
00777 
00778       while (!walk_stack.empty())
00779       {
00780         walk_stack.back()->update_sizes();
00781         walk_stack.pop_back();
00782       }
00783 
00784       return cur;
00785     }
00786 
00787     std::unique_ptr<Path> path(size_t index)
00788     {
00789       MERKLECPP_TRACE(MERKLECPP_TOUT << "> path from " << index << std::endl;);
00790       std::list<typename Path::Element> elements;
00791 
00792       walk_to(index, false, [&elements](Node* n, bool go_right) {
00793         typename Path::Element e;
00794         e.hash = go_right ? n->left->hash : n->right->hash;
00795         e.direction = go_right ? Path::PATH_LEFT : Path::PATH_RIGHT;
00796         elements.push_front(std::move(e));
00797         return true;
00798       });
00799 
00800       return std::make_unique<Path>(
00801         leaf_node(index)->hash, index, std::move(elements), max_index());
00802     }
00803 
00804     void serialise(std::vector<uint8_t>& bytes)
00805     {
00806       MERKLECPP_TRACE(MERKLECPP_TOUT << "> serialise " << std::endl;);
00807 
00808       compute_root();
00809 
00810 
00811                                      << std::endl;);
00812 
00813       serialise_size_t(leaf_nodes.size() + uninserted_leaf_nodes.size(), bytes);
00814       serialise_size_t(num_flushed, bytes);
00815       for (auto& n : leaf_nodes)
00816         n->hash.serialise(bytes);
00817       for (auto& n : uninserted_leaf_nodes)
00818         n->hash.serialise(bytes);
00819 
00820       // Find conflated/flushed nodes along the left edge of the tree.
00821       std::vector<Node*> extras;
00822       walk_to(min_index(), false, [&extras](Node*& n, bool go_right) {
00823         if (go_right)
00824           extras.push_back(n->left);
00825         return true;
00826       });
00827       for (size_t i = extras.size() - 1; i != SIZE_MAX; i--)
00828         extras[i]->hash.serialise(bytes);
00829     }
00830 
00831     void deserialise(const std::vector<uint8_t>& bytes)
00832     {
00833       size_t position = 0;
00834       deserialise(bytes, position);
00835     }
00836 
00837     void deserialise(const std::vector<uint8_t>& bytes, size_t& position)
00838     {
00839       MERKLECPP_TRACE(MERKLECPP_TOUT << "> deserialise " << std::endl;);
00840 
00841       delete (_root);
00842       leaf_nodes.clear();
00843       for (auto n : uninserted_leaf_nodes)
00844         delete (n);
00845       uninserted_leaf_nodes.clear();
00846       insertion_stack.clear();
00847       hashing_stack.clear();
00848       walk_stack.clear();
00849       _root = nullptr;
00850 
00851       size_t num_leaf_nodes = deserialise_size_t(bytes, position);
00852       num_flushed = deserialise_size_t(bytes, position);
00853 
00854       leaf_nodes.reserve(num_leaf_nodes);
00855       for (size_t i = 0; i < num_leaf_nodes; i++)
00856       {
00857         Node* n = Node::make(bytes.data() + position);
00858         position += HASH_SIZE;
00859         leaf_nodes.push_back(n);
00860       }
00861 
00862       std::vector<Node*> level = leaf_nodes, next_level;
00863       size_t it = num_flushed;
00864       MERKLECPP_TRACE(MERKLECPP_TOUT << "num_flushed=" << num_flushed
00865                                      << " it=" << it << std::endl;);
00866       uint8_t level_no = 0;
00867       while (it != 0 || level.size() > 1)
00868       {
00869         // Restore extra hashes on the left edge of the tree
00870         if (it & 0x01)
00871         {
00872           Hash h(bytes, position);
00873           MERKLECPP_TRACE(MERKLECPP_TOUT << "+";);
00874           auto n = Node::make(h);
00875           n->height = level_no + 1;
00876           n->size = (1 << n->height) - 1;
00877           assert(n->invariant());
00878           level.insert(level.begin(), n);
00879         }
00880 
00881         MERKLECPP_TRACE(for (auto& n
00882                              : level) MERKLECPP_TOUT
00883                           << " " << n->hash.to_string(TRACE_HASH_SIZE);
00884                         MERKLECPP_TOUT << std::endl;);
00885 
00886         // Rebuild the level
00887         for (size_t i = 0; i < level.size(); i += 2)
00888         {
00889           if (i + 1 >= level.size())
00890             next_level.push_back(level[i]);
00891           else
00892             next_level.push_back(Node::make(level[i], level[i + 1]));
00893         }
00894 
00895         level.swap(next_level);
00896         next_level.clear();
00897 
00898         it >>= 1;
00899         level_no++;
00900       }
00901 
00902       assert(level.size() == 0 || level.size() == 1);
00903 
00904       if (level.size() == 1)
00905       {
00906         _root = level[0];
00907         assert(_root->invariant());
00908       }
00909     }
00910 
00911     operator std::vector<uint8_t>() const
00912     {
00913       std::vector<uint8_t> bytes;
00914       serialise(bytes);
00915       return bytes;
00916     }
00917 
00918     const Hash& operator[](size_t index) const
00919     {
00920       return leaf(index);
00921     }
00922 
00923     const Hash& leaf(size_t index) const
00924     {
00925       MERKLECPP_TRACE(MERKLECPP_TOUT << "> leaf " << index << std::endl;);
00926       if (index >= num_leaves())
00927         throw std::runtime_error("leaf index out of bounds");
00928       if (index - num_flushed >= leaf_nodes.size())
00929         return uninserted_leaf_nodes[index - num_flushed - leaf_nodes.size()]
00930           ->hash;
00931       else
00932         return leaf_nodes[index - num_flushed]->hash;
00933     }
00934 
00935     const Node* leaf_node(size_t index) const
00936     {
00937       if (index < min_index() || max_index() < index)
00938         throw std::runtime_error("leaf index out of bounds");
00939       size_t real_index = index - num_flushed;
00940       if (real_index < leaf_nodes.size())
00941         return leaf_nodes[real_index];
00942       else
00943         return uninserted_leaf_nodes[real_index - leaf_nodes.size()];
00944     }
00945 
00946     size_t num_leaves() const
00947     {
00948       return num_flushed + leaf_nodes.size() + uninserted_leaf_nodes.size();
00949     }
00950 
00951     size_t min_index() const
00952     {
00953       return num_flushed;
00954     }
00955 
00956     size_t max_index() const
00957     {
00958       return num_leaves() - 1;
00959     }
00960 
00961     size_t size()
00962     {
00963       if (!uninserted_leaf_nodes.empty())
00964         insert_leaves();
00965       return _root ? _root->size : 0;
00966     }
00967 
00968     size_t serialised_size()
00969     {
00970       size_t num_extras = 0;
00971       walk_to(min_index(), false, [&num_extras](Node*&, bool go_right) {
00972         if (go_right)
00973           num_extras++;
00974         return true;
00975       });
00976 
00977       return sizeof(leaf_nodes.size()) + sizeof(num_flushed) +
00978         leaf_nodes.size() * sizeof(Hash) + num_extras * sizeof(Hash);
00979     }
00980 
00981     mutable struct Statistics
00982     {
00983       size_t num_insert = 0, num_hash = 0;
00984       size_t num_root = 0, num_past_root = 0;
00985       size_t num_flush = 0, num_retract = 0;
00986       size_t num_split = 0;
00987 
00988       std::string to_string() const
00989       {
00990         std::stringstream stream;
00991         stream << "num_insert=" << num_insert << " num_hash=" << num_hash
00992                << " num_root=" << num_root << " num_retract=" << num_retract
00993                << " num_flush=" << num_flush << " num_split=" << num_split;
00994         return stream.str();
00995       }
00996     } statistics;
00997 
00998     std::string to_string(size_t num_bytes = HASH_SIZE) const
00999     {
01000       static const std::string dirty_hash(2 * num_bytes, '?');
01001       std::stringstream stream;
01002       std::vector<Node*> level, next_level;
01003 
01004       if (num_leaves() == 0)
01005       {
01006         stream << "<EMPTY>" << std::endl;
01007         return stream.str();
01008       }
01009 
01010       if (!_root)
01011       {
01012         stream << "No root." << std::endl;
01013       }
01014       else
01015       {
01016         size_t level_no = 0;
01017         level.push_back(_root);
01018         while (!level.empty())
01019         {
01020           stream << level_no++ << ": ";
01021           for (auto n : level)
01022           {
01023             stream << (n->dirty ? dirty_hash : n->hash.to_string(num_bytes));
01024             stream << "(" << n->size << "," << (unsigned)n->height << ")";
01025             if (n->left)
01026               next_level.push_back(n->left);
01027             if (n->right)
01028               next_level.push_back(n->right);
01029             stream << " ";
01030           }
01031           stream << std::endl << std::flush;
01032           std::swap(level, next_level);
01033           next_level.clear();
01034         }
01035       }
01036 
01037       stream << "+: "
01038              << "leaves=" << leaf_nodes.size() << ", "
01039              << "uninserted leaves=" << uninserted_leaf_nodes.size() << ", "
01040              << "flushed=" << num_flushed << std::endl;
01041       stream << "S: " << statistics.to_string() << std::endl;
01042 
01043       return stream.str();
01044     }
01045 
01046   protected:
01047     std::vector<Node*> leaf_nodes;
01048     std::vector<Node*> uninserted_leaf_nodes;
01049     size_t num_flushed = 0;
01050     Node* _root = nullptr;
01051 
01052     typedef struct
01053     {
01054       Node* n;
01055       bool left;
01056     } InsertionStackElement;
01057     mutable std::vector<InsertionStackElement> insertion_stack;
01058     mutable std::vector<Node*> hashing_stack;
01059     mutable std::vector<Node*> walk_stack;
01060 
01061     void hash(Node* n, size_t indent = 2) const
01062     {
01063 
01064       (void)indent;
01065 
01066 
01067       assert(hashing_stack.empty());
01068       hashing_stack.reserve(n->height);
01069       hashing_stack.push_back(n);
01070 
01071       while (!hashing_stack.empty())
01072       {
01073         n = hashing_stack.back();
01074         assert((n->left && n->right) || (!n->left && !n->right));
01075 
01076         if (n->left && n->left->dirty)
01077           hashing_stack.push_back(n->left);
01078         else if (n->right && n->right->dirty)
01079           hashing_stack.push_back(n->right);
01080         else
01081         {
01082           assert(n->left && n->right);
01083           HASH_FUNCTION(n->left->hash, n->right->hash, n->hash);
01084           statistics.num_hash++;
01085           MERKLECPP_TRACE(
01086             MERKLECPP_TOUT << std::string(indent, ' ') << "+ h("
01087                            << n->left->hash.to_string(TRACE_HASH_SIZE) << ", "
01088                            << n->right->hash.to_string(TRACE_HASH_SIZE)
01089                            << ") == " << n->hash.to_string(TRACE_HASH_SIZE)
01090                            << " (" << n->size << "/" << (unsigned)n->height
01091                            << ")" << std::endl);
01092           n->dirty = false;
01093           hashing_stack.pop_back();
01094         }
01095       }
01096     }
01097 
01098     void compute_root()
01099     {
01100       insert_leaves(true);
01101       assert(_root);
01102       assert(_root->invariant());
01103       assert(_root->parent == nullptr);
01104       if (_root->dirty)
01105       {
01106         if (num_leaves() == 0)
01107           throw std::runtime_error("empty tree does not have a root");
01108         hash(_root);
01109         assert(_root && !_root->dirty);
01110       }
01111     }
01112 
01113     void insert_leaf_recursive(Node*& n, Node* new_leaf)
01114     {
01115       if (!n)
01116         n = new_leaf;
01117       else
01118       {
01119         if (n->is_full())
01120         {
01121           Node* p = n->parent;
01122           n = Node::make(n, new_leaf);
01123           n->parent = p;
01124         }
01125         else
01126         {
01127           MERKLECPP_TRACE(MERKLECPP_TOUT << " @ "
01128                                          << n->hash.to_string(TRACE_HASH_SIZE)
01129                                          << std::endl;);
01130           assert(n->left && n->right);
01131           if (!n->left->is_full())
01132             insert_leaf_recursive(n->left, new_leaf);
01133           else
01134             insert_leaf_recursive(n->right, new_leaf);
01135           n->dirty = true;
01136           n->update_sizes();
01137         }
01138       }
01139     }
01140 
01141     void continue_insertion_stack(Node* n, Node* new_leaf)
01142     {
01143       while (true)
01144       {
01145         MERKLECPP_TRACE(MERKLECPP_TOUT << "  @ "
01146                                        << n->hash.to_string(TRACE_HASH_SIZE)
01147                                        << std::endl;);
01148         assert(n->invariant());
01149 
01150         if (n->is_full())
01151         {
01152           Node* result = Node::make(n, new_leaf);
01153           assert(!insertion_stack.empty() || result->parent == nullptr);
01154           if (!insertion_stack.empty())
01155             result->parent = insertion_stack.back().n;
01156           insertion_stack.push_back(InsertionStackElement());
01157           insertion_stack.back().n = result;
01158           return;
01159         }
01160         else
01161         {
01162           assert(n->left && n->right);
01163           insertion_stack.push_back(InsertionStackElement());
01164           InsertionStackElement& se = insertion_stack.back();
01165           se.n = n;
01166           n->dirty = true;
01167           if (!n->left->is_full())
01168           {
01169             se.left = true;
01170             n = n->left;
01171           }
01172           else
01173           {
01174             se.left = false;
01175             n = n->right;
01176           }
01177         }
01178       }
01179     }
01180 
01181     Node* process_insertion_stack(bool complete = true)
01182     {
01183       MERKLECPP_TRACE(
01184         MERKLECPP_TOUT << "  X " << (complete ? "complete" : "continue") << ":";
01185         for (size_t i = 0; i < insertion_stack.size(); i++) MERKLECPP_TOUT
01186         << " " << insertion_stack[i].n->hash.to_string(TRACE_HASH_SIZE);
01187         MERKLECPP_TOUT << std::endl;);
01188 
01189       Node* result = insertion_stack.back().n;
01190       insertion_stack.pop_back();
01191 
01192       assert(result->dirty);
01193       result->update_sizes();
01194 
01195       while (!insertion_stack.empty())
01196       {
01197         InsertionStackElement& top = insertion_stack.back();
01198         Node* n = top.n;
01199         bool left = top.left;
01200         insertion_stack.pop_back();
01201 
01202         if (left)
01203           n->left = result;
01204         else
01205           n->right = result;
01206         n->dirty = true;
01207         n->update_sizes();
01208 
01209         result = n;
01210 
01211         if (!complete && !result->is_full())
01212         {
01213           MERKLECPP_TRACE(MERKLECPP_TOUT
01214                             << "  X save "
01215                             << result->hash.to_string(TRACE_HASH_SIZE)
01216                             << std::endl;);
01217           return result;
01218         }
01219       }
01220 
01221       assert(result->invariant());
01222 
01223       return result;
01224     }
01225 
01226     void insert_leaf(Node*& root, Node* n)
01227     {
01228       MERKLECPP_TRACE(MERKLECPP_TOUT << " - insert_leaf "
01229                                      << n->hash.to_string(TRACE_HASH_SIZE)
01230                                      << std::endl;);
01231       leaf_nodes.push_back(n);
01232       if (insertion_stack.empty() && !root)
01233         root = n;
01234       else
01235       {
01236         continue_insertion_stack(root, n);
01237         root = process_insertion_stack(false);
01238       }
01239     }
01240 
01241     void insert_leaves(bool complete = false)
01242     {
01243       if (!uninserted_leaf_nodes.empty())
01244       {
01245         MERKLECPP_TRACE(MERKLECPP_TOUT
01246                           << "* insert_leaves " << leaf_nodes.size() << " +"
01247                           << uninserted_leaf_nodes.size() << std::endl;);
01248         // Potential future improvement: make this go fast when there are many
01249         // leaves to insert.
01250         for (auto& n : uninserted_leaf_nodes)
01251           insert_leaf(_root, n);
01252         uninserted_leaf_nodes.clear();
01253       }
01254       if (complete && !insertion_stack.empty())
01255         _root = process_insertion_stack();
01256     }
01257   };
01258 
01259   // clang-format off
01260   void sha256_compress(const HashT<32> &l, const HashT<32> &r, HashT<32> &out) {
01261     static const uint32_t constants[] = {
01262       0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
01263       0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
01264       0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
01265       0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
01266       0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
01267       0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
01268       0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
01269       0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
01270     };
01271 
01272     uint8_t block[32 * 2];
01273     memcpy(&block[0], l.bytes, 32);
01274     memcpy(&block[32], r.bytes, 32);
01275 
01276     static const uint32_t s[8] = { 0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
01277                                    0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19 };
01278 
01279     uint32_t cws[64] = {0};
01280 
01281     for (int i=0; i < 16; i++)
01282       cws[i] = be32toh(((int32_t *)block)[i]);
01283 
01284     for (int i = 16; i < 64; i++) {
01285       uint32_t t16 = cws[i - 16];
01286       uint32_t t15 = cws[i - 15];
01287       uint32_t t7 = cws[i - 7];
01288       uint32_t t2 = cws[i - 2];
01289       uint32_t s1 = (t2 >> 17 | t2 << 15) ^ ((t2 >> 19 | t2 << 13) ^ t2 >> 10);
01290       uint32_t s0 = (t15 >> 7 | t15 << 25) ^ ((t15 >> 18 | t15 << 14) ^ t15 >> 3);
01291       cws[i] = (s1 + t7 + s0 + t16);
01292     }
01293 
01294     uint32_t h[8];
01295     for (int i=0; i < 8; i++)
01296       h[i] = s[i];
01297 
01298     for (int i=0; i < 64; i++) {
01299       uint32_t a0 = h[0], b0 = h[1], c0 = h[2], d0 = h[3], e0 = h[4], f0 = h[5], g0 = h[6], h03 = h[7];
01300       uint32_t w = cws[i];
01301       uint32_t t1 = h03 + ((e0 >> 6 | e0 << 26) ^ ((e0 >> 11 | e0 << 21) ^ (e0 >> 25 | e0 << 7))) + ((e0 & f0) ^ (~e0 & g0)) + constants[i] + w;
01302       uint32_t t2 = ((a0 >> 2 | a0 << 30) ^ ((a0 >> 13 | a0 << 19) ^ (a0 >> 22 | a0 << 10))) + ((a0 & b0) ^ ((a0 & c0) ^ (b0 & c0)));
01303       h[0] = t1 + t2;
01304       h[1] = a0;
01305       h[2] = b0;
01306       h[3] = c0;
01307       h[4] = d0 + t1;
01308       h[5] = e0;
01309       h[6] = f0;
01310       h[7] = g0;
01311     }
01312 
01313     for (int i=0; i < 8; i++)
01314       ((uint32_t*)out.bytes)[i] = htobe32(s[i] + h[i]);
01315   }
01316   // clang-format on
01317 
01318 
01319 
01320 
01321 
01322 
01323 
01324 
01325 
01326 
01327 
01328 
01329 
01330 
01331 
01332 
01333 
01334 
01335 
01336 
01337 
01338 
01339 
01340 
01341 
01342 
01343 
01344 
01345 
01346 
01347 
01348 
01349 
01350 
01351 
01352 
01353 
01354 
01355 
01356 
01357 
01358 
01359 
01360 
01361 
01362 
01363 
01364 
01365 
01366 
01367 
01368 
01369 
01370 
01371 
01372 
01373 
01374 
01375 
01376 
01377 
01378 
01379   // Default tree with default hash function
01380   typedef HashT<32> Hash;
01381   typedef PathT<32, sha256_compress> Path;
01382   typedef TreeT<32, sha256_compress> Tree;
01383 };
01384 
---------
Macros accessible in this file:
---------
MERKLECPP_TRACE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/merklecpp.h...
Preprocessing /data/git/CCF/src/libmerklecpp/test/compare_evercrypt.cpp...
#include merklecpp.h: not found! skipping...
#include vector: not found! skipping...
#include MerkleTree.h: not found! skipping...
#include chrono: not found! skipping...
#include iostream: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 4021 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 # 4 "/data/git/CCF/src/libmerklecpp/test/compare_evercrypt.cpp" 2
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define HSZ
00012 #define PRNTSZ
00013 
00014 void dump_ec_tree(merkle_tree* mt)
00015 {
00016   std::cout << "hs=" << std::endl;
00017   for (size_t i = 0; i < mt->hs.sz; i++)
00018   {
00019     MerkleTree_Low_Datastructures_hash_vec hv = mt->hs.vs[i];
00020     if (hv.sz > 0)
00021     {
00022       std::cout << i << ":";
00023       for (size_t j = 0; j < hv.sz; j++)
00024       {
00025         std::cout << " " << merkle::Hash(hv.vs[j]).to_string(PRNTSZ);
00026       }
00027       std::cout << std::endl;
00028     }
00029   }
00030   std::cout << "root=" << merkle::Hash(mt->mroot).to_string(PRNTSZ)
00031             << std::endl;
00032   std::cout << "rhs=";
00033   for (size_t i = 0; i < mt->rhs.sz; i++)
00034     std::cout << " " << merkle::Hash(mt->rhs.vs[i]).to_string(PRNTSZ);
00035   std::cout << std::endl;
00036   std::cout << "rhs_ok=" << mt->rhs_ok << std::endl;
00037   std::cout << "i=" << mt->i << ", j=" << mt->j << std::endl;
00038 }
00039 
00040 void compare_roots(merkle::Tree& mt, merkle_tree* ec_mt)
00041 {
00042   auto root = mt.root();
00043 
00044   uint8_t* ec_root_bytes = mt_init_hash(HSZ);
00045   mt_get_root(ec_mt, ec_root_bytes);
00046   auto ec_root = merkle::Hash(ec_root_bytes);
00047   mt_free_hash(ec_root_bytes);
00048 
00049   if (root != ec_root)
00050   {
00051     std::cout << mt.num_leaves() << ": " << root.to_string()
00052               << " != " << ec_root.to_string() << std::endl;
00053     std::cout << mt.to_string(PRNTSZ) << std::endl;
00054     std::cout << "EverCrypt tree: " << std::endl;
00055     dump_ec_tree(ec_mt);
00056     throw std::runtime_error("root hash mismatch");
00057   }
00058 }
00059 
00060 int main()
00061 {
00062   merkle_tree* ec_mt = NULL;
00063   uint8_t* ec_hash = mt_init_hash(HSZ);
00064 
00065   try
00066   {
00067 
00068     const size_t num_trees = 1024;
00069     const size_t root_interval = 31;
00070 
00071 
00072 
00073 
00074 
00075     // std::srand(0);
00076     std::srand(std::time(0));
00077 
00078     size_t total_inserts = 0, total_flushes = 0, total_retractions = 0;
00079 
00080     for (size_t k = 0; k < num_trees; k++)
00081     {
00082       merkle::Tree mt;
00083 
00084       // Build trees with k+1 leaves
00085       int j = 0;
00086       std::vector<merkle::Hash> hashes = make_hashes(k + 1);
00087       for (const auto h : hashes)
00088       {
00089         mt.insert(h);
00090         total_inserts++;
00091 
00092         memcpy(ec_hash, h.bytes, HSZ);
00093         if (!ec_mt)
00094           ec_mt = mt_create(ec_hash);
00095         else
00096           mt_insert(ec_mt, ec_hash);
00097 
00098         if ((j++ % root_interval) == 0)
00099         {
00100           size_t index =
00101             mt.min_index() + ((mt.max_index() - mt.min_index()) / 3);
00102           mt.flush_to(index);
00103           if (!mt_flush_to_pre(ec_mt, index))
00104             throw std::runtime_error("EverCrypt flush precondition violation");
00105           mt_flush_to(ec_mt, index);
00106           total_flushes++;
00107           compare_roots(mt, ec_mt);
00108         }
00109 
00110         if ((std::rand() / (double)RAND_MAX) > 0.9)
00111         {
00112           size_t index = random_index(mt);
00113           mt.retract_to(index);
00114           if (!mt_retract_to_pre(ec_mt, index))
00115             throw std::runtime_error(
00116               "EverCrypt retract precondition violation");
00117           mt_retract_to(ec_mt, index);
00118           total_retractions++;
00119           compare_roots(mt, ec_mt);
00120         }
00121 
00122         if (
00123           (total_inserts % 1000000 == 0) ||
00124           (k == num_trees - 1 && h == hashes.back()))
00125         {
00126           static char time_str[256] = "";
00127           std::time_t t = std::time(nullptr);
00128           std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00129           std::cout << time_str << ": " << k << " trees, " << total_inserts
00130                     << " inserts, " << total_flushes << " flushes, "
00131                     << total_retractions << " retractions: OK" << std::endl;
00132         }
00133       }
00134 
00135       compare_roots(mt, ec_mt);
00136 
00137       mt_free(ec_mt);
00138       ec_mt = NULL;
00139     }
00140   }
00141   catch (std::exception& ex)
00142   {
00143     std::cout << "Error: " << ex.what() << std::endl;
00144     mt_free_hash(ec_hash);
00145     mt_free(ec_mt);
00146     return 1;
00147   }
00148   catch (...)
00149   {
00150     std::cout << "Error" << std::endl;
00151     mt_free_hash(ec_hash);
00152     mt_free(ec_mt);
00153     return 1;
00154   }
00155 
00156   mt_free_hash(ec_hash);
00157 
00158   return 0;
00159 }
---------
Macros accessible in this file:
---------
PRNTSZ HSZ 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/compare_evercrypt.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/compare_hash_functions.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include iomanip: not found! skipping...
#include iostream: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 3400 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define HSZ
00012 #define PRNTSZ
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 
00059 template <
00060   void (*HF1)(
00061     const merkle::HashT<32>& l,
00062     const merkle::HashT<32>& r,
00063     merkle::HashT<32>& out),
00064   void (*HF2)(
00065     const merkle::HashT<32>& l,
00066     const merkle::HashT<32>& r,
00067     merkle::HashT<32>& out)>
00068 void compare_roots(
00069   merkle::TreeT<32, HF1>& mt1, merkle::TreeT<32, HF2>& mt2, const char* name)
00070 {
00071   auto mt1_root = mt1.root();
00072   auto mt2_root = mt2.root();
00073 
00074   if (mt1_root != mt2_root)
00075   {
00076     std::cout << mt1.num_leaves() << ": " << mt1_root.to_string()
00077               << " != " << mt2_root.to_string() << std::endl;
00078     std::cout << "mt1: " << std::endl;
00079     std::cout << mt1.to_string(PRNTSZ) << std::endl;
00080     std::cout << name << ": " << std::endl;
00081     std::cout << mt2.to_string(PRNTSZ) << std::endl;
00082     throw std::runtime_error("root hash mismatch");
00083   }
00084 }
00085 
00086 void compare_compression_hashes()
00087 {
00088 
00089   const size_t num_trees = 1024;
00090   const size_t root_interval = 31;
00091 
00092 
00093 
00094 
00095 
00096   size_t total_inserts = 0, total_roots = 0;
00097 
00098   for (size_t k = 0; k < num_trees; k++)
00099   {
00100     merkle::Tree mt;
00101 
00102 
00103 
00104 
00105 
00106 
00107 
00108 
00109 
00110 
00111 
00112 
00113 
00114     // Build trees with k+1 leaves
00115     int j = 0;
00116     auto hashes = make_hashes(k + 1);
00117 
00118     for (const auto h : hashes)
00119     {
00120       mt.insert(h);
00121 
00122 
00123 
00124 
00125 
00126 
00127 
00128 
00129 
00130 
00131 
00132 
00133 
00134       total_inserts++;
00135 
00136       if ((j++ % root_interval) == 0)
00137       {
00138 
00139 
00140 
00141 
00142 
00143 
00144 
00145 
00146 
00147 
00148 
00149 
00150         total_roots++;
00151       }
00152     }
00153 
00154 
00155 
00156 
00157 
00158 
00159 
00160 
00161 
00162 
00163 
00164 
00165   }
00166 
00167   static char time_str[256] = "";
00168   std::time_t t = std::time(nullptr);
00169   std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00170   std::cout << time_str << ": " << num_trees << " trees, " << total_inserts
00171             << " inserts, " << total_roots
00172             << " roots with SHA256 compression function: OK" << std::endl;
00173 }
00174 
00175 
00176 
00177 
00178 
00179 
00180 
00181 
00182 
00183 
00184 
00185 
00186 
00187 
00188 
00189 
00190 
00191 
00192 
00193 
00194 
00195 
00196 
00197 
00198 
00199 
00200 
00201 
00202 
00203 
00204 
00205 
00206 
00207 
00208 
00209 
00210 
00211 
00212 
00213 
00214 
00215 
00216 
00217 
00218 
00219 
00220 
00221 
00222 
00223 
00224 
00225 
00226 
00227 
00228 
00229 
00230 
00231 
00232 
00233 
00234 
00235 
00236 
00237 
00238 
00239 
00240 
00241 
00242 
00243 
00244 
00245 
00246 
00247 
00248 
00249 
00250 template <typename T>
00251 void bench(
00252   const std::vector<merkle::Hash>& hashes,
00253   const std::string& name,
00254   size_t root_interval)
00255 {
00256   size_t j = 0;
00257   auto start = std::chrono::high_resolution_clock::now();
00258   T mt;
00259   for (auto& h : hashes)
00260   {
00261     mt.insert(h);
00262     if ((j++ % root_interval) == 0)
00263       mt.root();
00264   }
00265   mt.root();
00266   auto stop = std::chrono::high_resolution_clock::now();
00267   double seconds =
00268     std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start).count() /
00269     1e9;
00270   std::cout << std::left << std::setw(10) << name << ": "
00271             << mt.statistics.num_insert << " insertions, "
00272             << mt.statistics.num_root << " roots in " << seconds << " sec"
00273             << std::endl;
00274 }
00275 
00276 
00277 
00278 
00279 
00280 
00281 
00282 
00283 
00284 
00285 
00286 
00287 
00288 
00289 
00290 
00291 
00292 
00293 
00294 
00295 
00296 
00297 
00298 
00299 
00300 
00301 
00302 
00303 
00304 
00305 
00306 
00307 
00308 
00309 
00310 
00311 int main()
00312 {
00313   try
00314   {
00315     // std::srand(0);
00316     std::srand(std::time(0));
00317 
00318     compare_compression_hashes();
00319 
00320 
00321 
00322 
00323 
00324 
00325     const size_t num_leaves = 128 * 1024;
00326     const size_t root_interval = 128;
00327 
00328 
00329 
00330 
00331 
00332     auto hashes = make_hashes(num_leaves);
00333 
00334     std::cout << "--- merklecpp trees with SHA256 compression function: "
00335               << std::endl;
00336 
00337     bench<merkle::Tree>(hashes, "merklecpp", root_interval);
00338 
00339 
00340 
00341 
00342 
00343 
00344 
00345 
00346 
00347 
00348 
00349 
00350 
00351     std::cout << "--- merklecpp trees with full SHA256: " << std::endl;
00352 
00353 
00354 
00355 
00356 
00357 
00358 
00359 
00360 
00361 
00362 
00363 
00364 
00365 
00366 
00367 
00368 
00369 
00370 
00371 
00372 
00373 
00374 
00375 
00376 
00377 
00378 
00379 
00380 
00381 
00382 
00383   }
00384   catch (std::exception& ex)
00385   {
00386     std::cout << "Error: " << ex.what() << std::endl;
00387     return 1;
00388   }
00389   catch (...)
00390   {
00391     std::cout << "Error" << std::endl;
00392     return 1;
00393   }
00394 
00395   return 0;
00396 }
---------
Macros accessible in this file:
---------
PRNTSZ HSZ 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/compare_hash_functions.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/demo_tree.cpp...
#include chrono: not found! skipping...
#include iomanip: not found! skipping...
#include iostream: not found! skipping...
#include util.h: already included! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 1616 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 #define PRINT_HASH_SIZE
00017 
00018 int main()
00019 {
00020   try
00021   {
00022     const size_t num_leaves = 11;
00023     {
00024       auto hashes = make_hashes(num_leaves);
00025 
00026       merkle::Tree mt;
00027       for (auto h : hashes)
00028         mt.insert(h);
00029       merkle::Tree::Hash root = mt.root();
00030       std::cout << mt.to_string(PRINT_HASH_SIZE) << std::endl;
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052       merkle::Tree mtl = mt.split(3);
00053       std::cout << "Left: " << std::endl;
00054       std::cout << mtl.to_string(PRINT_HASH_SIZE) << std::endl;
00055       std::cout << "Right: " << std::endl;
00056       std::cout << mt.to_string(PRINT_HASH_SIZE) << std::endl;
00057       std::cout << std::endl;
00058 
00059       std::cout << "Paths: " << std::endl;
00060       for (size_t i = mt.min_index(); i <= mt.max_index(); i++)
00061       {
00062         mt.flush_to(i);
00063         auto path = mt.path(i);
00064         std::cout << "P" << std::setw(2) << std::setfill('0') << i << ": "
00065                   << path->to_string(PRINT_HASH_SIZE) << " " << std::endl;
00066         if (!path->verify(root))
00067           throw std::runtime_error("root hash mismatch");
00068         std::vector<uint8_t> chk = *path;
00069       }
00070 
00071       std::vector<uint8_t> buffer;
00072       mt.serialise(buffer);
00073       merkle::Tree dmt(buffer);
00074       if (mt.root() != dmt.root())
00075         throw std::runtime_error("root hash mismatch");
00076 
00077       std::cout << std::endl;
00078     }
00079   }
00080   catch (std::exception& ex)
00081   {
00082     std::cout << "Error: " << ex.what() << std::endl;
00083     return 1;
00084   }
00085   catch (...)
00086   {
00087     std::cout << "Error" << std::endl;
00088     return 1;
00089   }
00090 
00091   return 0;
00092 }
00093 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/demo_tree.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/flush.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include cstdlib: not found! skipping...
#include iostream: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 1659 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define PRINT_HASH_SIZE
00012 
00013 int main()
00014 {
00015   try
00016   {
00017 
00018     const size_t num_trees = 32;
00019     const size_t max_num_leaves = 64 * 1024;
00020     const size_t max_flushes = 16;
00021 
00022 
00023 
00024 
00025 
00026 
00027     // std::srand(0);
00028     std::srand(std::time(0));
00029 
00030     size_t total_leaves = 0, total_flushes = 0;
00031 
00032     for (size_t k = 0; k < num_trees; k++)
00033     {
00034       size_t num_leaves = 1 + (std::rand() / (double)RAND_MAX) * max_num_leaves;
00035       total_leaves += num_leaves;
00036 
00037       auto hashes = make_hashes(num_leaves);
00038 
00039       merkle::Tree mt;
00040       for (size_t i = 0; i < hashes.size(); i++)
00041       {
00042         mt.insert(hashes[i]);
00043         if ((std::rand() / (double)RAND_MAX) > 0.95)
00044         {
00045           mt.flush_to(random_index(mt));
00046           total_flushes++;
00047         }
00048       }
00049 
00050       for (size_t i = 0; i < max_flushes; i++)
00051       {
00052         mt.flush_to(random_index(mt));
00053         total_flushes++;
00054         if (mt.min_index() == mt.max_index())
00055           break;
00056       }
00057 
00058       if ((k && k % 1000 == 0) || k == num_trees - 1)
00059       {
00060         static char time_str[256] = "";
00061         std::time_t t = std::time(nullptr);
00062         std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00063         std::cout << time_str << ": " << k << " trees, " << total_leaves
00064                   << " leaves, " << total_flushes << " flushes"
00065                   << ": OK." << std::endl;
00066       }
00067     }
00068   }
00069   catch (std::exception& ex)
00070   {
00071     std::cout << "Error: " << ex.what() << std::endl;
00072     return 1;
00073   }
00074   catch (...)
00075   {
00076     std::cout << "Error" << std::endl;
00077     return 1;
00078   }
00079 
00080   return 0;
00081 }
00082 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/flush.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/past_root.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include cstdlib: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include merklecpp.h: not found! skipping...
#include stdexcept: not found! skipping...
Preprocessor output (size: 2056 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 #define PRINT_HASH_SIZE
00014 
00015 int main()
00016 {
00017   try
00018   {
00019 
00020     const size_t num_trees = 64;
00021     const size_t max_num_leaves = 8 * 1024;
00022 
00023 
00024 
00025 
00026 
00027     // std::srand(0);
00028     std::srand(std::time(0));
00029 
00030     size_t total_leaves = 0, total_roots = 0;
00031 
00032     for (size_t k = 0; k < num_trees; k++)
00033     {
00034       std::map<size_t, merkle::Hash> past_roots;
00035       size_t num_leaves = 1 + (std::rand() / (double)RAND_MAX) * max_num_leaves;
00036       total_leaves += num_leaves;
00037       auto hashes = make_hashes(num_leaves);
00038 
00039       {
00040         // Extract some normal roots along the way
00041         merkle::Tree mt;
00042         for (size_t i = 0; i < hashes.size(); i++)
00043         {
00044           mt.insert(hashes[i]);
00045           if ((std::rand() / (double)RAND_MAX) > 0.95)
00046             past_roots[i] = mt.root();
00047         }
00048       }
00049 
00050       // Build new tree without taking roots
00051       merkle::Tree mt;
00052       for (auto& h : hashes)
00053         mt.insert(h);
00054 
00055       // Extract and check past roots
00056       for (auto& kv : past_roots)
00057       {
00058         auto pr = mt.past_root(kv.first);
00059         total_roots++;
00060         if (*pr != kv.second)
00061         {
00062           std::cout << pr->to_string(PRINT_HASH_SIZE)
00063                     << " != " << kv.second.to_string(PRINT_HASH_SIZE)
00064                     << std::endl;
00065           throw std::runtime_error("past root hash mismatch");
00066         }
00067       }
00068 
00069       if ((k && k % 1000 == 999) || k == num_trees - 1)
00070       {
00071         static char time_str[256] = "";
00072         std::time_t t = std::time(nullptr);
00073         std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00074         std::cout << time_str << ": " << k + 1 << " trees, " << total_leaves
00075                   << " leaves, " << total_roots << " roots"
00076                   << ": OK." << std::endl;
00077       }
00078     }
00079   }
00080   catch (std::exception& ex)
00081   {
00082     std::cout << "Error: " << ex.what() << std::endl;
00083     return 1;
00084   }
00085   catch (...)
00086   {
00087     std::cout << "Error" << std::endl;
00088     return 1;
00089   }
00090 
00091   return 0;
00092 }
00093 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/past_root.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/paths.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include cstdlib: not found! skipping...
#include iostream: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 1424 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define PRINT_HASH_SIZE
00012 
00013 int main()
00014 {
00015   try
00016   {
00017 
00018     const size_t num_trees = 128;
00019     const size_t max_num_paths = 64;
00020     const size_t max_num_leaves = 64 * 1024;
00021 
00022 
00023 
00024 
00025 
00026 
00027     // std::srand(0);
00028     std::srand(std::time(0));
00029 
00030     size_t total_paths = 0, total_leaves = 0;
00031 
00032     for (size_t l = 0; l < num_trees; l++)
00033     {
00034       size_t num_leaves = 1 + (std::rand() / (double)RAND_MAX) * max_num_leaves;
00035       size_t num_paths = 1 + (std::rand() / (double)RAND_MAX) * max_num_paths;
00036 
00037       total_leaves += num_leaves;
00038       total_paths += num_paths;
00039 
00040       auto hashes = make_hashes(num_leaves);
00041 
00042       merkle::Tree mt;
00043       for (auto h : hashes)
00044         mt.insert(h);
00045       merkle::Tree::Hash root = mt.root();
00046 
00047       for (size_t p = 0; p < num_paths; p++)
00048       {
00049         size_t i = (std::rand() / (double)(RAND_MAX)) * (num_leaves - 1);
00050         auto path = mt.path(i);
00051         if (!path->verify(root))
00052           throw std::runtime_error("path verification failed");
00053       }
00054     }
00055 
00056     std::cout << num_trees << " trees, " << total_leaves << " leaves, "
00057               << total_paths << " paths: OK." << std::endl;
00058   }
00059   catch (std::exception& ex)
00060   {
00061     std::cout << "Error: " << ex.what() << std::endl;
00062     return 1;
00063   }
00064   catch (...)
00065   {
00066     std::cout << "Error" << std::endl;
00067     return 1;
00068   }
00069 
00070   return 0;
00071 }
00072 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/paths.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/retract.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include cstdlib: not found! skipping...
#include iostream: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 2009 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define PRINT_HASH_SIZE
00012 
00013 int main()
00014 {
00015   try
00016   {
00017 
00018     const size_t num_trees = 128;
00019     const size_t max_num_leaves = 64 * 1024;
00020     const size_t max_retractions = 16;
00021 
00022 
00023 
00024 
00025 
00026 
00027     // std::srand(0);
00028     std::srand(std::time(0));
00029 
00030     size_t total_leaves = 0, total_retractions = 0;
00031 
00032     for (size_t k = 0; k < num_trees; k++)
00033     {
00034       size_t num_leaves = 1 + (std::rand() / (double)RAND_MAX) * max_num_leaves;
00035       total_leaves += num_leaves;
00036 
00037       auto hashes = make_hashes(num_leaves);
00038 
00039       merkle::Tree mt;
00040       for (size_t i = 0; i < hashes.size(); i++)
00041       {
00042         mt.insert(hashes[i]);
00043         if (i > 0 && std::rand() / (double)RAND_MAX > 0.5)
00044         {
00045           mt.retract_to(mt.max_index() - 1);
00046           total_retractions++;
00047           mt.insert(hashes[i]);
00048           mt.retract_to(mt.max_index());
00049           if (mt.max_index() != i)
00050             std::runtime_error("invalid max index");
00051         }
00052 
00053         if ((std::rand() / (double)RAND_MAX) > 0.95)
00054         {
00055           mt.retract_to(random_index(mt));
00056           total_retractions++;
00057         }
00058       }
00059 
00060       for (size_t i = 0; i < max_retractions; i++)
00061       {
00062         mt.retract_to(random_index(mt));
00063         total_retractions++;
00064         if (mt.min_index() == mt.max_index())
00065           break;
00066       }
00067 
00068       if ((k && k % 1000 == 0) || k == num_trees - 1)
00069       {
00070         static char time_str[256] = "";
00071         std::time_t t = std::time(nullptr);
00072         std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00073         std::cout << time_str << ": " << k << " trees, " << total_leaves
00074                   << " leaves, " << total_retractions << " retractions"
00075                   << ": OK." << std::endl;
00076       }
00077     }
00078   }
00079   catch (std::exception& ex)
00080   {
00081     std::cout << "Error: " << ex.what() << std::endl;
00082     return 1;
00083   }
00084   catch (...)
00085   {
00086     std::cout << "Error" << std::endl;
00087     return 1;
00088   }
00089 
00090   return 0;
00091 }
00092 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/retract.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/serialisation.cpp...
#include util.h: already included! skipping...
#include chrono: not found! skipping...
#include cstdlib: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include merklecpp.h: not found! skipping...
#include stdexcept: not found! skipping...
Preprocessor output (size: 2676 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 #define PRINT_HASH_SIZE
00014 
00015 int main()
00016 {
00017   try
00018   {
00019 
00020     const size_t num_trees = 32;
00021     const size_t max_num_leaves = 32 * 1024;
00022 
00023 
00024 
00025 
00026 
00027     // std::srand(0);
00028     std::srand(std::time(0));
00029 
00030     size_t total_leaves = 0, total_flushes = 0, total_retractions = 0;
00031 
00032     for (size_t k = 0; k < num_trees; k++)
00033     {
00034       std::map<size_t, merkle::Hash> past_roots;
00035       size_t num_leaves = 1 + (std::rand() / (double)RAND_MAX) * max_num_leaves;
00036       total_leaves += num_leaves;
00037       auto hashes = make_hashes(num_leaves);
00038 
00039       // Build
00040       merkle::Tree mt;
00041       for (auto& h : hashes)
00042       {
00043         assert(mt.invariant());
00044         mt.insert(h);
00045         assert(mt.invariant());
00046         if ((std::rand() / (double)RAND_MAX) > 0.95)
00047         {
00048           assert(mt.invariant());
00049           mt.flush_to(random_index(mt));
00050           assert(mt.invariant());
00051           total_flushes++;
00052         }
00053         if ((std::rand() / (double)RAND_MAX) > 0.95)
00054         {
00055           assert(mt.invariant());
00056           mt.retract_to(random_index(mt));
00057           assert(mt.invariant());
00058           total_retractions++;
00059         }
00060       }
00061 
00062       // Serialise
00063       std::vector<uint8_t> buffer;
00064       mt.serialise(buffer);
00065 
00066       // Deserialise
00067       size_t index = 0;
00068       merkle::Tree mt2(buffer, index);
00069 
00070       // Check roots and other properties
00071       if (
00072         mt.root() != mt2.root() || mt.min_index() != mt2.min_index() ||
00073         mt.max_index() != mt2.max_index() ||
00074         mt.num_leaves() != mt2.num_leaves() ||
00075         mt.serialised_size() != mt2.serialised_size() ||
00076         mt.size() != mt2.size())
00077       {
00078         std::cout << "before:" << std::endl
00079                   << mt.to_string(PRINT_HASH_SIZE) << std::endl;
00080         std::cout << "after:" << std::endl
00081                   << mt2.to_string(PRINT_HASH_SIZE) << std::endl;
00082         throw std::runtime_error("tree properties mismatch");
00083       }
00084 
00085       if ((k && k % 1000 == 999) || k == num_trees - 1)
00086       {
00087         static char time_str[256] = "";
00088         std::time_t t = std::time(nullptr);
00089         std::strftime(time_str, sizeof(time_str), "%R", std::localtime(&t));
00090         std::cout << time_str << ": " << k + 1 << " trees, " << total_leaves
00091                   << " leaves, " << total_flushes << " flushes, "
00092                   << total_retractions << " retractions"
00093                   << ": OK." << std::endl;
00094       }
00095     }
00096   }
00097   catch (std::exception& ex)
00098   {
00099     std::cout << "Error: " << ex.what() << std::endl;
00100     return 1;
00101   }
00102   catch (...)
00103   {
00104     std::cout << "Error" << std::endl;
00105     return 1;
00106   }
00107 
00108   return 0;
00109 }
00110 
---------
Macros accessible in this file:
---------
PRINT_HASH_SIZE 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/serialisation.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/time_large_trees.cpp...
#include chrono: not found! skipping...
#include iostream: not found! skipping...
#include util.h: already included! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 1054 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 #define HSZ
00016 
00017 int main()
00018 {
00019   try
00020   {
00021 
00022     const size_t num_leaves = 128 * 1024;
00023     const size_t root_interval = 128;
00024 
00025 
00026 
00027 
00028 
00029     auto hashes = make_hashes(num_leaves);
00030 
00031     merkle::Tree mt;
00032     size_t j = 0;
00033     auto start = std::chrono::high_resolution_clock::now();
00034     for (auto& h : hashes)
00035     {
00036       mt.insert(h);
00037       if ((j++ % root_interval) == 0)
00038         mt.root();
00039     }
00040     auto root = mt.root();
00041     auto stop = std::chrono::high_resolution_clock::now();
00042     double seconds =
00043       std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start)
00044         .count() /
00045       1e9;
00046     std::cout << "NEW: " << mt.statistics.to_string() << " in " << seconds
00047               << " sec" << std::endl;
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 
00065 
00066 
00067 
00068 
00069 
00070 
00071 
00072 
00073 
00074 
00075 
00076 
00077 
00078 
00079 
00080 
00081 
00082 
00083 
00084 
00085   }
00086   catch (std::exception& ex)
00087   {
00088     std::cout << "Error: " << ex.what() << std::endl;
00089     return 1;
00090   }
00091   catch (...)
00092   {
00093     std::cout << "Error" << std::endl;
00094     return 1;
00095   }
00096 
00097   return 0;
00098 }
---------
Macros accessible in this file:
---------
HSZ 
---------
Parsing file /data/git/CCF/src/libmerklecpp/test/time_large_trees.cpp...
Preprocessing /data/git/CCF/src/libmerklecpp/test/util.h...
#include merklecpp.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 562 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 inline std::vector<merkle::Hash> make_hashes(size_t n, size_t print_size = 3)
00010 {
00011   std::vector<merkle::Hash> hashes;
00012   merkle::Tree::Hash h;
00013   for (size_t i = 0; i < n; i++)
00014   {
00015     hashes.push_back(h);
00016     for (size_t j = print_size - 1; ++h.bytes[j] == 0 && j != -1; j--)
00017       ;
00018   }
00019   return hashes;
00020 }
00021 
00022 inline size_t random_index(merkle::Tree& mt)
00023 {
00024   return mt.min_index() +
00025     (std::rand() / (double)RAND_MAX) * (mt.max_index() - mt.min_index());
00026 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/libmerklecpp/test/util.h...
Preprocessing /data/git/CCF/src/lua_interp/lua_interp.h...
#include optional: not found! skipping...
#include ostream: not found! skipping...
#include sstream: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include ../../3rdparty/lua/lualib.h: not found! skipping...
      #include fmt/format.h: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
#include type_traits: not found! skipping...
#include vector: not found! skipping...
#include ../../3rdparty/lua/lauxlib.h: not found! skipping...
#include ../../3rdparty/lua/lua.h: not found! skipping...
#include typeinfo: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 11532 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 extern "C"
00012 {
00013 
00014 }
00015 # 15 "/data/git/CCF/src/lua_interp/lua_interp.h" 2
00016 
00017 /**
00018  * @file lua_interp.h
00019  * @brief Lua interpreter and associated helpers
00020  */
00021 namespace ccf
00022 {
00023   namespace lua
00024   {
00025     /**
00026      * Hook called if lua instruction count gets too high - assume this is an
00027      * unwanted infinite loop and abandon by throwing an exception
00028      */
00029     inline void instruction_limit_hook(lua_State* l, lua_Debug* dbg)
00030     {
00031       std::stringstream ss;
00032 
00033       lua_getinfo(l, "S", dbg);
00034       ss << "Lua instruction limit reached while executing " << dbg->short_src
00035          << std::endl;
00036 
00037       int level = 0;
00038       ss << "Callstack:" << std::endl;
00039       while (lua_getstack(l, level, dbg) == 1)
00040       {
00041         lua_getinfo(l, "nSl", dbg);
00042 
00043         ss << " [" << level << "] Line " << dbg->currentline << " in ";
00044         if (dbg->name != nullptr)
00045         {
00046           if (strlen(dbg->namewhat) > 0)
00047           {
00048             ss << dbg->namewhat << " ";
00049           }
00050           ss << dbg->name;
00051         }
00052         else
00053         {
00054           ss << "<unknown>";
00055         }
00056 
00057         ss << " : " << dbg->short_src << std::endl;
00058 
00059         ++level;
00060       }
00061 
00062       throw ex(ss.str());
00063     }
00064 
00065     /**
00066      * @brief C++ frontend for the Lua interpreter
00067      */
00068     class Interpreter
00069     {
00070     private:
00071       lua_State* l;
00072 
00073       std::optional<size_t> execution_limit;
00074 
00075       /**
00076        * @brief Check that the stack has enough space to push an element of the
00077        * templated type
00078        *
00079        */
00080       void prepare_push(unsigned int slots = 1)
00081       {
00082         if (!lua_checkstack(l, slots))
00083           throw lua::ex("Lua stack size exceeded.");
00084       }
00085 
00086       /* required for cases where invoke() is called without args.
00087         Could be avoided in C++17 with if constexpr (sizeof...(T)) */
00088       void push_n() {}
00089 
00090       static int panic(lua_State*)
00091       {
00092         throw lua::ex("Lua panicked.");
00093         return 0;
00094       }
00095 
00096       template <typename T, typename... Args>
00097       void _push_table(const char* k, T&& v, Args&&... args)
00098       {
00099         push(v);
00100         lua_setfield(l, -2, k);
00101         _push_table(std::forward<Args>(args)...);
00102       }
00103 
00104       void _push_table() {}
00105 
00106     public:
00107       Interpreter() : execution_limit(1 << 22)
00108       {
00109         l = luaL_newstate();
00110         lua_atpanic(l, panic);
00111 
00112         // Modules that are exposed, to expose a new module
00113         // add it to this list
00114         static const luaL_Reg libs[] = {{LUA_GNAME, luaopen_base},
00115                                         {LUA_TABLIBNAME, luaopen_table},
00116                                         {LUA_STRLIBNAME, luaopen_string},
00117                                         {LUA_MATHLIBNAME, luaopen_math},
00118                                         {nullptr, nullptr}};
00119 
00120         // load these into the global table (same as luaL_openlibs, but with a
00121         // custom module list)
00122         const luaL_Reg* lib;
00123         for (lib = libs; lib->func; lib++)
00124         {
00125           luaL_requiref(l, lib->name, lib->func, 1);
00126           lua_pop(l, 1); /* remove lib */
00127         }
00128 
00129         // lua's garbage collector is left in its default state. As long as
00130         // instances of this Interpreter remain reasonably short-lived their
00131         // memory use is unlikely to be a problem - either they are destroyed
00132         // before the garbage collector ever runs, or they kept in check by
00133         // occasional
00134         //  mark-and-sweep passes.
00135         // If we trust that all scripts will avoid long-term growth and want to
00136         // remove the GC interruptions we could disable GC entirely:
00137         // lua_gc(l, LUA_GCSTOP);
00138       }
00139 
00140       ~Interpreter()
00141       {
00142         lua_close(l);
00143       }
00144 
00145       /**
00146        * @brief Push item to stack.
00147        *
00148        * @tparam T type of item
00149        * @param o the item
00150        */
00151       template <typename T>
00152       void push(T&& o)
00153       {
00154         prepare_push();
00155         lua::push_raw(l, std::forward<T>(o));
00156       }
00157 
00158       /**
00159        * @brief Push sequence of items to stack.
00160        */
00161       template <typename T, typename... Args>
00162       void push_n(T&& first, Args&&... args)
00163       {
00164         push(first);
00165         push_n(std::forward<Args>(args)...);
00166       }
00167 
00168       /**
00169        * @brief Pop item from stack.
00170        * @return T the type of the item
00171        */
00172       template <typename T>
00173       T pop()
00174       {
00175         const auto r = lua::get_top<T>(l);
00176         lua_pop(l, 1);
00177         return r;
00178       }
00179 
00180       /**
00181        * @brief Push a table with strings as keys and variying types as values.
00182        * For example:
00183        * interp.push_table(
00184        *   "a", 5, // 1st entry
00185        *   "b", 2, // 2nd entry
00186        *   "c", "x", // 3rd entry
00187        *   "d", true); // 4th entry
00188        *
00189        * @param k the first key
00190        * @param v the first value
00191        * @param args the remaining entries
00192        */
00193       template <typename T, typename... Args>
00194       void push_table(const char* k, T&& v, Args&&... args)
00195       {
00196         lua_newtable(l);
00197         _push_table(k, v, std::forward<Args>(args)...);
00198       }
00199 
00200       /**
00201        * @brief Invoke Lua script on sequence of arguments.
00202        *
00203        * Within the Lua code, the arguments can be accessed through "...".
00204        * For example, to add two numbers:
00205        * local a, b = ...
00206        * return a + b
00207        *
00208        * @param script the Lua script
00209        * @param args the arguments
00210        * @return T the result of invoking the Lua code on the arguments
00211        */
00212       template <typename T, typename... Args>
00213       T invoke(const std::string& script, Args&&... args)
00214       {
00215         push_code(script);
00216         return invoke_raw<T>(0, std::forward<Args>(args)...);
00217       }
00218 
00219       /**
00220        * @brief Invoke pre-compiled Lua bytecode on sequence of arguments.
00221        *
00222        * Within the Lua code, the arguments can be accessed through "...".
00223        * For example, to add two numbers:
00224        * local a, b = ...
00225        * return a + b
00226        *
00227        * @param bc the Lua bytecode
00228        * @param args the arguments
00229        * @return T the result of invoking the Lua bytecode on the arguments
00230        */
00231       template <typename T, typename... Args>
00232       T invoke(const std::vector<uint8_t>& bc, Args&&... args)
00233       {
00234         push_code(bc);
00235         return invoke_raw<T>(0, std::forward<Args>(args)...);
00236       }
00237 
00238       template <typename... Args>
00239       void invoke(const std::vector<uint8_t>& bc, Args&&... args)
00240       {
00241         push_code(bc);
00242         invoke_raw(0, std::forward<Args>(args)...);
00243       }
00244 
00245       template <typename... Args>
00246       void invoke(const std::string& s, Args&&... args)
00247       {
00248         push_code(s);
00249         invoke_raw(0, std::forward<Args>(args)...);
00250       }
00251 
00252       /**
00253        * @brief Invoke script that was previously pushed
00254        *
00255        * @param n_args_on_stack number of arguments that are already on the
00256        * stack; if n_args_on_stack=0, consider using invoke() instead.
00257        * @param args additional arguments to be pushed
00258        * @return T the result of invoking the Lua bytecode on the arguments
00259        */
00260       template <typename T, typename... Args>
00261       T invoke_raw(unsigned int n_args_on_stack, Args&&... args)
00262       {
00263         invoke_raw(n_args_on_stack, std::forward<Args>(args)...);
00264         return pop<T>();
00265       }
00266 
00267       template <typename... Args>
00268       void invoke_raw(unsigned int n_args_on_stack, Args&&... args)
00269       {
00270         push_n(std::forward<Args>(args)...);
00271 
00272         if (execution_limit.has_value())
00273         {
00274           lua_sethook(
00275             l, instruction_limit_hook, LUA_MASKCOUNT, execution_limit.value());
00276         }
00277 
00278         if (lua_pcall(l, sizeof...(Args) + n_args_on_stack, 1, 0))
00279         {
00280           const auto err = pop<std::string>();
00281           std::stringstream ss;
00282           ss << "Failed to run Lua code: " << err;
00283           throw lua::ex(ss.str());
00284         }
00285       }
00286 
00287       /** Push bytecode
00288        * @param bc the bytecode
00289        */
00290       void push_code(const std::vector<uint8_t>& bc)
00291       {
00292         push_code(reinterpret_cast<const char*>(bc.data()), bc.size());
00293       }
00294 
00295       /** Push script
00296        * @param s the script
00297        */
00298       void push_code(const std::string& s)
00299       {
00300         push_code(s.data(), s.size());
00301       }
00302 
00303       /** Push script
00304        * @param c the script
00305        * @param s the length of the string
00306        */
00307       void push_code(const char* c, const size_t s)
00308       {
00309         prepare_push();
00310         if (luaL_loadbufferx(l, c, s, nullptr, nullptr))
00311         {
00312           const auto err = pop<std::string>();
00313           std::stringstream ss;
00314           ss << "Failed to load Lua code: " << err;
00315           throw lua::ex(ss.str());
00316         }
00317       }
00318 
00319       /**
00320        * @brief Load a named module into the global table
00321        *
00322        * @param name the name which should be used to access the module from lua
00323        * @param open function which pushes this module onto the top of the
00324        * stack, eg luaopen_math
00325        */
00326       template <typename FOpen>
00327       void load_module(const char* name, FOpen open)
00328       {
00329         luaL_requiref(l, name, open, 1);
00330         lua_pop(l, 1); /* remove copy of module table from stack */
00331       }
00332 
00333       /**
00334        * @brief Register a named metatable, which can later be retrieved through
00335        * luaL_getmetatable
00336        *
00337        * @param name the metatable's identifier
00338        * @param funcs C-array of luaL_Reg entries giving the metatable's named
00339        * functions, terminated by a nullptr pair
00340        * @param skip_existing skip if metatable already exists. Otherwise,
00341        * merge.
00342        */
00343       void register_metatable(
00344         const char* name, const luaL_Reg* funcs, bool skip_existing)
00345       {
00346         constexpr auto metatable = -1;
00347         constexpr auto field = -2;
00348         prepare_push(2);
00349         const auto exists = !luaL_newmetatable(l, name);
00350         if (exists && skip_existing)
00351         {
00352           lua_pop(l, 1); // remove metatable from stack
00353           return;
00354         }
00355 
00356         for (const luaL_Reg* method = funcs; method->func; method++)
00357         {
00358           lua_pushcfunction(l, method->func);
00359           lua_setfield(l, field, method->name);
00360         }
00361 
00362         lua_pushvalue(l, metatable); // dup metatable
00363         lua_setfield(l, field, "__index"); // metatable.__index = metatable
00364 
00365         lua_pop(l, 1); // remove metatable from stack
00366       }
00367 
00368       //! Register a metatable for a certain UserData type.
00369       template <typename T, typename X = T>
00370       void register_metatable(const luaL_Reg* funcs, bool skip_existing = true)
00371       {
00372         register_metatable(
00373           UserData<T, X>::metatable_name(), funcs, skip_existing);
00374       }
00375 
00376       /** Get the raw state object */
00377       auto get_state()
00378       {
00379         return l;
00380       }
00381 
00382       /**
00383        * @brief Print the stack
00384        *
00385        * @param os the ostream to print to
00386        */
00387       void print_stack(std::ostream& os)
00388       {
00389         const auto stack_size = lua_gettop(l);
00390         for (int i = 1; i <= stack_size; i++)
00391         {
00392           const auto j = check_get<nlohmann::json>(l, i);
00393           os << i << " (" << lua_typename(l, lua_type(l, i)) << ")\n"
00394              << j.dump() << std::endl;
00395         }
00396       }
00397 
00398       /** Set maximum number of instructions which may be executed in a single
00399        * call to invoke */
00400       void set_execution_limit(size_t n)
00401       {
00402         execution_limit = {n};
00403       }
00404 
00405       void remove_execution_limit()
00406       {
00407         execution_limit = std::nullopt;
00408       }
00409     };
00410   } // namespace lua
00411 } // namespace ccf 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/lua_interp.h...
Preprocessing /data/git/CCF/src/lua_interp/lua_json.h...
#include lua_user_data.h: already included! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 7004 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 /**
00010  * @file lua_json.h
00011  * @brief Convert between nlohmann::json and lua
00012  */
00013 namespace ccf
00014 {
00015   namespace lua
00016   {
00017     /**
00018      * Push a json value onto the lua stack
00019      *
00020      * Leaves a single new value, but may use additional stack space. Objects
00021      * and arrays in json become tables in lua, with string and integer indexes
00022      * (starting from 1) respectively.
00023      */
00024     template <>
00025     inline void push_raw(lua_State* l, const nlohmann::json& j)
00026     {
00027       const auto stack_before = lua_gettop(l);
00028 
00029       switch (j.type())
00030       {
00031         case nlohmann::json::value_t::null:
00032         {
00033           lua_pushnil(l);
00034           break;
00035         }
00036         case nlohmann::json::value_t::object:
00037         {
00038           lua_createtable(l, 0, j.size());
00039           for (auto it = j.begin(); it != j.end(); ++it)
00040           {
00041             push_raw(l, it.value());
00042             lua_setfield(l, -2, it.key().c_str());
00043           }
00044           // Set custom __was_object metatable property
00045           if (lua_getmetatable(l, -1) == 0)
00046           {
00047             lua_createtable(l, 0, 1);
00048           }
00049           lua_pushboolean(l, true);
00050           lua_setfield(l, -2, "__was_object");
00051           lua_setmetatable(l, -2);
00052           break;
00053         }
00054         case nlohmann::json::value_t::array:
00055         {
00056           lua_createtable(l, j.size(), 0);
00057           size_t i = 0;
00058           for (const auto& v : j)
00059           {
00060             push_raw(l, v);
00061             lua_seti(
00062               l, -2, ++i); // lua 'arrays' are 1-indexed, so pre-increment
00063           }
00064           // Set custom __was_object metatable property
00065           if (lua_getmetatable(l, -1) == 0)
00066           {
00067             lua_createtable(l, 0, 1);
00068           }
00069           lua_pushboolean(l, false);
00070           lua_setfield(l, -2, "__was_object");
00071           lua_setmetatable(l, -2);
00072           break;
00073         }
00074         case nlohmann::json::value_t::string:
00075         {
00076           const std::string s = j;
00077           lua_pushstring(l, s.c_str());
00078           break;
00079         }
00080         case nlohmann::json::value_t::boolean:
00081         {
00082           const bool b = j;
00083           lua_pushboolean(l, b);
00084           break;
00085         }
00086         case nlohmann::json::value_t::number_integer:
00087         case nlohmann::json::value_t::number_unsigned:
00088         {
00089           const lua_Integer i = j;
00090           lua_pushinteger(l, i);
00091           break;
00092         }
00093         case nlohmann::json::value_t::number_float:
00094         {
00095           const lua_Number n = j;
00096           lua_pushnumber(l, n);
00097           break;
00098         }
00099         default:
00100         {
00101           throw ex("Unhandled json type, unable to push onto lua stack");
00102         }
00103       }
00104 
00105       expect_top(l, stack_before + 1);
00106     }
00107 
00108     template <>
00109     inline nlohmann::json check_get(lua_State* l, int arg)
00110     {
00111       const auto stack_before = lua_gettop(l);
00112       arg = sanitize_stack_idx(l, arg);
00113 
00114       nlohmann::json j;
00115       switch (lua_type(l, arg))
00116       {
00117         case LUA_TNIL:
00118         {
00119           j = nullptr;
00120           break;
00121         }
00122         case LUA_TNUMBER:
00123         {
00124           if (lua_isinteger(l, arg))
00125             j = lua_tointegerx(l, arg, nullptr);
00126           else
00127             j = lua_tonumberx(l, arg, nullptr);
00128           break;
00129         }
00130         case LUA_TBOOLEAN:
00131         {
00132           j = bool(lua_toboolean(l, arg));
00133           break;
00134         }
00135         case LUA_TSTRING:
00136         {
00137           j = lua_tolstring(l, arg, nullptr);
00138           break;
00139         }
00140         case LUA_TTABLE:
00141         {
00142           constexpr auto ikey = -2;
00143           constexpr auto ivalue = -1;
00144 
00145           // to parse a table, we need two additional stack slots
00146           if (!lua_checkstack(l, 2))
00147             throw ex("Not enough stack left for iterating over table.");
00148 
00149           // (1) attempt to create a json array
00150           // there must a sequence of integer keys starting from 1
00151           auto a = nlohmann::json::array();
00152           bool is_array = false;
00153           bool saw_integer_key = false;
00154           int prev_key = 0;
00155           lua_pushnil(l); // first key
00156           while (lua_next(l, arg) != 0)
00157           {
00158             is_array = false;
00159             // is the key an integer
00160             if (!lua_isinteger(l, ikey))
00161             {
00162               lua_pop(l, 2);
00163               break;
00164             }
00165             saw_integer_key = true;
00166 
00167             // does the key come directly after the previous one?
00168             if (const auto key = lua_tointegerx(l, ikey, nullptr);
00169                 key != ++prev_key)
00170             {
00171               lua_pop(l, 2);
00172               break;
00173             }
00174 
00175             is_array = true;
00176             a.push_back(check_get<nlohmann::json>(l, ivalue));
00177             // remove value and keep key for next iteration
00178             lua_pop(l, 1);
00179           }
00180           if (is_array)
00181           {
00182             j = std::move(a);
00183             break;
00184           }
00185 
00186           const auto non_string_key = []() {
00187             throw ex("Cannot create Json table with integer key.");
00188           };
00189           if (saw_integer_key)
00190             non_string_key();
00191 
00192           expect_top(l, stack_before);
00193 
00194           // (2) parse the table as dictionary instead
00195           // since json only supports strings as keys, we throw for anything
00196           // else
00197           j = nlohmann::json::object();
00198           lua_pushnil(l); // first key
00199           while (lua_next(l, arg) != 0)
00200           {
00201             // need an extra check here, because Lua will report ints to be
00202             // strings
00203             if (lua_isinteger(l, ikey))
00204               non_string_key();
00205 
00206             const auto key = check_get<std::string>(l, ikey);
00207             j[key] = check_get<nlohmann::json>(l, ivalue);
00208             // pop value and keep original key for next iteration
00209             lua_pop(l, 1);
00210           }
00211           if (!j.empty())
00212           {
00213             // Found some keys, done
00214             break;
00215           }
00216 
00217           expect_top(l, stack_before);
00218 
00219           // (3) Have an empty Lua table. See if there is a metatable to
00220           // distinguish empty-object (will be present if this value was
00221           // originally a JSON object) from empty-array
00222           if (lua_getmetatable(l, -1) != 0)
00223           {
00224             lua_getfield(l, -1, "__was_object");
00225             if (lua_isboolean(l, -1))
00226             {
00227               if (lua_toboolean(l, -1))
00228               {
00229                 j = nlohmann::json::object();
00230               }
00231               else
00232               {
00233                 j = nlohmann::json::array();
00234               }
00235             }
00236 
00237             // pop metatable and requested field
00238             lua_pop(l, 2);
00239           }
00240 
00241           break;
00242         }
00243         case LUA_TUSERDATA:
00244         case LUA_TFUNCTION:
00245           // do nothing
00246           break;
00247 
00248         default:
00249           throw ex(
00250             "Encountered unexpected lua type while constructing json object.");
00251       }
00252       expect_top(l, stack_before);
00253       return j;
00254     }
00255   } // namespace lua
00256 } // namespace ccf 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/lua_json.h...
Preprocessing /data/git/CCF/src/lua_interp/lua_kv.h...
#include lua_json.h: already included! skipping...
Preprocessor output (size: 4737 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 /**
00007  * @brief Wrap KvTable structures so they can be used in lua. Types are
00008  * translated using nlohmann::json.
00009  */
00010 namespace ccf
00011 {
00012   namespace lua
00013   {
00014     /**
00015      * Static functions to interact with a kv::Map<K, V>::TxView from lua.
00016      *
00017      * Each of the Txs public methods have an equivalent lua function. Where the
00018      * C++ api throws exceptions or returns empty options, the lua version will
00019      * return nil.
00020      *
00021      * nlohmann::json is used to transfer types between C++/the KvTable and lua.
00022      * Thus, all types that nlohmann::json can serialize/unserialize can be
00023      * passed.
00024      */
00025     template <typename TxView, typename X = TxView>
00026     struct KvTable
00027     {
00028       using UD = UserData<TxView, X>;
00029       using K = typename TxView::KeyType;
00030       using V = typename TxView::ValueType;
00031 
00032       /**
00033        * @brief Callable from lua.
00034        * Expects the following arguments from lua.
00035        * #1 (-2): self/table
00036        * #2 (-1): key
00037        *
00038        * @param l
00039        * @return int
00040        */
00041       static int get(lua_State* l)
00042       {
00043         constexpr int n_args = 2;
00044         sanitize_stack_idx(l, n_args);
00045 
00046         auto tx = UD::unbox(l, -2);
00047         const K key = lua::check_get<nlohmann::json>(l, -1);
00048         const auto search = tx->get(key);
00049         if (!search)
00050         {
00051           lua_pushnil(l);
00052           return 1;
00053         }
00054         lua::push_raw<nlohmann::json>(l, *search);
00055         return 1;
00056       }
00057 
00058       /**
00059        * @brief Callable from lua.
00060        * Expects the following arguments from lua.
00061        * #1 (-2): self/table
00062        * #2 (-1): key
00063        * @param l
00064        * @return int
00065        */
00066       static int get_globally_committed(lua_State* l)
00067       {
00068         constexpr int n_args = 2;
00069         sanitize_stack_idx(l, n_args);
00070 
00071         auto tx = UD::unbox(l, -2);
00072         const K key = lua::check_get<nlohmann::json>(l, -1);
00073         const auto search = tx->get_globally_committed(key);
00074         if (!search)
00075         {
00076           lua_pushnil(l);
00077           return 1;
00078         }
00079         lua::push_raw<nlohmann::json>(l, *search);
00080         return 1;
00081       }
00082 
00083       /**
00084        * @brief Callable from lua.
00085        * Expects the following arguments from lua.
00086        * #1 (-3): self/table
00087        * #2 (-2): key
00088        * #3 (-1): value
00089        *
00090        * @param l
00091        * @return int
00092        */
00093       static int put(lua_State* l)
00094       {
00095         constexpr int n_args = 3;
00096         sanitize_stack_idx(l, n_args);
00097 
00098         auto tx = UD::unbox(l, -3);
00099         const K key = lua::check_get<nlohmann::json>(l, -2);
00100         const V value = lua::check_get<nlohmann::json>(l, -1);
00101         const auto b = tx->put(key, value);
00102         lua_pushboolean(l, b);
00103         return 1;
00104       }
00105 
00106       static int remove(lua_State* l)
00107       {
00108         constexpr int n_args = 2;
00109         sanitize_stack_idx(l, n_args);
00110 
00111         auto tx = UD::unbox(l, -2);
00112         const K key = lua::check_get<nlohmann::json>(l, -1);
00113         const auto b = tx->remove(key);
00114         lua_pushboolean(l, b);
00115         return 1;
00116       }
00117 
00118       static int foreach(lua_State* l)
00119       {
00120         constexpr int n_args = 2;
00121         sanitize_stack_idx(l, n_args);
00122 
00123         const auto ifunc = absolute_stack_idx(l, -1);
00124         if (!lua_isfunction(l, ifunc))
00125         {
00126           lua_pushnil(l);
00127           return 1;
00128         }
00129 
00130         UD::unbox(l, -2)->foreach([l, ifunc](const K& k, const V& v) {
00131           // Dup the lua functor on the top of the stack
00132           lua_pushvalue(l, ifunc);
00133 
00134           // Translate the arguments using nlohmann::json and push them to the
00135           // stack
00136           lua::push_raw<nlohmann::json>(l, k);
00137           lua::push_raw<nlohmann::json>(l, v);
00138 
00139           // Call the lua functor. This pops the args and functor-copy
00140           const auto ret = lua_pcall(l, 2, 0, 0);
00141 
00142           if (ret != 0)
00143           {
00144             const auto err = lua::check_get<std::string>(l, -1);
00145             throw lua::ex(err);
00146           }
00147 
00148           return true;
00149         });
00150 
00151         return 0;
00152       }
00153     };
00154 
00155     template <typename T, typename X = T>
00156     const luaL_Reg kv_methods[] = {
00157       {"get", KvTable<T, X>::get},
00158       {"get_globally_committed", KvTable<T, X>::get_globally_committed},
00159       {"remove", KvTable<T, X>::remove},
00160       {"foreach", KvTable<T, X>::foreach},
00161       {"put", KvTable<T, X>::put},
00162       {nullptr, nullptr}};
00163 
00164     template <typename T, typename X = T>
00165     const luaL_Reg kv_methods_read_only[] = {
00166       {"get", KvTable<T, X>::get},
00167       {"get_globally_committed", KvTable<T, X>::get_globally_committed},
00168       {"foreach", KvTable<T, X>::foreach},
00169       {nullptr, nullptr}};
00170 
00171   } // namespace lua
00172 } // namespace ccf 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/lua_kv.h...
Preprocessing /data/git/CCF/src/lua_interp/lua_user_data.h...
#include lua_util.h: already included! skipping...
#include typeinfo: not found! skipping...
Preprocessor output (size: 4931 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 /**
00010  * @file lua_user_data.h
00011  * @brief Helper to hide common lua boilerplate
00012  *
00013  * To pass data from C++ to lua, we push userdata onto the stack. This
00014  * userdata is a simple box containing a pointer to the real data, with an
00015  * associated metatable containing the methods which can be called on it. The
00016  * real data is owned and managed in C++, only the box is garbage collected by
00017  * Lua. The metatable is identified and looked up by a string name, and the same
00018  * boxing boilerplate is needed for every type. This aims to cut down that
00019  * boilerplate, providing templated functions and removing any knowledge of
00020  * magic strings or the boxing process.
00021  *
00022  * For example, to wrap a simple Point struct:
00023  *
00024  * @code
00025  *    // The type we want to wrap
00026  *    struct Point
00027  *    {
00028  *      int x;
00029  *      int y;
00030  *    };
00031  *
00032  *    using PointUD = UserData<Point>;
00033  *
00034  *    // Define some lua C functions, using unbox
00035  *    static int get_x(lua_State* l)
00036  *    {
00037  *      const auto p = PointUD::unbox(l);
00038  *      lua_pushinteger(l, p->x);
00039  *      return 1;
00040  *    }
00041  *
00042  *    static int set_x(lua_State* l)
00043  *    {
00044  *      auto p = PointUD::unbox(l);
00045  *      auto n = luaL_checkinteger(l, 2);
00046  *      p->x = n;
00047  *      return 0;
00048  *    }
00049  *
00050  *    ...
00051  *
00052  *    // Associate functions with the names they'll be called from in lua
00053  *    constexpr luaL_Reg point_metatable_methods[] = {{"getx", get_x},
00054  *      {"setx", set_x}, ... {nullptr, nullptr}};
00055  * @endcode
00056  *
00057  * Then you can pass a Point to Interpreter:
00058  *
00059  * @code
00060  *    auto li = Interpreter();
00061  *    li.register_metatable<Point>(point_metatable_methods);
00062  *
00063  *    Point p;
00064  *    li.invoke<...>(..., &p);
00065  * @endcode
00066  *
00067  * And access it from lua:
00068  *
00069  * @code
00070  *    local p = ...
00071  *    local n = p:getx();
00072  *    p:setx(n + 5);
00073  *    ...
00074  * @endcode
00075  *
00076  */
00077 namespace ccf
00078 {
00079   namespace lua
00080   {
00081     template <typename T, typename X = T>
00082     struct UserData
00083     {
00084       /**
00085        * Returns a name for looking up the type's metatable
00086        *
00087        * The metatable for this type is looked up and registered by string, but
00088        * that is entirely an internal implementation detail. We could require
00089        * users to declare a static string themselves but this is an ugly bit of
00090        * boilerplate, with no guarantee of uniqueness. Instead we rely on
00091        * typeid, which may be mangled but should give us the uniqueness we're
00092        * looking for.
00093        */
00094       static const char* metatable_name()
00095       {
00096         return typeid(X).name();
00097       }
00098 
00099       /**
00100        * Pushes userdata onto the lua stack which wraps the given data.
00101        *
00102        * A metatable for T must have set in l, else an exception will be thrown.
00103        * The caller is responsible for ensuring that d remains valid.
00104        */
00105       static void push_boxed(lua_State* l, T* d)
00106       {
00107         auto p = reinterpret_cast<T**>(lua_newuserdata(l, sizeof(d)));
00108         auto name = metatable_name();
00109         if (luaL_getmetatable(l, name) == LUA_TNIL)
00110           throw ex("Metatable not registered");
00111 
00112         lua_setmetatable(l, -2);
00113         *p = d;
00114       }
00115 
00116       /**
00117        * Checks the item on the lua stack at the given position is of the
00118        * correct type, and returns a raw pointer to the wrapped data.
00119        *
00120        * CAUTION: arg here means the n-th (1-based) arg to the function.
00121        *  Lua-style negative indexing does not work.
00122        */
00123       static T* unbox(lua_State* l, int arg = 1)
00124       {
00125         return *reinterpret_cast<T**>(
00126           luaL_checkudata(l, arg, metatable_name()));
00127       }
00128     };
00129 
00130     /**
00131      * @brief specialization of push_raw() that 'boxes' pointers.
00132      * Disabled for const char* as we want to treat those as strings (see
00133      * lua_util.h).
00134      *
00135      * @tparam T object type of the pointer
00136      * @param l Lua context
00137      * @param p the pointer
00138      */
00139     template <
00140       typename T,
00141       /* exclude const char* */
00142       typename = std::enable_if_t<!std::is_same_v<T, const char>>>
00143     void push_raw(lua_State* l, T* p)
00144     {
00145       UserData<T>::push_boxed(l, p);
00146     }
00147 
00148     /**
00149      * @brief Wrapper class for specifying "extended types" for metatable
00150      * registration. This addresses the problem of registering different
00151      * metatables for a single C++ type. (With the basic UserData only a single
00152      * metatable can be registered per type.)
00153      *
00154      * @tparam T the actual type of the pointer that is to be pushd to Lua
00155      * @tparam X an arbitrary type "modifier"; likely s.th. likely an empty type
00156      * like struct M {};
00157      */
00158     template <typename T, typename X>
00159     struct UserDataExt
00160     {
00161       T* p;
00162     };
00163 
00164     template <typename T, typename X>
00165     void push_raw(lua_State* l, const UserDataExt<T, X>& udx)
00166     {
00167       UserData<T, UserDataExt<T, X>>::push_boxed(l, udx.p);
00168     }
00169 
00170   } // namespace lua
00171 } // namespace ccf 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/lua_user_data.h...
Preprocessing /data/git/CCF/src/lua_interp/lua_util.h...
#include fmt/format.h: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
#include type_traits: not found! skipping...
#include vector: not found! skipping...
#include ../../3rdparty/lua/lauxlib.h: not found! skipping...
#include ../../3rdparty/lua/lua.h: not found! skipping...
Preprocessor output (size: 5464 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 #define FMT_HEADER_ONLY
00006 
00007 
00008 
00009 
00010 
00011 extern "C"
00012 {
00013 
00014 
00015 }
00016 
00017 namespace ccf
00018 {
00019   namespace lua
00020   {
00021     /** Lua exception
00022      */
00023     class ex : public std::logic_error
00024     {
00025       using logic_error::logic_error;
00026     };
00027 
00028     /**
00029      * @brief Sanitize a possibly relative stack index
00030      *
00031      * @param l Lua context
00032      * @param idx stack index
00033      * @return int if the stack index is negative/relative, the absolute index
00034      * is returned.
00035      */
00036     inline int sanitize_stack_idx(lua_State* l, int idx)
00037     {
00038       const auto stack_size = lua_gettop(l);
00039       if (stack_size < abs(idx))
00040         throw ex("Index exceeds stack size.");
00041 
00042       // if arg is a negative relative index, make it absolute
00043       return idx < 0 ? stack_size + 1 + idx : idx;
00044     }
00045 
00046     /**
00047      * @brief Get the absolute stack index from a negative/relative one.
00048      *
00049      * @param l Lua context
00050      * @param idx stack index
00051      * @return int the absolute index
00052      */
00053     inline int absolute_stack_idx(lua_State* l, int idx)
00054     {
00055       const auto stack_size = lua_gettop(l);
00056       return idx < 0 ? stack_size + 1 + idx : idx;
00057     }
00058 
00059     static void expect_top(lua_State* l, int i)
00060     {
00061       const auto actual = lua_gettop(l);
00062       if (actual != i)
00063       {
00064         throw ex(fmt::format(
00065           "Expected {} items in Lua stack, actually have {}", i, actual));
00066       }
00067     }
00068 
00069     inline void push_raw(lua_State* l, const char* s)
00070     {
00071       lua_pushstring(l, s);
00072     }
00073 
00074     inline void push_raw(lua_State* l, int i)
00075     {
00076       lua_pushinteger(l, i);
00077     }
00078 
00079     inline void push_raw(lua_State* l, uint64_t i)
00080     {
00081       lua_pushinteger(l, (lua_Integer)i);
00082     }
00083 
00084     inline void push_raw(lua_State* l, double d)
00085     {
00086       lua_pushnumber(l, d);
00087     }
00088 
00089     inline void push_raw(lua_State* l, bool b)
00090     {
00091       lua_pushboolean(l, b);
00092     }
00093 
00094     inline void push_raw(lua_State* l, std::nullptr_t)
00095     {
00096       lua_pushnil(l);
00097     }
00098 
00099     /** The base push case. Specialize this to push other types onto the lua
00100      * stack.
00101      */
00102     template <typename T>
00103     void push_raw(lua_State*, const T&)
00104     {
00105       static_assert(
00106         std::is_empty<T>::value,
00107         "Unsupported type for Lua stack object (push).");
00108     }
00109 
00110     template <>
00111     inline void push_raw(lua_State* l, const std::string& s)
00112     {
00113       lua_pushstring(l, s.c_str());
00114     }
00115 
00116     template <typename F0, typename F1>
00117     auto check_and_convert(lua_State* l, int arg, F0 check, F1 convert)
00118     {
00119       arg = sanitize_stack_idx(l, arg);
00120       const auto stack_before = lua_gettop(l);
00121 
00122       const auto check_ok = check(l, arg); // e.g., lua_isnumber()
00123       expect_top(l, stack_before);
00124       if (!check_ok)
00125         throw ex("Lua stack object has wrong type.");
00126 
00127       const auto convert_result =
00128         convert(l, arg, nullptr); // e.g., lua_tonumberx()
00129       expect_top(l, stack_before);
00130       return convert_result;
00131     }
00132 
00133     template <typename F0, typename F1>
00134     auto top_of_stack(lua_State* l, F0 check, F1 convert)
00135     {
00136       return check_and_convert(l, -1, check, convert);
00137     }
00138 
00139     template <typename T>
00140     inline T check_get(lua_State*, int)
00141     {
00142       static_assert(
00143         std::is_empty<T>::value,
00144         "Unsupported type for Lua stack object (check_get).");
00145       return {};
00146     }
00147 
00148     template <>
00149     inline int check_get(lua_State* l, int arg)
00150     {
00151       return check_and_convert(l, arg, lua_isinteger, lua_tointegerx);
00152     }
00153 
00154     template <>
00155     inline uint64_t check_get(lua_State* l, int arg)
00156     {
00157       return (uint64_t)check_get<int>(l, arg);
00158     }
00159 
00160     template <>
00161     inline double check_get(lua_State* l, int arg)
00162     {
00163       return check_and_convert(l, arg, lua_isnumber, lua_tonumberx);
00164     }
00165 
00166     template <>
00167     inline std::string check_get(lua_State* l, int arg)
00168     {
00169       return std::string(
00170         check_and_convert(l, arg, lua_isstring, lua_tolstring));
00171     }
00172 
00173     template <>
00174     inline bool check_get(lua_State* l, int arg)
00175     {
00176       return check_and_convert(
00177         l,
00178         arg,
00179         [](lua_State* L, int n) { return lua_isboolean(L, n); },
00180         [](lua_State* L, int n, void*) { return lua_toboolean(L, n) != 0; });
00181     }
00182 
00183     template <>
00184     inline std::nullptr_t check_get(lua_State* l, int arg)
00185     {
00186       return check_and_convert(
00187         l,
00188         arg,
00189         [](lua_State* L, int n) { return lua_isnil(L, n); },
00190         [](lua_State*, int, void*) { return nullptr; });
00191     }
00192 
00193     template <typename T>
00194     inline T get_top(lua_State* l)
00195     {
00196       return check_get<T>(l, -1);
00197     }
00198 
00199     /**
00200      * @brief Compile Lua script to bytecode.
00201      *
00202      * @param script the Lua script
00203      * @return std::vector<uint8_t> the compiled bytecode
00204      */
00205     inline std::vector<uint8_t> compile(const std::string& script)
00206     {
00207       auto l = luaL_newstate();
00208       if (luaL_loadbuffer(l, script.c_str(), script.size(), nullptr))
00209         throw lua::ex("Failed to load Lua code (compile)");
00210 
00211       std::vector<uint8_t> b;
00212       lua_dump(
00213         l,
00214         [](lua_State*, const void* p, size_t sz, void* v) {
00215           auto const _v = reinterpret_cast<std::vector<uint8_t>*>(v);
00216           auto const _p = reinterpret_cast<const uint8_t*>(p);
00217           _v->insert(_v->end(), _p, _p + sz);
00218           return 0;
00219         },
00220         &b,
00221         1); // strip debug symbols
00222       lua_close(l);
00223       return b;
00224     }
00225 
00226   } // namespace lua
00227 } // namespace ccf
00228 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/lua_util.h...
Preprocessing /data/git/CCF/src/lua_interp/test/lua_kv.cpp...
#include lua_json.h: already included! skipping...
#include optional: not found! skipping...
#include ostream: not found! skipping...
#include sstream: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include ../../3rdparty/lua/lualib.h: not found! skipping...
#include lua_json.h: already included! skipping...
#include ds/hash.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include kv/kv_serialiser.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 10495 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/lua_interp/test/lua_kv.cpp" 2
00004 
00005 # 5 "/data/git/CCF/src/lua_interp/test/lua_kv.cpp" 2
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 using namespace ccf::lua;
00014 using namespace ccfapp;
00015 using namespace std;
00016 using namespace nlohmann;
00017 
00018 namespace ccf
00019 {
00020   using TableII = kv::Map<int, int>;
00021   using TxII = TableII::TxView;
00022 
00023   using TableIS = kv::Map<int, std::string>;
00024   using TxIS = TableIS::TxView;
00025 
00026   using TableSB = kv::Map<std::string, bool>;
00027   using TxSB = TableSB::TxView;
00028 
00029   using TableVI = kv::Map<vector<uint8_t>, int>;
00030   using TxVI = TableVI::TxView;
00031 
00032   TEST_CASE("lua tx")
00033   {
00034     kv::Store tables;
00035     TableIS table("public:test");
00036 
00037     auto txs = tables.create_tx();
00038 
00039     const auto a = "Alice";
00040     const auto b = "Bob";
00041 
00042     auto tx = txs.get_view(table);
00043     tx->put(0, a);
00044 
00045     auto li = Interpreter();
00046     li.register_metatable<TxIS>(kv_methods<TxIS>);
00047 
00048     SUBCASE("basic")
00049     {
00050       constexpr auto code(
00051         "local tx, a, b = ...;"
00052         "if tx:get(0) ~= a then return 'tx get failed' end;"
00053 
00054         "if tx:get(1) ~= nil then return 'index 1 already populated' end;"
00055         "tx:put(1, '');"
00056         "if tx:get(1) ~= '' then return 'tx put failed' end;"
00057 
00058         "tx:put(1, b);"
00059         "if tx:get(1) ~= b then return 'tx overwrite failed' end;");
00060 
00061       li.invoke<nullptr_t>(code, tx, a, b);
00062 
00063       const auto res0 = tx->get(0);
00064       REQUIRE(res0.has_value());
00065       REQUIRE(res0.value() == a);
00066 
00067       const auto res1 = tx->get(1);
00068       REQUIRE(res1.has_value());
00069       REQUIRE(res1.value() == b);
00070 
00071       REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00072     }
00073 
00074     SUBCASE("all methods")
00075     {
00076       constexpr auto count_keys(
00077         "local tx = ...;"
00078         "local n = 0;"
00079         "tx:foreach( function(k, v) n = n + 1 end );"
00080         "return n");
00081       constexpr auto foreach_error(
00082         "tx:foreach( function(k, v) nil = nil + nil end )");
00083       constexpr auto put(
00084         "local tx, k, v = ...;"
00085         "return tx:put(k, v)");
00086       constexpr auto get(
00087         "local tx, k = ...;"
00088         "return tx:get(k)");
00089       constexpr auto get_globally_committed(
00090         "local tx, k = ...;"
00091         "return tx:get_globally_committed(k)");
00092       constexpr auto remove(
00093         "local tx, n = ...;"
00094         "return tx:remove(n)");
00095       constexpr auto k = 0;
00096       constexpr auto s0 = "Something";
00097       constexpr auto s1 = "Something else";
00098 
00099       INFO("1 key initially");
00100       {
00101         REQUIRE(li.invoke<int>(count_keys, tx) == 1);
00102       }
00103 
00104       INFO("Added key is counted");
00105       {
00106         REQUIRE(li.invoke<bool>(put, tx, 1, b));
00107         REQUIRE(li.invoke<int>(count_keys, tx) == 2);
00108       }
00109 
00110       INFO("Same key is not counted twice");
00111       {
00112         REQUIRE(li.invoke<bool>(put, tx, 1, b));
00113         REQUIRE(li.invoke<int>(count_keys, tx) == 2);
00114       }
00115 
00116       INFO("Removed key is not counted");
00117       {
00118         REQUIRE(li.invoke<bool>(remove, tx, 1));
00119         REQUIRE(li.invoke<int>(count_keys, tx) == 1);
00120       }
00121 
00122       INFO("Transaction is committed");
00123       {
00124         REQUIRE(tx->put(k, s0));
00125         REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00126       }
00127 
00128       INFO("get_commit from lua");
00129       {
00130         tables.compact(tables.current_version());
00131 
00132         auto next_txs = tables.create_tx();
00133         auto next_tx = next_txs.get_view(table);
00134 
00135         REQUIRE(next_tx->put(k, s1));
00136 
00137         INFO("get and get_globally_committed may return different values");
00138         {
00139           REQUIRE(li.invoke<string>(get_globally_committed, next_tx, k) == s0);
00140           REQUIRE(li.invoke<string>(get, next_tx, k) == s1);
00141         }
00142 
00143         INFO("get_globally_committed for a new key returns nil");
00144         {
00145           const auto next_k = k + 1;
00146           REQUIRE(next_tx->put(next_k, s1));
00147           REQUIRE(
00148             li.invoke<nullptr_t>(get_globally_committed, next_tx, next_k) ==
00149             nullptr);
00150         }
00151 
00152         REQUIRE(next_txs.commit() == kv::CommitSuccess::OK);
00153       }
00154 
00155       INFO("Errors caught in foreach");
00156       {
00157         REQUIRE_THROWS_AS(li.invoke<int>(foreach_error, tx), lua::ex);
00158       }
00159     }
00160   }
00161 
00162   TEST_CASE("multiple tables")
00163   {
00164     kv::Store tables;
00165     TableII ii("public:test_ii");
00166     TableIS is("public:test_is");
00167     TableSB sb("public:test_sb");
00168 
00169     auto txs = tables.create_tx();
00170     auto tx = txs.get_view(ii, is, sb);
00171     auto tx_ii = get<0>(tx);
00172     auto tx_is = get<1>(tx);
00173     auto tx_sb = get<2>(tx);
00174 
00175     auto li = Interpreter();
00176     li.register_metatable<TxII>(kv_methods<TxII>);
00177     li.register_metatable<TxIS>(kv_methods<TxIS>);
00178     li.register_metatable<TxSB>(kv_methods<TxSB>);
00179 
00180     constexpr auto code(
00181       "local i_to_i, i_to_s, s_to_b = ...;"
00182 
00183       "local l = {1, 2, 3, 4, 5, 6, 7};"
00184 
00185       "for _, n in ipairs(l) do"
00186       "  assert(i_to_i:put(n, math.tointeger(n^n)));"
00187       "end;"
00188 
00189       "for _, n in ipairs(l) do"
00190       "  local pow = i_to_i:get(n);"
00191       "  assert(i_to_s:put(pow, tostring(pow)));"
00192       "end;"
00193 
00194       "for _, n in ipairs(l) do"
00195       "  local pow = i_to_i:get(n);"
00196       "  local s = i_to_s:get(pow);"
00197       "  local contains_n = s:find(tostring(n)) ~= nil;"
00198       "  assert(s_to_b:put(s, contains_n));"
00199       "end;");
00200 
00201     li.invoke<nullptr_t>(code, tx_ii, tx_is, tx_sb);
00202 
00203     // Does string(n**n) contain string(n)?
00204     auto expect_result = [tx_ii, tx_is, tx_sb](int n, auto s, bool b) {
00205       auto r_ii = tx_ii->get(n);
00206       REQUIRE(r_ii.has_value());
00207       REQUIRE(r_ii.value() == pow(n, n));
00208 
00209       auto r_is = tx_is->get(r_ii.value());
00210       REQUIRE(r_is.has_value());
00211       REQUIRE(r_is.value() == s);
00212 
00213       auto r_sb = tx_sb->get(r_is.value());
00214       REQUIRE(r_sb.has_value());
00215       REQUIRE(r_sb.value() == b);
00216     };
00217 
00218     expect_result(1, "1", true);
00219     expect_result(2, "4", false);
00220     expect_result(3, "27", false);
00221     expect_result(4, "256", false);
00222     expect_result(5, "3125", true);
00223     expect_result(6, "46656", true);
00224     expect_result(7, "823543", false);
00225 
00226     REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00227   }
00228 
00229   TEST_CASE("vector as index")
00230   {
00231     Interpreter li;
00232     li.register_metatable<TxVI>(kv_methods<TxVI>);
00233 
00234     kv::Store tables;
00235     TableVI table("v");
00236     auto txs = tables.create_tx();
00237     auto tx = txs.get_view(table);
00238     tx->put(vector<uint8_t>(100, 1), 123);
00239 
00240     SUBCASE("read 1")
00241     {
00242       constexpr auto code(
00243         "local tx = ...;"
00244         "a = {}"
00245         "for i=1, 100 do a[i] = 1 end;"
00246         "return tx:get(a) == 123;");
00247 
00248       REQUIRE(li.invoke<bool>(code, tx));
00249     }
00250 
00251     SUBCASE("write 1")
00252     {
00253       constexpr auto code(
00254         "local tx = ...;"
00255         "a = {}"
00256         "for i=1, 100 do a[i] = i end;"
00257         "tx:put(a, 321)");
00258 
00259       li.invoke<nullptr_t>(code, tx);
00260       vector<uint8_t> v(100);
00261       std::iota(v.begin(), v.end(), 1);
00262       REQUIRE(tx->get(v) == 321);
00263     }
00264 
00265     SUBCASE("write many")
00266     {
00267       constexpr auto code(
00268         "local tx = ...;"
00269         "for i=1, 100 do tx:put({i,i}, i) end;");
00270 
00271       li.invoke<nullptr_t>(code, tx);
00272       for (uint8_t i = 1; i <= 100; i++)
00273         REQUIRE(tx->get({i, i}) == i);
00274     }
00275   }
00276 
00277   TEST_CASE("simple bank")
00278   {
00279     static constexpr auto code = R"xxx(
00280   tx, caller, id, method, params = ...
00281 
00282   function jsucc(id, result)
00283     return {serdes = "2.0", id = id, result = result}
00284   end
00285 
00286   function jerr(id, code, message)
00287     return {serdes = "2.0", id = id, error = {code = code, message = message}}
00288   end
00289 
00290   handlers = {}
00291   function handlers.SB_create()
00292     local dst = params.dst
00293     if tx:get(dst) ~= nil then
00294       return jerr(id, -32602, "account already exists")
00295     end
00296 
00297     tx:put(dst, params.amt)
00298     return jsucc(id, 1)
00299   end
00300 
00301   function handlers.SB_read()
00302     local acc = params.account
00303     local amt = tx:get(acc)
00304     if amt == nil then
00305       return jerr(id, -32602, "account " .. acc .. " does not exist")
00306     end
00307 
00308     return jsucc(id, amt)
00309   end
00310 
00311   function handlers.SB_transfer()
00312     local src = params.src
00313     local dst = params.dst
00314     local src_n = tx:get(src)
00315     if src_n == nil then
00316       return jerr(id, -32602, "source account does not exist")
00317     end
00318 
00319     local dst_n = tx:get(dst)
00320     if dst_n == nil then
00321       return jerr(id, -32602, "destination account does not exist")
00322     end
00323 
00324     local amt = params.amt
00325     if src_n < amt then
00326       return jerr(id, -32602, "insufficient funds")
00327     end
00328 
00329     tx:put(src, src_n - amt)
00330     tx:put(dst, dst_n + amt)
00331 
00332     return jsucc(id, 1)
00333   end
00334 
00335   return handlers[method]()
00336   )xxx";
00337 
00338     kv::Store tables;
00339     TableII table("public:t");
00340     auto txs = tables.create_tx();
00341     auto tx = txs.get_view(table);
00342 
00343     auto create = [tx](int dst, int amt) {
00344       json params;
00345       params["dst"] = dst;
00346       params["amt"] = amt;
00347       Interpreter li;
00348       li.register_metatable<TxII>(kv_methods<TxII>);
00349       const auto r = li.invoke<json>(code, tx, 1, 1, "SB_create", params);
00350       REQUIRE(r.find("error") == r.end());
00351       REQUIRE(tx->get(dst) == amt);
00352     };
00353 
00354     auto read = [tx](int acc, int expected) {
00355       json params;
00356       params["account"] = acc;
00357       Interpreter li;
00358       li.register_metatable<TxII>(kv_methods<TxII>);
00359       const auto r = li.invoke<json>(code, tx, 1, 1, "SB_read", params);
00360       REQUIRE(int(r["result"]) == expected);
00361     };
00362 
00363     auto transfer = [tx](int src, int dst, int amt) {
00364       json params;
00365       params["src"] = src;
00366       params["dst"] = dst;
00367       params["amt"] = amt;
00368       const auto dst_before = tx->get(dst);
00369       const auto src_before = tx->get(src);
00370 
00371       Interpreter li;
00372       li.register_metatable<TxII>(kv_methods<TxII>);
00373       const auto r = li.invoke<json>(code, tx, 1, 1, "SB_transfer", params);
00374       REQUIRE(r.find("error") == r.end());
00375       REQUIRE(*tx->get(dst) == *dst_before + amt);
00376       REQUIRE(*tx->get(src) == *src_before - amt);
00377     };
00378 
00379     create(1, 234);
00380     read(1, 234);
00381 
00382     create(5, 678);
00383     read(5, 678);
00384 
00385     transfer(1, 5, 7);
00386     read(5, 685);
00387   }
00388 
00389   TEST_CASE("read-only")
00390   {
00391     constexpr auto put(
00392       "local tx, k, v = ...;"
00393       "return tx:put(k, v)");
00394     constexpr auto get(
00395       "local tx, k = ...;"
00396       "return tx:get(k)");
00397 
00398     kv::Store tables;
00399     TableII table("public:t");
00400     auto txs = tables.create_tx();
00401     auto tx = txs.get_view(table);
00402 
00403     Interpreter li;
00404     li.register_metatable<TxII>(kv_methods_read_only<TxII>);
00405     tx->put(1, 2);
00406 
00407     // read works
00408     REQUIRE(li.invoke<int>(get, tx, 1) == 2);
00409     // write doesn't
00410     REQUIRE_THROWS_AS(li.invoke<bool>(put, tx, 1, 3), lua::ex);
00411   }
00412 }
00413 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/test/lua_kv.cpp...
Preprocessing /data/git/CCF/src/lua_interp/test/lua_test.cpp...
#include ../lua_interp.h: already included! skipping...
#include ../lua_json.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include map: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 10251 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 
00010 
00011 
00012 using namespace ccf;
00013 using namespace ccf::lua;
00014 using namespace std;
00015 
00016 static constexpr auto retnil = "return nil";
00017 static constexpr auto ret5 = "return 5";
00018 static constexpr auto mulab = "local a, b = ...; return a*b";
00019 
00020 TEST_CASE("return constant")
00021 {
00022   REQUIRE(Interpreter().invoke<int>(ret5) == 5);
00023 }
00024 
00025 TEST_CASE("wrong return type")
00026 {
00027   REQUIRE_THROWS_AS(Interpreter().invoke<bool>(ret5), lua::ex);
00028 }
00029 
00030 TEST_CASE("return nil")
00031 {
00032   REQUIRE(Interpreter().invoke<std::nullptr_t>(retnil) == nullptr);
00033 }
00034 
00035 TEST_CASE("pass nil")
00036 {
00037   REQUIRE(Interpreter().invoke<bool>("return ... == nil", nullptr));
00038 }
00039 
00040 TEST_CASE("basic number multiplication")
00041 {
00042   constexpr auto a = 5;
00043   constexpr auto b = 4;
00044   REQUIRE(Interpreter().invoke<int>(mulab, a, b) == a * b);
00045 
00046   // Extra arguments are ignored
00047   REQUIRE(Interpreter().invoke<int>(mulab, a, b, a) == a * b);
00048   REQUIRE(Interpreter().invoke<int>(mulab, a, b, b) == a * b);
00049   REQUIRE(Interpreter().invoke<int>(mulab, a, b, nullptr, nullptr) == a * b);
00050   REQUIRE(
00051     Interpreter().invoke<int>(mulab, a, b, "Extra nonsense", nullptr, a) ==
00052     a * b);
00053 }
00054 
00055 TEST_CASE("compile bytecode")
00056 {
00057   constexpr auto a = 5;
00058   constexpr auto b = 4;
00059   const auto code = compile(mulab);
00060 
00061   REQUIRE(
00062     Interpreter().invoke<int>(code, b, a) ==
00063     Interpreter().invoke<int>(mulab, b, a));
00064 }
00065 
00066 TEST_CASE("compare doubles")
00067 {
00068   constexpr auto a = 1.1;
00069   constexpr auto b = 1.2;
00070   REQUIRE(
00071     Interpreter().invoke<bool>("local a,b = ...; return a >= b", a, b) ==
00072     false);
00073   REQUIRE(
00074     Interpreter().invoke<bool>("local a,b = ...; return b > a", a, b) == true);
00075 }
00076 
00077 TEST_CASE("multiple invokes")
00078 {
00079   auto a = 1;
00080   auto b = 2;
00081   constexpr auto return_arg("local n = ...; return n");
00082 
00083   constexpr auto set_global("g = ...; return g");
00084   constexpr auto get_global("return g");
00085 
00086   auto li = Interpreter();
00087 
00088   REQUIRE(li.invoke<int>(ret5) == 5);
00089   REQUIRE(li.invoke<int>(ret5) == 5);
00090 
00091   REQUIRE(li.invoke<int>(return_arg, a) == a);
00092   REQUIRE(li.invoke<int>(return_arg, b) == b);
00093 
00094   REQUIRE(li.invoke<int>(set_global, a) == a);
00095   REQUIRE(li.invoke<int>(get_global) == a);
00096   REQUIRE(li.invoke<int>(return_arg, b) == b);
00097   REQUIRE(li.invoke<int>(get_global) == a);
00098 }
00099 
00100 TEST_CASE("build and modify table")
00101 {
00102   constexpr auto a = 5;
00103   constexpr auto b = 4;
00104   constexpr auto code(
00105     "local a,b = ...;"
00106     "local t = {};"
00107     "t.x = a;"
00108     "t.y = b;"
00109     "t.result = a * b;"
00110     "return t.result");
00111 
00112   REQUIRE(Interpreter().invoke<int>(code, a, b) == a * b);
00113 }
00114 
00115 TEST_CASE("access modules")
00116 {
00117   REQUIRE(Interpreter().invoke<bool>("return nil ~= math"));
00118   REQUIRE(
00119     Interpreter().invoke<int>("return math.maxinteger") == (int)LUA_MAXINTEGER);
00120 
00121   REQUIRE(Interpreter().invoke<bool>("return nil ~= string.reverse"));
00122   REQUIRE(
00123     Interpreter().invoke<std::string>(
00124       "return string.reverse(...)", "reverse") == "esrever");
00125 
00126   REQUIRE(Interpreter().invoke<bool>("return nil ~= table.sort"));
00127   REQUIRE(
00128     Interpreter().invoke<std::string>(
00129       "local t = {'d', 'a', 'c', 'b'}; table.sort(t); return t[2]") == "b");
00130 }
00131 
00132 namespace moduletest
00133 {
00134   static int foo(lua_State* l)
00135   {
00136     auto a = lua_tointeger(l, 1);
00137     auto b = lua_tointeger(l, 2);
00138     auto c = lua_tointeger(l, 3);
00139 
00140     lua_pushinteger(l, a + b + c);
00141     return 1;
00142   }
00143 
00144   static constexpr auto initial_bar = 3;
00145   static constexpr auto NAME = "test";
00146   static constexpr auto BAR = "bar";
00147 
00148   static constexpr luaL_Reg lib[] = {
00149     {"foo", foo}, {BAR, nullptr}, {nullptr, nullptr}};
00150 
00151   LUAMOD_API int open(lua_State* l)
00152   {
00153     luaL_newlib(l, lib);
00154     lua_pushnumber(l, initial_bar);
00155     lua_setfield(l, -2, BAR);
00156     return 1;
00157   }
00158 }
00159 
00160 TEST_CASE("user module")
00161 {
00162   constexpr auto n = 2;
00163   constexpr auto code(
00164     "local n = ...; local b = test.bar; test.bar = 7;"
00165     "return test.foo(n, b, test.bar)");
00166 
00167   auto li = Interpreter();
00168   li.load_module(moduletest::NAME, moduletest::open);
00169   REQUIRE(li.invoke<int>(code, n) == n + moduletest::initial_bar + 7);
00170 }
00171 
00172 namespace ccf
00173 {
00174   struct Point
00175   {
00176     int x = 2;
00177     int y = 3;
00178   };
00179 
00180   using PointUD = UserData<Point>;
00181 
00182   static int get_x(lua_State* l)
00183   {
00184     const auto p = PointUD::unbox(l);
00185     lua_pushinteger(l, p->x);
00186     return 1;
00187   }
00188 
00189   static int get_y(lua_State* l)
00190   {
00191     const auto p = PointUD::unbox(l);
00192     lua_pushinteger(l, p->y);
00193     return 1;
00194   }
00195 
00196   static int set_x(lua_State* l)
00197   {
00198     auto p = PointUD::unbox(l);
00199     auto n = luaL_checkinteger(l, 2);
00200     p->x = n;
00201     return 0;
00202   }
00203 
00204   static int set_y(lua_State* l)
00205   {
00206     auto p = PointUD::unbox(l);
00207     auto n = luaL_checkinteger(l, 2);
00208     p->y = n;
00209     return 0;
00210   }
00211 
00212   constexpr luaL_Reg point_metatable_methods[] = {{"getX", get_x},
00213                                                   {"getY", get_y},
00214                                                   {"setX", set_x},
00215                                                   {"setY", set_y},
00216                                                   {nullptr, nullptr}};
00217 }
00218 
00219 TEST_CASE("boxed user data")
00220 {
00221   Point p;
00222 
00223   auto li = Interpreter();
00224   li.register_metatable<Point>(point_metatable_methods);
00225 
00226   constexpr auto getsum(
00227     "local p = ...;"
00228     "return p:getX() + p:getY()");
00229 
00230   SUBCASE("access")
00231   {
00232     REQUIRE(li.invoke<int>(getsum, &p) == p.x + p.y);
00233   }
00234 
00235   SUBCASE("modify")
00236   {
00237     Point orig = p;
00238 
00239     constexpr auto doubler(
00240       "local p = ...;"
00241       "p:setX(p:getX() * 2);"
00242       "p:setY(p:getY() * 2)");
00243 
00244     li.invoke<std::nullptr_t>(doubler, &p);
00245     REQUIRE(p.x == orig.x * 2);
00246     REQUIRE(p.y == orig.y * 2);
00247     REQUIRE(li.invoke<int>(getsum, &p) == p.x + p.y);
00248   }
00249 }
00250 
00251 TEST_CASE("json")
00252 {
00253   SUBCASE("null")
00254   {
00255     const nlohmann::json j;
00256     REQUIRE(Interpreter().invoke<bool>("return nil == ...", j));
00257   }
00258 
00259   SUBCASE("int")
00260   {
00261     constexpr int n = 666;
00262     const nlohmann::json j = n;
00263     REQUIRE(Interpreter().invoke<int>("return ...", n) == n);
00264   }
00265 
00266   SUBCASE("string")
00267   {
00268     constexpr auto s = "Round trip me";
00269     const nlohmann::json j = s;
00270     REQUIRE(Interpreter().invoke<std::string>("return ...", s) == s);
00271   }
00272 
00273   SUBCASE("table")
00274   {
00275     const nlohmann::json j = {
00276       {"pi", 3.141},
00277       {"happy", true},
00278       {"name", "Niels"},
00279       {"nothing", nullptr},
00280       {"answer", {{"everything", 42}}},
00281       {"list", {1, 0, 2}},
00282       {"object", {{"currency", "USD"}, {"value", 42.99}}}};
00283 
00284     constexpr auto code(
00285       "local j, s = ...;"
00286       "if not j.happy then return 'unhappy' end;"
00287       "if j.name ~= s then return 'badly named' end;"
00288       "return j.pi + j.answer.everything");
00289 
00290     auto expected = (double)j["pi"] + (double)j["answer"]["everything"];
00291     auto actual = Interpreter().invoke<double>(code, j, j["name"]);
00292     REQUIRE(actual == expected);
00293   }
00294 
00295   SUBCASE("empty table")
00296   {
00297     constexpr auto code("return {}");
00298     const auto j = Interpreter().invoke<nlohmann::json>(code);
00299     // an empty table is supposed to be translated into an empty object
00300     REQUIRE(j.type() == nlohmann::json::value_t::object);
00301     REQUIRE(j.empty());
00302   }
00303 
00304   SUBCASE("empty array")
00305   {
00306     // With some work, it is possible to build a table that will become an empty
00307     // JSON array
00308     constexpr auto code(
00309       "t = {}; setmetatable(t, {__was_object = false}); return t");
00310     const auto j = Interpreter().invoke<nlohmann::json>(code);
00311     REQUIRE(j.type() == nlohmann::json::value_t::array);
00312     REQUIRE(j.empty());
00313   }
00314 
00315   SUBCASE("roundtrip empty object")
00316   {
00317     const auto j1 = nlohmann::json::object();
00318     constexpr auto code("a = ...; b = a; return b");
00319     const auto j2 = Interpreter().invoke<nlohmann::json>(code, j1);
00320     REQUIRE(j1 == j2);
00321   }
00322 
00323   SUBCASE("roundtrip empty array")
00324   {
00325     const auto j1 = nlohmann::json::array();
00326     constexpr auto code("a = ...; b = a; return b");
00327     const auto j2 = Interpreter().invoke<nlohmann::json>(code, j1);
00328     REQUIRE(j1 == j2);
00329   }
00330 }
00331 
00332 TEST_CASE("push table and attempt to print")
00333 {
00334   static constexpr auto script = R"xxx(
00335   t = ...
00336   return (t['a'] * t['b']) == 10 and t['d']
00337   )xxx";
00338 
00339   Interpreter interp;
00340   interp.push_code(script);
00341   interp.push_table("a", 5, "b", 2, "c", "x", "d", true);
00342 
00343   // write the stack to a stringstream
00344   stringstream ss;
00345   interp.print_stack(ss);
00346   REQUIRE(ss.str().length());
00347   REQUIRE(interp.invoke_raw<bool>(1) == true);
00348 }
00349 
00350 TEST_CASE("table parsing")
00351 {
00352   // this should be translated to an array (since there are consecutive indexes)
00353   constexpr auto valid = "return {1, 2}";
00354   vector<int> a = Interpreter().invoke<nlohmann::json>(valid);
00355   REQUIRE(a == vector<int>{1, 2});
00356 
00357   // this should throw, because it can neither be translated to an array, nor to
00358   // a map (because Json does not support integer keys) However, if we should
00359   // ever move away from json, this could work.
00360   constexpr auto invalid = "return {[1] = 1, [3] = 2}";
00361   REQUIRE_THROWS_AS(Interpreter().invoke<nlohmann::json>(invalid), lua::ex);
00362 }
00363 
00364 TEST_CASE("infinite loop prevention")
00365 {
00366   REQUIRE_THROWS_AS(Interpreter().invoke("while true do end"), lua::ex);
00367 
00368   {
00369     INFO("Callstack in error message");
00370 
00371     bool threw = false;
00372     try
00373     {
00374       Interpreter().invoke(R"xxx(
00375         function foo()
00376           local function baz()
00377             while true do end
00378           end
00379 
00380           t = {}
00381           function t:bar()
00382             while true do
00383               baz()
00384             end
00385           end
00386 
00387           while true do
00388             t.bar()
00389           end
00390         end
00391 
00392         foo()
00393       )xxx");
00394     }
00395     catch (const lua::ex& e)
00396     {
00397       threw = true;
00398       const std::string msg = e.what();
00399       REQUIRE(msg.find("baz") != std::string::npos);
00400       REQUIRE(msg.find("bar") != std::string::npos);
00401       REQUIRE(msg.find("foo") != std::string::npos);
00402     }
00403     REQUIRE(threw);
00404   }
00405 
00406   {
00407     constexpr auto script = R"xxx(
00408       n = 1
00409       for i = 1, 10 do
00410         n = n * 2
00411       end
00412     )xxx";
00413 
00414     Interpreter interp;
00415     REQUIRE_NOTHROW(interp.invoke(script));
00416 
00417     INFO("Execution limit can be adjusted");
00418     interp.set_execution_limit(10);
00419     REQUIRE_THROWS_AS(interp.invoke(script), lua::ex);
00420 
00421     INFO("Execution limit can be removed entirely");
00422     interp.remove_execution_limit();
00423     REQUIRE_NOTHROW(interp.invoke(script));
00424   }
00425 }
00426 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/lua_interp/test/lua_test.cpp...
Preprocessing /data/git/CCF/src/lua_interp/tx_script_runner.h...
#include lua_interp/lua_interp.h: not found! skipping...
#include lua_interp/lua_kv.h: not found! skipping...
#include node/network_tables.h: not found! skipping...
#include node/rpc/rpc_exception.h: not found! skipping...
#include sstream: not found! skipping...
#include type_traits: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 9206 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ccf
00015 {
00016   namespace lua
00017   {
00018     //! Describes a script to be run within a transaction
00019     struct TxScript
00020     {
00021       //! the script to run
00022       const Script script;
00023       //! [optional] the id of the write whitelist to apply
00024       std::optional<WlId> whitelist_write;
00025       //! [optional] the id of the read whitelist to apply
00026       std::optional<WlId> whitelist_read;
00027       //! [optional] script to setup the environment for the actual script
00028       std::optional<Script> env_script;
00029     };
00030 
00031     class TxScriptRunner
00032     {
00033     protected:
00034       static constexpr auto env_table_name = "env";
00035 
00036       /** Dummy type to distinguish writable from read-only tables at compile
00037        * time. Used to instantiate lua::UserDataExt for writable tables.
00038        */
00039       struct _W
00040       {};
00041 
00042       template <bool READ_ONLY>
00043       class TableCreator
00044       {
00045       private:
00046         template <typename T>
00047         using WT = lua::UserDataExt<T, _W>;
00048 
00049         template <typename T>
00050         static void register_meta(lua::Interpreter& li)
00051         {
00052           using TT = typename T::TxView;
00053           if constexpr (READ_ONLY)
00054             li.register_metatable<TT>(lua::kv_methods_read_only<TT>);
00055           else
00056             li.register_metatable<TT, WT<TT>>(lua::kv_methods<TT, WT<TT>>);
00057         }
00058 
00059         template <typename T>
00060         static void add_table(lua::Interpreter& li, kv::Tx& tx, T& table)
00061         {
00062           decltype(auto) name = table.get_name();
00063 
00064           using TT = typename T::TxView;
00065           auto view = tx.get_view(table);
00066           if constexpr (READ_ONLY)
00067             li.push(view);
00068           else
00069             li.push(WT<TT>{view});
00070           lua_setfield(li.get_state(), -2, name.c_str());
00071         }
00072 
00073         template <typename T, typename... Tables>
00074         static void process_tables(
00075           lua::Interpreter& li,
00076           kv::Tx& tx,
00077           const Whitelist& wl,
00078           T& table,
00079           Tables&... tables)
00080         {
00081           decltype(auto) name = table.get_name();
00082           if (wl.find(name) != wl.end())
00083           {
00084             register_meta<T>(li);
00085             add_table(li, tx, table);
00086           }
00087           process_tables(li, tx, wl, tables...);
00088         }
00089         static void process_tables(lua::Interpreter&, kv::Tx&, const Whitelist&)
00090         {}
00091 
00092         // helper method to expand parameters in the table tuple
00093         template <typename... T, std::size_t... Is>
00094         static void call_process_tables(
00095           lua::Interpreter& li,
00096           kv::Tx& tx,
00097           const Whitelist& wl,
00098           const std::tuple<T&...>& tables,
00099           std::index_sequence<Is...>)
00100         {
00101           process_tables(li, tx, wl, std::get<Is>(tables)...);
00102         }
00103 
00104       public:
00105         template <typename T>
00106         static void create(
00107           lua::Interpreter& li, kv::Tx& tx, const std::vector<T>& tables)
00108         {
00109           register_meta<T>(li);
00110           lua_newtable(li.get_state());
00111           for (decltype(auto) table : tables)
00112             add_table(li, tx, table);
00113         }
00114 
00115         template <typename... T>
00116         static void create(
00117           lua::Interpreter& li,
00118           kv::Tx& tx,
00119           const Whitelist& wl,
00120           const std::tuple<T&...>& tables)
00121         {
00122           lua_newtable(li.get_state());
00123           call_process_tables(
00124             li, tx, wl, tables, std::index_sequence_for<T...>());
00125         }
00126       };
00127 
00128       const NetworkTables& network_tables;
00129 
00130       static void load(lua::Interpreter& li, Script s)
00131       {
00132         if (s.bytecode)
00133           li.push_code(*s.bytecode);
00134         else if (s.text)
00135           li.push_code(*s.text);
00136         else
00137           throw std::logic_error("no bytecode or string to load as script");
00138       }
00139 
00140       Whitelist get_whitelist(kv::Tx& tx, WlId id) const
00141       {
00142         const auto wl = tx.get_view(network_tables.whitelists)->get(id);
00143         if (!wl)
00144           throw std::logic_error(
00145             "Whitelist with id: " + std::to_string(id) + " does not exist");
00146         return *wl;
00147       }
00148 
00149       [[noreturn]] static void lua_fail(const lua::ex& e)
00150       {
00151         std::stringstream ss;
00152         ss << "Script failed: " << e.what();
00153         throw RpcException(
00154           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00155           ccf::errors::InternalError,
00156           ss.str());
00157       }
00158 
00159       static std::string get_var_string_from_args(lua_State* l)
00160       {
00161         size_t args = lua_gettop(l);
00162         std::stringstream ss;
00163         for (size_t i = 1; i <= args; ++i)
00164         {
00165           const int type = lua_type(l, i);
00166           if (type != LUA_TNUMBER && type != LUA_TSTRING)
00167           {
00168             throw std::runtime_error(fmt::format(
00169               "Can only format lua args which are numbers or strings - got {}. "
00170               "Call tostring from within Lua",
00171               lua_typename(l, type)));
00172           }
00173           ss << lua_tostring(l, i);
00174         }
00175         return ss.str();
00176       }
00177 
00178       static int lua_log_trace(lua_State* l)
00179       {
00180         LOG_TRACE_FMT("{}", get_var_string_from_args(l));
00181         return 0;
00182       }
00183 
00184       static int lua_log_debug(lua_State* l)
00185       {
00186         LOG_DEBUG_FMT("{}", get_var_string_from_args(l));
00187         return 0;
00188       }
00189 
00190       static int lua_log_info(lua_State* l)
00191       {
00192         LOG_INFO_FMT("{}", get_var_string_from_args(l));
00193         return 0;
00194       }
00195 
00196       static int lua_log_fail(lua_State* l)
00197       {
00198         LOG_FAIL_FMT("{}", get_var_string_from_args(l));
00199         return 0;
00200       }
00201 
00202       static int lua_log_fatal(lua_State* l)
00203       {
00204         throw std::logic_error(get_var_string_from_args(l));
00205         return 0;
00206       }
00207 
00208       virtual void setup_environment(
00209         lua::Interpreter& li, const std::optional<Script>& env_script) const
00210       {
00211         auto l = li.get_state();
00212 
00213         // Register global logging functions
00214         lua_register(l, "LOG_TRACE", lua_log_trace);
00215         lua_register(l, "LOG_DEBUG", lua_log_debug);
00216         lua_register(l, "LOG_INFO", lua_log_info);
00217         lua_register(l, "LOG_FAIL", lua_log_fail);
00218         lua_register(l, "LOG_FATAL", lua_log_fatal);
00219 
00220         if (env_script)
00221         {
00222           load(li, *env_script);
00223           li.invoke_raw(0);
00224         }
00225       }
00226 
00227       virtual void add_custom_tables(lua::Interpreter&, kv::Tx&, int&) const {}
00228 
00229     public:
00230       /** Run a script transactionally in a given environment.
00231        *
00232        * For each given whitelist id (read or write, in TxScript), a table of
00233        * corresponding table objects is passed to the script as arguments. The
00234        * script can use those table objects to access the key-value store. For
00235        * example, if both a read and a write whitelist are specified, a script
00236        * with three arguments a,b,c would start as follows:
00237        *
00238        * tables_writable, tables_readable, a, b, c = ...
00239        * -- read members table
00240        * local member_0 = tables_readable["public:ccf.gov.members"]:get(0)
00241        *
00242        * Further, subclasses of this class may add custom tables by overriding
00243        * the add_custom_tables() method.
00244        *
00245        * @tparam T the return type of the script
00246        * @tparam Args the types of the arguments to the script
00247        * @param tx the transaction to run the script in
00248        * @param txs the script to run and corresponding parameters (i.e.,
00249        * read/write whitelists and environment script).
00250        * @param args the arguments to the script
00251        * @return T the result of the script
00252        */
00253       template <typename T, typename... Args>
00254       T run(kv::Tx& tx, const TxScript& txs, Args&&... args) const
00255       {
00256         lua::Interpreter li;
00257 
00258         // run an optional environment script
00259         setup_environment(li, txs.env_script);
00260 
00261         load(li, txs.script);
00262 
00263         // register writable and read-only tables with respect to the given
00264         // whitelists the table of writable tables will be pushed on the stack
00265         // first. the table of readable tables second
00266         int n_registered_tables = 0;
00267         add_custom_tables(li, tx, n_registered_tables);
00268 
00269         if (txs.whitelist_write || txs.whitelist_read)
00270         {
00271           auto tables = network_tables.get_scriptable_tables();
00272           if (txs.whitelist_write)
00273           {
00274             TableCreator<false>::create(
00275               li, tx, get_whitelist(tx, *txs.whitelist_write), tables);
00276             n_registered_tables++;
00277           }
00278 
00279           if (txs.whitelist_read)
00280           {
00281             TableCreator<true>::create(
00282               li, tx, get_whitelist(tx, *txs.whitelist_read), tables);
00283             n_registered_tables++;
00284           }
00285         }
00286         try
00287         {
00288           // no return if T == void
00289           if constexpr (std::is_same_v<T, void>)
00290             li.invoke_raw(n_registered_tables, std::forward<Args>(args)...);
00291           else
00292             return li.template invoke_raw<T>(
00293               n_registered_tables, std::forward<Args>(args)...);
00294         }
00295         catch (const lua::ex& e)
00296         {
00297           lua_fail(e);
00298         }
00299       }
00300 
00301       TxScriptRunner(NetworkTables& network_tables) :
00302         network_tables(network_tables)
00303       {}
00304 
00305       virtual ~TxScriptRunner(){};
00306     };
00307   }
00308 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/lua_interp/tx_script_runner.h...
Preprocessing /data/git/CCF/src/node/backup_signatures.h...
#include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/json.h: not found! skipping...
  #include limits: not found! skipping...
#include map: not found! skipping...
#include stdint.h: not found! skipping...
#include vector: not found! skipping...
#include vector: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 746 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/node/backup_signatures.h" 2
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct BackupSignatures
00015   {
00016     kv::Consensus::View view = 0;
00017     kv::Consensus::SeqNo seqno = 0;
00018     crypto::Sha256Hash root;
00019     std::vector<NodeSignature> signatures;
00020 
00021     MSGPACK_DEFINE(view, seqno, root, signatures);
00022 
00023     BackupSignatures() = default;
00024 
00025     BackupSignatures(
00026       kv::Consensus::View view_,
00027       kv::Consensus::SeqNo seqno_,
00028       const crypto::Sha256Hash root_) :
00029       view(view_),
00030       seqno(seqno_),
00031       root(root_)
00032     {}
00033   };
00034   DECLARE_JSON_TYPE(BackupSignatures);
00035 
00036   using BackupSignaturesMap = kv::Map<ObjectId, BackupSignatures>;
00037 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/backup_signatures.h...
Preprocessing /data/git/CCF/src/node/channels.h...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include entities.h: already included! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include entities.h: already included! skipping...
#include cstdint: not found! skipping...
#include limits: not found! skipping...
#include tls/key_exchange.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include mbedtls/ecdh.h: not found! skipping...
Preprocessor output (size: 13596 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 # 8 "/data/git/CCF/src/node/channels.h" 2
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   using SeqNo = uint64_t;
00019   using GcmHdr = crypto::GcmHeader<sizeof(SeqNo)>;
00020 
00021   struct RecvNonce
00022   {
00023     uint8_t tid;
00024     uint64_t nonce : (sizeof(uint64_t) - sizeof(uint8_t)) * CHAR_BIT;
00025 
00026     RecvNonce(uint64_t nonce_, uint8_t tid_) : tid(tid_), nonce(nonce_) {}
00027     RecvNonce(const uint64_t header)
00028     {
00029       *this = *reinterpret_cast<const RecvNonce*>(&header);
00030     }
00031 
00032     uint64_t get_val() const
00033     {
00034       return *reinterpret_cast<const uint64_t*>(this);
00035     }
00036   };
00037   static_assert(
00038     sizeof(RecvNonce) == sizeof(SeqNo), "RecvNonce is the wrong size");
00039 
00040   static inline RecvNonce get_nonce(const GcmHdr& header)
00041   {
00042     return RecvNonce(header.get_iv_int());
00043   }
00044 
00045   enum ChannelStatus
00046   {
00047     INITIATED = 0,
00048     ESTABLISHED
00049   };
00050 
00051   class Channel
00052   {
00053   private:
00054     struct OutgoingMsg
00055     {
00056       NodeMsgType type;
00057       std::vector<uint8_t> raw_plain; // To be integrity-protected
00058       std::vector<uint8_t> raw_cipher; // To be encrypted
00059 
00060       OutgoingMsg(
00061         NodeMsgType msg_type, CBuffer raw_plain_, CBuffer raw_cipher_) :
00062         type(msg_type),
00063         raw_plain(raw_plain_),
00064         raw_cipher(raw_cipher_)
00065       {}
00066     };
00067 
00068     NodeId self;
00069     tls::KeyPairPtr network_kp;
00070 
00071     // Notifies the host to create a new outgoing connection
00072     ringbuffer::WriterPtr to_host;
00073     NodeId peer_id;
00074     std::string peer_hostname;
00075     std::string peer_service;
00076     bool outgoing;
00077 
00078     // Used for key exchange
00079     tls::KeyExchangeContext ctx;
00080     ChannelStatus status = INITIATED;
00081 
00082     // Used for AES GCM authentication/encryption
00083     std::unique_ptr<crypto::KeyAesGcm> key;
00084 
00085     // Incremented for each tagged/encrypted message
00086     std::atomic<SeqNo> send_nonce{1};
00087 
00088     // Used to buffer at most one message sent on the channel before it is
00089     // established
00090     std::optional<OutgoingMsg> outgoing_msg;
00091 
00092     // Used to prevent replayed messages.
00093     // Set to the latest successfully received nonce.
00094     struct ChannelSeqno
00095     {
00096       SeqNo main_thread_seqno;
00097       SeqNo tid_seqno;
00098     };
00099     std::array<ChannelSeqno, threading::ThreadMessaging::max_num_threads>
00100       local_recv_nonce = {{}};
00101 
00102     bool verify_or_decrypt(
00103       const GcmHdr& header,
00104       CBuffer aad,
00105       CBuffer cipher = nullb,
00106       Buffer plain = {})
00107     {
00108       if (status != ESTABLISHED)
00109       {
00110         throw std::logic_error("Channel is not established for verifying");
00111       }
00112 
00113       RecvNonce recv_nonce(header.get_iv_int());
00114       auto tid = recv_nonce.tid;
00115 
00116       uint16_t current_tid = threading::get_current_thread_id();
00117       assert(
00118         current_tid == threading::ThreadMessaging::main_thread ||
00119         current_tid % threading::ThreadMessaging::thread_count == tid);
00120 
00121       SeqNo* local_nonce;
00122       if (current_tid == threading::ThreadMessaging::main_thread)
00123       {
00124         local_nonce = &local_recv_nonce[tid].main_thread_seqno;
00125       }
00126       else
00127       {
00128         local_nonce = &local_recv_nonce[tid].tid_seqno;
00129       }
00130 
00131       if (recv_nonce.nonce <= *local_nonce)
00132       {
00133         // If the nonce received has already been processed, return
00134         LOG_FAIL_FMT(
00135           "Invalid nonce, possible replay attack, received:{}, last_seen:{}, "
00136           "recv_nonce.tid:{}",
00137           reinterpret_cast<uint64_t>(recv_nonce.nonce),
00138           *local_nonce,
00139           recv_nonce.tid);
00140         return false;
00141       }
00142 
00143       auto ret =
00144         key->decrypt(header.get_iv(), header.tag, cipher, aad, plain.p);
00145       if (ret)
00146       {
00147         // Set local recv nonce to received nonce only if verification is
00148         // successful
00149         *local_nonce = recv_nonce.nonce;
00150       }
00151 
00152       return ret;
00153     }
00154 
00155     void try_establish_channel()
00156     {
00157       ChannelHeader msg = {ChannelMsg::key_exchange, self};
00158       to_host->write(
00159         node_outbound,
00160         peer_id,
00161         NodeMsgType::channel_msg,
00162         msg,
00163         get_signed_public());
00164 
00165       LOG_DEBUG_FMT("node channel with {} initiated", peer_id);
00166     }
00167 
00168   public:
00169     Channel(
00170       ringbuffer::AbstractWriterFactory& writer_factory,
00171       tls::KeyPairPtr network_kp_,
00172       NodeId self_,
00173       NodeId peer_id_,
00174       const std::string& peer_hostname_,
00175       const std::string& peer_service_) :
00176       self(self_),
00177       network_kp(network_kp_),
00178       to_host(writer_factory.create_writer_to_outside()),
00179       peer_id(peer_id_),
00180       peer_hostname(peer_hostname_),
00181       peer_service(peer_service_),
00182       outgoing(true)
00183     {
00184       RINGBUFFER_WRITE_MESSAGE(
00185         ccf::add_node, to_host, peer_id, peer_hostname, peer_service);
00186     }
00187 
00188     Channel(
00189       ringbuffer::AbstractWriterFactory& writer_factory,
00190       tls::KeyPairPtr network_kp_,
00191       NodeId self_,
00192       NodeId peer_id_) :
00193       self(self_),
00194       network_kp(network_kp_),
00195       to_host(writer_factory.create_writer_to_outside()),
00196       peer_id(peer_id_),
00197       outgoing(false)
00198     {}
00199 
00200     ~Channel()
00201     {
00202       if (outgoing)
00203       {
00204         RINGBUFFER_WRITE_MESSAGE(ccf::remove_node, to_host, peer_id);
00205       }
00206     }
00207 
00208     void set_status(ChannelStatus status_)
00209     {
00210       status = status_;
00211     }
00212 
00213     ChannelStatus get_status()
00214     {
00215       return status;
00216     }
00217 
00218     bool is_outgoing() const
00219     {
00220       return outgoing;
00221     }
00222 
00223     void set_outgoing(
00224       const std::string& peer_hostname_, const std::string& peer_service_)
00225     {
00226       peer_hostname = peer_hostname_;
00227       peer_service = peer_service_;
00228 
00229       if (!outgoing)
00230       {
00231         RINGBUFFER_WRITE_MESSAGE(
00232           ccf::add_node, to_host, peer_id, peer_hostname, peer_service);
00233       }
00234       outgoing = true;
00235     }
00236 
00237     void reset_outgoing()
00238     {
00239       if (outgoing)
00240       {
00241         RINGBUFFER_WRITE_MESSAGE(ccf::remove_node, to_host, peer_id);
00242       }
00243       outgoing = false;
00244     }
00245 
00246     std::vector<uint8_t> get_signed_public()
00247     {
00248       const auto own_public = ctx.get_own_public();
00249       auto signature = network_kp->sign(own_public);
00250 
00251       // Serialise channel public and network signature and length-prefix both
00252       auto space = own_public.size() + signature.size() + 2 * sizeof(size_t);
00253       std::vector<uint8_t> serialised_signed_public(space);
00254       auto data_ = serialised_signed_public.data();
00255       serialized::write(data_, space, own_public.size());
00256       serialized::write(data_, space, own_public.data(), own_public.size());
00257       serialized::write(data_, space, signature.size());
00258       serialized::write(data_, space, signature.data(), signature.size());
00259 
00260       return serialised_signed_public;
00261     }
00262 
00263     bool load_peer_signed_public(
00264       bool complete, const uint8_t* data, size_t size)
00265     {
00266       if (status == ESTABLISHED)
00267       {
00268         return false;
00269       }
00270 
00271       auto network_pubk = tls::make_public_key(network_kp->public_key_pem());
00272 
00273       auto peer_public_size = serialized::read<size_t>(data, size);
00274       auto peer_public_start = data;
00275 
00276       if (peer_public_size > size)
00277       {
00278         LOG_FAIL_FMT(
00279           "Peer public key header wants {} bytes, but only {} remain",
00280           peer_public_size,
00281           size);
00282         return false;
00283       }
00284 
00285       data += peer_public_size;
00286       size -= peer_public_size;
00287 
00288       auto signature_size = serialized::read<size_t>(data, size);
00289       auto signature_start = data;
00290 
00291       if (signature_size > size)
00292       {
00293         LOG_FAIL_FMT(
00294           "Signature header wants {} bytes, but only {} remain",
00295           signature_size,
00296           size);
00297         return false;
00298       }
00299 
00300       if (signature_size < size)
00301       {
00302         LOG_FAIL_FMT(
00303           "Expected signature to use all remaining {} bytes, but only uses "
00304           "{}",
00305           size,
00306           signature_size);
00307         return false;
00308       }
00309 
00310       if (!network_pubk->verify(
00311             peer_public_start,
00312             peer_public_size,
00313             signature_start,
00314             signature_size))
00315       {
00316         LOG_FAIL_FMT(
00317           "node channel peer signature verification failed {}", peer_id);
00318         return false;
00319       }
00320 
00321       ctx.load_peer_public(peer_public_start, peer_public_size);
00322 
00323       establish(complete);
00324 
00325       return true;
00326     }
00327 
00328     void establish(bool complete)
00329     {
00330       auto shared_secret = ctx.compute_shared_secret();
00331       key = std::make_unique<crypto::KeyAesGcm>(shared_secret);
00332       ctx.free_ctx();
00333       status = ESTABLISHED;
00334 
00335       if (outgoing_msg.has_value())
00336       {
00337         send(
00338           outgoing_msg->type,
00339           outgoing_msg->raw_plain,
00340           outgoing_msg->raw_cipher);
00341         outgoing_msg.reset();
00342       }
00343 
00344       LOG_INFO_FMT("node channel with {} is now established", peer_id);
00345 
00346       if (!complete)
00347       {
00348         ChannelHeader msg = {ChannelMsg::key_exchange_response, self};
00349         to_host->write(
00350           node_outbound,
00351           peer_id,
00352           NodeMsgType::channel_msg,
00353           msg,
00354           get_signed_public());
00355       }
00356     }
00357 
00358     bool send(NodeMsgType msg_type, CBuffer aad, CBuffer plain = nullb)
00359     {
00360       if (status != ESTABLISHED)
00361       {
00362         try_establish_channel();
00363         outgoing_msg = OutgoingMsg(msg_type, aad, plain);
00364         return false;
00365       }
00366 
00367       RecvNonce nonce(
00368         send_nonce.fetch_add(1), threading::get_current_thread_id());
00369 
00370       serializer::ByteRange aad_byte_range = {aad.p, aad.n};
00371       GcmHdr hdr;
00372       hdr.set_iv_seq(nonce.get_val());
00373 
00374       std::vector<uint8_t> cipher(plain.n);
00375       key->encrypt(hdr.get_iv(), plain, aad, cipher.data(), hdr.tag);
00376 
00377       to_host->write(
00378         node_outbound, peer_id, msg_type, aad_byte_range, hdr, cipher);
00379 
00380       return true;
00381     }
00382 
00383     bool recv_authenticated(CBuffer aad, const uint8_t*& data, size_t& size)
00384     {
00385       // Receive authenticated message, modifying data to point to the start of
00386       // the non-authenticated plaintext payload
00387       if (status != ESTABLISHED)
00388       {
00389         LOG_FAIL_FMT(
00390           "node channel with {} cannot receive authenticated message: not "
00391           "yet established",
00392           peer_id);
00393         return false;
00394       }
00395 
00396       const auto& hdr = serialized::overlay<GcmHdr>(data, size);
00397       if (!verify_or_decrypt(hdr, aad))
00398       {
00399         LOG_FAIL_FMT("Failed to verify node message from {}", peer_id);
00400         return false;
00401       }
00402 
00403       return true;
00404     }
00405 
00406     bool recv_authenticated_with_load(const uint8_t*& data, size_t& size)
00407     {
00408       // Receive authenticated message, modifying data to point to the start of
00409       // the non-authenticated plaintex payload. data contains payload first,
00410       // then GCM header
00411 
00412       const uint8_t* data_ = data;
00413       size_t size_ = size;
00414 
00415       serialized::skip(data_, size_, (size_ - sizeof(GcmHdr)));
00416       const auto& hdr = serialized::overlay<GcmHdr>(data_, size_);
00417       size -= sizeof(GcmHdr);
00418 
00419       if (!verify_or_decrypt(hdr, {data, size}))
00420       {
00421         LOG_FAIL_FMT("Failed to verify node message from {}", peer_id);
00422         return false;
00423       }
00424 
00425       return true;
00426     }
00427 
00428     std::optional<std::vector<uint8_t>> recv_encrypted(
00429       CBuffer aad, const uint8_t* data, size_t size)
00430     {
00431       // Receive encrypted message, returning the decrypted payload
00432       if (status != ESTABLISHED)
00433       {
00434         LOG_FAIL_FMT(
00435           "node channel with {} cannot receive encrypted message: not yet "
00436           "established",
00437           peer_id);
00438         return std::nullopt;
00439       }
00440 
00441       const auto& hdr = serialized::overlay<GcmHdr>(data, size);
00442       std::vector<uint8_t> plain(size);
00443       if (!verify_or_decrypt(hdr, aad, {data, size}, plain))
00444       {
00445         LOG_FAIL_FMT("Failed to decrypt node message from {}", peer_id);
00446         return std::nullopt;
00447       }
00448 
00449       return plain;
00450     }
00451   };
00452 
00453   class ChannelManager
00454   {
00455   private:
00456     std::unordered_map<NodeId, Channel> channels;
00457     ringbuffer::AbstractWriterFactory& writer_factory;
00458     tls::KeyPairPtr network_kp;
00459     NodeId self;
00460 
00461   public:
00462     ChannelManager(
00463       ringbuffer::AbstractWriterFactory& writer_factory_,
00464       const tls::Pem& network_pkey,
00465       NodeId self_) :
00466       writer_factory(writer_factory_),
00467       network_kp(tls::make_key_pair(network_pkey)),
00468       self(self_)
00469     {}
00470 
00471     void create_channel(
00472       NodeId peer_id, const std::string& hostname, const std::string& service)
00473     {
00474       auto search = channels.find(peer_id);
00475       if (search != channels.end() && !search->second.is_outgoing())
00476       {
00477         // Channel with peer already exists but is incoming. Create host
00478         // outgoing connection.
00479         search->second.set_outgoing(hostname, service);
00480         return;
00481       }
00482 
00483       channels.try_emplace(
00484         peer_id, writer_factory, network_kp, self, peer_id, hostname, service);
00485     }
00486 
00487     void destroy_channel(NodeId peer_id)
00488     {
00489       auto search = channels.find(peer_id);
00490       if (search == channels.end())
00491       {
00492         LOG_FAIL_FMT(
00493           "Cannot destroy node channel with {}: channel does not exist",
00494           peer_id);
00495         return;
00496       }
00497 
00498       channels.erase(peer_id);
00499     }
00500 
00501     void destroy_all_channels()
00502     {
00503       channels.clear();
00504     }
00505 
00506     void close_all_outgoing()
00507     {
00508       for (auto& c : channels)
00509       {
00510         if (c.second.is_outgoing())
00511         {
00512           c.second.reset_outgoing();
00513         }
00514       }
00515     }
00516 
00517     Channel& get(NodeId peer_id)
00518     {
00519       auto search = channels.find(peer_id);
00520       if (search != channels.end())
00521       {
00522         return search->second;
00523       }
00524 
00525       // Creating temporary channel that is not outgoing (at least for now)
00526       channels.try_emplace(peer_id, writer_factory, network_kp, self, peer_id);
00527       return channels.at(peer_id);
00528     }
00529   };
00530 }
00531 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/channels.h...
Preprocessing /data/git/CCF/src/node/client_signatures.h...
#include ds/hash.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include mbedtls/md.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1158 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 MSGPACK_ADD_ENUM(mbedtls_md_type_t);
00014 
00015 DECLARE_JSON_ENUM(
00016   mbedtls_md_type_t,
00017   {{MBEDTLS_MD_NONE, "MBEDTLS_MD_NONE"},
00018    {MBEDTLS_MD_SHA1, "MBEDTLS_MD_SHA1"},
00019    {MBEDTLS_MD_SHA256, "MBEDTLS_MD_SHA256"},
00020    {MBEDTLS_MD_SHA384, "MBEDTLS_MD_SHA384"},
00021    {MBEDTLS_MD_SHA512, "MBEDTLS_MD_SHA512"}});
00022 
00023 namespace ccf
00024 {
00025   struct SignedReq
00026   {
00027     // signature
00028     std::vector<uint8_t> sig = {};
00029     // signed content
00030     std::vector<uint8_t> req = {};
00031 
00032     // request body
00033     std::vector<uint8_t> request_body = {};
00034 
00035     // signature hashing algorithm used
00036     mbedtls_md_type_t md = MBEDTLS_MD_NONE;
00037 
00038     // The key id, if declared in the request
00039     std::string key_id = {};
00040 
00041     bool operator==(const SignedReq& other) const
00042     {
00043       return (sig == other.sig) && (req == other.req) && (md == other.md) &&
00044         (request_body == other.request_body) && (key_id == other.key_id);
00045     }
00046 
00047     MSGPACK_DEFINE(sig, req, request_body, md);
00048   };
00049 
00050 
00051   // this maps client-id to latest SignedReq
00052   using ClientSignatures = kv::Map<CallerId, SignedReq>;
00053 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/client_signatures.h...
Preprocessing /data/git/CCF/src/node/config.h...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 406 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   struct Config
00013   {
00014     // Number of required shares to decrypt ledger secrets (recovery)
00015     size_t recovery_threshold = 0;
00016 
00017 
00018   };
00019 
00020 
00021 
00022   // The key for this table is always 0 as there is always only one active
00023   // configuration.
00024   using Configuration = kv::Map<size_t, Config>;
00025 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/config.h...
Preprocessing /data/git/CCF/src/node/consensus.h...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 317 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   using ConsensusTable = kv::Map<ObjectId, ConsensusType>;
00012 }
00013 
00014 DECLARE_JSON_ENUM(
00015   ConsensusType, {{ConsensusType::CFT, "CFT"}, {ConsensusType::BFT, "BFT"}})
00016 
00017 MSGPACK_ADD_ENUM(ConsensusType);
00018 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/consensus.h...
Preprocessing /data/git/CCF/src/node/encryptor.h...
#include kv/encryptor.h: not found! skipping...
#include entities.h: already included! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include atomic: not found! skipping...
#include list: not found! skipping...
Preprocessor output (size: 1700 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace ccf
00014 {
00015   template <typename BaseEncryptor>
00016   class SeqTrackingMixin : public BaseEncryptor
00017   {
00018   private:
00019     std::atomic<size_t> seq_no{0};
00020 
00021     void set_iv(
00022       crypto::GcmHeader<crypto::GCM_SIZE_IV>& gcm_hdr,
00023       kv::Version,
00024       bool) override
00025     {
00026       gcm_hdr.set_iv_seq(seq_no.fetch_add(1));
00027       gcm_hdr.set_iv_id(BaseEncryptor::iv_id);
00028     }
00029 
00030     using BaseEncryptor::BaseEncryptor;
00031   };
00032 
00033   template <typename BaseEncryptor>
00034   class LedgerSecretsMixin : public BaseEncryptor
00035   {
00036   private:
00037     std::shared_ptr<LedgerSecrets> ledger_secrets;
00038     bool is_recovery;
00039 
00040     using KeyInfo = kv::TxEncryptor::KeyInfo;
00041 
00042     static std::list<KeyInfo> keys_from_secrets(
00043       const std::shared_ptr<LedgerSecrets>& ls)
00044     {
00045       std::list<KeyInfo> keys;
00046       for (const auto& s : ls->secrets_list)
00047       {
00048         keys.push_back(kv::TxEncryptor::KeyInfo{s.version, s.secret.master});
00049       }
00050       return keys;
00051     }
00052 
00053   protected:
00054     void record_compacted_keys(
00055       const std::list<kv::TxEncryptor::KeyInfo>& keys) override
00056     {
00057       if (!is_recovery)
00058       {
00059         for (auto const& k : keys)
00060         {
00061           ledger_secrets->add_new_secret(k.version, k.raw_key);
00062         }
00063       }
00064     }
00065 
00066   public:
00067     LedgerSecretsMixin(
00068       const std::shared_ptr<LedgerSecrets>& ls, bool is_recovery_ = false) :
00069       BaseEncryptor(keys_from_secrets(ls)),
00070       ledger_secrets(ls),
00071       is_recovery(is_recovery_)
00072     {}
00073   };
00074 
00075   using CftTxEncryptor = LedgerSecretsMixin<SeqTrackingMixin<kv::TxEncryptor>>;
00076   using BftTxEncryptor = LedgerSecretsMixin<kv::TxEncryptor>;
00077 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/encryptor.h...
Preprocessing /data/git/CCF/src/node/entities.h...
#include limits: not found! skipping...
#include map: not found! skipping...
#include stdint.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 3525 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   using ObjectId = uint64_t;
00013 
00014   constexpr ObjectId INVALID_ID = (std::numeric_limits<ObjectId>::max)();
00015 
00016   using Index = int64_t;
00017   using Node2NodeMsg = uint64_t;
00018 
00019   using MemberId = ObjectId;
00020   using UserId = ObjectId;
00021   using CallerId = ObjectId;
00022   using Cert = std::vector<uint8_t>;
00023 
00024   // SGX MRENCLAVE is SHA256 digest
00025   static constexpr size_t CODE_DIGEST_BYTES = 256 / 8;
00026   using CodeDigest = std::array<uint8_t, CODE_DIGEST_BYTES>;
00027 
00028   enum class ActorsType : uint64_t
00029   {
00030     members = 0,
00031     users,
00032     nodes,
00033     // not to be used
00034     unknown
00035   };
00036 
00037   constexpr auto get_actor_prefix(ActorsType at)
00038   {
00039     switch (at)
00040     {
00041       case ActorsType::members:
00042       {
00043         return "gov";
00044       }
00045       case ActorsType::users:
00046       {
00047         return "app";
00048       }
00049       case ActorsType::nodes:
00050       {
00051         return "node";
00052       }
00053       default:
00054       {
00055         return "";
00056       }
00057     }
00058   }
00059 
00060   struct Tables
00061   {
00062     // Governance tables
00063     static constexpr auto MEMBERS = "public:ccf.gov.members";
00064     static constexpr auto MEMBER_ACKS = "public:ccf.gov.member_acks";
00065     static constexpr auto MEMBER_CERT_DERS = "public:ccf.gov.member_cert_ders";
00066     static constexpr auto MEMBER_DIGESTS = "public:ccf.gov.member_digests";
00067     static constexpr auto USERS = "public:ccf.gov.users";
00068     static constexpr auto USER_CERT_DERS = "public:ccf.gov.user_cert_ders";
00069     static constexpr auto USER_DIGESTS = "public:ccf.gov.user_digests";
00070     static constexpr auto VALUES = "public:ccf.gov.values";
00071     static constexpr auto CONSENSUS = "public:ccf.gov.consensus";
00072     static constexpr auto WHITELISTS = "public:ccf.gov.whitelists";
00073     static constexpr auto PROPOSALS = "public:ccf.gov.proposals";
00074     static constexpr auto GOV_SCRIPTS = "public:ccf.gov.governance.scripts";
00075     static constexpr auto APP_SCRIPTS = "public:ccf.gov.app_scripts";
00076     static constexpr auto MODULES = "public:ccf.gov.modules";
00077     static constexpr auto SECRETS = "public:ccf.gov.secrets";
00078     static constexpr auto NODE_CODE_IDS = "public:ccf.gov.nodes.code_ids";
00079     static constexpr auto GOV_HISTORY = "public:ccf.gov.governance.history";
00080     static constexpr auto SERVICE = "public:ccf.gov.service";
00081     static constexpr auto SHARES = "public:ccf.gov.shares";
00082     static constexpr auto CONFIGURATION = "public:ccf.gov.config";
00083     static constexpr auto SUBMITTED_SHARES = "public:ccf.gov.submitted_shares";
00084     static constexpr auto SNAPSHOT_EVIDENCE =
00085       "public:ccf.gov.snapshot_evidence";
00086     static constexpr auto CA_CERT_DERS = "public:ccf.gov.ca_cert_ders";
00087     static constexpr auto JWT_ISSUERS = "public:ccf.gov.jwt_issuers";
00088     static constexpr auto JWT_PUBLIC_SIGNING_KEYS =
00089       "public:ccf.gov.jwt_public_signing_keys";
00090     static constexpr auto JWT_PUBLIC_SIGNING_KEY_ISSUER =
00091       "public:ccf.gov.jwt_public_signing_key_issuer";
00092     static constexpr auto ENDPOINTS = "public:ccf.gov.endpoints";
00093 
00094     static constexpr auto SIGNATURES = "public:ccf.internal.signatures";
00095 
00096     static constexpr auto BACKUP_SIGNATURES =
00097       "public:ccf.internal.backup_signatures";
00098     static constexpr auto NONCES = "public:ccf.internal.nonces";
00099 
00100     // Consensus specific tables
00101     static constexpr auto AFT_REQUESTS = "public:ccf.gov.aft.requests";
00102     static constexpr auto NEW_VIEWS = "public:ccf.internal.new_views";
00103   };
00104 
00105 }
00106 
00107 namespace enclave
00108 {
00109   enum FrameFormat : uint8_t
00110   {
00111     http = 0,
00112     ws
00113   };
00114 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/entities.h...
Preprocessing /data/git/CCF/src/node/genesis_gen.h...
#include code_id.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/tx.h: not found! skipping...
#include lua_interp/lua_interp.h: not found! skipping...
#include lua_interp/lua_util.h: not found! skipping...
  #include ds/hash.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include mbedtls/md.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
#include ds/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include node_signature.h: already included! skipping...
#include tls/pem.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
  #include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include certs.h: not found! skipping...
#include client_signatures.h: already included! skipping...
#include code_id.h: not found! skipping...
  #include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
  #include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include consensus/aft/raft_tables.h: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include consensus/aft/revealed_nonces.h: not found! skipping...
#include entities.h: already included! skipping...
  #include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
    #include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
  #include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
#include kv/map.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include members.h: already included! skipping...
  #include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include nodes.h: not found! skipping...
  #include ds/json.h: not found! skipping...
#include ds/msgpack_adaptor_nlohmann.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include script.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
  #include script.h: already included! skipping...
  #include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
  #include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
  #include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include map: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
  #include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
  #include crypto/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
  #include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include vector: not found! skipping...
  #include kv/map.h: not found! skipping...
#include tls/pem.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
  #include kv/map.h: not found! skipping...
#include exception: not found! skipping...
  #include kv/map.h: not found! skipping...
#include set: not found! skipping...
#include string: not found! skipping...
#include memory: not found! skipping...
#include tuple: not found! skipping...
#include node_info_network.h: not found! skipping...
#include nodes.h: not found! skipping...
#include runtime_config/default_whitelists.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include values.h: already included! skipping...
#include algorithm: not found! skipping...
#include fstream: not found! skipping...
#include ostream: not found! skipping...
Preprocessor output (size: 14147 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 # 10 "/data/git/CCF/src/node/genesis_gen.h" 2
00011 # 11 "/data/git/CCF/src/node/genesis_gen.h" 2
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 namespace ccf
00023 {
00024   class GenesisGenerator
00025   {
00026     NetworkTables& tables;
00027 
00028     kv::Tx& tx;
00029 
00030     template <typename T>
00031     void set_scripts(
00032       std::map<std::string, std::string> scripts,
00033       T& table,
00034       const bool compile = false)
00035     {
00036       auto tx_scripts = tx.get_view(table);
00037       for (auto& rs : scripts)
00038       {
00039         if (compile)
00040           tx_scripts->put(rs.first, lua::compile(rs.second));
00041         else
00042           tx_scripts->put(rs.first, rs.second);
00043       }
00044     }
00045 
00046   public:
00047     GenesisGenerator(NetworkTables& tables_, kv::Tx& tx_) :
00048       tables(tables_),
00049       tx(tx_)
00050     {}
00051 
00052     void init_values()
00053     {
00054       auto v = tx.get_view(tables.values);
00055       for (int id_type = 0; id_type < ValueIds::END_ID; id_type++)
00056         v->put(id_type, 0);
00057     }
00058 
00059     auto finalize()
00060     {
00061       return tx.commit();
00062     }
00063 
00064     void retire_active_nodes()
00065     {
00066       auto nodes_view = tx.get_view(tables.nodes);
00067 
00068       std::map<NodeId, NodeInfo> nodes_to_delete;
00069       nodes_view->foreach(
00070         [&nodes_to_delete](const NodeId& nid, const NodeInfo& ni) {
00071           // Only retire nodes that have not already been retired
00072           if (ni.status != NodeStatus::RETIRED)
00073             nodes_to_delete[nid] = ni;
00074           return true;
00075         });
00076 
00077       for (auto [nid, ni] : nodes_to_delete)
00078       {
00079         ni.status = NodeStatus::RETIRED;
00080         nodes_view->put(nid, ni);
00081       }
00082     }
00083 
00084     auto add_consensus(ConsensusType consensus_type)
00085     {
00086       auto cv = tx.get_view(tables.consensus);
00087       cv->put(0, consensus_type);
00088     }
00089 
00090     auto get_active_recovery_members()
00091     {
00092       auto members_view = tx.get_view(tables.members);
00093       std::map<MemberId, tls::Pem> active_members_info;
00094 
00095       members_view->foreach(
00096         [&active_members_info](const MemberId& mid, const MemberInfo& mi) {
00097           if (mi.status == MemberStatus::ACTIVE && mi.is_recovery())
00098           {
00099             active_members_info[mid] = mi.encryption_pub_key.value();
00100           }
00101           return true;
00102         });
00103       return active_members_info;
00104     }
00105 
00106     MemberId add_member(const MemberPubInfo& member_pub_info)
00107     {
00108       auto [m, mc, md, v, ma, sig] = tx.get_view(
00109         tables.members,
00110         tables.member_certs,
00111         tables.member_digests,
00112         tables.values,
00113         tables.member_acks,
00114         tables.signatures);
00115 
00116       // The key to a CertDERs table must be a DER, for easy comparison against
00117       // the DER peer cert retrieved from the connection
00118       auto member_cert_der =
00119         tls::make_verifier(member_pub_info.cert)->der_cert_data();
00120 
00121       auto member_id = mc->get(member_cert_der);
00122       if (member_id.has_value())
00123       {
00124         throw std::logic_error(fmt::format(
00125           "Member certificate already exists (member {})", member_id.value()));
00126       }
00127 
00128       const auto id = get_next_id(v, ValueIds::NEXT_MEMBER_ID);
00129       m->put(id, MemberInfo(member_pub_info, MemberStatus::ACCEPTED));
00130       mc->put(member_cert_der, id);
00131 
00132       crypto::Sha256Hash member_cert_digest(member_pub_info.cert.contents());
00133       md->put(member_cert_digest.hex_str(), id);
00134 
00135       auto s = sig->get(0);
00136       if (!s)
00137       {
00138         ma->put(id, MemberAck());
00139       }
00140       else
00141       {
00142         ma->put(id, MemberAck(s->root));
00143       }
00144       return id;
00145     }
00146 
00147     void activate_member(MemberId member_id)
00148     {
00149       auto members = tx.get_view(tables.members);
00150       auto member = members->get(member_id);
00151       if (!member.has_value())
00152       {
00153         throw std::logic_error(fmt::format(
00154           "Member {} cannot be activated as they do not exist", member_id));
00155       }
00156 
00157       // Only accepted members can transition to active state
00158       if (member->status != MemberStatus::ACCEPTED)
00159       {
00160         return;
00161       }
00162 
00163       member->status = MemberStatus::ACTIVE;
00164       if (
00165         member->is_recovery() &&
00166         (get_active_recovery_members().size() >= max_active_recovery_members))
00167       {
00168         throw std::logic_error(fmt::format(
00169           "No more than {} active recovery members are allowed",
00170           max_active_recovery_members));
00171       }
00172       members->put(member_id, member.value());
00173     }
00174 
00175     bool retire_member(MemberId member_id)
00176     {
00177       auto m = tx.get_view(tables.members);
00178       auto member_to_retire = m->get(member_id);
00179       if (!member_to_retire.has_value())
00180       {
00181         LOG_FAIL_FMT(
00182           "Could not retire member {}: member does not exist", member_id);
00183         return false;
00184       }
00185 
00186       if (member_to_retire->status != MemberStatus::ACTIVE)
00187       {
00188         LOG_DEBUG_FMT(
00189           "Could not retire member {}: member is not active", member_id);
00190         return true;
00191       }
00192 
00193       // If the member was active and had a recovery share, check that
00194       // the new number of active members is still sufficient for
00195       // recovery
00196       if (member_to_retire->is_recovery())
00197       {
00198         // Because the member to retire is active, there is at least one active
00199         // member (i.e. get_active_recovery_members_count_after >= 0)
00200         size_t get_active_recovery_members_count_after =
00201           get_active_recovery_members().size() - 1;
00202         auto recovery_threshold = get_recovery_threshold();
00203         if (get_active_recovery_members_count_after < recovery_threshold)
00204         {
00205           LOG_FAIL_FMT(
00206             "Failed to retire member {}: number of active recovery members "
00207             "({}) would be less than recovery threshold ({})",
00208             member_id,
00209             get_active_recovery_members_count_after,
00210             recovery_threshold);
00211           return false;
00212         }
00213       }
00214 
00215       member_to_retire->status = MemberStatus::RETIRED;
00216       m->put(member_id, member_to_retire.value());
00217       return true;
00218     }
00219 
00220     std::optional<MemberInfo> get_member_info(MemberId member_id)
00221     {
00222       auto m = tx.get_view(tables.members);
00223       auto member = m->get(member_id);
00224       if (!member.has_value())
00225       {
00226         return {};
00227       }
00228 
00229       return member.value();
00230     }
00231 
00232     auto add_user(const ccf::UserInfo& user_info)
00233     {
00234       auto [u, uc, ud, v] = tx.get_view(
00235         tables.users, tables.user_certs, tables.user_digests, tables.values);
00236 
00237       auto user_cert_der = tls::make_verifier(user_info.cert)->der_cert_data();
00238 
00239       // Cert should be unique
00240       auto user_id = uc->get(user_cert_der);
00241       if (user_id.has_value())
00242       {
00243         throw std::logic_error(fmt::format(
00244           "User certificate already exists (user {})", user_id.value()));
00245       }
00246 
00247       const auto id = get_next_id(v, ValueIds::NEXT_USER_ID);
00248       u->put(id, user_info);
00249       uc->put(user_cert_der, id);
00250 
00251       crypto::Sha256Hash user_cert_digest(user_info.cert.contents());
00252       ud->put(user_cert_digest.hex_str(), id);
00253       return id;
00254     }
00255 
00256     bool remove_user(UserId user_id)
00257     {
00258       auto [u, uc] = tx.get_view(tables.users, tables.user_certs);
00259 
00260       auto user_info = u->get(user_id);
00261       if (!user_info.has_value())
00262       {
00263         return false;
00264       }
00265 
00266       auto pem = tls::Pem(user_info.value().cert);
00267       auto user_cert_der = tls::make_verifier(pem)->der_cert_data();
00268 
00269       u->remove(user_id);
00270       uc->remove(user_cert_der);
00271       return true;
00272     }
00273 
00274     auto add_node(const NodeInfo& node_info)
00275     {
00276       auto node_id =
00277         get_next_id(tx.get_view(tables.values), ValueIds::NEXT_NODE_ID);
00278 
00279       auto raw_cert = tls::make_verifier(node_info.cert)->der_cert_data();
00280 
00281       auto node_view = tx.get_view(tables.nodes);
00282       node_view->put(node_id, node_info);
00283       return node_id;
00284     }
00285 
00286     auto get_trusted_nodes(std::optional<NodeId> self_to_exclude = std::nullopt)
00287     {
00288       // Returns the list of trusted nodes. If self_to_exclude is set,
00289       // self_to_exclude is not included in the list of returned nodes.
00290       std::map<NodeId, NodeInfo> active_nodes;
00291 
00292       auto [nodes_view, secrets_view] =
00293         tx.get_view(tables.nodes, tables.secrets);
00294 
00295       nodes_view->foreach([&active_nodes, self_to_exclude](
00296                             const NodeId& nid, const NodeInfo& ni) {
00297         if (
00298           ni.status == ccf::NodeStatus::TRUSTED &&
00299           (!self_to_exclude.has_value() || self_to_exclude.value() != nid))
00300         {
00301           active_nodes[nid] = ni;
00302         }
00303         return true;
00304       });
00305 
00306       return active_nodes;
00307     }
00308 
00309     // Service status should use a state machine, very much like NodeState.
00310     void create_service(const tls::Pem& network_cert)
00311     {
00312       auto service_view = tx.get_view(tables.service);
00313       service_view->put(0, {network_cert, ServiceStatus::OPENING});
00314     }
00315 
00316     bool is_service_created()
00317     {
00318       auto service_view = tx.get_view(tables.service);
00319       return service_view->get(0).has_value();
00320     }
00321 
00322     bool open_service()
00323     {
00324       auto service_view = tx.get_view(tables.service);
00325 
00326       auto active_recovery_members_count = get_active_recovery_members().size();
00327       if (active_recovery_members_count < get_recovery_threshold())
00328       {
00329         LOG_FAIL_FMT(
00330           "Cannot open network as number of active recovery members ({}) is "
00331           "less than recovery threshold ({})",
00332           active_recovery_members_count,
00333           get_recovery_threshold());
00334         return false;
00335       }
00336 
00337       auto active_service = service_view->get(0);
00338       if (!active_service.has_value())
00339       {
00340         LOG_FAIL_FMT("Failed to get active service");
00341         return false;
00342       }
00343 
00344       if (
00345         active_service->status != ServiceStatus::OPENING &&
00346         active_service->status != ServiceStatus::WAITING_FOR_RECOVERY_SHARES)
00347       {
00348         LOG_FAIL_FMT("Could not open current service: status is not OPENING");
00349         return false;
00350       }
00351 
00352       active_service->status = ServiceStatus::OPEN;
00353       service_view->put(0, active_service.value());
00354 
00355       return true;
00356     }
00357 
00358     std::optional<ServiceStatus> get_service_status()
00359     {
00360       auto service_view = tx.get_view(tables.service);
00361       auto active_service = service_view->get(0);
00362       if (!active_service.has_value())
00363       {
00364         LOG_FAIL_FMT("Failed to get active service");
00365         return {};
00366       }
00367 
00368       return active_service->status;
00369     }
00370 
00371     bool service_wait_for_shares()
00372     {
00373       auto service_view = tx.get_view(tables.service);
00374       auto active_service = service_view->get(0);
00375       if (!active_service.has_value())
00376       {
00377         LOG_FAIL_FMT("Failed to get active service");
00378         return false;
00379       }
00380 
00381       if (active_service->status != ServiceStatus::OPENING)
00382       {
00383         LOG_FAIL_FMT(
00384           "Could not wait for shares on current service: status is not "
00385           "OPENING");
00386         return false;
00387       }
00388 
00389       active_service->status = ServiceStatus::WAITING_FOR_RECOVERY_SHARES;
00390       service_view->put(0, active_service.value());
00391 
00392       return true;
00393     }
00394 
00395     void trust_node(NodeId node_id)
00396     {
00397       auto nodes_view = tx.get_view(tables.nodes);
00398       auto node_info = nodes_view->get(node_id);
00399       if (node_info.has_value())
00400       {
00401         node_info->status = NodeStatus::TRUSTED;
00402         nodes_view->put(node_id, node_info.value());
00403       }
00404       else
00405       {
00406         LOG_FAIL_FMT("Unknown node {} could not be trusted", node_id);
00407       }
00408     }
00409 
00410     auto get_last_signature()
00411     {
00412       auto sig_view = tx.get_view(tables.signatures);
00413       return sig_view->get(0);
00414     }
00415 
00416     void set_whitelist(WlIds id, Whitelist wl)
00417     {
00418       tx.get_view(tables.whitelists)->put(id, wl);
00419     }
00420 
00421     void set_gov_scripts(std::map<std::string, std::string> scripts)
00422     {
00423       // don't compile, because gov scripts are important functionally but not
00424       // performance-wise
00425       set_scripts(scripts, tables.gov_scripts, false);
00426     }
00427 
00428     void set_app_scripts(std::map<std::string, std::string> scripts)
00429     {
00430       set_scripts(scripts, tables.app_scripts, true);
00431     }
00432 
00433     void trust_node_code_id(CodeDigest& node_code_id)
00434     {
00435       auto codeid_view = tx.get_view(tables.node_code_ids);
00436       codeid_view->put(node_code_id, CodeStatus::ALLOWED_TO_JOIN);
00437     }
00438 
00439     void add_key_share_info(const RecoverySharesInfo& key_share_info)
00440     {
00441       auto shares_view = tx.get_view(tables.shares);
00442       shares_view->put(0, key_share_info);
00443     }
00444 
00445     bool set_recovery_threshold(size_t threshold, bool allow_zero = false)
00446     {
00447       auto config_view = tx.get_view(tables.config);
00448 
00449       if (!allow_zero && threshold == 0)
00450       {
00451         LOG_FAIL_FMT("Cannot set recovery threshold to 0");
00452         return false;
00453       }
00454 
00455       auto service_status = get_service_status();
00456       if (!service_status.has_value())
00457       {
00458         LOG_FAIL_FMT("Failed to get active service");
00459         return false;
00460       }
00461 
00462       if (service_status.value() == ServiceStatus::WAITING_FOR_RECOVERY_SHARES)
00463       {
00464         // While waiting for recovery shares, the recovery threshold cannot be
00465         // modified. Otherwise, the threshold could be passed without triggering
00466         // the end of recovery procedure
00467         LOG_FAIL_FMT(
00468           "Cannot set recovery threshold: service is currently waiting for "
00469           "recovery shares");
00470         return false;
00471       }
00472       else if (service_status.value() == ServiceStatus::OPEN)
00473       {
00474         auto get_active_recovery_members_count =
00475           get_active_recovery_members().size();
00476         if (threshold > get_active_recovery_members_count)
00477         {
00478           LOG_FAIL_FMT(
00479             "Cannot set recovery threshold to {} as it is greater than the "
00480             "number of active recovery members ({})",
00481             threshold,
00482             get_active_recovery_members_count);
00483           return false;
00484         }
00485       }
00486 
00487       config_view->put(0, {threshold});
00488       return true;
00489     }
00490 
00491     size_t get_recovery_threshold()
00492     {
00493       auto config_view = tx.get_view(tables.config);
00494       auto config = config_view->get(0);
00495       if (!config.has_value())
00496       {
00497         throw std::logic_error(
00498           "Failed to get recovery threshold: No active configuration found");
00499       }
00500       return config->recovery_threshold;
00501     }
00502   };
00503 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/genesis_gen.h...
Preprocessing /data/git/CCF/src/node/governance_history.h...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include script.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 312 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ccf
00015 {
00016   struct GovernanceHistoryEntry
00017   {
00018     SignedReq signed_request;
00019     MSGPACK_DEFINE(signed_request);
00020   };
00021 
00022 
00023   using GovernanceHistory = kv::Map<MemberId, GovernanceHistoryEntry>;
00024 }
00025 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/governance_history.h...
Preprocessing /data/git/CCF/src/node/historical_queries.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include node/historical_queries_interface.h: not found! skipping...
#include node/history.h: not found! skipping...
#include node/rpc/node_interface.h: not found! skipping...
#include list: not found! skipping...
#include map: not found! skipping...
#include memory: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 9685 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf::historical
00017 {
00018   class StateCache : public AbstractStateCache
00019   {
00020   protected:
00021     kv::Store& source_store;
00022     ringbuffer::WriterPtr to_host;
00023 
00024     enum class RequestStage
00025     {
00026       Fetching,
00027       Untrusted,
00028       Trusted,
00029     };
00030 
00031     using LedgerEntry = std::vector<uint8_t>;
00032 
00033     struct Request
00034     {
00035       RequestStage current_stage = RequestStage::Fetching;
00036       crypto::Sha256Hash entry_hash = {};
00037       StorePtr store = nullptr;
00038     };
00039 
00040     // These constitute a simple LRU, where only user queries will refresh an
00041     // entry's priority
00042     static constexpr size_t MAX_ACTIVE_REQUESTS = 10;
00043     std::map<consensus::Index, Request> requests;
00044     std::list<consensus::Index> recent_requests;
00045 
00046     // To trust an index, we currently need to fetch a sequence of entries
00047     // around it - these aren't user requests, so we don't store them, but we do
00048     // need to distinguish things-we-asked-for from junk-from-the-host
00049     std::set<consensus::Index> pending_fetches;
00050 
00051     void request_entry_at(consensus::Index idx)
00052     {
00053       // To avoid duplicates, remove index if it was already requested
00054       recent_requests.remove(idx);
00055 
00056       // Add request to front of list, most recently requested
00057       recent_requests.emplace_front(idx);
00058 
00059       // Cull old requests
00060       while (recent_requests.size() > MAX_ACTIVE_REQUESTS)
00061       {
00062         const auto old_idx = recent_requests.back();
00063         recent_requests.pop_back();
00064         requests.erase(old_idx);
00065       }
00066 
00067       // Try to insert new request
00068       const auto ib = requests.insert(std::make_pair(idx, Request{}));
00069       if (ib.second)
00070       {
00071         // If its a new request, begin fetching it
00072         fetch_entry_at(idx);
00073       }
00074     }
00075 
00076     void fetch_entry_at(consensus::Index idx)
00077     {
00078       const auto it =
00079         std::find(pending_fetches.begin(), pending_fetches.end(), idx);
00080       if (it != pending_fetches.end())
00081       {
00082         // Already fetching this index
00083         return;
00084       }
00085 
00086       RINGBUFFER_WRITE_MESSAGE(
00087         consensus::ledger_get,
00088         to_host,
00089         idx,
00090         consensus::LedgerRequestPurpose::HistoricalQuery);
00091       pending_fetches.insert(idx);
00092     }
00093 
00094     std::optional<ccf::PrimarySignature> get_signature(
00095       const StorePtr& sig_store)
00096     {
00097       auto tx = sig_store->create_tx();
00098       auto sig_view = tx.get_view<ccf::Signatures>(ccf::Tables::SIGNATURES);
00099       return sig_view->get(0);
00100     }
00101 
00102     std::optional<ccf::NodeInfo> get_node_info(ccf::NodeId node_id)
00103     {
00104       // Current solution: Use current state of Nodes table from real store.
00105       // This only works while entries are never deleted from this table, and
00106       // makes no check that the signing node was active at the point it
00107       // produced this signature
00108       auto tx = source_store.create_tx();
00109       auto nodes_view = tx.get_view<ccf::Nodes>(ccf::Tables::NODES);
00110       return nodes_view->get(node_id);
00111     }
00112 
00113     void handle_signature_transaction(
00114       consensus::Index sig_idx, const StorePtr& sig_store)
00115     {
00116       const auto sig = get_signature(sig_store);
00117       if (!sig.has_value())
00118       {
00119         throw std::logic_error(
00120           "Missing signature value in signature transaction");
00121       }
00122 
00123       // Build tree from signature
00124       ccf::MerkleTreeHistory tree(sig->tree);
00125       const auto real_root = tree.get_root();
00126       if (real_root != sig->root)
00127       {
00128         throw std::logic_error("Invalid signature: invalid root");
00129       }
00130 
00131       const auto node_info = get_node_info(sig->node);
00132       if (!node_info.has_value())
00133       {
00134         throw std::logic_error(fmt::format(
00135           "Signature {} claims it was produced by node {}: This node is "
00136           "unknown",
00137           sig_idx,
00138           sig->node));
00139       }
00140 
00141       auto verifier = tls::make_verifier(node_info->cert);
00142       const auto verified = verifier->verify_hash(
00143         real_root.h.data(),
00144         real_root.h.size(),
00145         sig->sig.data(),
00146         sig->sig.size());
00147       if (!verified)
00148       {
00149         throw std::logic_error(
00150           fmt::format("Signature at {} is invalid", sig_idx));
00151       }
00152 
00153       auto it = requests.begin();
00154       while (it != requests.end())
00155       {
00156         auto& request = it->second;
00157         const auto& untrusted_idx = it->first;
00158 
00159         if (
00160           request.current_stage == RequestStage::Untrusted &&
00161           tree.in_range(untrusted_idx))
00162         {
00163           // Compare signed hash, from signature mini-tree, with hash of the
00164           // entry which was used to populate the store
00165           const auto& untrusted_hash = request.entry_hash;
00166           const auto trusted_hash = tree.get_leaf(untrusted_idx);
00167           if (trusted_hash != untrusted_hash)
00168           {
00169             LOG_FAIL_FMT(
00170               "Signature at {} has a different transaction at {} than "
00171               "previously received",
00172               sig_idx,
00173               untrusted_idx);
00174             // We trust the signature but not the store - delete this untrusted
00175             // store. If it is re-requested, maybe the host will give us a valid
00176             // pair of transaction+sig next time
00177             it = requests.erase(it);
00178             continue;
00179           }
00180 
00181           // Move store from untrusted to trusted
00182           LOG_DEBUG_FMT(
00183             "Now trusting {} due to signature at {}", untrusted_idx, sig_idx);
00184           request.current_stage = RequestStage::Trusted;
00185           ++it;
00186         }
00187         else
00188         {
00189           // Already trusted or still fetching, or this signature doesn't cover
00190           // this transaction - skip it and try the next
00191           ++it;
00192         }
00193       }
00194     }
00195 
00196     void deserialise_ledger_entry(
00197       consensus::Index idx, const LedgerEntry& entry)
00198     {
00199       StorePtr store = std::make_shared<kv::Store>(false);
00200 
00201       store->set_encryptor(source_store.get_encryptor());
00202 
00203       const auto deserialise_result = store->deserialise_views(entry);
00204 
00205       switch (deserialise_result)
00206       {
00207         case kv::DeserialiseSuccess::FAILED:
00208         {
00209           throw std::logic_error("Deserialise failed!");
00210           break;
00211         }
00212         case kv::DeserialiseSuccess::PASS:
00213         case kv::DeserialiseSuccess::PASS_SIGNATURE:
00214         case kv::DeserialiseSuccess::PASS_BACKUP_SIGNATURE:
00215         case kv::DeserialiseSuccess::PASS_BACKUP_SIGNATURE_SEND_ACK:
00216         case kv::DeserialiseSuccess::PASS_NONCES:
00217         case kv::DeserialiseSuccess::PASS_NEW_VIEW:
00218         case kv::DeserialiseSuccess::PASS_SNAPSHOT_EVIDENCE:
00219         {
00220           LOG_DEBUG_FMT("Processed transaction at {}", idx);
00221 
00222           auto request_it = requests.find(idx);
00223           if (request_it != requests.end())
00224           {
00225             auto& request = request_it->second;
00226             if (request.current_stage == RequestStage::Fetching)
00227             {
00228               // We were looking for this entry. Store the produced store
00229               request.current_stage = RequestStage::Untrusted;
00230               request.entry_hash = crypto::Sha256Hash(entry);
00231               request.store = store;
00232             }
00233             else
00234             {
00235               LOG_DEBUG_FMT(
00236                 "Not fetching ledger entry {}: already have it in stage {}",
00237                 request_it->first,
00238                 request.current_stage);
00239             }
00240           }
00241 
00242           if (deserialise_result == kv::DeserialiseSuccess::PASS_SIGNATURE)
00243           {
00244             // This looks like a valid signature - try to use this signature to
00245             // move some stores from untrusted to trusted
00246             handle_signature_transaction(idx, store);
00247           }
00248           else
00249           {
00250             // This is not a signature - try the next transaction
00251             fetch_entry_at(idx + 1);
00252           }
00253           break;
00254         }
00255         default:
00256         {
00257           throw std::logic_error("Unexpected deserialise result");
00258         }
00259       }
00260     }
00261 
00262   public:
00263     StateCache(kv::Store& store, const ringbuffer::WriterPtr& host_writer) :
00264       source_store(store),
00265       to_host(host_writer)
00266     {}
00267 
00268     StorePtr get_store_at(consensus::Index idx) override
00269     {
00270       const auto it = requests.find(idx);
00271       if (it == requests.end())
00272       {
00273         // Treat this as a hint and start fetching it
00274         request_entry_at(idx);
00275 
00276         return nullptr;
00277       }
00278 
00279       if (it->second.current_stage == RequestStage::Trusted)
00280       {
00281         // Have this store and trust it
00282         return it->second.store;
00283       }
00284 
00285       // Still fetching this store or don't trust it yet
00286       return nullptr;
00287     }
00288 
00289     bool handle_ledger_entry(consensus::Index idx, const LedgerEntry& data)
00290     {
00291       const auto it =
00292         std::find(pending_fetches.begin(), pending_fetches.end(), idx);
00293       if (it == pending_fetches.end())
00294       {
00295         // Unexpected entry - ignore it?
00296         return false;
00297       }
00298 
00299       pending_fetches.erase(it);
00300 
00301       try
00302       {
00303         deserialise_ledger_entry(idx, data);
00304       }
00305       catch (const std::exception& e)
00306       {
00307         LOG_FAIL_FMT("Unable to deserialise entry {}: {}", idx, e.what());
00308         return false;
00309       }
00310 
00311       return true;
00312     }
00313 
00314     void handle_no_entry(consensus::Index idx)
00315     {
00316       const auto request_it = requests.find(idx);
00317       if (request_it != requests.end())
00318       {
00319         if (request_it->second.current_stage == RequestStage::Fetching)
00320         {
00321           requests.erase(request_it);
00322         }
00323       }
00324 
00325       // The host failed or refused to give this entry. Currently just forget
00326       // about it - don't have a mechanism for remembering this failure and
00327       // reporting it to users.
00328       pending_fetches.erase(idx);
00329     }
00330   };
00331 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/historical_queries.h...
Preprocessing /data/git/CCF/src/node/historical_queries_interface.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include node/rpc/endpoint_registry.h: not found! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 4281 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf::historical
00012 {
00013   using StorePtr = std::shared_ptr<kv::Store>;
00014 
00015   class AbstractStateCache
00016   {
00017   public:
00018     virtual ~AbstractStateCache() = default;
00019 
00020     virtual StorePtr get_store_at(consensus::Index idx) = 0;
00021   };
00022 
00023   class StubStateCache : public AbstractStateCache
00024   {
00025   public:
00026     StorePtr get_store_at(consensus::Index) override
00027     {
00028       return nullptr;
00029     }
00030   };
00031 
00032   using CheckAvailability = std::function<bool(
00033     kv::Consensus::View view,
00034     kv::Consensus::SeqNo seqno,
00035     std::string& error_reason)>;
00036 
00037   using HandleHistoricalQuery = std::function<void(
00038     ccf::EndpointContext& args,
00039     StorePtr store,
00040     kv::Consensus::View view,
00041     kv::Consensus::SeqNo seqno)>;
00042 
00043 // Unused in most sample apps
00044 
00045 
00046   static ccf::EndpointFunction adapter(
00047     const HandleHistoricalQuery& f,
00048     AbstractStateCache& state_cache,
00049     const CheckAvailability& available)
00050   {
00051     return [f, &state_cache, available](EndpointContext& args) {
00052       // Extract the requested transaction ID
00053       kv::Consensus::View target_view;
00054       kv::Consensus::SeqNo target_seqno;
00055 
00056       {
00057         const auto target_view_opt =
00058           args.rpc_ctx->get_request_header(http::headers::CCF_TX_VIEW);
00059         if (!target_view_opt.has_value())
00060         {
00061           args.rpc_ctx->set_error(
00062             HTTP_STATUS_BAD_REQUEST,
00063             ccf::errors::MissingRequiredHeader,
00064             fmt::format(
00065               "Historical query is missing '{}' header.",
00066               http::headers::CCF_TX_VIEW));
00067           return;
00068         }
00069 
00070         target_view =
00071           std::strtoul(target_view_opt.value().c_str(), nullptr, 10);
00072         if (target_view == 0)
00073         {
00074           args.rpc_ctx->set_error(
00075             HTTP_STATUS_BAD_REQUEST,
00076             ccf::errors::InvalidHeaderValue,
00077             fmt::format(
00078               "The value '{}' in header '{}' could not be converted to a valid "
00079               "view.",
00080               target_view_opt.value(),
00081               http::headers::CCF_TX_VIEW));
00082           return;
00083         }
00084 
00085         const auto target_seqno_opt =
00086           args.rpc_ctx->get_request_header(http::headers::CCF_TX_SEQNO);
00087         if (!target_seqno_opt.has_value())
00088         {
00089           args.rpc_ctx->set_error(
00090             HTTP_STATUS_BAD_REQUEST,
00091             ccf::errors::MissingRequiredHeader,
00092             fmt::format(
00093               "Historical query is missing '{}' header.",
00094               http::headers::CCF_TX_SEQNO));
00095           return;
00096         }
00097 
00098         target_seqno =
00099           std::strtoul(target_seqno_opt.value().c_str(), nullptr, 10);
00100         if (target_view == 0)
00101         {
00102           args.rpc_ctx->set_error(
00103             HTTP_STATUS_BAD_REQUEST,
00104             ccf::errors::InvalidHeaderValue,
00105             fmt::format(
00106               "The value '{}' in header '{}' could not be converted to a valid "
00107               "seqno.",
00108               target_seqno_opt.value(),
00109               http::headers::CCF_TX_SEQNO));
00110           return;
00111         }
00112       }
00113 
00114       // Check that the requested transaction ID is available
00115       {
00116         auto error_reason = fmt::format(
00117           "Transaction {}.{} is not available.", target_view, target_seqno);
00118         if (!available(target_view, target_seqno, error_reason))
00119         {
00120           args.rpc_ctx->set_error(
00121             HTTP_STATUS_BAD_REQUEST,
00122             ccf::errors::TransactionNotFound,
00123             std::move(error_reason));
00124           return;
00125         }
00126       }
00127 
00128       // Get a store at the target version from the cache, if it is present
00129       auto historical_store = state_cache.get_store_at(target_seqno);
00130       if (historical_store == nullptr)
00131       {
00132         args.rpc_ctx->set_response_status(HTTP_STATUS_ACCEPTED);
00133         static constexpr size_t retry_after_seconds = 3;
00134         args.rpc_ctx->set_response_header(
00135           http::headers::RETRY_AFTER, retry_after_seconds);
00136         args.rpc_ctx->set_response_body(fmt::format(
00137           "Historical transaction at seqno {} in view {} is not currently "
00138           "available.",
00139           target_seqno,
00140           target_view));
00141         return;
00142       }
00143 
00144       // Call the provided handler
00145       f(args, historical_store, target_view, target_seqno);
00146     };
00147   }
00148 
00149 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/historical_queries_interface.h...
Preprocessing /data/git/CCF/src/node/history.h...
#include crypto/hash.h: not found! skipping...
#include ds/dl_list.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include nodes.h: not found! skipping...
#include signatures.h: already included! skipping...
#include tls/tls.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include array: not found! skipping...
#include deque: not found! skipping...
#include string.h: not found! skipping...
#include merklecpp.h: not found! skipping...
Preprocessor output (size: 22874 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 #define HAVE_OPENSSL
00022 #define HAVE_MBEDTLS
00023 // merklecpp traces are off by default, even when CCF tracing is enabled
00024 // #include "merklecpp_trace.h"
00025 
00026 
00027 namespace fmt
00028 {
00029   template <>
00030   struct formatter<kv::TxHistory::RequestID>
00031   {
00032     template <typename ParseContext>
00033     constexpr auto parse(ParseContext& ctx)
00034     {
00035       return ctx.begin();
00036     }
00037 
00038     template <typename FormatContext>
00039     auto format(const kv::TxHistory::RequestID& p, FormatContext& ctx)
00040     {
00041       return format_to(
00042         ctx.out(), "<RID {0}, {1}>", std::get<0>(p), std::get<1>(p));
00043     }
00044   };
00045 }
00046 
00047 namespace ccf
00048 {
00049   enum HashOp
00050   {
00051     APPEND,
00052     VERIFY,
00053     ROLLBACK,
00054     COMPACT
00055   };
00056 
00057   constexpr int MAX_HISTORY_LEN = 1000;
00058 
00059   static std::ostream& operator<<(std::ostream& os, HashOp flag)
00060   {
00061     switch (flag)
00062     {
00063       case APPEND:
00064         os << "append";
00065         break;
00066 
00067       case VERIFY:
00068         os << "verify";
00069         break;
00070 
00071       case ROLLBACK:
00072         os << "rollback";
00073         break;
00074 
00075       case COMPACT:
00076         os << "compact";
00077         break;
00078     }
00079 
00080     return os;
00081   }
00082 
00083   static void log_hash(const crypto::Sha256Hash& h, HashOp flag)
00084   {
00085     LOG_DEBUG_FMT("History [{}] {}", flag, h);
00086   }
00087 
00088   class NullTxHistory : public kv::TxHistory
00089   {
00090     kv::Store& store;
00091     NodeId id;
00092 
00093   public:
00094     NullTxHistory(kv::Store& store_, NodeId id_, tls::KeyPair&) :
00095       store(store_),
00096       id(id_)
00097     {}
00098 
00099     void append(const std::vector<uint8_t>&) override {}
00100 
00101     void append(const uint8_t*, size_t) override {}
00102 
00103     kv::TxHistory::Result verify_and_sign(PrimarySignature&, kv::Term*) override
00104     {
00105       return kv::TxHistory::Result::OK;
00106     }
00107 
00108     bool verify(kv::Term*, ccf::PrimarySignature*) override
00109     {
00110       return true;
00111     }
00112 
00113     void rollback(kv::Version) override {}
00114 
00115     void compact(kv::Version) override {}
00116 
00117     bool init_from_snapshot(const std::vector<uint8_t>&) override
00118     {
00119       return true;
00120     }
00121 
00122     std::vector<uint8_t> get_raw_leaf(uint64_t) override
00123     {
00124       return {};
00125     }
00126 
00127     void emit_signature() override
00128     {
00129       auto txid = store.next_txid();
00130       LOG_INFO_FMT("Issuing signature at {}.{}", txid.term, txid.version);
00131       store.commit(
00132         txid,
00133         [txid, this]() {
00134           auto sig = store.create_reserved_tx(txid.version);
00135           auto sig_view =
00136             sig.template get_view<ccf::Signatures>(ccf::Tables::SIGNATURES);
00137           PrimarySignature sig_value(id, txid.version);
00138           sig_view->put(0, sig_value);
00139           return sig.commit_reserved();
00140         },
00141         true);
00142     }
00143 
00144     void try_emit_signature() override
00145     {
00146       emit_signature();
00147     }
00148 
00149     bool add_request(
00150       kv::TxHistory::RequestID,
00151       const std::vector<uint8_t>&,
00152       const std::vector<uint8_t>&,
00153       uint8_t) override
00154     {
00155       return true;
00156     }
00157 
00158     void add_result(
00159       kv::TxHistory::RequestID,
00160       kv::Version,
00161       const std::vector<uint8_t>&) override
00162     {}
00163 
00164     void add_pending(
00165       kv::TxHistory::RequestID,
00166       kv::Version,
00167       std::shared_ptr<std::vector<uint8_t>>) override
00168     {}
00169 
00170     void flush_pending() override {}
00171 
00172     virtual void add_result(
00173       RequestID, kv::Version, const uint8_t*, size_t) override
00174     {}
00175 
00176     void add_result(RequestID, kv::Version) override {}
00177 
00178     void add_response(
00179       kv::TxHistory::RequestID, const std::vector<uint8_t>&) override
00180     {}
00181 
00182     void register_on_result(ResultCallbackHandler) override {}
00183 
00184     void register_on_response(ResponseCallbackHandler) override {}
00185 
00186     void clear_on_result() override {}
00187 
00188     void clear_on_response() override {}
00189 
00190     crypto::Sha256Hash get_replicated_state_root() override
00191     {
00192       return crypto::Sha256Hash();
00193     }
00194 
00195     std::vector<uint8_t> get_receipt(kv::Version) override
00196     {
00197       return {};
00198     }
00199 
00200     bool verify_receipt(const std::vector<uint8_t>&) override
00201     {
00202       return true;
00203     }
00204   };
00205 
00206   typedef merkle::TreeT<32, merkle::sha256_openssl> HistoryTree;
00207 
00208   class Receipt
00209   {
00210   private:
00211     HistoryTree::Hash root;
00212     std::shared_ptr<HistoryTree::Path> path = nullptr;
00213 
00214   public:
00215     Receipt() {}
00216 
00217     Receipt(const std::vector<uint8_t>& v)
00218     {
00219       size_t position = 0;
00220       root.deserialise(v, position);
00221       path = std::make_shared<HistoryTree::Path>(v, position);
00222     }
00223 
00224     Receipt(HistoryTree* tree, uint64_t index)
00225     {
00226       root = tree->root();
00227       path = tree->path(index);
00228     }
00229 
00230     Receipt(const Receipt&) = delete;
00231 
00232     bool verify(HistoryTree* tree) const
00233     {
00234       return tree->max_index() == path->max_index() && tree->root() == root &&
00235         path->verify(root);
00236     }
00237 
00238     std::vector<uint8_t> to_v() const
00239     {
00240       std::vector<uint8_t> v;
00241       root.serialise(v);
00242       path->serialise(v);
00243       return v;
00244     }
00245   };
00246 
00247   class MerkleTreeHistory
00248   {
00249     HistoryTree* tree;
00250 
00251   public:
00252     MerkleTreeHistory(MerkleTreeHistory const&) = delete;
00253 
00254     MerkleTreeHistory(const std::vector<uint8_t>& serialised)
00255     {
00256       tree = new HistoryTree(serialised);
00257     }
00258 
00259     MerkleTreeHistory(crypto::Sha256Hash first_hash = {})
00260     {
00261       tree = new HistoryTree(merkle::Hash(first_hash.h));
00262     }
00263 
00264     ~MerkleTreeHistory()
00265     {
00266       delete (tree);
00267       tree = nullptr;
00268     }
00269 
00270     void deserialise(const std::vector<uint8_t>& serialised)
00271     {
00272       delete (tree);
00273       tree = new HistoryTree(serialised);
00274     }
00275 
00276     void append(crypto::Sha256Hash& hash)
00277     {
00278       tree->insert(merkle::Hash(hash.h));
00279     }
00280 
00281     crypto::Sha256Hash get_root() const
00282     {
00283       const merkle::Hash& root = tree->root();
00284       crypto::Sha256Hash result;
00285       std::copy(root.bytes, root.bytes + root.size(), result.h.begin());
00286       return result;
00287     }
00288 
00289     void operator=(const MerkleTreeHistory& rhs)
00290     {
00291       delete (tree);
00292       crypto::Sha256Hash root(rhs.get_root());
00293       tree = new HistoryTree(merkle::Hash(root.h));
00294     }
00295 
00296     void flush(uint64_t index)
00297     {
00298       LOG_TRACE_FMT("mt_flush_to index={}", index);
00299       tree->flush_to(index);
00300     }
00301 
00302     void retract(uint64_t index)
00303     {
00304       LOG_TRACE_FMT("mt_retract_to index={}", index);
00305       tree->retract_to(index);
00306     }
00307 
00308     Receipt get_receipt(uint64_t index)
00309     {
00310       if (index < begin_index())
00311       {
00312         throw std::logic_error(fmt::format(
00313           "Cannot produce receipt for {}: index is too old and has been "
00314           "flushed from memory",
00315           index));
00316       }
00317       if (index > end_index())
00318       {
00319         throw std::logic_error(fmt::format(
00320           "Cannot produce receipt for {}: index is not yet known", index));
00321       }
00322       return Receipt(tree, index);
00323     }
00324 
00325     bool verify(const Receipt& r)
00326     {
00327       return r.verify(tree);
00328     }
00329 
00330     std::vector<uint8_t> serialise()
00331     {
00332       LOG_TRACE_FMT("mt_serialize_size {}", tree->serialised_size());
00333       std::vector<uint8_t> output;
00334       tree->serialise(output);
00335       return output;
00336     }
00337 
00338     uint64_t begin_index()
00339     {
00340       return tree->min_index();
00341     }
00342 
00343     uint64_t end_index()
00344     {
00345       return tree->max_index();
00346     }
00347 
00348     bool in_range(uint64_t index)
00349     {
00350       return index >= begin_index() && index <= end_index();
00351     }
00352 
00353     crypto::Sha256Hash get_leaf(uint64_t index)
00354     {
00355       const merkle::Hash& leaf = tree->leaf(index);
00356       crypto::Sha256Hash result;
00357       std::copy(leaf.bytes, leaf.bytes + leaf.size(), result.h.begin());
00358       return result;
00359     }
00360   };
00361 
00362   template <class T>
00363   class HashedTxHistory : public kv::TxHistory
00364   {
00365     kv::Store& store;
00366     NodeId id;
00367     T replicated_state_tree;
00368 
00369     tls::KeyPair& kp;
00370 
00371     std::map<RequestID, std::vector<uint8_t>> requests;
00372     std::map<RequestID, std::pair<kv::Version, crypto::Sha256Hash>> results;
00373     std::map<RequestID, std::vector<uint8_t>> responses;
00374     std::optional<ResultCallbackHandler> on_result;
00375     std::optional<ResponseCallbackHandler> on_response;
00376 
00377     threading::Task::TimerEntry emit_signature_timer_entry;
00378     size_t sig_tx_interval;
00379     size_t sig_ms_interval;
00380 
00381     void discard_pending(kv::Version v)
00382     {
00383       std::lock_guard<SpinLock> vguard(version_lock);
00384       auto* p = pending_inserts.get_head();
00385       while (p != nullptr)
00386       {
00387         auto* next = p->next;
00388         if (p->version > v)
00389         {
00390           pending_inserts.remove(p);
00391           delete p;
00392         }
00393         p = next;
00394       }
00395     }
00396 
00397   public:
00398     HashedTxHistory(
00399       kv::Store& store_,
00400       NodeId id_,
00401       tls::KeyPair& kp_,
00402       size_t sig_tx_interval_ = 0,
00403       size_t sig_ms_interval_ = 0) :
00404       store(store_),
00405       id(id_),
00406       kp(kp_),
00407       sig_tx_interval(sig_tx_interval_),
00408       sig_ms_interval(sig_ms_interval_)
00409     {
00410       start_signature_emit_timer();
00411     }
00412 
00413     void start_signature_emit_timer()
00414     {
00415       struct EmitSigMsg
00416       {
00417         EmitSigMsg(HashedTxHistory<T>* self_) : self(self_) {}
00418         HashedTxHistory<T>* self;
00419       };
00420 
00421       auto emit_sig_msg = std::make_unique<threading::Tmsg<EmitSigMsg>>(
00422         [](std::unique_ptr<threading::Tmsg<EmitSigMsg>> msg) {
00423           auto self = msg->data.self;
00424 
00425           std::unique_lock<SpinLock> mguard(
00426             self->signature_lock, std::defer_lock);
00427 
00428           const int64_t sig_ms_interval = self->sig_ms_interval;
00429           int64_t delta_time_to_next_sig = sig_ms_interval;
00430 
00431           if (mguard.try_lock())
00432           {
00433             // NOTE: time is set on every thread via a thread message
00434             //       time_of_last_signature is a atomic that can be set by any
00435             //       thread
00436             auto time = threading::ThreadMessaging::thread_messaging
00437                           .get_current_time_offset()
00438                           .count();
00439             auto time_of_last_signature = self->time_of_last_signature.count();
00440 
00441             auto consensus = self->store.get_consensus();
00442             if (
00443               (consensus != nullptr) && consensus->is_primary() &&
00444               self->store.commit_gap() > 0 && time > time_of_last_signature &&
00445               (time - time_of_last_signature) > sig_ms_interval)
00446             {
00447               msg->data.self->emit_signature();
00448             }
00449 
00450             delta_time_to_next_sig =
00451               sig_ms_interval - (time - self->time_of_last_signature.count());
00452 
00453             if (
00454               delta_time_to_next_sig <= 0 ||
00455               delta_time_to_next_sig > sig_ms_interval)
00456             {
00457               delta_time_to_next_sig = sig_ms_interval;
00458             }
00459           }
00460 
00461           self->emit_signature_timer_entry =
00462             threading::ThreadMessaging::thread_messaging.add_task_after(
00463               std::move(msg),
00464               std::chrono::milliseconds(delta_time_to_next_sig));
00465         },
00466         this);
00467 
00468       emit_signature_timer_entry =
00469         threading::ThreadMessaging::thread_messaging.add_task_after(
00470           std::move(emit_sig_msg), std::chrono::milliseconds(1000));
00471     }
00472 
00473     ~HashedTxHistory()
00474     {
00475       threading::ThreadMessaging::thread_messaging.cancel_timer_task(
00476         emit_signature_timer_entry);
00477     }
00478 
00479     void register_on_result(ResultCallbackHandler func) override
00480     {
00481       if (on_result.has_value())
00482       {
00483         throw std::logic_error("on_result has already been set");
00484       }
00485       on_result = func;
00486     }
00487 
00488     void register_on_response(ResponseCallbackHandler func) override
00489     {
00490       if (on_response.has_value())
00491       {
00492         throw std::logic_error("on_response has already been set");
00493       }
00494       on_response = func;
00495     }
00496 
00497     void clear_on_result() override
00498     {
00499       on_result.reset();
00500     }
00501 
00502     void clear_on_response() override
00503     {
00504       on_response.reset();
00505     }
00506 
00507     void set_node_id(NodeId id_)
00508     {
00509       id = id_;
00510     }
00511 
00512     bool init_from_snapshot(
00513       const std::vector<uint8_t>& hash_at_snapshot) override
00514     {
00515       // The history can be initialised after a snapshot has been applied by
00516       // deserialising the tree in the signatures table and then applying the
00517       // hash of the transaction at which the snapshot was taken
00518       auto tx = store.create_read_only_tx();
00519       auto sig_tv = tx.template get_read_only_view<ccf::Signatures>(
00520         ccf::Tables::SIGNATURES);
00521       auto sig = sig_tv->get(0);
00522       if (!sig.has_value())
00523       {
00524         LOG_FAIL_FMT("No signature found in signatures map");
00525         return false;
00526       }
00527 
00528       CCF_ASSERT_FMT(
00529         !replicated_state_tree.in_range(1),
00530         "Tree is not empty before initialising from snapshot");
00531 
00532       replicated_state_tree.deserialise(sig->tree);
00533 
00534       crypto::Sha256Hash hash;
00535       std::copy_n(
00536         hash_at_snapshot.begin(), crypto::Sha256Hash::SIZE, hash.h.begin());
00537       replicated_state_tree.append(hash);
00538       return true;
00539     }
00540 
00541     crypto::Sha256Hash get_replicated_state_root() override
00542     {
00543       return replicated_state_tree.get_root();
00544     }
00545 
00546     void append(const std::vector<uint8_t>& replicated) override
00547     {
00548       append(replicated.data(), replicated.size());
00549     }
00550 
00551     void append(const uint8_t* replicated, size_t replicated_size) override
00552     {
00553       crypto::Sha256Hash rh({replicated, replicated_size});
00554       log_hash(rh, APPEND);
00555       replicated_state_tree.append(rh);
00556     }
00557 
00558     kv::TxHistory::Result verify_and_sign(
00559       PrimarySignature& sig, kv::Term* term = nullptr) override
00560     {
00561       if (!verify(term, &sig))
00562       {
00563         return kv::TxHistory::Result::FAIL;
00564       }
00565 
00566       kv::TxHistory::Result result = kv::TxHistory::Result::OK;
00567 
00568       auto progress_tracker = store.get_progress_tracker();
00569       CCF_ASSERT(progress_tracker != nullptr, "progress_tracker is not set");
00570       result = progress_tracker->record_primary(
00571         {sig.view, sig.seqno},
00572         sig.node,
00573         sig.root,
00574         sig.sig,
00575         sig.hashed_nonce,
00576         store.get_consensus()->node_count());
00577 
00578       sig.node = id;
00579       sig.sig = kp.sign_hash(sig.root.h.data(), sig.root.h.size());
00580 
00581       return result;
00582     }
00583 
00584     bool verify(
00585       kv::Term* term = nullptr, PrimarySignature* signature = nullptr) override
00586     {
00587       auto tx = store.create_tx();
00588       auto [sig_tv, ni_tv] = tx.template get_view<ccf::Signatures, ccf::Nodes>(
00589         ccf::Tables::SIGNATURES, ccf::Tables::NODES);
00590       auto sig = sig_tv->get(0);
00591       if (!sig.has_value())
00592       {
00593         LOG_FAIL_FMT("No signature found in signatures map");
00594         return false;
00595       }
00596       auto& sig_value = sig.value();
00597       if (term)
00598       {
00599         *term = sig_value.view;
00600       }
00601 
00602       if (signature)
00603       {
00604         *signature = sig_value;
00605       }
00606 
00607       auto ni = ni_tv->get(sig_value.node);
00608       if (!ni.has_value())
00609       {
00610         LOG_FAIL_FMT(
00611           "No node info, and therefore no cert for node {}", sig_value.node);
00612         return false;
00613       }
00614       tls::VerifierPtr from_cert = tls::make_verifier(ni.value().cert);
00615       crypto::Sha256Hash root = replicated_state_tree.get_root();
00616       log_hash(root, VERIFY);
00617       bool result = from_cert->verify_hash(
00618         root.h.data(),
00619         root.h.size(),
00620         sig_value.sig.data(),
00621         sig_value.sig.size());
00622 
00623       if (!result)
00624       {
00625         return false;
00626       }
00627 
00628       return true;
00629     }
00630 
00631     void rollback(kv::Version v) override
00632     {
00633       discard_pending(v);
00634       replicated_state_tree.retract(v);
00635       log_hash(replicated_state_tree.get_root(), ROLLBACK);
00636     }
00637 
00638     void compact(kv::Version v) override
00639     {
00640       flush_pending();
00641       // Receipts can only be retrieved to the flushed index. Keep a range of
00642       // history so that a range of receipts are available.
00643       if (v > MAX_HISTORY_LEN)
00644       {
00645         replicated_state_tree.flush(v - MAX_HISTORY_LEN);
00646       }
00647       log_hash(replicated_state_tree.get_root(), COMPACT);
00648     }
00649 
00650     kv::Version last_signed_tx = 0;
00651     std::chrono::milliseconds time_of_last_signature =
00652       std::chrono::milliseconds(0);
00653 
00654     SpinLock signature_lock;
00655 
00656     void try_emit_signature() override
00657     {
00658       std::unique_lock<SpinLock> mguard(signature_lock, std::defer_lock);
00659       if (store.commit_gap() < sig_tx_interval || !mguard.try_lock())
00660       {
00661         return;
00662       }
00663 
00664       if (store.commit_gap() >= sig_tx_interval)
00665       {
00666         emit_signature();
00667       }
00668     }
00669 
00670     void emit_signature() override
00671     {
00672       // Signatures are only emitted when there is a consensus
00673       auto consensus = store.get_consensus();
00674       if (!consensus)
00675       {
00676         return;
00677       }
00678 
00679       // Signatures are only emitted when the consensus is establishing commit
00680       // over the node's own transactions
00681       auto signable_txid = consensus->get_signable_txid();
00682       if (!signable_txid.has_value())
00683       {
00684         return;
00685       }
00686 
00687       auto commit_txid = signable_txid.value();
00688       auto txid = store.next_txid();
00689 
00690       last_signed_tx = commit_txid.second;
00691       time_of_last_signature =
00692         threading::ThreadMessaging::thread_messaging.get_current_time_offset();
00693 
00694       LOG_DEBUG_FMT(
00695         "Signed at {} in view: {} commit was: {}.{}",
00696         txid.version,
00697         txid.term,
00698         commit_txid.first,
00699         commit_txid.second);
00700 
00701       store.commit(
00702         txid,
00703         [txid, commit_txid, this]() {
00704           auto sig = store.create_reserved_tx(txid.version);
00705           auto sig_view =
00706             sig.template get_view<ccf::Signatures>(ccf::Tables::SIGNATURES);
00707           crypto::Sha256Hash root = replicated_state_tree.get_root();
00708 
00709           Nonce hashed_nonce;
00710           std::vector<uint8_t> primary_sig;
00711           auto consensus = store.get_consensus();
00712           if (consensus != nullptr && consensus->type() == ConsensusType::BFT)
00713           {
00714             auto progress_tracker = store.get_progress_tracker();
00715             CCF_ASSERT(
00716               progress_tracker != nullptr, "progress_tracker is not set");
00717             auto r = progress_tracker->record_primary(
00718               txid, id, root, primary_sig, hashed_nonce);
00719             if (r != kv::TxHistory::Result::OK)
00720             {
00721               throw ccf::ccf_logic_error(fmt::format(
00722                 "Expected success when primary added signature to the "
00723                 "progress "
00724                 "tracker. r:{}, view:{}, seqno:{}",
00725                 r,
00726                 txid.term,
00727                 txid.version));
00728             }
00729 
00730             progress_tracker->get_my_hashed_nonce(txid, hashed_nonce);
00731           }
00732           else
00733           {
00734             hashed_nonce.h.fill(0);
00735           }
00736 
00737           primary_sig = kp.sign_hash(root.h.data(), root.h.size());
00738 
00739           PrimarySignature sig_value(
00740             id,
00741             txid.version,
00742             txid.term,
00743             commit_txid.second,
00744             commit_txid.first,
00745             root,
00746             hashed_nonce,
00747             primary_sig,
00748             replicated_state_tree.serialise());
00749 
00750           if (consensus != nullptr && consensus->type() == ConsensusType::BFT)
00751           {
00752             auto progress_tracker = store.get_progress_tracker();
00753             CCF_ASSERT(
00754               progress_tracker != nullptr, "progress_tracker is not set");
00755             progress_tracker->record_primary_signature(txid, primary_sig);
00756           }
00757 
00758           sig_view->put(0, sig_value);
00759           return sig.commit_reserved();
00760         },
00761         true);
00762     }
00763 
00764     std::vector<uint8_t> get_receipt(kv::Version index) override
00765     {
00766       return replicated_state_tree.get_receipt(index).to_v();
00767     }
00768 
00769     bool verify_receipt(const std::vector<uint8_t>& v) override
00770     {
00771       Receipt r(v);
00772       return replicated_state_tree.verify(r);
00773     }
00774 
00775     std::vector<uint8_t> get_raw_leaf(uint64_t index) override
00776     {
00777       auto leaf = replicated_state_tree.get_leaf(index);
00778       return {leaf.h.begin(), leaf.h.end()};
00779     }
00780 
00781     bool add_request(
00782       kv::TxHistory::RequestID id,
00783       const std::vector<uint8_t>& caller_cert,
00784       const std::vector<uint8_t>& request,
00785       uint8_t frame_format) override
00786     {
00787       LOG_DEBUG_FMT("HISTORY: add_request {0}", id);
00788       requests[id] = request;
00789 
00790       auto consensus = store.get_consensus();
00791       if (!consensus)
00792       {
00793         return false;
00794       }
00795 
00796       return consensus->on_request({id, request, caller_cert, frame_format});
00797     }
00798 
00799     struct PendingInsert
00800     {
00801       PendingInsert(
00802         kv::TxHistory::RequestID i,
00803         kv::Version v,
00804         std::shared_ptr<std::vector<uint8_t>> r) :
00805         id(i),
00806         version(v),
00807         replicated(std::move(r)),
00808         next(nullptr),
00809         prev(nullptr)
00810       {}
00811 
00812       kv::TxHistory::RequestID id;
00813       kv::Version version;
00814       std::shared_ptr<std::vector<uint8_t>> replicated;
00815       PendingInsert* next;
00816       PendingInsert* prev;
00817     };
00818 
00819     SpinLock version_lock;
00820     snmalloc::DLList<PendingInsert, std::nullptr_t, true> pending_inserts;
00821 
00822     void add_pending(
00823       kv::TxHistory::RequestID id,
00824       kv::Version version,
00825       std::shared_ptr<std::vector<uint8_t>> replicated) override
00826     {
00827       add_result(id, version, replicated->data(), replicated->size());
00828     }
00829 
00830     void flush_pending() override
00831     {
00832       snmalloc::DLList<PendingInsert, std::nullptr_t, true> pi;
00833       {
00834         std::lock_guard<SpinLock> vguard(version_lock);
00835         pi = std::move(pending_inserts);
00836       }
00837 
00838       PendingInsert* p = pi.get_head();
00839       while (p != nullptr)
00840       {
00841         add_result(p->id, p->version, *p->replicated);
00842         p = p->next;
00843       }
00844     }
00845 
00846     void add_result(
00847       kv::TxHistory::RequestID id,
00848       kv::Version version,
00849       const std::vector<uint8_t>& replicated) override
00850     {
00851       add_result(id, version, replicated.data(), replicated.size());
00852     }
00853 
00854     void add_result(
00855       RequestID id,
00856       kv::Version version,
00857       const uint8_t* replicated,
00858       size_t replicated_size) override
00859     {
00860       append(replicated, replicated_size);
00861 
00862       auto consensus = store.get_consensus();
00863 
00864       if (consensus != nullptr && consensus->type() == ConsensusType::BFT)
00865       {
00866         if (on_result.has_value())
00867         {
00868           auto root = get_replicated_state_root();
00869           LOG_DEBUG_FMT("HISTORY: add_result {0} {1} {2}", id, version, root);
00870           results[id] = {version, root};
00871           on_result.value()({id, version, root});
00872         }
00873       }
00874     }
00875 
00876     void add_result(kv::TxHistory::RequestID id, kv::Version version) override
00877     {
00878       auto consensus = store.get_consensus();
00879 
00880       if (consensus != nullptr && consensus->type() == ConsensusType::BFT)
00881       {
00882         if (on_result.has_value())
00883         {
00884           auto root = get_replicated_state_root();
00885           LOG_DEBUG_FMT("HISTORY: add_result {0} {1} {2}", id, version, root);
00886           results[id] = {version, root};
00887           on_result.value()({id, version, root});
00888         }
00889       }
00890     }
00891 
00892     void add_response(
00893       kv::TxHistory::RequestID id,
00894       const std::vector<uint8_t>& response) override
00895     {
00896       LOG_DEBUG_FMT("HISTORY: add_response {0}", id);
00897       responses[id] = response;
00898     }
00899   };
00900 
00901   using MerkleTxHistory = HashedTxHistory<MerkleTreeHistory>;
00902 }
---------
Macros accessible in this file:
---------
HAVE_OPENSSL HAVE_MBEDTLS 
---------
Parsing file /data/git/CCF/src/node/history.h...
Preprocessing /data/git/CCF/src/node/identity.h...
#include tls/key_pair.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 584 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   struct NetworkIdentity
00013   {
00014     tls::Pem cert;
00015     tls::Pem priv_key;
00016 
00017     bool operator==(const NetworkIdentity& other) const
00018     {
00019       return cert == other.cert && priv_key == other.priv_key;
00020     }
00021 
00022     NetworkIdentity() = default;
00023 
00024     NetworkIdentity(const std::string& name)
00025     {
00026       auto identity_key_pair = tls::make_key_pair();
00027       cert = identity_key_pair->self_sign(name);
00028       priv_key = identity_key_pair->private_key_pem();
00029     }
00030   };
00031 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/identity.h...
Preprocessing /data/git/CCF/src/node/jwt.h...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 1581 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   struct JwtIssuerKeyPolicy
00014   {
00015     // OE claim name -> hex-encoded claim value
00016     // See openenclave/attestation/verifier.h
00017     std::optional<std::map<std::string, std::string>> sgx_claims;
00018 
00019     bool operator!=(const JwtIssuerKeyPolicy& rhs) const
00020     {
00021       return rhs.sgx_claims != sgx_claims;
00022     }
00023 
00024     MSGPACK_DEFINE(sgx_claims);
00025   };
00026 
00027   DECLARE_JSON_TYPE(JwtIssuerKeyPolicy);
00028   DECLARE_JSON_REQUIRED_FIELDS(JwtIssuerKeyPolicy, sgx_claims);
00029 
00030   enum class JwtIssuerKeyFilter
00031   {
00032     All,
00033     SGX
00034   };
00035 
00036   DECLARE_JSON_ENUM(
00037     JwtIssuerKeyFilter,
00038     {{JwtIssuerKeyFilter::All, "all"}, {JwtIssuerKeyFilter::SGX, "sgx"}});
00039 
00040   struct JwtIssuerMetadata
00041   {
00042     JwtIssuerKeyFilter key_filter;
00043     std::optional<JwtIssuerKeyPolicy> key_policy;
00044     std::optional<std::string> ca_cert_name;
00045     bool auto_refresh = false;
00046 
00047     MSGPACK_DEFINE(key_filter, key_policy, ca_cert_name, auto_refresh);
00048   };
00049 
00050   DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(JwtIssuerMetadata);
00051   DECLARE_JSON_REQUIRED_FIELDS(JwtIssuerMetadata, key_filter);
00052   DECLARE_JSON_OPTIONAL_FIELDS(
00053     JwtIssuerMetadata, key_policy, ca_cert_name, auto_refresh);
00054 
00055   using JwtIssuer = std::string;
00056   using JwtKeyId = std::string;
00057 
00058   using JwtIssuers = kv::Map<JwtIssuer, JwtIssuerMetadata>;
00059   using JwtPublicSigningKeys = kv::RawCopySerialisedMap<JwtKeyId, Cert>;
00060   using JwtPublicSigningKeyIssuer =
00061     kv::RawCopySerialisedMap<JwtKeyId, JwtIssuer>;
00062 }
00063 
00064 MSGPACK_ADD_ENUM(ccf::JwtIssuerKeyFilter);
00065 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/jwt.h...
Preprocessing /data/git/CCF/src/node/jwt_key_auto_refresh.h...
#include http/http_builder.h: not found! skipping...
#include http/http_rpc_context.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/jwt.h: not found! skipping...
#include node/rpc/member_frontend.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mutex: not found! skipping...
Preprocessor output (size: 10642 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 #define FMT_HEADER_ONLY
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   class JwtKeyAutoRefresh
00019   {
00020   private:
00021     size_t refresh_interval_s;
00022     NetworkState& network;
00023     std::shared_ptr<kv::Consensus> consensus;
00024     std::shared_ptr<enclave::RPCSessions> rpcsessions;
00025     std::shared_ptr<enclave::RPCMap> rpc_map;
00026     tls::Pem node_cert;
00027 
00028   public:
00029     JwtKeyAutoRefresh(
00030       size_t refresh_interval_s,
00031       NetworkState& network,
00032       std::shared_ptr<kv::Consensus> consensus,
00033       std::shared_ptr<enclave::RPCSessions> rpcsessions,
00034       std::shared_ptr<enclave::RPCMap> rpc_map,
00035       tls::Pem node_cert) :
00036       refresh_interval_s(refresh_interval_s),
00037       network(network),
00038       consensus(consensus),
00039       rpcsessions(rpcsessions),
00040       rpc_map(rpc_map),
00041       node_cert(node_cert)
00042     {}
00043 
00044     struct RefreshTimeMsg
00045     {
00046       RefreshTimeMsg(JwtKeyAutoRefresh& self_) : self(self_) {}
00047 
00048       JwtKeyAutoRefresh& self;
00049     };
00050 
00051     void start()
00052     {
00053       auto refresh_msg = std::make_unique<threading::Tmsg<RefreshTimeMsg>>(
00054         [](std::unique_ptr<threading::Tmsg<RefreshTimeMsg>> msg) {
00055           if (!msg->data.self.consensus->is_primary())
00056           {
00057             LOG_DEBUG_FMT(
00058               "JWT key auto-refresh: Node is not primary, skipping");
00059           }
00060           else
00061           {
00062             msg->data.self.refresh_jwt_keys();
00063           }
00064           LOG_DEBUG_FMT(
00065             "JWT key auto-refresh: Scheduling in {}s",
00066             msg->data.self.refresh_interval_s);
00067           auto delay = std::chrono::seconds(msg->data.self.refresh_interval_s);
00068           threading::ThreadMessaging::thread_messaging.add_task_after(
00069             std::move(msg), delay);
00070         },
00071         *this);
00072 
00073       LOG_DEBUG_FMT(
00074         "JWT key auto-refresh: Scheduling in {}s", refresh_interval_s);
00075       auto delay = std::chrono::seconds(refresh_interval_s);
00076       threading::ThreadMessaging::thread_messaging.add_task_after(
00077         std::move(refresh_msg), delay);
00078     }
00079 
00080     void schedule_once()
00081     {
00082       auto refresh_msg = std::make_unique<threading::Tmsg<RefreshTimeMsg>>(
00083         [](std::unique_ptr<threading::Tmsg<RefreshTimeMsg>> msg) {
00084           if (!msg->data.self.consensus->is_primary())
00085           {
00086             LOG_DEBUG_FMT(
00087               "JWT key one-off refresh: Node is not primary, skipping");
00088           }
00089           else
00090           {
00091             msg->data.self.refresh_jwt_keys();
00092           }
00093         },
00094         *this);
00095 
00096       LOG_DEBUG_FMT("JWT key one-off refresh: Scheduling without delay");
00097       auto delay = std::chrono::seconds(0);
00098       threading::ThreadMessaging::thread_messaging.add_task_after(
00099         std::move(refresh_msg), delay);
00100     }
00101 
00102     template <typename T>
00103     void send_refresh_jwt_keys(T msg)
00104     {
00105       auto body = serdes::pack(msg, serdes::Pack::Text);
00106 
00107       http::Request request(fmt::format(
00108         "/{}/{}",
00109         ccf::get_actor_prefix(ccf::ActorsType::members),
00110         "jwt_keys/refresh"));
00111       request.set_header(
00112         http::headers::CONTENT_TYPE, http::headervalues::contenttype::JSON);
00113       request.set_body(&body);
00114       // Need a custom authentication policy that accepts only node certs.
00115       // See https://github.com/microsoft/CCF/issues/1904
00116       // http::sign_request(request, node_sign_kp);
00117       auto packed = request.build_request();
00118 
00119       auto node_session = std::make_shared<enclave::SessionContext>(
00120         enclave::InvalidSessionId, node_cert.raw());
00121       auto ctx = enclave::make_rpc_context(node_session, packed);
00122 
00123       const auto actor_opt = http::extract_actor(*ctx);
00124       if (!actor_opt.has_value())
00125       {
00126         throw std::logic_error("Unable to get actor");
00127       }
00128 
00129       const auto actor = rpc_map->resolve(actor_opt.value());
00130       auto frontend_opt = this->rpc_map->find(actor);
00131       if (!frontend_opt.has_value())
00132       {
00133         throw std::logic_error(
00134           "RpcMap::find returned invalid (empty) frontend");
00135       }
00136       auto frontend = frontend_opt.value();
00137       frontend->process(ctx);
00138     }
00139 
00140     void send_refresh_jwt_keys_error()
00141     {
00142       // A message that the endpoint fails to parse, leading to 500.
00143       // This is done purely for exposing errors as endpoint metrics.
00144       auto msg = false;
00145       send_refresh_jwt_keys(msg);
00146     }
00147 
00148     void handle_jwt_jwks_response(
00149       const std::string& issuer,
00150       http_status status,
00151       std::vector<uint8_t>&& data)
00152     {
00153       if (status != HTTP_STATUS_OK)
00154       {
00155         LOG_FAIL_FMT(
00156           "JWT key auto-refresh: Error while requesting JWKS: {} {}{}",
00157           status,
00158           http_status_str(status),
00159           data.empty() ?
00160             "" :
00161             fmt::format("  '{}'", std::string(data.begin(), data.end())));
00162         send_refresh_jwt_keys_error();
00163         return;
00164       }
00165 
00166       LOG_DEBUG_FMT(
00167         "JWT key auto-refresh: Received JWKS for issuer '{}'", issuer);
00168 
00169       JsonWebKeySet jwks;
00170       try
00171       {
00172         jwks = nlohmann::json::parse(data).get<JsonWebKeySet>();
00173       }
00174       catch (const std::exception& e)
00175       {
00176         LOG_FAIL_FMT(
00177           "JWT key auto-refresh: Cannot parse JWKS for issuer '{}': {}",
00178           issuer,
00179           e.what());
00180         send_refresh_jwt_keys_error();
00181         return;
00182       }
00183 
00184       // call internal endpoint to update keys
00185       auto msg = SetJwtPublicSigningKeys{issuer, jwks};
00186       send_refresh_jwt_keys(msg);
00187     }
00188 
00189     void handle_jwt_metadata_response(
00190       const std::string& issuer,
00191       std::shared_ptr<tls::CA> ca,
00192       http_status status,
00193       std::vector<uint8_t>&& data)
00194     {
00195       if (status != HTTP_STATUS_OK)
00196       {
00197         LOG_FAIL_FMT(
00198           "JWT key auto-refresh: Error while requesting OpenID metadata: {} "
00199           "{}{}",
00200           status,
00201           http_status_str(status),
00202           data.empty() ?
00203             "" :
00204             fmt::format("  '{}'", std::string(data.begin(), data.end())));
00205         send_refresh_jwt_keys_error();
00206         return;
00207       }
00208 
00209       LOG_DEBUG_FMT(
00210         "JWT key auto-refresh: Received OpenID metadata for issuer '{}'",
00211         issuer);
00212 
00213       std::string jwks_url_str;
00214       try
00215       {
00216         auto metadata = nlohmann::json::parse(data);
00217         jwks_url_str = metadata.at("jwks_uri").get<std::string>();
00218       }
00219       catch (const std::exception& e)
00220       {
00221         LOG_FAIL_FMT(
00222           "JWT key auto-refresh: Cannot parse OpenID metadata for issuer '{}': "
00223           "{}",
00224           issuer,
00225           e.what());
00226         send_refresh_jwt_keys_error();
00227         return;
00228       }
00229       http::URL jwks_url;
00230       try
00231       {
00232         jwks_url = http::parse_url_full(jwks_url_str);
00233       }
00234       catch (const std::invalid_argument& e)
00235       {
00236         LOG_FAIL_FMT(
00237           "JWT key auto-refresh: Cannot parse jwks_uri for issuer '{}': {}",
00238           issuer,
00239           jwks_url_str);
00240         send_refresh_jwt_keys_error();
00241         return;
00242       }
00243       auto jwks_url_port = !jwks_url.port.empty() ? jwks_url.port : "443";
00244 
00245       auto ca_cert = std::make_shared<tls::Cert>(
00246         ca,
00247         std::nullopt,
00248         std::nullopt,
00249         nullb,
00250         tls::auth_required,
00251         jwks_url.host);
00252 
00253       LOG_DEBUG_FMT(
00254         "JWT key auto-refresh: Requesting JWKS at https://{}:{}{}",
00255         jwks_url.host,
00256         jwks_url_port,
00257         jwks_url.path);
00258       auto http_client = rpcsessions->create_client(ca_cert);
00259       // Note: Connection errors are not signalled and hence not tracked in
00260       // endpoint metrics currently.
00261       http_client->connect(
00262         std::string(jwks_url.host),
00263         std::string(jwks_url_port),
00264         [this, issuer](
00265           http_status status, http::HeaderMap&&, std::vector<uint8_t>&& data) {
00266           handle_jwt_jwks_response(issuer, status, std::move(data));
00267           return true;
00268         });
00269       http::Request r(jwks_url.path, HTTP_GET);
00270       r.set_header(http::headers::HOST, std::string(jwks_url.host));
00271       http_client->send_request(r.build_request());
00272     }
00273 
00274     void refresh_jwt_keys()
00275     {
00276       auto tx = network.tables->create_read_only_tx();
00277       auto jwt_issuers_view = tx.get_read_only_view(network.jwt_issuers);
00278       auto ca_certs_view = tx.get_read_only_view(network.ca_certs);
00279       jwt_issuers_view->foreach([this, &ca_certs_view](
00280                                   const JwtIssuer& issuer,
00281                                   const JwtIssuerMetadata& metadata) {
00282         if (!metadata.auto_refresh)
00283         {
00284           LOG_DEBUG_FMT(
00285             "JWT key auto-refresh: Skipping issuer '{}', auto-refresh is "
00286             "disabled",
00287             issuer);
00288           return true;
00289         }
00290         LOG_DEBUG_FMT(
00291           "JWT key auto-refresh: Refreshing keys for issuer '{}'", issuer);
00292         auto& ca_cert_name = metadata.ca_cert_name.value();
00293         auto ca_cert_der = ca_certs_view->get(ca_cert_name);
00294         if (!ca_cert_der.has_value())
00295         {
00296           LOG_FAIL_FMT(
00297             "JWT key auto-refresh: CA cert with name '{}' for issuer '{}' not "
00298             "found",
00299             ca_cert_name,
00300             issuer);
00301           send_refresh_jwt_keys_error();
00302           return true;
00303         }
00304 
00305         auto metadata_url_str = issuer + "/.well-known/openid-configuration";
00306         auto metadata_url = http::parse_url_full(metadata_url_str);
00307         auto metadata_url_port =
00308           !metadata_url.port.empty() ? metadata_url.port : "443";
00309 
00310         auto ca = std::make_shared<tls::CA>(ca_cert_der.value());
00311         auto ca_cert = std::make_shared<tls::Cert>(
00312           ca,
00313           std::nullopt,
00314           std::nullopt,
00315           nullb,
00316           tls::auth_required,
00317           metadata_url.host);
00318 
00319         LOG_DEBUG_FMT(
00320           "JWT key auto-refresh: Requesting OpenID metadata at https://{}:{}{}",
00321           metadata_url.host,
00322           metadata_url_port,
00323           metadata_url.path);
00324         auto http_client = rpcsessions->create_client(ca_cert);
00325         // Note: Connection errors are not signalled and hence not tracked in
00326         // endpoint metrics currently.
00327         http_client->connect(
00328           std::string(metadata_url.host),
00329           std::string(metadata_url_port),
00330           [this, issuer, ca](
00331             http_status status,
00332             http::HeaderMap&&,
00333             std::vector<uint8_t>&& data) {
00334             handle_jwt_metadata_response(issuer, ca, status, std::move(data));
00335             return true;
00336           });
00337         http::Request r(metadata_url.path, HTTP_GET);
00338         r.set_header(http::headers::HOST, std::string(metadata_url.host));
00339         http_client->send_request(r.build_request());
00340         return true;
00341       });
00342     }
00343   };
00344 
00345 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/node/jwt_key_auto_refresh.h...
Preprocessing /data/git/CCF/src/node/ledger_secrets.h...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include algorithm: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 2808 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace ccf
00014 {
00015   struct LedgerSecret
00016   {
00017     static constexpr auto MASTER_KEY_SIZE = crypto::GCM_SIZE_KEY;
00018 
00019     std::vector<uint8_t> master; // Referred to as "sd" in TR
00020 
00021     bool operator==(const LedgerSecret& other) const
00022     {
00023       return master == other.master;
00024     }
00025 
00026     LedgerSecret()
00027     {
00028       master = tls::create_entropy()->random(MASTER_KEY_SIZE);
00029     }
00030 
00031     LedgerSecret(const std::vector<uint8_t>& master_) : master(master_) {}
00032   };
00033 
00034   class LedgerSecrets
00035   {
00036   public:
00037     struct VersionedLedgerSecret
00038     {
00039       kv::Version version;
00040       LedgerSecret secret;
00041 
00042       bool operator==(const VersionedLedgerSecret& other) const
00043       {
00044         return version == other.version && secret == other.secret;
00045       }
00046     };
00047     // List of ledger secrets that are valid from a specific version to the
00048     // version of the next entry in the list. The last entry in the list is
00049     // valid for all subsequent versions.
00050     std::list<VersionedLedgerSecret> secrets_list;
00051 
00052     LedgerSecrets() = default;
00053 
00054     bool operator==(const LedgerSecrets& other) const
00055     {
00056       return secrets_list == other.secrets_list;
00057     }
00058 
00059     void init(kv::Version version = 1)
00060     {
00061       if (secrets_list.size() != 0)
00062       {
00063         throw std::logic_error("Ledger secrets have already been initialised!");
00064       }
00065 
00066       secrets_list.push_back({version, LedgerSecret()});
00067     }
00068 
00069     LedgerSecret get_latest()
00070     {
00071       if (secrets_list.size() == 0)
00072       {
00073         throw std::logic_error(
00074           "Could not retrieve latest ledger secret: no secret set");
00075       }
00076       return secrets_list.back().secret;
00077     }
00078 
00079     std::optional<LedgerSecret> get_penultimate()
00080     {
00081       if (secrets_list.size() <= 1)
00082       {
00083         return std::nullopt;
00084       }
00085       return std::next(secrets_list.rbegin())->secret;
00086     }
00087 
00088     void add_new_secret(kv::Version v, const LedgerSecret& ledger_secret)
00089     {
00090       secrets_list.push_back({v, ledger_secret});
00091     }
00092 
00093     void restore(std::list<VersionedLedgerSecret>&& restored_secrets)
00094     {
00095       if (
00096         secrets_list.size() >= 1 &&
00097         restored_secrets.back().version >= secrets_list.front().version)
00098       {
00099         throw std::logic_error(fmt::format(
00100           "Restored historical secrets should be before {}",
00101           secrets_list.front().version));
00102       }
00103 
00104       secrets_list.splice(secrets_list.begin(), std::move(restored_secrets));
00105     }
00106 
00107     std::optional<LedgerSecret> get_secret(kv::Version v)
00108     {
00109       for (auto const& s : secrets_list)
00110       {
00111         if (s.version == v)
00112         {
00113           return s.secret;
00114         }
00115       }
00116       LOG_FAIL_FMT("Ledger secret at version {} does not exist", v);
00117       return std::nullopt;
00118     }
00119   };
00120 }
00121 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/ledger_secrets.h...
Preprocessing /data/git/CCF/src/node/members.h...
#include client_signatures.h: already included! skipping...
#include ds/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include node_signature.h: already included! skipping...
#include tls/pem.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2799 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace ccf
00014 {
00015   enum class MemberStatus
00016   {
00017     ACCEPTED = 0,
00018     ACTIVE = 1,
00019     RETIRED = 2
00020   };
00021   DECLARE_JSON_ENUM(
00022     MemberStatus,
00023     {{MemberStatus::ACCEPTED, "ACCEPTED"},
00024      {MemberStatus::ACTIVE, "ACTIVE"},
00025      {MemberStatus::RETIRED, "RETIRED"}});
00026 }
00027 
00028 MSGPACK_ADD_ENUM(ccf::MemberStatus);
00029 
00030 namespace ccf
00031 {
00032   // Current limitations of secret sharing library (sss).
00033   static constexpr size_t max_active_recovery_members = 255;
00034 
00035   struct MemberPubInfo
00036   {
00037     tls::Pem cert;
00038 
00039     // If encryption public key is set, the member is a recovery member
00040     std::optional<tls::Pem> encryption_pub_key = std::nullopt;
00041     nlohmann::json member_data = nullptr;
00042 
00043     MemberPubInfo() {}
00044 
00045     MemberPubInfo(
00046       const tls::Pem& cert_,
00047       const std::optional<tls::Pem>& encryption_pub_key_ = std::nullopt,
00048       const nlohmann::json& member_data_ = nullptr) :
00049       cert(cert_),
00050       encryption_pub_key(encryption_pub_key_),
00051       member_data(member_data_)
00052     {}
00053 
00054     bool operator==(const MemberPubInfo& rhs) const
00055     {
00056       return cert == rhs.cert && encryption_pub_key == rhs.encryption_pub_key &&
00057         member_data == rhs.member_data;
00058     }
00059 
00060     bool is_recovery() const
00061     {
00062       return encryption_pub_key.has_value();
00063     }
00064 
00065     MSGPACK_DEFINE(cert, encryption_pub_key, member_data);
00066   };
00067 
00068 
00069 
00070 
00071   struct MemberInfo : public MemberPubInfo
00072   {
00073     MemberStatus status = MemberStatus::ACCEPTED;
00074 
00075     MemberInfo() {}
00076 
00077     MemberInfo(const MemberPubInfo& member_pub_info, MemberStatus status_) :
00078       MemberPubInfo(member_pub_info),
00079       status(status_)
00080     {}
00081 
00082     bool operator==(const MemberInfo& rhs) const
00083     {
00084       return MemberPubInfo::operator==(rhs) && status == rhs.status;
00085     }
00086 
00087     MSGPACK_DEFINE(MSGPACK_BASE(MemberPubInfo), status);
00088   };
00089 
00090 
00091   using Members = kv::Map<MemberId, MemberInfo>;
00092 
00093   /** Records a signed signature containing the last state digest and the next
00094    * state digest to sign
00095    */
00096   struct StateDigest
00097   {
00098     //! the next state digest the member is supposed to sign
00099     std::string state_digest;
00100 
00101     StateDigest() {}
00102 
00103     StateDigest(const crypto::Sha256Hash& root) : state_digest(root.hex_str())
00104     {}
00105 
00106     MSGPACK_DEFINE(state_digest);
00107   };
00108 
00109 
00110 
00111   struct MemberAck : public StateDigest
00112   {
00113     //! the signed request containing the last state digest
00114     SignedReq signed_req = {};
00115 
00116     MemberAck() {}
00117 
00118     MemberAck(const crypto::Sha256Hash& root) : StateDigest(root) {}
00119 
00120     MemberAck(const crypto::Sha256Hash& root, const SignedReq& signed_req_) :
00121       StateDigest(root),
00122       signed_req(signed_req_)
00123     {}
00124 
00125     MSGPACK_DEFINE(MSGPACK_BASE(StateDigest), signed_req);
00126   };
00127 
00128 
00129   using MemberAcks = kv::Map<MemberId, MemberAck>;
00130 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/members.h...
Preprocessing /data/git/CCF/src/node/merklecpp_trace.h...
#include ds/logger.h: not found! skipping...
Preprocessor output (size: 253 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 // Use the CCF logging infrastructure for merklecpp traces.
00008 #define MERKLECPP_TRACE_ENABLED
00009 #define MERKLECPP_TRACE(X) 
00010 
00011 
00012 
00013 #define MERKLECPP_TOUT
00014 
---------
Macros accessible in this file:
---------
MERKLECPP_TRACE_ENABLED MERKLECPP_TOUT MERKLECPP_TRACE 
---------
Parsing file /data/git/CCF/src/node/merklecpp_trace.h...
Preprocessing /data/git/CCF/src/node/modules.h...
#include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 323 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   struct Module
00014   {
00015     std::string js;
00016 
00017     Module() = default;
00018 
00019     Module(const std::string& js_) : js(js_) {}
00020 
00021     MSGPACK_DEFINE(js);
00022   };
00023 
00024 
00025 
00026   using Modules = kv::Map<std::string, Module>;
00027 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/modules.h...
Preprocessing /data/git/CCF/src/node/network_state.h...
#include tls/key_pair.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include algorithm: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include network_tables.h: already included! skipping...
Preprocessor output (size: 623 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/node/network_state.h" 2
00006 # 6 "/data/git/CCF/src/node/network_state.h" 2
00007 
00008 
00009 namespace ccf
00010 {
00011   struct NetworkState : public NetworkTables
00012   {
00013     std::unique_ptr<NetworkIdentity> identity;
00014     std::shared_ptr<LedgerSecrets> ledger_secrets;
00015     // default set to Raft
00016     ConsensusType consensus_type = ConsensusType::CFT;
00017 
00018     NetworkState(const ConsensusType& consensus_type_) :
00019       NetworkTables(consensus_type_),
00020       consensus_type(consensus_type_)
00021     {}
00022     NetworkState() = default;
00023   };
00024 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/network_state.h...
Preprocessing /data/git/CCF/src/node/network_tables.h...
#include backup_signatures.h: already included! skipping...
#include certs.h: not found! skipping...
#include client_signatures.h: already included! skipping...
#include code_id.h: not found! skipping...
#include config.h: already included! skipping...
#include consensus.h: already included! skipping...
#include consensus/aft/raft_tables.h: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include consensus/aft/revealed_nonces.h: not found! skipping...
#include entities.h: already included! skipping...
#include governance_history.h: already included! skipping...
#include jwt.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include members.h: already included! skipping...
#include modules.h: already included! skipping...
#include nodes.h: not found! skipping...
#include proposals.h: already included! skipping...
#include scripts.h: already included! skipping...
#include secrets.h: already included! skipping...
#include service.h: already included! skipping...
#include shares.h: already included! skipping...
#include signatures.h: already included! skipping...
#include snapshot_evidence.h: already included! skipping...
#include submitted_shares.h: already included! skipping...
#include users.h: already included! skipping...
#include values.h: already included! skipping...
#include whitelists.h: already included! skipping...
#include memory: not found! skipping...
#include tuple: not found! skipping...
Preprocessor output (size: 4166 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 namespace ccf
00037 {
00038   struct NetworkTables
00039   {
00040     std::shared_ptr<kv::Store> tables;
00041 
00042     //
00043     // Governance tables
00044     //
00045     // members, member_certs and member_digests tables should always be in sync
00046     Members members;
00047     CertDERs member_certs;
00048     CertDigests member_digests;
00049 
00050     Scripts gov_scripts;
00051     Modules modules;
00052     Proposals proposals;
00053     Whitelists whitelists;
00054     CodeIDs node_code_ids;
00055     MemberAcks member_acks;
00056     GovernanceHistory governance_history;
00057     Shares shares;
00058     SubmittedShares submitted_shares;
00059     Configuration config;
00060 
00061     CACertDERs ca_certs;
00062 
00063     JwtIssuers jwt_issuers;
00064     JwtPublicSigningKeys jwt_public_signing_keys;
00065     JwtPublicSigningKeyIssuer jwt_public_signing_key_issuer;
00066 
00067     //
00068     // User tables
00069     //
00070     // users, user_certs and user_digests tables should always be in sync
00071     Users users;
00072     CertDERs user_certs;
00073     CertDigests user_digests;
00074 
00075     //
00076     // Node table
00077     //
00078     Nodes nodes;
00079 
00080     //
00081     // Lua application table
00082     //
00083     Scripts app_scripts;
00084 
00085     //
00086     // Internal CCF tables
00087     //
00088     Service service;
00089     Values values;
00090     Secrets secrets;
00091     Signatures signatures;
00092     ConsensusTable consensus;
00093     SnapshotEvidence snapshot_evidence;
00094 
00095     //
00096     // bft related tables
00097     //
00098     aft::RequestsMap bft_requests_map;
00099     BackupSignaturesMap backup_signatures_map;
00100     aft::RevealedNoncesMap revealed_nonces_map;
00101     NewViewsMap new_views_map;
00102 
00103     NetworkTables(const ConsensusType& consensus_type = ConsensusType::CFT) :
00104       tables(
00105         (consensus_type == ConsensusType::CFT) ?
00106           std::make_shared<kv::Store>(
00107             aft::replicate_type_raft, aft::replicated_tables_raft) :
00108           std::make_shared<kv::Store>(
00109             aft::replicate_type_bft, aft::replicated_tables_bft)),
00110       members(Tables::MEMBERS),
00111       member_certs(Tables::MEMBER_CERT_DERS),
00112       member_digests(Tables::MEMBER_DIGESTS),
00113       gov_scripts(Tables::GOV_SCRIPTS),
00114       modules(Tables::MODULES),
00115       proposals(Tables::PROPOSALS),
00116       whitelists(Tables::WHITELISTS),
00117       node_code_ids(Tables::NODE_CODE_IDS),
00118       member_acks(Tables::MEMBER_ACKS),
00119       governance_history(Tables::GOV_HISTORY),
00120       shares(Tables::SHARES),
00121       submitted_shares(Tables::SUBMITTED_SHARES),
00122       config(Tables::CONFIGURATION),
00123       ca_certs(Tables::CA_CERT_DERS),
00124       jwt_issuers(Tables::JWT_ISSUERS),
00125       jwt_public_signing_keys(Tables::JWT_PUBLIC_SIGNING_KEYS),
00126       jwt_public_signing_key_issuer(Tables::JWT_PUBLIC_SIGNING_KEY_ISSUER),
00127       users(Tables::USERS),
00128       user_certs(Tables::USER_CERT_DERS),
00129       user_digests(Tables::USER_DIGESTS),
00130       nodes(Tables::NODES),
00131       app_scripts(Tables::APP_SCRIPTS),
00132       service(Tables::SERVICE),
00133       values(Tables::VALUES),
00134       secrets(Tables::SECRETS),
00135       signatures(Tables::SIGNATURES),
00136       consensus(Tables::CONSENSUS),
00137       snapshot_evidence(Tables::SNAPSHOT_EVIDENCE),
00138       bft_requests_map(Tables::AFT_REQUESTS),
00139       backup_signatures_map(Tables::BACKUP_SIGNATURES),
00140       revealed_nonces_map(Tables::NONCES),
00141       new_views_map(Tables::NEW_VIEWS)
00142     {}
00143 
00144     /** Returns a tuple of all tables that are possibly accessible from scripts
00145      * (app and gov). More fine-grained access control is applied via
00146      * whitelists.
00147      */
00148     auto get_scriptable_tables() const
00149     {
00150       return std::make_tuple(
00151         std::ref(members),
00152         std::ref(member_certs),
00153         std::ref(gov_scripts),
00154         std::ref(modules),
00155         std::ref(proposals),
00156         std::ref(whitelists),
00157         std::ref(node_code_ids),
00158         std::ref(member_acks),
00159         std::ref(governance_history),
00160         std::ref(config),
00161         std::ref(ca_certs),
00162         std::ref(jwt_issuers),
00163         std::ref(jwt_public_signing_keys),
00164         std::ref(jwt_public_signing_key_issuer),
00165         std::ref(users),
00166         std::ref(user_certs),
00167         std::ref(nodes),
00168         std::ref(service),
00169         std::ref(app_scripts),
00170         std::ref(values),
00171         std::ref(signatures));
00172     }
00173   };
00174 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/network_tables.h...
Preprocessing /data/git/CCF/src/node/node_signature.h...
#include crypto/hash.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2059 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   using Nonce = crypto::Sha256Hash;
00013 
00014   struct NodeSignature
00015   {
00016     std::vector<uint8_t> sig;
00017     ccf::NodeId node;
00018     Nonce hashed_nonce;
00019 
00020     NodeSignature(const NodeSignature& ns) :
00021       sig(ns.sig),
00022       node(ns.node),
00023       hashed_nonce(ns.hashed_nonce)
00024     {}
00025     NodeSignature(
00026       const std::vector<uint8_t>& sig_, NodeId node_, Nonce hashed_nonce_) :
00027       sig(sig_),
00028       node(node_),
00029       hashed_nonce(hashed_nonce_)
00030     {}
00031     NodeSignature(ccf::NodeId node_, Nonce hashed_nonce_) :
00032       node(node_),
00033       hashed_nonce(hashed_nonce_)
00034     {}
00035     NodeSignature(ccf::NodeId node_) : node(node_) {}
00036     NodeSignature() = default;
00037 
00038     bool operator==(const NodeSignature& o) const
00039     {
00040       return sig == o.sig && hashed_nonce == o.hashed_nonce;
00041     }
00042 
00043     size_t get_serialized_size() const
00044     {
00045       return sizeof(node) + sizeof(hashed_nonce) + sizeof(size_t) + sig.size();
00046     }
00047 
00048     void serialize(uint8_t*& data, size_t& size) const
00049     {
00050       size_t sig_size = sig.size();
00051       serialized::write(
00052         data, size, reinterpret_cast<uint8_t*>(&sig_size), sizeof(sig_size));
00053       serialized::write(data, size, sig.data(), sig_size);
00054 
00055       serialized::write(
00056         data, size, reinterpret_cast<const uint8_t*>(&node), sizeof(node));
00057       serialized::write(
00058         data,
00059         size,
00060         reinterpret_cast<const uint8_t*>(&hashed_nonce),
00061         sizeof(hashed_nonce));
00062     }
00063 
00064     static NodeSignature deserialize(const uint8_t*& data, size_t& size)
00065     {
00066       NodeSignature n;
00067 
00068       size_t sig_size = serialized::read<size_t>(data, size);
00069       n.sig = serialized::read(data, size, sig_size);
00070       n.node = serialized::read<ccf::NodeId>(data, size);
00071       n.hashed_nonce = serialized::read<Nonce>(data, size);
00072 
00073       return n;
00074     }
00075 
00076     MSGPACK_DEFINE(sig, node, hashed_nonce);
00077   };
00078   DECLARE_JSON_TYPE(NodeSignature);
00079   DECLARE_JSON_REQUIRED_FIELDS(NodeSignature, sig, node, hashed_nonce);
00080 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/node_signature.h...
Preprocessing /data/git/CCF/src/node/node_state.h...
#include consensus/aft/raft_consensus.h: not found! skipping...
#include consensus/ledger_enclave.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/rpc_sessions.h: not found! skipping...
#include kv/encryptor.h: not found! skipping...
#include entities.h: already included! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include atomic: not found! skipping...
#include list: not found! skipping...
#include entities.h: already included! skipping...
#include code_id.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/tx.h: not found! skipping...
#include lua_interp/lua_interp.h: not found! skipping...
#include lua_interp/lua_util.h: not found! skipping...
#include members.h: already included! skipping...
#include network_tables.h: already included! skipping...
#include node_info_network.h: not found! skipping...
#include nodes.h: not found! skipping...
#include runtime_config/default_whitelists.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include values.h: already included! skipping...
#include algorithm: not found! skipping...
#include fstream: not found! skipping...
#include ostream: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/dl_list.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include nodes.h: not found! skipping...
#include signatures.h: already included! skipping...
#include tls/tls.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include array: not found! skipping...
#include deque: not found! skipping...
#include string.h: not found! skipping...
#include merklecpp.h: not found! skipping...
#include identity.h: already included! skipping...
#include ledger_secrets.h: already included! skipping...
#include network_tables.h: already included! skipping...
#include node/jwt_key_auto_refresh.h: not found! skipping...
#include node/progress_tracker.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
  #include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include entities.h: already included! skipping...
#include node_types.h: already included! skipping...
#include tls/key_exchange.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include mbedtls/ecdh.h: not found! skipping...
#include ds/serialized.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
#include node_types.h: already included! skipping...
#include algorithm: not found! skipping...
#include fmt/format.h: not found! skipping...
      #include ds/ccf_deprecated.h: not found! skipping...
#include ds/json_schema.h: not found! skipping...
#include ds/openapi.h: not found! skipping...
#include enclave/rpc_context.h: not found! skipping...
      #include ds/json.h: not found! skipping...
#include http/authentication/authentication_types.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include string: not found! skipping...
#include utility: not found! skipping...
#include http/authentication/cert_auth.h: not found! skipping...
#include http/authentication/jwt_auth.h: not found! skipping...
#include http/authentication/sig_auth.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/certs.h: not found! skipping...
      #include ds/json.h: not found! skipping...
#include enclave/interface.h: not found! skipping...
#include node/code_id.h: not found! skipping...
#include node/rpc/call_types.h: not found! skipping...
#include functional: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include regex: not found! skipping...
#include set: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
    #include enclave/rpc_context.h: not found! skipping...
#include endpoint_registry.h: already included! skipping...
#include http/http_consts.h: not found! skipping...
#include node/rpc/error.h: not found! skipping...
#include node/rpc/rpc_exception.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
    #include ds/histogram.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include serialization.h: already included! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include node/code_id.h: not found! skipping...
#include consensus/aft/request.h: not found! skipping...
#include ds/buffer.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
  #include enclave/forwarder_types.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include http/http_rpc_context.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/node_to_node.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
#include http/http_jwt.h: not found! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/jwt.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/service.h: not found! skipping...
  #include node/rpc/error.h: not found! skipping...
#include exception: not found! skipping...
#include string: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mutex: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
#include ds/nonstd.h: not found! skipping...
#include frontend.h: already included! skipping...
#include lua_interp/lua_json.h: not found! skipping...
#include lua_interp/tx_script_runner.h: not found! skipping...
#include node/genesis_gen.h: not found! skipping...
#include node/jwt.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/quote.h: not found! skipping...
#include node/secret_share.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
  #include node/entities.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
    #include ds/json_schema.h: not found! skipping...
#include node/identity.h: not found! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/node_info_network.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include openenclave/advanced/mallinfo.h: not found! skipping...
#include tls/base64.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include charconv: not found! skipping...
#include exception: not found! skipping...
#include initializer_list: not found! skipping...
#include map: not found! skipping...
#include memory: not found! skipping...
#include openenclave/attestation/verifier.h: not found! skipping...
#include set: not found! skipping...
#include sstream: not found! skipping...
#include openenclave/host_verify.h: not found! skipping...
#include rpc/serialization.h: already included! skipping...
#include tls/entropy.h: not found! skipping...
#include array: not found! skipping...
#include fmt/format.h: not found! skipping...
#include iostream: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
#include tls/random_bytes.h: not found! skipping...
#include sss/sss.h: not found! skipping...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include genesis_gen.h: already included! skipping...
#include ledger_secrets.h: already included! skipping...
#include network_state.h: already included! skipping...
#include secret_share.h: already included! skipping...
#include tls/entropy.h: not found! skipping...
#include tls/rsa_key_pair.h: not found! skipping...
#include vector: not found! skipping...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/snapshot_evidence.h: not found! skipping...
#include deque: not found! skipping...
#include optional: not found! skipping...
#include tls/client.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include ccf_t.h: not found! skipping...
#include atomic: not found! skipping...
#include chrono: not found! skipping...
#include fmt/format.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include stdexcept: not found! skipping...
#include unordered_set: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 57904 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 # 9 "/data/git/CCF/src/node/node_state.h" 2
00010 
00011 # 11 "/data/git/CCF/src/node/node_state.h" 2
00012 # 12 "/data/git/CCF/src/node/node_state.h" 2
00013 # 13 "/data/git/CCF/src/node/node_state.h" 2
00014 
00015 
00016 
00017 # 17 "/data/git/CCF/src/node/node_state.h" 2
00018 # 18 "/data/git/CCF/src/node/node_state.h" 2
00019 # 19 "/data/git/CCF/src/node/node_state.h" 2
00020 
00021 # 21 "/data/git/CCF/src/node/node_state.h" 2
00022 # 22 "/data/git/CCF/src/node/node_state.h" 2
00023 # 23 "/data/git/CCF/src/node/node_state.h" 2
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 #define FMT_HEADER_ONLY
00038 
00039 
00040 
00041 
00042 
00043 
00044 // Used by fmtlib to render ccf::State
00045 namespace std
00046 {
00047   std::ostream& operator<<(std::ostream& os, ccf::State s)
00048   {
00049     nlohmann::json j;
00050     to_json(j, s);
00051     return os << j.dump();
00052   }
00053 }
00054 
00055 namespace ccf
00056 {
00057   using RaftConsensusType =
00058     aft::Consensus<consensus::LedgerEnclave, NodeToNode, Snapshotter>;
00059   using RaftType = aft::Aft<consensus::LedgerEnclave, NodeToNode, Snapshotter>;
00060 
00061   struct NodeCreateInfo
00062   {
00063     tls::Pem node_cert;
00064     tls::Pem network_cert;
00065   };
00066 
00067   template <typename T>
00068   class StateMachine
00069   {
00070     std::atomic<T> s;
00071 
00072   public:
00073     StateMachine(T s) : s(s) {}
00074     void expect(T s) const
00075     {
00076       auto state = this->s.load();
00077       if (s != state)
00078       {
00079         throw std::logic_error(
00080           fmt::format("State is {}, but expected {}", state, s));
00081       }
00082     }
00083 
00084     bool check(T s) const
00085     {
00086       return s == this->s.load();
00087     }
00088 
00089     T value() const
00090     {
00091       return this->s.load();
00092     }
00093 
00094     void advance(T s)
00095     {
00096       LOG_DEBUG_FMT("Advancing to state {} (from {})", s, this->s.load());
00097       this->s.store(s);
00098     }
00099   };
00100 
00101   void reset_data(std::vector<uint8_t>& data)
00102   {
00103     data.clear();
00104     data.shrink_to_fit();
00105   }
00106 
00107   class NodeState : public ccf::AbstractNodeState
00108   {
00109   private:
00110     //
00111     // this node's core state
00112     //
00113     StateMachine<State> sm;
00114     SpinLock lock;
00115 
00116     static constexpr NodeId invalid_node_id = -1;
00117     NodeId self = invalid_node_id;
00118     tls::KeyPairPtr node_sign_kp;
00119     tls::KeyPairPtr node_encrypt_kp;
00120     tls::Pem node_cert;
00121     std::vector<uint8_t> quote;
00122     CodeDigest node_code_id;
00123 
00124     //
00125     // kv store, replication, and I/O
00126     //
00127     ringbuffer::AbstractWriterFactory& writer_factory;
00128     ringbuffer::WriterPtr to_host;
00129     consensus::Config consensus_config;
00130     size_t sig_tx_interval;
00131     size_t sig_ms_interval;
00132 
00133     NetworkState& network;
00134 
00135     std::shared_ptr<kv::Consensus> consensus;
00136     std::shared_ptr<enclave::RPCMap> rpc_map;
00137     std::shared_ptr<NodeToNode> n2n_channels;
00138     std::shared_ptr<Forwarder<NodeToNode>> cmd_forwarder;
00139     std::shared_ptr<enclave::RPCSessions> rpcsessions;
00140 
00141     std::shared_ptr<kv::TxHistory> history;
00142     std::shared_ptr<ccf::ProgressTracker> progress_tracker;
00143     std::shared_ptr<ccf::ProgressTrackerStoreAdapter> tracker_store;
00144     std::shared_ptr<kv::AbstractTxEncryptor> encryptor;
00145 
00146     ShareManager& share_manager;
00147     std::shared_ptr<Snapshotter> snapshotter;
00148 
00149     //
00150     // recovery
00151     //
00152     NodeInfoNetwork node_info_network;
00153     std::shared_ptr<kv::Store> recovery_store;
00154     std::shared_ptr<kv::TxHistory> recovery_history;
00155     std::shared_ptr<kv::AbstractTxEncryptor> recovery_encryptor;
00156 
00157     kv::Version recovery_v;
00158     crypto::Sha256Hash recovery_root;
00159     std::vector<kv::Version> view_history;
00160     consensus::Index last_recovered_signed_idx = 1;
00161     std::list<RecoveredLedgerSecret> recovery_ledger_secrets;
00162     consensus::Index ledger_idx = 0;
00163     size_t recovery_snapshot_tx_interval = Snapshotter::max_tx_interval;
00164 
00165     struct StartupSnapshotInfo
00166     {
00167       std::vector<uint8_t>& raw;
00168       consensus::Index seqno;
00169       consensus::Index evidence_seqno;
00170 
00171       bool has_evidence = false;
00172       // The snapshot to startup from (on join or recovery) is only valid once a
00173       // signature ledger entry confirms that the snapshot evidence was
00174       // committed
00175       bool is_evidence_committed = false;
00176 
00177       StartupSnapshotInfo(
00178         std::vector<uint8_t>& raw_,
00179         consensus::Index seqno_,
00180         consensus::Index evidence_seqno_) :
00181         raw(raw_),
00182         seqno(seqno_),
00183         evidence_seqno(evidence_seqno_)
00184       {}
00185 
00186       bool is_snapshot_verified()
00187       {
00188         return has_evidence && is_evidence_committed;
00189       }
00190 
00191       ~StartupSnapshotInfo()
00192       {
00193         reset_data(raw);
00194       }
00195     };
00196     std::unique_ptr<StartupSnapshotInfo> startup_snapshot_info = nullptr;
00197 
00198     void initialise_startup_snapshot(CCFConfig& config)
00199     {
00200       LOG_INFO_FMT(
00201         "Deserialising public snapshot ({})", config.startup_snapshot.size());
00202       auto rc = network.tables->deserialise_snapshot(
00203         config.startup_snapshot, &view_history, true);
00204       if (rc != kv::DeserialiseSuccess::PASS)
00205       {
00206         throw std::logic_error(
00207           fmt::format("Failed to apply public snapshot: {}", rc));
00208       }
00209 
00210       LOG_INFO_FMT(
00211         "Public snapshot deserialised at seqno {}",
00212         network.tables->current_version());
00213 
00214       ledger_idx = network.tables->current_version();
00215       last_recovered_signed_idx = ledger_idx;
00216 
00217       startup_snapshot_info = std::make_unique<StartupSnapshotInfo>(
00218         config.startup_snapshot,
00219         ledger_idx,
00220         config.startup_snapshot_evidence_seqno);
00221     }
00222 
00223     //
00224     // JWT key auto-refresh
00225     //
00226     std::shared_ptr<JwtKeyAutoRefresh> jwt_key_auto_refresh;
00227 
00228   public:
00229     NodeState(
00230       ringbuffer::AbstractWriterFactory& writer_factory,
00231       NetworkState& network,
00232       std::shared_ptr<enclave::RPCSessions> rpcsessions,
00233       ShareManager& share_manager) :
00234       sm(State::uninitialized),
00235       self(INVALID_ID),
00236       node_sign_kp(tls::make_key_pair()),
00237       node_encrypt_kp(tls::make_key_pair()),
00238       writer_factory(writer_factory),
00239       to_host(writer_factory.create_writer_to_outside()),
00240       network(network),
00241       rpcsessions(rpcsessions),
00242       share_manager(share_manager),
00243       snapshotter(std::make_shared<Snapshotter>(writer_factory, network))
00244     {}
00245 
00246     //
00247     // funcs in state "uninitialized"
00248     //
00249     void initialize(
00250       const consensus::Config& consensus_config_,
00251       std::shared_ptr<NodeToNode> n2n_channels_,
00252       std::shared_ptr<enclave::RPCMap> rpc_map_,
00253       std::shared_ptr<Forwarder<NodeToNode>> cmd_forwarder_,
00254       size_t sig_tx_interval_,
00255       size_t sig_ms_interval_)
00256     {
00257       std::lock_guard<SpinLock> guard(lock);
00258       sm.expect(State::uninitialized);
00259 
00260       consensus_config = consensus_config_;
00261       n2n_channels = n2n_channels_;
00262       rpc_map = rpc_map_;
00263       cmd_forwarder = cmd_forwarder_;
00264       sig_tx_interval = sig_tx_interval_;
00265       sig_ms_interval = sig_ms_interval_;
00266       sm.advance(State::initialized);
00267     }
00268 
00269     //
00270     // funcs in state "initialized"
00271     //
00272     NodeCreateInfo create(StartType start_type, CCFConfig& config)
00273     {
00274       std::lock_guard<SpinLock> guard(lock);
00275       sm.expect(State::initialized);
00276 
00277       create_node_cert(config);
00278       open_frontend(ActorsType::nodes);
00279 
00280 
00281 
00282 
00283 
00284 
00285 
00286 
00287 
00288 
00289 
00290 
00291 
00292 
00293 
00294 
00295 
00296 
00297 
00298 
00299       switch (start_type)
00300       {
00301         case StartType::New:
00302         {
00303           network.identity =
00304             std::make_unique<NetworkIdentity>("CN=CCF Network");
00305 
00306           network.ledger_secrets = std::make_shared<LedgerSecrets>();
00307           network.ledger_secrets->init();
00308 
00309           set_node_id(0); // The first node id is always 0
00310 
00311           setup_encryptor(network.consensus_type);
00312           setup_consensus();
00313           setup_progress_tracker();
00314           setup_history();
00315 
00316           snapshotter->set_tx_interval(config.snapshot_tx_interval);
00317 
00318           // Become the primary and force replication
00319           consensus->force_become_primary();
00320 
00321           // Open member frontend for members to configure and open the
00322           // network
00323           open_frontend(ActorsType::members);
00324 
00325           if (!create_and_send_request(config, quote))
00326           {
00327             throw std::runtime_error(
00328               "Genesis transaction could not be committed");
00329           }
00330 
00331           accept_network_tls_connections(config);
00332           auto_refresh_jwt_keys(config);
00333 
00334           reset_data(quote);
00335           sm.advance(State::partOfNetwork);
00336 
00337           return {node_cert, network.identity->cert};
00338         }
00339         case StartType::Join:
00340         {
00341           // TLS connections are not endorsed by the network until the node
00342           // has joined
00343           accept_node_tls_connections();
00344           auto_refresh_jwt_keys(config);
00345 
00346           if (!config.startup_snapshot.empty())
00347           {
00348             setup_history();
00349 
00350             // It is necessary to give an encryptor to the store for it to
00351             // deserialise the public domain when recovering the public ledger
00352             network.ledger_secrets = std::make_shared<LedgerSecrets>();
00353             setup_encryptor(network.consensus_type);
00354 
00355             initialise_startup_snapshot(config);
00356 
00357             sm.advance(State::verifyingSnapshot);
00358           }
00359           else
00360           {
00361             sm.advance(State::pending);
00362           }
00363 
00364           return {node_cert, {}};
00365         }
00366         case StartType::Recover:
00367         {
00368           node_info_network = config.node_info_network;
00369 
00370           network.identity =
00371             std::make_unique<NetworkIdentity>("CN=CCF Network");
00372           network.ledger_secrets = std::make_shared<LedgerSecrets>();
00373 
00374           setup_history();
00375 
00376           // It is necessary to give an encryptor to the store for it to
00377           // deserialise the public domain when recovering the public ledger.
00378           // Once the public recovery is complete, the existing encryptor is
00379           // replaced with a new one initialised with recovered ledger
00380           // secrets.
00381           setup_encryptor(network.consensus_type);
00382 
00383           // Snapshot generation is disabled until private recovery is
00384           // complete
00385           recovery_snapshot_tx_interval = config.snapshot_tx_interval;
00386 
00387           bool from_snapshot = !config.startup_snapshot.empty();
00388           setup_recovery_hook(from_snapshot);
00389 
00390           if (from_snapshot)
00391           {
00392             initialise_startup_snapshot(config);
00393             snapshotter->set_last_snapshot_idx(ledger_idx);
00394           }
00395 
00396           accept_network_tls_connections(config);
00397           auto_refresh_jwt_keys(config);
00398 
00399           sm.advance(State::readingPublicLedger);
00400           return {node_cert, network.identity->cert};
00401         }
00402         default:
00403         {
00404           throw std::logic_error(
00405             fmt::format("Node was started in unknown mode {}", start_type));
00406         }
00407       }
00408     }
00409 
00410     //
00411     // funcs in state "pending"
00412     //
00413     void initiate_join(CCFConfig& config)
00414     {
00415       auto network_ca = std::make_shared<tls::CA>(config.joining.network_cert);
00416       auto join_client_cert = std::make_unique<tls::Cert>(
00417         network_ca, node_cert, node_sign_kp->private_key_pem());
00418 
00419       // Create RPC client and connect to remote node
00420       auto join_client =
00421         rpcsessions->create_client(std::move(join_client_cert));
00422 
00423       join_client->connect(
00424         config.joining.target_host,
00425         config.joining.target_port,
00426         [this, &config](
00427           http_status status, http::HeaderMap&&, std::vector<uint8_t>&& data) {
00428           std::lock_guard<SpinLock> guard(lock);
00429           if (!sm.check(State::pending))
00430           {
00431             return false;
00432           }
00433 
00434           if (status != HTTP_STATUS_OK)
00435           {
00436             LOG_FAIL_FMT(
00437               "An error occurred while joining the network: {} {}{}",
00438               status,
00439               http_status_str(status),
00440               data.empty() ?
00441                 "" :
00442                 fmt::format("  '{}'", std::string(data.begin(), data.end())));
00443             return false;
00444           }
00445 
00446           auto j = serdes::unpack(data, serdes::Pack::Text);
00447 
00448           JoinNetworkNodeToNode::Out resp;
00449           try
00450           {
00451             resp = j.get<JoinNetworkNodeToNode::Out>();
00452           }
00453           catch (const std::exception& e)
00454           {
00455             LOG_FAIL_FMT(
00456               "An error occurred while parsing the join network response");
00457             LOG_DEBUG_FMT(
00458               "An error occurred while parsing the join network response: {}",
00459               j.dump());
00460             return false;
00461           }
00462 
00463           // Set network secrets, node id and become part of network.
00464           if (resp.node_status == NodeStatus::TRUSTED)
00465           {
00466             network.identity =
00467               std::make_unique<NetworkIdentity>(resp.network_info.identity);
00468             network.ledger_secrets =
00469               std::make_shared<LedgerSecrets>(resp.network_info.ledger_secrets);
00470 
00471             set_node_id(resp.node_id);
00472 
00473             if (resp.network_info.consensus_type != network.consensus_type)
00474             {
00475               throw std::logic_error(fmt::format(
00476                 "Enclave initiated with consensus type {} but target node "
00477                 "responded with consensus {}",
00478                 network.consensus_type,
00479                 resp.network_info.consensus_type));
00480             }
00481 
00482             setup_encryptor(resp.network_info.consensus_type);
00483             setup_consensus(resp.network_info.public_only);
00484             setup_progress_tracker();
00485             setup_history();
00486 
00487             if (startup_snapshot_info)
00488             {
00489               // It is only possible to deserialise the entire snapshot then,
00490               // once the ledger secrets have been passed in by the network
00491               LOG_DEBUG_FMT(
00492                 "Deserialising snapshot ({})",
00493                 startup_snapshot_info->raw.size());
00494               std::vector<kv::Version> view_history;
00495               auto rc = network.tables->deserialise_snapshot(
00496                 startup_snapshot_info->raw,
00497                 &view_history,
00498                 resp.network_info.public_only);
00499               if (rc != kv::DeserialiseSuccess::PASS)
00500               {
00501                 throw std::logic_error(
00502                   fmt::format("Failed to apply snapshot on join: {}", rc));
00503               }
00504 
00505               auto tx = network.tables->create_read_only_tx();
00506               auto sig_view = tx.get_read_only_view(network.signatures);
00507               auto sig = sig_view->get(0);
00508               if (!sig.has_value())
00509               {
00510                 throw std::logic_error(
00511                   fmt::format("No signatures found after applying snapshot"));
00512               }
00513 
00514               auto seqno = network.tables->current_version();
00515               consensus->init_as_backup(seqno, sig->view, view_history);
00516 
00517               if (!resp.network_info.public_only)
00518               {
00519                 // Only clear snapshot if not recovering. When joining the
00520                 // public network the snapshot is used later to initialise the
00521                 // recovery store
00522                 startup_snapshot_info.reset();
00523               }
00524               else
00525               {
00526                 recovery_snapshot_tx_interval = config.snapshot_tx_interval;
00527               }
00528 
00529               LOG_INFO_FMT(
00530                 "Joiner successfully resumed from snapshot at seqno {} and "
00531                 "view {}",
00532                 seqno,
00533                 sig->view);
00534             }
00535 
00536             open_frontend(ActorsType::members);
00537 
00538             accept_network_tls_connections(config);
00539 
00540             if (resp.network_info.public_only)
00541             {
00542               last_recovered_signed_idx =
00543                 resp.network_info.last_recovered_signed_idx;
00544               setup_recovery_hook(startup_snapshot_info != nullptr);
00545               sm.advance(State::partOfPublicNetwork);
00546             }
00547             else
00548             {
00549               snapshotter->set_tx_interval(config.snapshot_tx_interval);
00550               reset_data(quote);
00551               sm.advance(State::partOfNetwork);
00552             }
00553 
00554             LOG_INFO_FMT(
00555               "Node has now joined the network as node {}: {}",
00556               self,
00557               (resp.network_info.public_only ? "public only" : "all domains"));
00558 
00559             // The network identity is now known, the user frontend can be
00560             // opened once the KV state catches up
00561             open_user_frontend();
00562           }
00563           else if (resp.node_status == NodeStatus::PENDING)
00564           {
00565             LOG_INFO_FMT(
00566               "Node {} is waiting for votes of members to be trusted",
00567               resp.node_id);
00568           }
00569 
00570           return true;
00571         });
00572 
00573       // Send RPC request to remote node to join the network.
00574       JoinNetworkNodeToNode::In join_params;
00575 
00576       join_params.node_info_network = config.node_info_network;
00577       join_params.public_encryption_key =
00578         node_encrypt_kp->public_key_pem().raw();
00579       join_params.quote = quote;
00580       join_params.consensus_type = network.consensus_type;
00581 
00582       LOG_DEBUG_FMT(
00583         "Sending join request to {}:{}",
00584         config.joining.target_host,
00585         config.joining.target_port);
00586 
00587       const auto body = serdes::pack(join_params, serdes::Pack::Text);
00588 
00589       http::Request r(fmt::format(
00590         "/{}/{}", ccf::get_actor_prefix(ccf::ActorsType::nodes), "join"));
00591       r.set_header(
00592         http::headers::CONTENT_TYPE, http::headervalues::contenttype::JSON);
00593       r.set_body(&body);
00594 
00595       join_client->send_request(r.build_request());
00596     }
00597 
00598     void start_join_timer(CCFConfig& config)
00599     {
00600       initiate_join(config);
00601 
00602       struct JoinTimeMsg
00603       {
00604         JoinTimeMsg(NodeState& self_, CCFConfig& config_) :
00605           self(self_),
00606           config(config_)
00607         {}
00608 
00609         NodeState& self;
00610         CCFConfig& config;
00611       };
00612 
00613       auto join_timer_msg = std::make_unique<threading::Tmsg<JoinTimeMsg>>(
00614         [](std::unique_ptr<threading::Tmsg<JoinTimeMsg>> msg) {
00615           if (msg->data.self.sm.check(State::pending))
00616           {
00617             msg->data.self.initiate_join(msg->data.config);
00618             auto delay =
00619               std::chrono::milliseconds(msg->data.config.joining.join_timer);
00620 
00621             threading::ThreadMessaging::thread_messaging.add_task_after(
00622               std::move(msg), delay);
00623           }
00624         },
00625         *this,
00626         config);
00627 
00628       threading::ThreadMessaging::thread_messaging.add_task_after(
00629         std::move(join_timer_msg),
00630         std::chrono::milliseconds(config.joining.join_timer));
00631     }
00632 
00633     void join(CCFConfig& config)
00634     {
00635       std::lock_guard<SpinLock> guard(lock);
00636       sm.expect(State::pending);
00637       start_join_timer(config);
00638     }
00639 
00640     void auto_refresh_jwt_keys(const CCFConfig& config)
00641     {
00642       if (!consensus)
00643       {
00644         LOG_INFO_FMT(
00645           "JWT key auto-refresh: consensus not initialized, not starting "
00646           "auto-refresh");
00647         return;
00648       }
00649       jwt_key_auto_refresh = std::make_shared<JwtKeyAutoRefresh>(
00650         config.jwt_key_refresh_interval_s,
00651         network,
00652         consensus,
00653         rpcsessions,
00654         rpc_map,
00655         node_cert);
00656       jwt_key_auto_refresh->start();
00657 
00658       network.tables->set_local_hook(
00659         network.jwt_issuers.get_name(),
00660         [this](kv::Version, const kv::untyped::Write&) {
00661           jwt_key_auto_refresh->schedule_once();
00662         });
00663     }
00664 
00665     //
00666     // funcs in state "readingPublicLedger" or "verifyingSnapshot"
00667     //
00668     void start_ledger_recovery()
00669     {
00670       std::lock_guard<SpinLock> guard(lock);
00671       if (
00672         !sm.check(State::readingPublicLedger) &&
00673         !sm.check(State::verifyingSnapshot))
00674       {
00675         throw std::logic_error(fmt::format(
00676           "Node should be in state {} or {} to recover public ledger entry",
00677           State::readingPublicLedger,
00678           State::verifyingSnapshot));
00679       }
00680 
00681       LOG_INFO_FMT("Starting public recovery");
00682       read_ledger_idx(++ledger_idx);
00683     }
00684 
00685     void recover_public_ledger_entry(const std::vector<uint8_t>& ledger_entry)
00686     {
00687       std::lock_guard<SpinLock> guard(lock);
00688       if (
00689         !sm.check(State::readingPublicLedger) &&
00690         !sm.check(State::verifyingSnapshot))
00691       {
00692         throw std::logic_error(fmt::format(
00693           "Node should be in state {} or {} to recover public ledger entry",
00694           State::readingPublicLedger,
00695           State::verifyingSnapshot));
00696       }
00697 
00698       LOG_INFO_FMT(
00699         "Deserialising public ledger entry ({})", ledger_entry.size());
00700 
00701       // When reading the public ledger, deserialise in the real store
00702       auto result = network.tables->deserialise(ledger_entry, true);
00703       if (result == kv::DeserialiseSuccess::FAILED)
00704       {
00705         LOG_FAIL_FMT("Failed to deserialise entry in public ledger");
00706         network.tables->rollback(ledger_idx - 1);
00707         if (sm.check(State::verifyingSnapshot))
00708         {
00709           throw std::logic_error(
00710             "Error deserialising public ledger entry when verifying snapshot");
00711         }
00712         recover_public_ledger_end_unsafe();
00713         return;
00714       }
00715 
00716       // If the ledger entry is a signature, it is safe to compact the store
00717       if (result == kv::DeserialiseSuccess::PASS_SIGNATURE)
00718       {
00719         network.tables->compact(ledger_idx);
00720         auto tx = network.tables->create_tx();
00721         GenesisGenerator g(network, tx);
00722         auto last_sig = g.get_last_signature();
00723 
00724         if (!last_sig.has_value())
00725         {
00726           throw std::logic_error("Signature missing");
00727         }
00728 
00729         LOG_DEBUG_FMT(
00730           "Read signature at {} for view {}", ledger_idx, last_sig->view);
00731         // Initial transactions, before the first signature, must have
00732         // happened in the first signature's view (eg - if the first
00733         // signature is at seqno 20 in view 4, then transactions 1->19 must
00734         // also have been in view 4). The brief justification is that while
00735         // the first node may start in an arbitrarily high view (it does not
00736         // necessarily start in view 1), it cannot _change_ view before a
00737         // valid signature.
00738         const auto view_start_idx =
00739           view_history.empty() ? 1 : last_recovered_signed_idx + 1;
00740         CCF_ASSERT_FMT(
00741           last_sig->view >= 0, "last_sig->view is invalid, {}", last_sig->view);
00742         for (auto i = view_history.size();
00743              i < static_cast<size_t>(last_sig->view);
00744              ++i)
00745         {
00746           view_history.push_back(view_start_idx);
00747         }
00748         last_recovered_signed_idx = ledger_idx;
00749 
00750         if (
00751           startup_snapshot_info && startup_snapshot_info->has_evidence &&
00752           last_sig->commit_seqno >= startup_snapshot_info->evidence_seqno)
00753         {
00754           startup_snapshot_info->is_evidence_committed = true;
00755         }
00756       }
00757       else if (
00758         result == kv::DeserialiseSuccess::PASS_SNAPSHOT_EVIDENCE &&
00759         startup_snapshot_info)
00760       {
00761         auto tx = network.tables->create_read_only_tx();
00762         auto snapshot_evidence_view =
00763           tx.get_read_only_view(network.snapshot_evidence);
00764         if (!snapshot_evidence_view)
00765         {
00766           throw std::logic_error("Invalid snapshot evidence");
00767         }
00768 
00769         if (ledger_idx == startup_snapshot_info->evidence_seqno)
00770         {
00771           auto snapshot_evidence = snapshot_evidence_view->get(0);
00772           if (!snapshot_evidence.has_value())
00773           {
00774             throw std::logic_error("Invalid snapshot evidence");
00775           }
00776 
00777           if (
00778             snapshot_evidence->hash ==
00779             crypto::Sha256Hash(startup_snapshot_info->raw))
00780           {
00781             LOG_DEBUG_FMT(
00782               "Snapshot evidence for snapshot found at {}",
00783               startup_snapshot_info->evidence_seqno);
00784             startup_snapshot_info->has_evidence = true;
00785           }
00786         }
00787       }
00788 
00789       read_ledger_idx(++ledger_idx);
00790     }
00791 
00792     void verify_snapshot_end(CCFConfig& config)
00793     {
00794       std::lock_guard<SpinLock> guard(lock);
00795       sm.expect(State::verifyingSnapshot);
00796 
00797       if (
00798         !startup_snapshot_info ||
00799         !startup_snapshot_info->is_snapshot_verified())
00800       {
00801         throw std::logic_error("Snapshot evidence was not committed in ledger");
00802       }
00803 
00804       network.tables->clear();
00805       ledger_truncate(startup_snapshot_info->seqno);
00806 
00807       sm.advance(State::pending);
00808       start_join_timer(config);
00809     }
00810 
00811     void recover_public_ledger_end_unsafe()
00812     {
00813       sm.expect(State::readingPublicLedger);
00814 
00815       if (startup_snapshot_info)
00816       {
00817         if (!startup_snapshot_info->is_snapshot_verified())
00818         {
00819           throw std::logic_error(
00820             "Snapshot evidence was not committed in ledger");
00821         }
00822 
00823         if (last_recovered_signed_idx < startup_snapshot_info->evidence_seqno)
00824         {
00825           throw std::logic_error("Snapshot evidence would be rolled back");
00826         }
00827       }
00828 
00829       // When reaching the end of the public ledger, truncate to last signed
00830       // index and promote network secrets to this index
00831       network.tables->rollback(last_recovered_signed_idx);
00832       ledger_truncate(last_recovered_signed_idx);
00833       LOG_INFO_FMT(
00834         "End of public ledger recovery - Truncating ledger to last signed "
00835         "index: {}",
00836         last_recovered_signed_idx);
00837 
00838       network.ledger_secrets->init(last_recovered_signed_idx + 1);
00839       // KV term must be set before the first Tx is committed
00840       auto new_term = view_history.size() + 2;
00841       LOG_INFO_FMT("Setting term on public recovery KV to {}", new_term);
00842       network.tables->set_term(new_term);
00843 
00844       auto tx = network.tables->create_tx();
00845       GenesisGenerator g(network, tx);
00846       g.create_service(network.identity->cert);
00847       g.retire_active_nodes();
00848 
00849       set_node_id(g.add_node({node_info_network,
00850                               node_cert,
00851                               quote,
00852                               node_encrypt_kp->public_key_pem().raw(),
00853                               NodeStatus::PENDING}));
00854 
00855       setup_encryptor(network.consensus_type);
00856 
00857       LOG_INFO_FMT("Deleted previous nodes and added self as {}", self);
00858 
00859       kv::Version index = 0;
00860       kv::Term view = 0;
00861       kv::Version global_commit = 0;
00862 
00863       auto ls = g.get_last_signature();
00864       if (ls.has_value())
00865       {
00866         auto s = ls.value();
00867         index = s.seqno;
00868         view = s.view;
00869         global_commit = s.commit_seqno;
00870       }
00871 
00872       auto h = dynamic_cast<MerkleTxHistory*>(history.get());
00873       if (h)
00874       {
00875         h->set_node_id(self);
00876       }
00877 
00878       if (progress_tracker != nullptr)
00879       {
00880         progress_tracker->set_node_id(self);
00881       }
00882 
00883       setup_raft(true);
00884 
00885       LOG_DEBUG_FMT(
00886         "Restarting consensus at view: {} seqno: {} commit_seqno {}",
00887         view,
00888         index,
00889         global_commit);
00890 
00891       consensus->force_become_primary(index, view, view_history, index);
00892 
00893       // Sets itself as trusted
00894       g.trust_node(self);
00895 
00896 
00897 
00898 
00899 
00900 
00901 
00902 
00903       if (g.finalize() != kv::CommitSuccess::OK)
00904       {
00905         throw std::logic_error(
00906           "Could not commit transaction when starting recovered public "
00907           "network");
00908       }
00909 
00910       open_frontend(ActorsType::members);
00911 
00912       sm.advance(State::partOfPublicNetwork);
00913     }
00914 
00915     //
00916     // funcs in state "readingPrivateLedger"
00917     //
00918     void recover_private_ledger_entry(const std::vector<uint8_t>& ledger_entry)
00919     {
00920       std::lock_guard<SpinLock> guard(lock);
00921       sm.expect(State::readingPrivateLedger);
00922 
00923       LOG_INFO_FMT(
00924         "Deserialising private ledger entry ({})", ledger_entry.size());
00925 
00926       // When reading the private ledger, deserialise in the recovery store
00927       auto result = recovery_store->deserialise(ledger_entry);
00928       if (result == kv::DeserialiseSuccess::FAILED)
00929       {
00930         LOG_FAIL_FMT("Failed to deserialise entry in private ledger");
00931         recovery_store->rollback(ledger_idx - 1);
00932         recover_private_ledger_end_unsafe();
00933         return;
00934       }
00935 
00936       if (result == kv::DeserialiseSuccess::PASS_SIGNATURE)
00937       {
00938         recovery_store->compact(ledger_idx);
00939       }
00940 
00941       if (recovery_store->current_version() == recovery_v)
00942       {
00943         LOG_INFO_FMT("Reached recovery final version at {}", recovery_v);
00944         recover_private_ledger_end_unsafe();
00945       }
00946       else
00947       {
00948         read_ledger_idx(++ledger_idx);
00949       }
00950     }
00951 
00952     void recover_private_ledger_end_unsafe()
00953     {
00954       // When reaching the end of the private ledger, make sure the same
00955       // ledger has been read and swap in private state
00956 
00957       sm.expect(State::readingPrivateLedger);
00958 
00959       if (recovery_v != recovery_store->current_version())
00960       {
00961         throw std::logic_error(fmt::format(
00962           "Private recovery did not reach public ledger version: {}/{}",
00963           recovery_store->current_version(),
00964           recovery_v));
00965       }
00966 
00967       auto h = dynamic_cast<MerkleTxHistory*>(recovery_history.get());
00968       if (h->get_replicated_state_root() != recovery_root)
00969       {
00970         throw std::logic_error(fmt::format(
00971           "Root of public store does not match root of private store at {}",
00972           recovery_v));
00973       }
00974 
00975       network.tables->swap_private_maps(*recovery_store.get());
00976       recovery_history.reset();
00977       recovery_store.reset();
00978       reset_recovery_hook();
00979 
00980       // Raft should deserialise all security domains when network is opened
00981       consensus->enable_all_domains();
00982 
00983       // Snapshots are only generated after recovery is complete
00984       snapshotter->set_tx_interval(recovery_snapshot_tx_interval);
00985 
00986       // Open the service
00987       if (consensus->is_primary())
00988       {
00989         auto tx = network.tables->create_tx();
00990 
00991         // Shares for the new ledger secret can only be issued now, once the
00992         // previous ledger secrets have been recovered
00993         share_manager.issue_shares_on_recovery(
00994           tx, last_recovered_signed_idx + 1);
00995         GenesisGenerator g(network, tx);
00996         if (!g.open_service())
00997         {
00998           throw std::logic_error("Service could not be opened");
00999         }
01000 
01001         if (g.finalize() != kv::CommitSuccess::OK)
01002         {
01003           throw std::logic_error(
01004             "Could not commit transaction when finishing network recovery");
01005         }
01006       }
01007       open_user_frontend();
01008       reset_data(quote);
01009       sm.advance(State::partOfNetwork);
01010     }
01011 
01012     //
01013     // funcs in state "readingPublicLedger" or "readingPrivateLedger"
01014     //
01015     void recover_ledger_end()
01016     {
01017       std::lock_guard<SpinLock> guard(lock);
01018 
01019       if (is_reading_public_ledger())
01020       {
01021         recover_public_ledger_end_unsafe();
01022       }
01023       else if (is_reading_private_ledger())
01024       {
01025         recover_private_ledger_end_unsafe();
01026       }
01027       else
01028       {
01029         throw std::logic_error(
01030           "Cannot end ledger recovery if not reading public or private "
01031           "ledger");
01032       }
01033     }
01034 
01035     //
01036     // funcs in state "partOfPublicNetwork"
01037     //
01038     void setup_private_recovery_store()
01039     {
01040       // Setup recovery store by cloning tables of store
01041       recovery_store = std::make_shared<kv::Store>();
01042 
01043       recovery_history = std::make_shared<MerkleTxHistory>(
01044         *recovery_store.get(),
01045         self,
01046         *node_sign_kp,
01047         sig_tx_interval,
01048         sig_ms_interval);
01049 
01050 
01051 
01052 
01053       if (network.consensus_type == ConsensusType::BFT)
01054       {
01055         recovery_encryptor =
01056           std::make_shared<BftTxEncryptor>(network.ledger_secrets, true);
01057       }
01058       else if (network.consensus_type == ConsensusType::CFT)
01059       {
01060         recovery_encryptor =
01061           std::make_shared<CftTxEncryptor>(network.ledger_secrets, true);
01062         recovery_encryptor->set_iv_id(self); // RaftEncryptor uses node ID in iv
01063       }
01064       else
01065       {
01066         throw std::logic_error(
01067           fmt::format("Unknown consensus type: {}", network.consensus_type));
01068       }
01069 
01070 
01071       recovery_store->set_history(recovery_history);
01072       recovery_store->set_encryptor(recovery_encryptor);
01073 
01074       // Record real store version and root
01075       recovery_v = network.tables->current_version();
01076       auto h = dynamic_cast<MerkleTxHistory*>(history.get());
01077       recovery_root = h->get_replicated_state_root();
01078 
01079       if (startup_snapshot_info)
01080       {
01081         LOG_INFO_FMT(
01082           "Deserialising private snapshot for recovery ({})",
01083           startup_snapshot_info->raw.size());
01084         std::vector<kv::Version> view_history;
01085         auto rc = recovery_store->deserialise_snapshot(
01086           startup_snapshot_info->raw, &view_history);
01087         if (rc != kv::DeserialiseSuccess::PASS)
01088         {
01089           throw std::logic_error(fmt::format(
01090             "Could not deserialise snapshot in recovery store: {}", rc));
01091         }
01092 
01093         startup_snapshot_info.reset();
01094       }
01095 
01096       LOG_DEBUG_FMT(
01097         "Recovery store successfully setup at {}. Target recovery seqno: {}",
01098         recovery_store->current_version(),
01099         recovery_v);
01100     }
01101 
01102     bool accept_recovery(kv::Tx& tx) override
01103     {
01104       std::lock_guard<SpinLock> guard(lock);
01105       sm.expect(State::partOfPublicNetwork);
01106 
01107       GenesisGenerator g(network, tx);
01108       share_manager.clear_submitted_recovery_shares(tx);
01109       return g.service_wait_for_shares();
01110     }
01111 
01112     void initiate_private_recovery(kv::Tx& tx) override
01113     {
01114       std::lock_guard<SpinLock> guard(lock);
01115       sm.expect(State::partOfPublicNetwork);
01116 
01117       auto restored_versions =
01118         share_manager.restore_recovery_shares_info(tx, recovery_ledger_secrets);
01119 
01120       LOG_INFO_FMT("Initiating end of recovery (primary)");
01121 
01122       // Emit signature to certify transactions that happened on public
01123       // network
01124       history->emit_signature();
01125 
01126       for (auto const& v : restored_versions)
01127       {
01128         broadcast_ledger_secret(
01129           tx, network.ledger_secrets->get_secret(v).value(), v, true);
01130       }
01131 
01132       setup_private_recovery_store();
01133 
01134       // Start reading private security domain of ledger
01135       ledger_idx = recovery_store->current_version();
01136       read_ledger_idx(++ledger_idx);
01137 
01138       recovery_ledger_secrets.clear();
01139       sm.advance(State::readingPrivateLedger);
01140     }
01141 
01142     //
01143     // funcs in state "partOfNetwork" or "partOfPublicNetwork"
01144     //
01145     void tick(std::chrono::milliseconds elapsed)
01146     {
01147       if (
01148         !sm.check(State::partOfNetwork) &&
01149         !sm.check(State::partOfPublicNetwork) &&
01150         !sm.check(State::readingPrivateLedger))
01151       {
01152         return;
01153       }
01154 
01155       consensus->periodic(elapsed);
01156     }
01157 
01158     void tick_end()
01159     {
01160       if (
01161         !sm.check(State::partOfNetwork) &&
01162         !sm.check(State::partOfPublicNetwork) &&
01163         !sm.check(State::readingPrivateLedger))
01164       {
01165         return;
01166       }
01167 
01168       consensus->periodic_end();
01169     }
01170 
01171     void node_msg(const std::vector<uint8_t>& data)
01172     {
01173       // Only process messages once part of network
01174       if (
01175         !sm.check(State::partOfNetwork) &&
01176         !sm.check(State::partOfPublicNetwork) &&
01177         !sm.check(State::readingPrivateLedger))
01178       {
01179         return;
01180       }
01181 
01182       OArray oa(std::move(data));
01183       NodeMsgType msg_type =
01184         serialized::overlay<NodeMsgType>(oa.data(), oa.size());
01185 
01186       switch (msg_type)
01187       {
01188         case channel_msg:
01189         {
01190           n2n_channels->recv_message(std::move(oa));
01191           break;
01192         }
01193         case consensus_msg:
01194         {
01195           consensus->recv_message(std::move(oa));
01196           break;
01197         }
01198 
01199         default:
01200         {
01201         }
01202       }
01203     }
01204 
01205     //
01206     // always available
01207     //
01208     bool is_primary() const override
01209     {
01210       return (
01211         (sm.check(State::partOfNetwork) ||
01212          sm.check(State::partOfPublicNetwork) ||
01213          sm.check(State::readingPrivateLedger)) &&
01214         consensus->is_primary());
01215     }
01216 
01217     bool is_part_of_network() const override
01218     {
01219       return sm.check(State::partOfNetwork);
01220     }
01221 
01222     bool is_reading_public_ledger() const override
01223     {
01224       return sm.check(State::readingPublicLedger);
01225     }
01226 
01227     bool is_reading_private_ledger() const override
01228     {
01229       return sm.check(State::readingPrivateLedger);
01230     }
01231 
01232     bool is_verifying_snapshot() const override
01233     {
01234       return sm.check(State::verifyingSnapshot);
01235     }
01236 
01237     bool is_part_of_public_network() const override
01238     {
01239       return sm.check(State::partOfPublicNetwork);
01240     }
01241 
01242     ExtendedState state() override
01243     {
01244       std::lock_guard<SpinLock> guard(lock);
01245       State s = sm.value();
01246       if (s == State::readingPrivateLedger)
01247       {
01248         return {s, recovery_v, recovery_store->current_version()};
01249       }
01250       else
01251       {
01252         return {s, std::nullopt, std::nullopt};
01253       }
01254     }
01255 
01256     bool rekey_ledger(kv::Tx& tx) override
01257     {
01258       std::lock_guard<SpinLock> guard(lock);
01259       sm.expect(State::partOfNetwork);
01260 
01261       // Because submitted recovery shares are encrypted with the latest
01262       // ledger secret, it is not possible to rekey the ledger if the service
01263       // is in that state.
01264       GenesisGenerator g(network, tx);
01265       if (
01266         g.get_service_status().value() ==
01267         ServiceStatus::WAITING_FOR_RECOVERY_SHARES)
01268       {
01269         LOG_FAIL_FMT(
01270           "Cannot rekey ledger while the service is waiting for recovery "
01271           "shares");
01272         return false;
01273       }
01274 
01275       // Effects of ledger rekey are only observed from the next transaction,
01276       // once the local hook on the secrets table has been triggered.
01277 
01278       auto new_ledger_secret = LedgerSecret();
01279       share_manager.issue_shares_on_rekey(tx, new_ledger_secret);
01280       broadcast_ledger_secret(tx, new_ledger_secret);
01281 
01282       return true;
01283     }
01284 
01285     void node_quotes(
01286       kv::ReadOnlyTx& tx,
01287       GetQuotes::Out& result,
01288       const std::optional<std::set<NodeId>>& filter) override
01289     {
01290       auto nodes_view = tx.get_read_only_view(network.nodes);
01291 
01292       nodes_view->foreach([&result, &filter, this](
01293                             const NodeId& nid, const NodeInfo& ni) {
01294         if (!filter.has_value() || (filter->find(nid) != filter->end()))
01295         {
01296           if (ni.status == ccf::NodeStatus::TRUSTED)
01297           {
01298             GetQuotes::Quote q;
01299             q.node_id = nid;
01300             q.raw = fmt::format("{:02x}", fmt::join(ni.quote, ""));
01301 
01302             if (this->network.consensus_type != ConsensusType::BFT)
01303             {
01304 
01305 
01306 
01307 
01308 
01309 
01310 
01311 
01312 
01313 
01314 
01315 
01316             }
01317             result.quotes.push_back(q);
01318           }
01319         }
01320         return true;
01321       });
01322     };
01323 
01324     NodeId get_node_id() const override
01325     {
01326       return self;
01327     }
01328 
01329   private:
01330     void set_node_id(NodeId n)
01331     {
01332       LOG_INFO_FMT("Setting self node ID: {}", n);
01333       if (self != invalid_node_id)
01334       {
01335         throw std::logic_error(fmt::format(
01336           "Trying to reset node ID. Was previously {}, proposed {}", self, n));
01337       }
01338 
01339       self = n;
01340     }
01341 
01342     tls::SubjectAltName get_subject_alt_name(const CCFConfig& config)
01343     {
01344       // If a domain is passed at node creation, record domain in SAN for node
01345       // hostname authentication over TLS. Otherwise, record IP in SAN.
01346       bool san_is_ip = config.domain.empty();
01347       return {san_is_ip ? config.node_info_network.rpchost : config.domain,
01348               san_is_ip};
01349     }
01350 
01351     std::vector<tls::SubjectAltName> get_subject_alternative_names(
01352       const CCFConfig& config)
01353     {
01354       std::vector<tls::SubjectAltName> sans = config.subject_alternative_names;
01355       sans.push_back(get_subject_alt_name(config));
01356       return sans;
01357     }
01358 
01359     void create_node_cert(const CCFConfig& config)
01360     {
01361       auto sans = get_subject_alternative_names(config);
01362       node_cert = node_sign_kp->self_sign(config.subject_name, sans);
01363     }
01364 
01365     void accept_node_tls_connections()
01366     {
01367       // Accept TLS connections, presenting self-signed (i.e. non-endorsed)
01368       // node certificate. Once the node is part of the network, this
01369       // certificate should be replaced with network-endorsed counterpart
01370       rpcsessions->set_cert(node_cert, node_sign_kp->private_key_pem());
01371       LOG_INFO_FMT("Node TLS connections now accepted");
01372     }
01373 
01374     void accept_network_tls_connections(const CCFConfig& config)
01375     {
01376       // Accept TLS connections, presenting node certificate signed by network
01377       // certificate
01378       auto nw = tls::make_key_pair({network.identity->priv_key});
01379 
01380       auto sans = get_subject_alternative_names(config);
01381       auto endorsed_node_cert = nw->sign_csr(
01382         node_sign_kp->create_csr(config.subject_name),
01383         fmt::format("CN={}", "CCF Network"),
01384         sans);
01385 
01386       rpcsessions->set_cert(
01387         endorsed_node_cert, node_sign_kp->private_key_pem());
01388       LOG_INFO_FMT("Network TLS connections now accepted");
01389     }
01390 
01391     void open_frontend(
01392       ccf::ActorsType actor, std::optional<tls::Pem*> identity = std::nullopt)
01393     {
01394       auto fe = rpc_map->find(actor);
01395       if (!fe.has_value())
01396       {
01397         throw std::logic_error(
01398           fmt::format("Cannot open {} frontend", (int)actor));
01399       }
01400       fe.value()->open(identity);
01401     }
01402 
01403     void open_user_frontend() override
01404     {
01405       open_frontend(ccf::ActorsType::users, &network.identity->cert);
01406     }
01407 
01408     void broadcast_ledger_secret(
01409       kv::Tx& tx,
01410       const LedgerSecret& secret,
01411       kv::Version version = kv::NoVersion,
01412       bool exclude_self = false)
01413     {
01414       GenesisGenerator g(network, tx);
01415       auto secrets_view = tx.get_view(network.secrets);
01416 
01417       auto trusted_nodes = g.get_trusted_nodes(
01418         exclude_self ? std::make_optional(self) : std::nullopt);
01419 
01420       ccf::EncryptedLedgerSecrets secret_set;
01421       secret_set.primary_public_encryption_key =
01422         node_encrypt_kp->public_key_pem().raw();
01423 
01424       for (auto [nid, ni] : trusted_nodes)
01425       {
01426         ccf::EncryptedLedgerSecret secret_for_node;
01427         secret_for_node.node_id = nid;
01428 
01429         // Encrypt secrets with a shared secret derived from backup public
01430         // key
01431         auto backup_pubk = tls::make_public_key(ni.encryption_pub_key);
01432         crypto::KeyAesGcm backup_shared_secret(
01433           tls::KeyExchangeContext(node_encrypt_kp, backup_pubk)
01434             .compute_shared_secret());
01435 
01436         crypto::GcmCipher gcmcipher(secret.master.size());
01437         auto iv = tls::create_entropy()->random(gcmcipher.hdr.get_iv().n);
01438         std::copy(iv.begin(), iv.end(), gcmcipher.hdr.iv);
01439 
01440         backup_shared_secret.encrypt(
01441           iv, secret.master, nullb, gcmcipher.cipher.data(), gcmcipher.hdr.tag);
01442 
01443         secret_for_node.encrypted_secret = gcmcipher.serialise();
01444         secret_set.secrets.emplace_back(std::move(secret_for_node));
01445       }
01446 
01447       secrets_view->put(version, secret_set);
01448     }
01449 
01450     std::vector<uint8_t> serialize_create_request(
01451       const CCFConfig& config, const std::vector<uint8_t>& quote)
01452     {
01453       CreateNetworkNodeToNode::In create_params;
01454 
01455       for (const auto& m_info : config.genesis.members_info)
01456       {
01457         create_params.members_info.push_back(m_info);
01458       }
01459 
01460       create_params.gov_script = config.genesis.gov_script;
01461       create_params.node_cert = node_cert;
01462       create_params.network_cert = network.identity->cert;
01463       create_params.quote = quote;
01464       create_params.public_encryption_key = node_encrypt_kp->public_key_pem();
01465       create_params.code_digest =
01466         std::vector<uint8_t>(std::begin(node_code_id), std::end(node_code_id));
01467       create_params.node_info_network = config.node_info_network;
01468       create_params.consensus_type = network.consensus_type;
01469       create_params.recovery_threshold = config.genesis.recovery_threshold;
01470 
01471       const auto body = serdes::pack(create_params, serdes::Pack::Text);
01472 
01473       http::Request request(fmt::format(
01474         "/{}/{}", ccf::get_actor_prefix(ccf::ActorsType::members), "create"));
01475       request.set_header(
01476         http::headers::CONTENT_TYPE, http::headervalues::contenttype::JSON);
01477 
01478       request.set_body(&body);
01479       http::sign_request(request, node_sign_kp);
01480 
01481       return request.build_request();
01482     }
01483 
01484     bool parse_create_response(const std::vector<uint8_t>& response)
01485     {
01486       http::SimpleResponseProcessor processor;
01487       http::ResponseParser parser(processor);
01488 
01489       parser.execute(response.data(), response.size());
01490 
01491       if (processor.received.size() != 1)
01492       {
01493         LOG_FAIL_FMT(
01494           "Expected single message, found {}", processor.received.size());
01495         return false;
01496       }
01497 
01498       const auto& r = processor.received.front();
01499 
01500       if (r.status != HTTP_STATUS_OK)
01501       {
01502         LOG_FAIL_FMT(
01503           "Create response is error: {} {}",
01504           r.status,
01505           http_status_str(r.status));
01506         return false;
01507       }
01508 
01509       const auto body = serdes::unpack(r.body, serdes::Pack::Text);
01510       if (!body.is_boolean())
01511       {
01512         LOG_FAIL_FMT("Expected boolean body in create response");
01513         LOG_DEBUG_FMT(
01514           "Expected boolean body in create response: {}", body.dump());
01515         return false;
01516       }
01517 
01518       return body;
01519     }
01520 
01521     bool send_create_request(const std::vector<uint8_t>& packed)
01522     {
01523       auto node_session = std::make_shared<enclave::SessionContext>(
01524         enclave::InvalidSessionId, node_cert.raw());
01525       auto ctx = enclave::make_rpc_context(node_session, packed);
01526 
01527       ctx->is_create_request = true;
01528 
01529       const auto actor_opt = http::extract_actor(*ctx);
01530       if (!actor_opt.has_value())
01531       {
01532         throw std::logic_error("Unable to get actor for create request");
01533       }
01534 
01535       const auto actor = rpc_map->resolve(actor_opt.value());
01536       auto frontend_opt = this->rpc_map->find(actor);
01537       if (!frontend_opt.has_value())
01538       {
01539         throw std::logic_error(
01540           "RpcMap::find returned invalid (empty) frontend");
01541       }
01542       auto frontend = frontend_opt.value();
01543 
01544       const auto response = frontend->process(ctx);
01545       if (!response.has_value())
01546       {
01547         return false;
01548       }
01549 
01550       return parse_create_response(response.value());
01551     }
01552 
01553     bool create_and_send_request(
01554       const CCFConfig& config, const std::vector<uint8_t>& quote)
01555     {
01556       const auto create_success =
01557         send_create_request(serialize_create_request(config, quote));
01558       if (network.consensus_type == ConsensusType::BFT)
01559       {
01560         return true;
01561       }
01562       else
01563       {
01564         return create_success;
01565       }
01566     }
01567 
01568     void backup_finish_recovery()
01569     {
01570       if (!consensus->is_backup())
01571         return;
01572 
01573       sm.expect(State::partOfPublicNetwork);
01574 
01575       LOG_INFO_FMT("Initiating end of recovery (backup)");
01576 
01577       setup_private_recovery_store();
01578 
01579       // Start reading private security domain of ledger
01580       ledger_idx = recovery_store->current_version();
01581       read_ledger_idx(++ledger_idx);
01582 
01583       sm.advance(State::readingPrivateLedger);
01584     }
01585 
01586     void setup_basic_hooks()
01587     {
01588       network.tables->set_local_hook(
01589         network.secrets.get_name(),
01590         network.secrets.wrap_commit_hook(
01591           [this](kv::Version version, const Secrets::Write& w) {
01592             bool has_secrets = false;
01593             std::list<LedgerSecrets::VersionedLedgerSecret> restored_secrets;
01594 
01595             for (const auto& [v, opt_secret_set] : w)
01596             {
01597               if (!opt_secret_set.has_value())
01598               {
01599                 throw std::logic_error(fmt::format(
01600                   "Unexpected: removal from secrets table ({})", v));
01601               }
01602 
01603               const auto& secret_set = opt_secret_set.value();
01604 
01605               for (auto& encrypted_secret_for_node : secret_set.secrets)
01606               {
01607                 if (encrypted_secret_for_node.node_id == self)
01608                 {
01609                   crypto::GcmCipher gcmcipher;
01610                   gcmcipher.deserialise(
01611                     encrypted_secret_for_node.encrypted_secret);
01612                   std::vector<uint8_t> plain_secret(gcmcipher.cipher.size());
01613 
01614                   auto primary_pubk = tls::make_public_key(
01615                     secret_set.primary_public_encryption_key);
01616 
01617                   crypto::KeyAesGcm primary_shared_key(
01618                     tls::KeyExchangeContext(node_encrypt_kp, primary_pubk)
01619                       .compute_shared_secret());
01620 
01621                   if (!primary_shared_key.decrypt(
01622                         gcmcipher.hdr.get_iv(),
01623                         gcmcipher.hdr.tag,
01624                         gcmcipher.cipher,
01625                         nullb,
01626                         plain_secret.data()))
01627                   {
01628                     throw std::logic_error(
01629                       "Decryption of past network secrets failed");
01630                   }
01631 
01632                   has_secrets = true;
01633 
01634                   // If the version key is NoVersion, we are rekeying. Use the
01635                   // version passed to the hook instead. For recovery, the
01636                   // version of the past secrets is passed as the key.
01637                   kv::Version secret_version =
01638                     (v == kv::NoVersion) ? version : v;
01639 
01640                   if (is_part_of_public_network())
01641                   {
01642                     restored_secrets.push_back(
01643                       {secret_version, LedgerSecret(plain_secret)});
01644                   }
01645                   else
01646                   {
01647                     // When rekeying, set the encryption key for the next
01648                     // version onward (for the backups to deserialise this
01649                     // transaction with the old key). The encryptor is in charge
01650                     // of updating the ledger secrets on global commit.
01651                     encryptor->update_encryption_key(
01652                       secret_version + 1, plain_secret);
01653                   }
01654                 }
01655               }
01656             }
01657 
01658             // When recovering, trigger end of recovery protocol
01659             if (has_secrets && is_part_of_public_network())
01660             {
01661               restored_secrets.sort(
01662                 [](
01663                   const LedgerSecrets::VersionedLedgerSecret& a,
01664                   const LedgerSecrets::VersionedLedgerSecret& b) {
01665                   return a.version < b.version;
01666                 });
01667 
01668               network.ledger_secrets->restore(std::move(restored_secrets));
01669               backup_finish_recovery();
01670             }
01671           }));
01672     }
01673 
01674     kv::Version get_last_recovered_signed_idx() override
01675     {
01676       // On recovery, only one node recovers the public ledger and is thus
01677       // aware of the version at which the new ledger secret is applicable
01678       // from. If the primary changes while the network is public-only, the
01679       // new primary should also know at which version the new ledger secret
01680       // is applicable from.
01681       std::lock_guard<SpinLock> guard(lock);
01682       return last_recovered_signed_idx;
01683     }
01684 
01685     void setup_recovery_hook(bool from_snapshot)
01686     {
01687       // When recoverying from a snapshot, the first secret is valid from the
01688       // version at which it was recorded
01689       static bool is_first_secret = !from_snapshot;
01690 
01691       network.tables->set_local_hook(
01692         network.shares.get_name(),
01693         network.shares.wrap_commit_hook(
01694           [this](kv::Version version, const Shares::Write& w) {
01695             for (const auto& [k, opt_v] : w)
01696             {
01697               if (!opt_v.has_value())
01698               {
01699                 throw std::logic_error(
01700                   fmt::format("Unexpected: removal from shares table ({})", k));
01701               }
01702 
01703               const auto& v = opt_v.value();
01704 
01705               kv::Version ledger_secret_version;
01706               if (is_first_secret)
01707               {
01708                 // Special case for the first recovery share issuing (at network
01709                 // open), which is applicable from the very first transaction.
01710                 ledger_secret_version = 1;
01711                 is_first_secret = false;
01712               }
01713               else
01714               {
01715                 // If the version is not set (rekeying), use the version
01716                 // from the hook plus one. Otherwise (recovery), use the
01717                 // version specified.
01718                 ledger_secret_version =
01719                   v.wrapped_latest_ledger_secret.version == kv::NoVersion ?
01720                   (version + 1) :
01721                   v.wrapped_latest_ledger_secret.version;
01722               }
01723 
01724               // No encrypted ledger secret are stored in the case of a pure
01725               // re-share (i.e. no ledger rekey).
01726               if (
01727                 !v.encrypted_previous_ledger_secret.empty() ||
01728                 ledger_secret_version == 1)
01729               {
01730                 LOG_TRACE_FMT(
01731                   "Adding one encrypted recovery ledger secret at {}",
01732                   ledger_secret_version);
01733 
01734                 recovery_ledger_secrets.push_back(
01735                   {ledger_secret_version, v.encrypted_previous_ledger_secret});
01736               }
01737             }
01738           }));
01739     }
01740 
01741     void reset_recovery_hook()
01742     {
01743       network.tables->unset_local_hook(network.shares.get_name());
01744     }
01745 
01746     void setup_n2n_channels()
01747     {
01748       n2n_channels->initialize(self, {network.identity->priv_key});
01749     }
01750 
01751     void setup_cmd_forwarder()
01752     {
01753       cmd_forwarder->initialize(self);
01754     }
01755 
01756     void setup_raft(bool public_only = false)
01757     {
01758       setup_n2n_channels();
01759       setup_cmd_forwarder();
01760       setup_tracker_store();
01761 
01762       auto request_tracker = std::make_shared<aft::RequestTracker>();
01763       auto view_change_tracker = std::make_unique<aft::ViewChangeTracker>(
01764         tracker_store,
01765         std::chrono::milliseconds(consensus_config.raft_election_timeout));
01766       auto shared_state = std::make_shared<aft::State>(self);
01767       auto raft = std::make_unique<RaftType>(
01768         network.consensus_type,
01769         std::make_unique<aft::Adaptor<kv::Store, kv::DeserialiseSuccess>>(
01770           network.tables),
01771         std::make_unique<consensus::LedgerEnclave>(writer_factory),
01772         n2n_channels,
01773         snapshotter,
01774         rpcsessions,
01775         rpc_map,
01776         node_cert.raw(),
01777         shared_state,
01778         std::make_shared<aft::ExecutorImpl>(shared_state, rpc_map, rpcsessions),
01779         request_tracker,
01780         std::move(view_change_tracker),
01781         std::chrono::milliseconds(consensus_config.raft_request_timeout),
01782         std::chrono::milliseconds(consensus_config.raft_election_timeout),
01783         std::chrono::milliseconds(consensus_config.bft_view_change_timeout),
01784         sig_tx_interval,
01785         public_only);
01786 
01787       consensus = std::make_shared<RaftConsensusType>(
01788         std::move(raft), network.consensus_type);
01789 
01790       network.tables->set_consensus(consensus);
01791       cmd_forwarder->set_request_tracker(request_tracker);
01792 
01793       // When a node is added, even locally, inform raft so that it
01794       // can add a new active configuration.
01795       network.tables->set_local_hook(
01796         network.nodes.get_name(),
01797         network.nodes.wrap_commit_hook(
01798           [this](kv::Version version, const Nodes::Write& w) {
01799             bool configure = false;
01800             auto configuration = consensus->get_latest_configuration();
01801 
01802             for (const auto& [node_id, opt_ni] : w)
01803             {
01804               if (!opt_ni.has_value())
01805               {
01806                 throw std::logic_error(fmt::format(
01807                   "Unexpected: removal from nodes table ({})", node_id));
01808               }
01809 
01810               const auto& ni = opt_ni.value();
01811               switch (ni.status)
01812               {
01813                 case NodeStatus::PENDING:
01814                 {
01815                   // Pending nodes are not added to consensus until they are
01816                   // trusted
01817                   break;
01818                 }
01819                 case NodeStatus::TRUSTED:
01820                 {
01821                   configuration.try_emplace(node_id, ni.nodehost, ni.nodeport);
01822                   configure = true;
01823                   break;
01824                 }
01825                 case NodeStatus::RETIRED:
01826                 {
01827                   configuration.erase(node_id);
01828                   configure = true;
01829                   break;
01830                 }
01831                 default:
01832                 {
01833                 }
01834               }
01835             }
01836 
01837             if (configure)
01838             {
01839               consensus->add_configuration(version, configuration);
01840             }
01841           }));
01842 
01843       setup_basic_hooks();
01844     }
01845 
01846     void setup_history()
01847     {
01848       // This function can be called once the node has started up and before
01849       // it has joined the service.
01850       history = std::make_shared<MerkleTxHistory>(
01851         *network.tables.get(),
01852         self,
01853         *node_sign_kp,
01854         sig_tx_interval,
01855         sig_ms_interval);
01856 
01857       network.tables->set_history(history);
01858     }
01859 
01860     void setup_encryptor(ConsensusType consensus_type)
01861     {
01862       // This function makes use of network secrets and should be called once
01863       // the node has joined the service (either via start_network() or
01864       // join_network())
01865 
01866 
01867 
01868       if (network.consensus_type == ConsensusType::BFT)
01869       {
01870         encryptor = std::make_shared<BftTxEncryptor>(network.ledger_secrets);
01871       }
01872       else if (network.consensus_type == ConsensusType::CFT)
01873       {
01874         encryptor = std::make_shared<CftTxEncryptor>(network.ledger_secrets);
01875         encryptor->set_iv_id(self); // RaftEncryptor uses node ID in iv
01876       }
01877       else
01878       {
01879         throw std::logic_error(
01880           "Unknown consensus type " + std::to_string(consensus_type));
01881       }
01882 
01883 
01884       network.tables->set_encryptor(encryptor);
01885     }
01886 
01887     void setup_consensus(bool public_only = false)
01888     {
01889       setup_raft(public_only);
01890     }
01891 
01892     void setup_progress_tracker()
01893     {
01894       if (network.consensus_type == ConsensusType::BFT)
01895       {
01896         setup_tracker_store();
01897         progress_tracker =
01898           std::make_shared<ccf::ProgressTracker>(tracker_store, self);
01899         network.tables->set_progress_tracker(progress_tracker);
01900       }
01901     }
01902 
01903     void setup_tracker_store()
01904     {
01905       if (tracker_store == nullptr)
01906       {
01907         tracker_store = std::make_shared<ccf::ProgressTrackerStoreAdapter>(
01908           *network.tables.get(),
01909           *node_sign_kp,
01910           network.nodes,
01911           network.backup_signatures_map,
01912           network.revealed_nonces_map,
01913           network.new_views_map);
01914       }
01915     }
01916 
01917     void read_ledger_idx(consensus::Index idx)
01918     {
01919       RINGBUFFER_WRITE_MESSAGE(
01920         consensus::ledger_get,
01921         to_host,
01922         idx,
01923         consensus::LedgerRequestPurpose::Recovery);
01924     }
01925 
01926     void ledger_truncate(consensus::Index idx)
01927     {
01928       RINGBUFFER_WRITE_MESSAGE(consensus::ledger_truncate, to_host, idx);
01929     }
01930   };
01931 }
01932 
---------
Macros accessible in this file:
---------
HAVE_OPENSSL TX_RATE_BUCKETS_LEN HAVE_MBEDTLS FMT_HEADER_ONLY HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/node_state.h...
Preprocessing /data/git/CCF/src/node/node_to_node.h...
#include channels.h: already included! skipping...
#include ds/serialized.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
#include node_types.h: already included! skipping...
#include algorithm: not found! skipping...
#include fmt/format.h: not found! skipping...
Preprocessor output (size: 6967 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define FMT_HEADER_ONLY
00012 
00013 
00014 namespace ccf
00015 {
00016   class NodeToNode
00017   {
00018   public:
00019     virtual ~NodeToNode() = default;
00020 
00021     virtual void create_channel(
00022       NodeId peer_id,
00023       const std::string& peer_hostname,
00024       const std::string& peer_service) = 0;
00025 
00026     virtual void destroy_channel(NodeId peer_id) = 0;
00027 
00028     virtual void close_all_outgoing() = 0;
00029 
00030     virtual void destroy_all_channels() = 0;
00031 
00032     template <class T>
00033     bool send_authenticated(
00034       const NodeMsgType& msg_type, NodeId to, const T& data)
00035     {
00036       return send_authenticated(
00037         msg_type, to, reinterpret_cast<const uint8_t*>(&data), sizeof(T));
00038     }
00039 
00040     template <>
00041     bool send_authenticated(
00042       const NodeMsgType& msg_type, NodeId to, const std::vector<uint8_t>& data)
00043     {
00044       return send_authenticated(msg_type, to, data.data(), data.size());
00045     }
00046 
00047     virtual bool send_authenticated(
00048       const ccf::NodeMsgType& msg_type,
00049       NodeId to,
00050       const uint8_t* data,
00051       size_t size) = 0;
00052 
00053     template <class T>
00054     const T& recv_authenticated(const uint8_t*& data, size_t& size)
00055     {
00056       auto& t = serialized::overlay<T>(data, size);
00057 
00058       if (!recv_authenticated(t.from_node, asCb(t), data, size))
00059       {
00060         throw std::logic_error(fmt::format(
00061           "Invalid authenticated node2node message from node {}", t.from_node));
00062       }
00063 
00064       return t;
00065     }
00066 
00067     template <class T>
00068     const T& recv_authenticated_with_load(const uint8_t*& data, size_t& size)
00069     {
00070       const auto* data_ = data;
00071       auto size_ = size;
00072 
00073       const auto& t = serialized::overlay<T>(data_, size_);
00074 
00075       if (!recv_authenticated_with_load(t.from_node, data, size))
00076       {
00077         throw std::logic_error(fmt::format(
00078           "Invalid authenticated node2node message with load from node {}",
00079           t.from_node));
00080       }
00081       serialized::skip(data, size, sizeof(T));
00082 
00083       return t;
00084     }
00085 
00086     virtual bool recv_authenticated_with_load(
00087       NodeId from_node, const uint8_t*& data, size_t& size) = 0;
00088 
00089     virtual bool recv_authenticated(
00090       NodeId from_node, CBuffer cb, const uint8_t*& data, size_t& size) = 0;
00091 
00092     virtual void recv_message(OArray&& oa) = 0;
00093 
00094     virtual void initialize(NodeId self_id, const tls::Pem& network_pkey) = 0;
00095 
00096     virtual bool send_encrypted(
00097       const NodeMsgType& msg_type,
00098       CBuffer cb,
00099       NodeId to,
00100       const std::vector<uint8_t>& data) = 0;
00101 
00102     template <class T>
00103     bool send_encrypted(
00104       const NodeMsgType& msg_type,
00105       NodeId to,
00106       const std::vector<uint8_t>& data,
00107       const T& msg_hdr)
00108     {
00109       return send_encrypted(msg_type, asCb(msg_hdr), to, data);
00110     }
00111 
00112     template <class T>
00113     std::pair<T, std::vector<uint8_t>> recv_encrypted(
00114       const uint8_t* data, size_t size)
00115     {
00116       auto t = serialized::read<T>(data, size);
00117 
00118       std::vector<uint8_t> plain =
00119         recv_encrypted(t.from_node, asCb(t), data, size);
00120       return std::make_pair(t, plain);
00121     }
00122 
00123     virtual std::vector<uint8_t> recv_encrypted(
00124       NodeId from_node, CBuffer cb, const uint8_t* data, size_t size) = 0;
00125   };
00126 
00127   class NodeToNodeImpl : public NodeToNode
00128   {
00129   private:
00130     NodeId self;
00131     std::unique_ptr<ChannelManager> channels;
00132     ringbuffer::AbstractWriterFactory& writer_factory;
00133 
00134   public:
00135     NodeToNodeImpl(ringbuffer::AbstractWriterFactory& writer_factory_) :
00136       writer_factory(writer_factory_)
00137     {}
00138 
00139     void initialize(NodeId self_id, const tls::Pem& network_pkey) override
00140     {
00141       self = self_id;
00142       channels =
00143         std::make_unique<ChannelManager>(writer_factory, network_pkey, self);
00144     }
00145 
00146     void create_channel(
00147       NodeId peer_id,
00148       const std::string& hostname,
00149       const std::string& service) override
00150     {
00151       if (peer_id == self)
00152       {
00153         return;
00154       }
00155 
00156       channels->create_channel(peer_id, hostname, service);
00157     }
00158 
00159     void destroy_channel(NodeId peer_id) override
00160     {
00161       if (peer_id == self)
00162       {
00163         return;
00164       }
00165 
00166       channels->destroy_channel(peer_id);
00167     }
00168 
00169     void close_all_outgoing() override
00170     {
00171       channels->close_all_outgoing();
00172     }
00173 
00174     void destroy_all_channels() override
00175     {
00176       channels->destroy_all_channels();
00177     }
00178 
00179     bool send_authenticated(
00180       const ccf::NodeMsgType& msg_type,
00181       NodeId to,
00182       const uint8_t* data,
00183       size_t size) override
00184     {
00185       auto& n2n_channel = channels->get(to);
00186       return n2n_channel.send(msg_type, {data, size});
00187     }
00188 
00189     bool recv_authenticated(
00190       NodeId from_node, CBuffer cb, const uint8_t*& data, size_t& size) override
00191     {
00192       auto& n2n_channel = channels->get(from_node);
00193       return n2n_channel.recv_authenticated(cb, data, size);
00194     }
00195 
00196     bool send_encrypted(
00197       const NodeMsgType& msg_type,
00198       CBuffer cb,
00199       NodeId to,
00200       const std::vector<uint8_t>& data) override
00201     {
00202       auto& n2n_channel = channels->get(to);
00203       return n2n_channel.send(msg_type, cb, data);
00204     }
00205 
00206     bool recv_authenticated_with_load(
00207       NodeId from_node, const uint8_t*& data, size_t& size) override
00208     {
00209       auto& n2n_channel = channels->get(from_node);
00210       return n2n_channel.recv_authenticated_with_load(data, size);
00211     }
00212 
00213     std::vector<uint8_t> recv_encrypted(
00214       NodeId from_node, CBuffer cb, const uint8_t* data, size_t size) override
00215     {
00216       auto& n2n_channel = channels->get(from_node);
00217 
00218       auto plain = n2n_channel.recv_encrypted(cb, data, size);
00219       if (!plain.has_value())
00220       {
00221         throw std::logic_error(fmt::format(
00222           "Invalid encrypted node2node message from node {}", from_node));
00223       }
00224 
00225       return plain.value();
00226     }
00227 
00228     void process_key_exchange(const uint8_t* data, size_t size)
00229     {
00230       // Called on channel target when a key exchange message is received from
00231       // the initiator
00232       const auto& ke = serialized::overlay<ChannelHeader>(data, size);
00233 
00234       auto& n2n_channel = channels->get(ke.from_node);
00235       n2n_channel.load_peer_signed_public(false, data, size);
00236     }
00237 
00238     void complete_key_exchange(const uint8_t* data, size_t size)
00239     {
00240       // Called on channel initiator when a key exchange response message is
00241       // received from the target
00242       const auto& ke = serialized::overlay<ChannelHeader>(data, size);
00243 
00244       auto& n2n_channel = channels->get(ke.from_node);
00245       n2n_channel.load_peer_signed_public(true, data, size);
00246     }
00247 
00248     void recv_message(OArray&& oa) override
00249     {
00250       const uint8_t* data = oa.data();
00251       size_t size = oa.size();
00252       switch (serialized::peek<ChannelMsg>(data, size))
00253       {
00254         case key_exchange:
00255         {
00256           process_key_exchange(data, size);
00257           break;
00258         }
00259 
00260         case key_exchange_response:
00261         {
00262           complete_key_exchange(data, size);
00263           break;
00264         }
00265 
00266         default:
00267         {
00268         }
00269         break;
00270       }
00271     }
00272   };
00273 }
00274 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/node/node_to_node.h...
Preprocessing /data/git/CCF/src/node/node_types.h...
#include crypto/hash.h: not found! skipping...
#include ds/ring_buffer_types.h: not found! skipping...
#include entities.h: already included! skipping...
#include cstdint: not found! skipping...
#include limits: not found! skipping...
Preprocessor output (size: 2023 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   using Node2NodeMsg = uint64_t;
00015 
00016   static constexpr NodeId NoNode = std::numeric_limits<NodeId>::max();
00017 
00018   // Type of messages exchanged between nodes
00019   enum NodeMsgType : uint64_t
00020   {
00021     channel_msg = 0,
00022     consensus_msg,
00023     forwarded_msg
00024   };
00025 
00026   // Types of channel messages
00027   enum ChannelMsg : Node2NodeMsg
00028   {
00029     key_exchange = 0,
00030     key_exchange_response,
00031     encrypted_msg
00032   };
00033 
00034   // Types of frontend messages
00035   enum ForwardedMsg : Node2NodeMsg
00036   {
00037     forwarded_cmd = 0,
00038     forwarded_response,
00039     request_hash
00040   };
00041 
00042 
00043   // Header for every message exchange between nodes
00044   struct Header
00045   {
00046     Node2NodeMsg msg;
00047     NodeId from_node;
00048   };
00049 
00050   // Channel-specific header for key exchange
00051   struct ChannelHeader
00052   {
00053     ChannelMsg msg;
00054     NodeId from_node;
00055   };
00056 
00057   // Frontend-specific header for forwarding
00058   struct ForwardedHeader
00059   {
00060     ForwardedMsg msg;
00061     NodeId from_node;
00062     enclave::FrameFormat frame_format = enclave::FrameFormat::http;
00063   };
00064 
00065   struct MessageHash
00066   {
00067     MessageHash() = default;
00068     MessageHash(ForwardedMsg msg_, NodeId from_node_) :
00069       msg(msg_),
00070       from_node(from_node_)
00071     {}
00072 
00073     ForwardedMsg msg;
00074     NodeId from_node;
00075     crypto::Sha256Hash hash;
00076   };
00077 
00078 
00079   /// Node-to-node related ringbuffer messages
00080   enum : ringbuffer::Message
00081   {
00082     ///@{
00083     /// Change the network nodes. Enclave -> Host
00084     DEFINE_RINGBUFFER_MSG_TYPE(add_node),
00085     DEFINE_RINGBUFFER_MSG_TYPE(remove_node),
00086     ///@}
00087 
00088     /// Receive data from another node. Host -> Enclave
00089     DEFINE_RINGBUFFER_MSG_TYPE(node_inbound),
00090 
00091     /// Send data to another node. Enclave -> Host
00092     DEFINE_RINGBUFFER_MSG_TYPE(node_outbound),
00093   };
00094 }
00095 
00096 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00097   ccf::add_node, ccf::NodeId, std::string, std::string);
00098 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(ccf::remove_node, ccf::NodeId);
00099 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(ccf::node_inbound, std::vector<uint8_t>);
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/node_types.h...
Preprocessing /data/git/CCF/src/node/progress_tracker.h...
#include ds/ccf_assert.h: not found! skipping...
#include ds/ccf_exception.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include nodes.h: not found! skipping...
#include backup_signatures.h: already included! skipping...
#include consensus/aft/revealed_nonces.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include tls/hash.h: not found! skipping...
#include tls/tls.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
  #include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
#include view_change.h: already included! skipping...
#include array: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 25242 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 # 10 "/data/git/CCF/src/node/progress_tracker.h" 2
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   class ProgressTracker
00019   {
00020   public:
00021     ProgressTracker(
00022       std::shared_ptr<ProgressTrackerStore> store_, kv::NodeId id_) :
00023       store(store_),
00024       id(id_),
00025       entropy(tls::create_entropy())
00026     {}
00027 
00028     std::shared_ptr<ProgressTrackerStore> store;
00029 
00030     kv::TxHistory::Result add_signature(
00031       kv::TxID tx_id,
00032       kv::NodeId node_id,
00033       uint32_t signature_size,
00034       std::array<uint8_t, MBEDTLS_ECDSA_MAX_LEN>& sig,
00035       Nonce hashed_nonce,
00036       uint32_t node_count,
00037       bool is_primary)
00038     {
00039       LOG_TRACE_FMT(
00040         "add_signature node_id:{}, seqno:{}, hashed_nonce:{}",
00041         node_id,
00042         tx_id.version,
00043         hashed_nonce);
00044       auto it = certificates.find(tx_id.version);
00045       if (it == certificates.end())
00046       {
00047         // We currently do not know what the root is, so lets save this
00048         // signature and and we will verify the root when we get it from the
00049         // primary
00050         auto r =
00051           certificates.insert(std::pair<kv::Consensus::SeqNo, CommitCert>(
00052             tx_id.version, CommitCert()));
00053         it = r.first;
00054       }
00055       else
00056       {
00057         if (
00058           node_id != id && it->second.have_primary_signature &&
00059           !store->verify_signature(
00060             node_id, it->second.root, signature_size, sig.data()))
00061         {
00062           // NOTE: We need to handle this case but for now having this make a
00063           // test fail will be very handy
00064           throw ccf::ccf_logic_error(fmt::format(
00065             "add_signatures: Signature verification from {} FAILED, view:{}, "
00066             "seqno:{}",
00067             node_id,
00068             tx_id.term,
00069             tx_id.version));
00070           return kv::TxHistory::Result::FAIL;
00071         }
00072         LOG_TRACE_FMT(
00073           "Signature verification from {} passed, view:{}, seqno:{}",
00074           node_id,
00075           tx_id.term,
00076           tx_id.version);
00077       }
00078 
00079       auto& cert = it->second;
00080       if (cert.wrote_sig_to_ledger)
00081       {
00082         LOG_TRACE_FMT(
00083           "Already wrote append entry view:{}, seqno:{}, ignoring",
00084           tx_id.term,
00085           tx_id.version);
00086         return kv::TxHistory::Result::OK;
00087       }
00088 
00089       std::vector<uint8_t> sig_vec;
00090       CCF_ASSERT_FMT(
00091         signature_size <= sig.size(),
00092         "Invalid signature size, signature_size:{}, sig.size:{}",
00093         signature_size,
00094         sig.size());
00095       sig_vec.assign(sig.begin(), sig.begin() + signature_size);
00096 
00097       CCF_ASSERT(
00098         node_id != id ||
00099           std::equal(
00100             hashed_nonce.h.begin(),
00101             hashed_nonce.h.end(),
00102             get_my_hashed_nonce(tx_id).h.begin()),
00103         "hashed_nonce does not match my nonce");
00104 
00105       BftNodeSignature bft_node_sig(std::move(sig_vec), node_id, hashed_nonce);
00106       try_match_unmatched_nonces(
00107         cert, bft_node_sig, tx_id.term, tx_id.version, node_id);
00108       cert.sigs.insert(std::pair<kv::NodeId, BftNodeSignature>(
00109         node_id, std::move(bft_node_sig)));
00110 
00111       if (can_send_sig_ack(cert, tx_id, node_count))
00112       {
00113         if (is_primary)
00114         {
00115           ccf::BackupSignatures sig_value(tx_id.term, tx_id.version, cert.root);
00116 
00117           for (const auto& sig : cert.sigs)
00118           {
00119             if (!sig.second.is_primary)
00120             {
00121               sig_value.signatures.push_back(ccf::NodeSignature(
00122                 sig.second.sig, sig.second.node, sig.second.hashed_nonce));
00123             }
00124           }
00125 
00126           LOG_TRACE_FMT("Adding signatures to ledger seqno:{}", tx_id.version);
00127           store->write_backup_signatures(sig_value);
00128           cert.wrote_sig_to_ledger = true;
00129         }
00130         return kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK;
00131       }
00132       return kv::TxHistory::Result::OK;
00133     }
00134 
00135     kv::TxHistory::Result record_primary(
00136       kv::TxID tx_id,
00137       kv::NodeId node_id,
00138       crypto::Sha256Hash& root,
00139       std::vector<uint8_t>& sig,
00140       Nonce hashed_nonce,
00141       uint32_t node_count = 0)
00142     {
00143       LOG_TRACE_FMT(
00144         "record_primary node_id:{}, seqno:{}, hashed_nonce:{}",
00145         node_id,
00146         tx_id.version,
00147         hashed_nonce);
00148       auto n = entropy->random(hashed_nonce.h.size());
00149       Nonce my_nonce;
00150       std::copy(n.begin(), n.end(), my_nonce.h.begin());
00151       if (node_id == id)
00152       {
00153         hash_data(my_nonce, hashed_nonce);
00154       }
00155 
00156       LOG_TRACE_FMT(
00157         "record_primary node_id:{}, seqno:{}, hashed_nonce:{}",
00158         node_id,
00159         tx_id.version,
00160         hashed_nonce);
00161 
00162       auto it = certificates.find(tx_id.version);
00163       if (it == certificates.end())
00164       {
00165         CommitCert cert(root, my_nonce);
00166         cert.have_primary_signature = true;
00167         BftNodeSignature bft_node_sig(sig, node_id, hashed_nonce);
00168         bft_node_sig.is_primary = true;
00169         try_match_unmatched_nonces(
00170           cert, bft_node_sig, tx_id.term, tx_id.version, node_id);
00171         cert.sigs.insert(
00172           std::pair<kv::NodeId, BftNodeSignature>(node_id, bft_node_sig));
00173 
00174         certificates.insert(
00175           std::pair<kv::Consensus::SeqNo, CommitCert>(tx_id.version, cert));
00176 
00177         LOG_TRACE_FMT(
00178           "Adding new root for view:{}, seqno:{}", tx_id.term, tx_id.version);
00179         return kv::TxHistory::Result::OK;
00180       }
00181       else
00182       {
00183         // We received some entries before we got the root so we now need to
00184         // verify the signatures
00185         auto& cert = it->second;
00186         cert.root = root;
00187         BftNodeSignature bft_node_sig({}, node_id, hashed_nonce);
00188         bft_node_sig.is_primary = true;
00189         try_match_unmatched_nonces(
00190           cert, bft_node_sig, tx_id.term, tx_id.version, node_id);
00191         cert.my_nonce = my_nonce;
00192         cert.have_primary_signature = true;
00193         for (auto& sig : cert.sigs)
00194         {
00195           if (
00196             !sig.second.is_primary &&
00197             !store->verify_signature(
00198               sig.second.node,
00199               cert.root,
00200               sig.second.sig.size(),
00201               sig.second.sig.data()))
00202           {
00203             // NOTE: We need to handle this case but for now having this make a
00204             // test fail will be very handy
00205             throw ccf::ccf_logic_error(fmt::format(
00206               "record_primary: Signature verification from {} FAILED, view:{}, "
00207               "seqno:{}",
00208               sig.first,
00209               tx_id.term,
00210               tx_id.version));
00211           }
00212           LOG_TRACE_FMT(
00213             "Signature verification from {} passed, view:{}, seqno:{}",
00214             sig.second.node,
00215             tx_id.term,
00216             tx_id.version);
00217         }
00218         cert.sigs.insert(
00219           std::pair<kv::NodeId, BftNodeSignature>(node_id, bft_node_sig));
00220       }
00221 
00222       auto& cert = it->second;
00223       if (cert.root != root)
00224       {
00225         // NOTE: At this point we have cryptographic proof that someone is being
00226         // dishonest we need to work out what to do.
00227         throw ccf::ccf_logic_error("We have proof someone is being dishonest");
00228       }
00229 
00230       if (node_count > 0 && can_send_sig_ack(cert, tx_id, node_count))
00231       {
00232         return kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK;
00233       }
00234       return kv::TxHistory::Result::OK;
00235     }
00236 
00237     kv::TxHistory::Result record_primary_signature(
00238       kv::TxID tx_id, std::vector<uint8_t>& sig)
00239     {
00240       auto it = certificates.find(tx_id.version);
00241       if (it == certificates.end())
00242       {
00243         LOG_FAIL_FMT(
00244           "Adding signature to primary that does not exist view:{}, seqno:{}",
00245           tx_id.term,
00246           tx_id.version);
00247         return kv::TxHistory::Result::FAIL;
00248       }
00249 
00250       for (auto& cert : it->second.sigs)
00251       {
00252         if (!cert.second.is_primary)
00253         {
00254           continue;
00255         }
00256 
00257         cert.second.sig = sig;
00258         break;
00259       }
00260 
00261       return kv::TxHistory::Result::OK;
00262     }
00263 
00264     kv::TxHistory::Result receive_backup_signatures(
00265       kv::TxID& tx_id, uint32_t node_count, bool is_primary)
00266     {
00267       std::optional<ccf::BackupSignatures> sigs =
00268         store->get_backup_signatures();
00269       CCF_ASSERT(sigs.has_value(), "sigs does not have a value");
00270       auto sigs_value = sigs.value();
00271 
00272       auto it = certificates.find(sigs_value.seqno);
00273       if (it == certificates.end())
00274       {
00275         LOG_FAIL_FMT(
00276           "Primary send backup signatures before sending the primary "
00277           "signature view:{}, seqno:{}",
00278           sigs_value.view,
00279           sigs_value.seqno);
00280         return kv::TxHistory::Result::FAIL;
00281       }
00282 
00283       auto& cert = it->second;
00284       if (!std::equal(
00285             cert.root.h.begin(), cert.root.h.end(), sigs_value.root.h.begin()))
00286       {
00287         LOG_FAIL_FMT(
00288           "Roots do not match at view:{}, seqno:{}",
00289           sigs_value.view,
00290           sigs_value.seqno);
00291         return kv::TxHistory::Result::FAIL;
00292       }
00293 
00294       kv::TxHistory::Result success = kv::TxHistory::Result::OK;
00295 
00296       for (auto& backup_sig : sigs_value.signatures)
00297       {
00298         auto it = cert.sigs.find(backup_sig.node);
00299         if (it == cert.sigs.end())
00300         {
00301           std::array<uint8_t, MBEDTLS_ECDSA_MAX_LEN> sig;
00302           std::copy(backup_sig.sig.begin(), backup_sig.sig.end(), sig.begin());
00303 
00304           kv::TxHistory::Result r = add_signature(
00305             {sigs_value.view, sigs_value.seqno},
00306             backup_sig.node,
00307             backup_sig.sig.size(),
00308             sig,
00309             backup_sig.hashed_nonce,
00310             node_count,
00311             is_primary);
00312           if (r == kv::TxHistory::Result::FAIL)
00313           {
00314             return kv::TxHistory::Result::FAIL;
00315           }
00316           else if (r == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK)
00317           {
00318             success = kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK;
00319           }
00320         }
00321         else
00322         {
00323           if (!std::equal(
00324                 backup_sig.sig.begin(),
00325                 backup_sig.sig.end(),
00326                 it->second.sig.begin()))
00327           {
00328             LOG_FAIL_FMT(
00329               "Signatures do not match at view:{}, seqno:{}, "
00330               "node_id:{}",
00331               sigs_value.view,
00332               sigs_value.seqno,
00333               backup_sig.node);
00334             return kv::TxHistory::Result::FAIL;
00335           }
00336         }
00337       }
00338 
00339       tx_id.term = sigs_value.view;
00340       tx_id.version = sigs_value.seqno;
00341 
00342       return success;
00343     }
00344 
00345     kv::TxHistory::Result receive_nonces()
00346     {
00347       std::optional<aft::RevealedNonces> nonces = store->get_nonces();
00348       CCF_ASSERT(nonces.has_value(), "nonces does not have a value");
00349       aft::RevealedNonces& nonces_value = nonces.value();
00350 
00351       auto it = certificates.find(nonces_value.tx_id.version);
00352       if (it == certificates.end())
00353       {
00354         LOG_FAIL_FMT(
00355           "Primary send backup signatures before sending the primary "
00356           "signature view:{}, seqno:{}",
00357           nonces_value.tx_id.term,
00358           nonces_value.tx_id.version);
00359         return kv::TxHistory::Result::FAIL;
00360       }
00361 
00362       auto& cert = it->second;
00363       for (auto& revealed_nonce : nonces_value.nonces)
00364       {
00365         auto it = cert.sigs.find(revealed_nonce.node_id);
00366         if (it == cert.sigs.end())
00367         {
00368           LOG_FAIL_FMT(
00369             "Node {} sent revealed nonce before sending a signature view:{}, "
00370             "seqno:{}",
00371             revealed_nonce.node_id,
00372             nonces_value.tx_id.term,
00373             nonces_value.tx_id.version);
00374           return kv::TxHistory::Result::FAIL;
00375         }
00376 
00377         BftNodeSignature& commit_cert = it->second;
00378         auto h = hash_data(revealed_nonce.nonce);
00379         if (!match_nonces(h, commit_cert.hashed_nonce))
00380         {
00381           LOG_FAIL_FMT(
00382             "Hashed nonces does not match with nonce view:{}, seqno:{}, "
00383             "node_id:{}",
00384             nonces_value.tx_id.term,
00385             nonces_value.tx_id.version,
00386             revealed_nonce.node_id);
00387           return kv::TxHistory::Result::FAIL;
00388         }
00389         if (cert.nonce_set.find(revealed_nonce.node_id) == cert.nonce_set.end())
00390         {
00391           cert.nonce_set.insert(revealed_nonce.node_id);
00392           std::copy(h.h.begin(), h.h.end(), commit_cert.nonce.h.begin());
00393         }
00394       }
00395 
00396       cert.nonces_committed_to_ledger = true;
00397       try_update_watermark(cert, nonces_value.tx_id.version, true);
00398       return kv::TxHistory::Result::OK;
00399     }
00400 
00401     kv::TxHistory::Result add_signature_ack(
00402       kv::TxID tx_id, kv::NodeId node_id, uint32_t node_count = 0)
00403     {
00404       auto it = certificates.find(tx_id.version);
00405       if (it == certificates.end())
00406       {
00407         // We currently do not know what the root is, so lets save this
00408         // signature and and we will verify the root when we get it from the
00409         // primary
00410         auto r =
00411           certificates.insert(std::pair<kv::Consensus::SeqNo, CommitCert>(
00412             tx_id.version, CommitCert()));
00413         it = r.first;
00414       }
00415 
00416       LOG_TRACE_FMT(
00417         "processing recv_signature_received_ack, from:{} view:{}, seqno:{}",
00418         node_id,
00419         tx_id.term,
00420         tx_id.version);
00421 
00422       auto& cert = it->second;
00423       cert.sig_acks.insert(node_id);
00424 
00425       if (can_send_reply_and_nonce(cert, node_count))
00426       {
00427         return kv::TxHistory::Result::SEND_REPLY_AND_NONCE;
00428       }
00429       return kv::TxHistory::Result::OK;
00430     }
00431 
00432     void add_nonce_reveal(
00433       kv::TxID tx_id,
00434       Nonce nonce,
00435       kv::NodeId node_id,
00436       uint32_t node_count,
00437       bool is_primary)
00438     {
00439       bool did_add = false;
00440       auto it = certificates.find(tx_id.version);
00441       if (it == certificates.end())
00442       {
00443         // We currently do not know what the root is, so lets save this
00444         // signature and and we will verify the root when we get it from the
00445         // primary
00446         auto r =
00447           certificates.insert(std::pair<kv::Consensus::SeqNo, CommitCert>(
00448             tx_id.version, CommitCert()));
00449         it = r.first;
00450         did_add = true;
00451       }
00452 
00453       auto& cert = it->second;
00454       auto it_node_sig = cert.sigs.find(node_id);
00455       if (it_node_sig == cert.sigs.end())
00456       {
00457         cert.unmatched_nonces.insert(
00458           std::pair<kv::NodeId, Nonce>(node_id, nonce));
00459         return;
00460       }
00461 
00462       BftNodeSignature& sig = it_node_sig->second;
00463       LOG_TRACE_FMT(
00464         "add_nonce_reveal view:{}, seqno:{}, node_id:{}, sig.hashed_nonce:{}, "
00465         " received.nonce:{}, hash(received.nonce):{} did_add:{}",
00466         tx_id.term,
00467         tx_id.version,
00468         node_id,
00469         sig.hashed_nonce,
00470         nonce,
00471         hash_data(nonce),
00472         did_add);
00473 
00474       if (!match_nonces(hash_data(nonce), sig.hashed_nonce))
00475       {
00476         // NOTE: We need to handle this case but for now having this make a
00477         // test fail will be very handy
00478         LOG_FAIL_FMT(
00479           "Nonces do not match add_nonce_reveal view:{}, seqno:{}, node_id:{}, "
00480           "sig.hashed_nonce:{}, "
00481           " received.nonce:{}, hash(received.nonce):{} did_add:{}",
00482           tx_id.term,
00483           tx_id.version,
00484           node_id,
00485           sig.hashed_nonce,
00486           nonce,
00487           hash_data(nonce),
00488           did_add);
00489         throw ccf::ccf_logic_error(fmt::format(
00490           "nonces do not match verification from {} FAILED, view:{}, seqno:{}",
00491           node_id,
00492           tx_id.term,
00493           tx_id.version));
00494       }
00495       sig.nonce = nonce;
00496       cert.nonce_set.insert(node_id);
00497 
00498       if (should_append_nonces_to_ledger(cert, node_count, is_primary))
00499       {
00500         aft::RevealedNonces revealed_nonces(tx_id);
00501 
00502         for (auto nonce_node_id : cert.nonce_set)
00503         {
00504           auto it = cert.sigs.find(nonce_node_id);
00505           CCF_ASSERT_FMT(
00506             it != cert.sigs.end(),
00507             "Expected cert not found, node_id:{}",
00508             nonce_node_id);
00509           revealed_nonces.nonces.push_back(
00510             aft::RevealedNonce(nonce_node_id, it->second.nonce));
00511         }
00512 
00513         store->write_nonces(revealed_nonces);
00514       }
00515 
00516       try_update_watermark(cert, tx_id.version, is_primary);
00517     }
00518 
00519     Nonce get_my_nonce(kv::TxID tx_id)
00520     {
00521       auto it = certificates.find(tx_id.version);
00522       if (it == certificates.end())
00523       {
00524         throw ccf::ccf_logic_error(fmt::format(
00525           "Attempting to access unknown nonce, view:{}, seqno:{}",
00526           tx_id.term,
00527           tx_id.version));
00528       }
00529       return it->second.my_nonce;
00530     }
00531 
00532     crypto::Sha256Hash get_my_hashed_nonce(kv::TxID tx_id)
00533     {
00534       Nonce nonce = get_my_nonce(tx_id);
00535       return hash_data(nonce);
00536     }
00537 
00538     void get_my_hashed_nonce(kv::TxID tx_id, crypto::Sha256Hash& hash)
00539     {
00540       Nonce nonce = get_my_nonce(tx_id);
00541       hash_data(nonce, hash);
00542     }
00543 
00544     void set_node_id(kv::NodeId id_)
00545     {
00546       id = id_;
00547     }
00548 
00549     crypto::Sha256Hash hash_data(Nonce& data)
00550     {
00551       crypto::Sha256Hash hash;
00552       hash_data(data, hash);
00553       return hash;
00554     }
00555 
00556     void hash_data(Nonce& data, crypto::Sha256Hash& hash)
00557     {
00558       tls::do_hash(
00559         reinterpret_cast<const uint8_t*>(&data),
00560         data.h.size(),
00561         hash.h,
00562         MBEDTLS_MD_SHA256);
00563     }
00564 
00565     kv::Consensus::SeqNo get_highest_committed_nonce()
00566     {
00567       return highest_commit_level;
00568     }
00569 
00570     std::tuple<std::unique_ptr<ViewChangeRequest>, kv::Consensus::SeqNo>
00571     get_view_change_message(kv::Consensus::View view)
00572     {
00573       auto it = certificates.find(highest_prepared_level.version);
00574       if (it == certificates.end())
00575       {
00576         throw ccf::ccf_logic_error(fmt::format(
00577           "Invalid prepared level, view:{}, seqno:{}",
00578           highest_prepared_level.term,
00579           highest_prepared_level.version));
00580       }
00581 
00582       auto& cert = it->second;
00583       auto m = std::make_unique<ViewChangeRequest>();
00584 
00585       for (const auto& sig : cert.sigs)
00586       {
00587         m->signatures.push_back(sig.second);
00588       }
00589 
00590       store->sign_view_change_request(*m, view, highest_prepared_level.version);
00591       return std::make_tuple(std::move(m), highest_prepared_level.version);
00592     }
00593 
00594     bool apply_view_change_message(
00595       ViewChangeRequest& view_change,
00596       kv::NodeId from,
00597       kv::Consensus::View view,
00598       kv::Consensus::SeqNo seqno)
00599     {
00600       if (!store->verify_view_change_request(view_change, from, view, seqno))
00601       {
00602         LOG_FAIL_FMT("Failed to verify view-change from:{}", from);
00603         return false;
00604       }
00605       LOG_TRACE_FMT(
00606         "Applying view-change from:{}, view:{}, seqno:{}", from, view, seqno);
00607 
00608       auto it = certificates.find(seqno);
00609 
00610       if (it == certificates.end())
00611       {
00612         LOG_INFO_FMT(
00613           "Received view-change for view:{} and seqno:{} that I am not aware "
00614           "of",
00615           view,
00616           seqno);
00617         return false;
00618       }
00619 
00620       bool verified_signatures = true;
00621 
00622       for (auto& sig : view_change.signatures)
00623       {
00624         if (!store->verify_signature(
00625               sig.node, it->second.root, sig.sig.size(), sig.sig.data()))
00626         {
00627           LOG_FAIL_FMT(
00628             "signatures do not match, view-change from:{}, view:{}, seqno:{}, "
00629             "node_id:{}",
00630             from,
00631             view,
00632             seqno,
00633             sig.node);
00634           verified_signatures = false;
00635           continue;
00636         }
00637 
00638         if (it->second.sigs.find(sig.node) == it->second.sigs.end())
00639         {
00640           continue;
00641         }
00642         it->second.sigs.insert(
00643           std::pair<kv::NodeId, BftNodeSignature>(sig.node, sig));
00644       }
00645 
00646       return verified_signatures;
00647     }
00648 
00649     bool apply_new_view(
00650       kv::NodeId from,
00651       uint32_t node_count,
00652       kv::Consensus::View& view_,
00653       kv::Consensus::SeqNo& seqno_) const
00654     {
00655       auto new_view = store->get_new_view();
00656       CCF_ASSERT(new_view.has_value(), "new view does not have a value");
00657       kv::Consensus::View view = new_view->view;
00658       kv::Consensus::SeqNo seqno = new_view->seqno;
00659 
00660       if (
00661         seqno < highest_prepared_level.version ||
00662         view < highest_prepared_level.term)
00663       {
00664         LOG_FAIL_FMT(
00665           "Invalid view and seqno in the new view highest prepared from:{}, "
00666           "view:{},seqno:{}, new_view view:{}, seqno:{}",
00667           from,
00668           highest_prepared_level.term,
00669           highest_prepared_level.version,
00670           view,
00671           seqno);
00672         return false;
00673       }
00674 
00675       if (
00676         new_view->view_change_messages.size() <
00677         ccf::get_message_threshold(node_count))
00678       {
00679         LOG_FAIL_FMT(
00680           "Not enough ViewChangeRequests from:{}, new_view view:{}, seqno:{}, "
00681           "num_requests:{}",
00682           from,
00683           view,
00684           seqno,
00685           new_view->view_change_messages.size());
00686         return false;
00687       }
00688 
00689       for (auto& vcp : new_view->view_change_messages)
00690       {
00691         kv::NodeId id = vcp.first;
00692         ccf::ViewChangeRequest& vc = vcp.second;
00693 
00694         if (!store->verify_view_change_request(vc, id, view, seqno))
00695         {
00696           LOG_FAIL_FMT(
00697             "Failed to verify view-change id:{},view:{}, seqno:{}",
00698             id,
00699             view,
00700             seqno);
00701           return false;
00702         }
00703       }
00704 
00705       if (!store->verify_view_change_request_confirmation(
00706             new_view.value(), from))
00707       {
00708         LOG_INFO_FMT("Failed to verify from:{}", from);
00709         return false;
00710       }
00711 
00712       view_ = view;
00713       seqno_ = seqno;
00714       return true;
00715     }
00716 
00717   private:
00718     kv::NodeId id;
00719     std::shared_ptr<tls::Entropy> entropy;
00720     kv::Consensus::SeqNo highest_commit_level = 0;
00721     kv::TxID highest_prepared_level = {0, 0};
00722 
00723     std::map<kv::Consensus::SeqNo, CommitCert> certificates;
00724 
00725     void try_match_unmatched_nonces(
00726       CommitCert& cert,
00727       BftNodeSignature& bft_node_sig,
00728       kv::Consensus::View view,
00729       kv::Consensus::SeqNo seqno,
00730       kv::NodeId node_id)
00731     {
00732       auto it_unmatched_nonces = cert.unmatched_nonces.find(node_id);
00733       if (it_unmatched_nonces != cert.unmatched_nonces.end())
00734       {
00735         if (!match_nonces(
00736               hash_data(it_unmatched_nonces->second),
00737               bft_node_sig.hashed_nonce))
00738         {
00739           // NOTE: We need to handle this case but for now having this make a
00740           // test fail will be very handy
00741           LOG_FAIL_FMT(
00742             "Nonces do not match add_nonce_reveal view:{}, seqno:{}, "
00743             "node_id:{}, "
00744             "sig.hashed_nonce:{}, "
00745             " received.nonce:{}, hash(received.nonce):{}",
00746             view,
00747             seqno,
00748             node_id,
00749             bft_node_sig.hashed_nonce,
00750             it_unmatched_nonces->second,
00751             hash_data(it_unmatched_nonces->second));
00752           throw ccf::ccf_logic_error(fmt::format(
00753             "nonces do not match verification from {} FAILED, view:{}, "
00754             "seqno:{}",
00755             node_id,
00756             view,
00757             seqno));
00758         }
00759         bft_node_sig.nonce = it_unmatched_nonces->second;
00760         cert.nonce_set.insert(node_id);
00761         cert.unmatched_nonces.erase(it_unmatched_nonces);
00762       }
00763     }
00764 
00765     bool match_nonces(const Nonce& n_1, const Nonce& n_2)
00766     {
00767       if (n_1.h.size() != n_2.h.size())
00768       {
00769         return false;
00770       }
00771 
00772       return std::equal(n_1.h.begin(), n_1.h.end(), n_2.h.begin());
00773     }
00774 
00775     bool can_send_sig_ack(
00776       CommitCert& cert, const kv::TxID& tx_id, uint32_t node_count)
00777     {
00778       if (
00779         cert.sigs.size() >= get_message_threshold(node_count) &&
00780         !cert.ack_sent && cert.have_primary_signature)
00781       {
00782         if (tx_id.version > highest_prepared_level.version)
00783         {
00784           CCF_ASSERT_FMT(
00785             tx_id.term >= highest_prepared_level.term,
00786             "Prepared terms are moving backwards new_term:{}, current_term:{}",
00787             tx_id.term,
00788             highest_prepared_level.term);
00789           highest_prepared_level = tx_id;
00790         }
00791 
00792         cert.ack_sent = true;
00793         return true;
00794       }
00795       return false;
00796     }
00797 
00798     bool can_send_reply_and_nonce(CommitCert& cert, uint32_t node_count)
00799     {
00800       if (
00801         cert.sig_acks.size() >= get_message_threshold(node_count) &&
00802         !cert.reply_and_nonce_sent && cert.ack_sent)
00803       {
00804         cert.reply_and_nonce_sent = true;
00805         return true;
00806       }
00807       return false;
00808     }
00809 
00810     void try_update_watermark(
00811       CommitCert& cert,
00812       kv::Consensus::SeqNo seqno,
00813       bool should_clear_old_entries)
00814     {
00815       if (cert.nonces_committed_to_ledger && seqno > highest_commit_level)
00816       {
00817         highest_commit_level = seqno;
00818         if (should_clear_old_entries)
00819         {
00820           LOG_INFO_FMT("Removing all entries upto:{}", seqno);
00821           for (auto it = certificates.begin();;)
00822           {
00823             CCF_ASSERT(
00824               it != certificates.end(),
00825               "Should never deleted all certificates");
00826 
00827             if (it->first == seqno)
00828             {
00829               break;
00830             }
00831             it = certificates.erase(it);
00832           }
00833         }
00834       }
00835     }
00836 
00837     bool should_append_nonces_to_ledger(
00838       CommitCert& cert, uint32_t node_count, bool is_primary)
00839     {
00840       if (
00841         cert.nonce_set.size() >= get_message_threshold(node_count) &&
00842         cert.reply_and_nonce_sent && cert.ack_sent &&
00843         !cert.nonces_committed_to_ledger)
00844       {
00845         cert.nonces_committed_to_ledger = true;
00846         return is_primary;
00847       }
00848       return false;
00849     }
00850   };
00851 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/progress_tracker.h...
Preprocessing /data/git/CCF/src/node/progress_tracker_types.h...
#include backup_signatures.h: already included! skipping...
#include consensus/aft/revealed_nonces.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include tls/hash.h: not found! skipping...
#include tls/tls.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include view_change.h: already included! skipping...
Preprocessor output (size: 9092 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct BftNodeSignature : public ccf::NodeSignature
00015   {
00016     bool is_primary;
00017     Nonce nonce;
00018 
00019     BftNodeSignature(const NodeSignature& ns) :
00020       NodeSignature(ns),
00021       is_primary(false)
00022     {}
00023 
00024     BftNodeSignature(
00025       const std::vector<uint8_t>& sig_, NodeId node_, Nonce hashed_nonce_) :
00026       NodeSignature(sig_, node_, hashed_nonce_),
00027       is_primary(false)
00028     {}
00029   };
00030 
00031   struct CommitCert
00032   {
00033     CommitCert(crypto::Sha256Hash& root_, Nonce my_nonce_) :
00034       root(root_),
00035       my_nonce(my_nonce_),
00036       have_primary_signature(true)
00037     {}
00038 
00039     CommitCert() = default;
00040 
00041     crypto::Sha256Hash root;
00042     std::map<kv::NodeId, BftNodeSignature> sigs;
00043     std::set<kv::NodeId> sig_acks;
00044     std::set<kv::NodeId> nonce_set;
00045     std::map<kv::NodeId, Nonce> unmatched_nonces;
00046     Nonce my_nonce;
00047     bool have_primary_signature = false;
00048     bool ack_sent = false;
00049     bool reply_and_nonce_sent = false;
00050     bool nonces_committed_to_ledger = false;
00051     bool wrote_sig_to_ledger = false;
00052   };
00053 
00054   class ProgressTrackerStore
00055   {
00056   public:
00057     virtual ~ProgressTrackerStore() = default;
00058     virtual void write_backup_signatures(ccf::BackupSignatures& sig_value) = 0;
00059     virtual std::optional<ccf::BackupSignatures> get_backup_signatures() = 0;
00060     virtual std::optional<ccf::ViewChangeConfirmation> get_new_view() = 0;
00061     virtual void write_nonces(aft::RevealedNonces& nonces) = 0;
00062     virtual std::optional<aft::RevealedNonces> get_nonces() = 0;
00063     virtual bool verify_signature(
00064       kv::NodeId node_id,
00065       crypto::Sha256Hash& root,
00066       uint32_t sig_size,
00067       uint8_t* sig) = 0;
00068     virtual void sign_view_change_request(
00069       ViewChangeRequest& view_change,
00070       kv::Consensus::View view,
00071       kv::Consensus::SeqNo seqno) = 0;
00072     virtual bool verify_view_change_request(
00073       ViewChangeRequest& view_change,
00074       kv::NodeId from,
00075       kv::Consensus::View view,
00076       kv::Consensus::SeqNo seqno) = 0;
00077     virtual kv::Consensus::SeqNo write_view_change_confirmation(
00078       ccf::ViewChangeConfirmation& new_view) = 0;
00079     virtual bool verify_view_change_request_confirmation(
00080       ccf::ViewChangeConfirmation& new_view, kv::NodeId from) = 0;
00081   };
00082 
00083   class ProgressTrackerStoreAdapter : public ProgressTrackerStore
00084   {
00085   public:
00086     ProgressTrackerStoreAdapter(
00087       kv::AbstractStore& store_,
00088       tls::KeyPair& kp_,
00089       ccf::Nodes& nodes_,
00090       ccf::BackupSignaturesMap& backup_signatures_,
00091       aft::RevealedNoncesMap& revealed_nonces_,
00092       ccf::NewViewsMap& new_views_) :
00093       store(store_),
00094       kp(kp_),
00095       nodes(nodes_),
00096       backup_signatures(backup_signatures_),
00097       revealed_nonces(revealed_nonces_),
00098       new_views(new_views_)
00099     {}
00100 
00101     void write_backup_signatures(ccf::BackupSignatures& sig_value) override
00102     {
00103       kv::Tx tx(&store);
00104       auto backup_sig_view = tx.get_view(backup_signatures);
00105 
00106       backup_sig_view->put(0, sig_value);
00107       auto r = tx.commit();
00108       LOG_TRACE_FMT("Adding signatures to ledger, result:{}", r);
00109       CCF_ASSERT_FMT(
00110         r == kv::CommitSuccess::OK,
00111         "Commiting backup signatures failed r:{}",
00112         r);
00113     }
00114 
00115     std::optional<ccf::BackupSignatures> get_backup_signatures() override
00116     {
00117       kv::Tx tx(&store);
00118       auto sigs_tv = tx.get_view(backup_signatures);
00119       auto sigs = sigs_tv->get(0);
00120       if (!sigs.has_value())
00121       {
00122         LOG_FAIL_FMT("No signatures found in signatures map");
00123         throw ccf::ccf_logic_error("No signatures found in signatures map");
00124       }
00125       return sigs;
00126     }
00127 
00128     std::optional<ccf::ViewChangeConfirmation> get_new_view() override
00129     {
00130       kv::Tx tx(&store);
00131       auto new_views_tv = tx.get_view(new_views);
00132       auto new_view = new_views_tv->get(0);
00133       if (!new_view.has_value())
00134       {
00135         LOG_FAIL_FMT("No new_view found in new_view map");
00136         throw ccf::ccf_logic_error("No new_view found in new_view map");
00137       }
00138       return new_view;
00139     }
00140 
00141     void write_nonces(aft::RevealedNonces& nonces) override
00142     {
00143       kv::Tx tx(&store);
00144       auto nonces_tv = tx.get_view(revealed_nonces);
00145 
00146       nonces_tv->put(0, nonces);
00147       auto r = tx.commit();
00148       if (r != kv::CommitSuccess::OK)
00149       {
00150         LOG_FAIL_FMT(
00151           "Failed to write nonces, view:{}, seqno:{}",
00152           nonces.tx_id.term,
00153           nonces.tx_id.version);
00154         throw ccf::ccf_logic_error(fmt::format(
00155           "Failed to write nonces, view:{}, seqno:{}",
00156           nonces.tx_id.term,
00157           nonces.tx_id.version));
00158       }
00159     }
00160 
00161     std::optional<aft::RevealedNonces> get_nonces() override
00162     {
00163       kv::Tx tx(&store);
00164       auto nonces_tv = tx.get_view(revealed_nonces);
00165       auto nonces = nonces_tv->get(0);
00166       if (!nonces.has_value())
00167       {
00168         LOG_FAIL_FMT("No signatures found in signatures map");
00169         throw ccf::ccf_logic_error("No signatures found in signatures map");
00170       }
00171       return nonces;
00172     }
00173 
00174     bool verify_signature(
00175       kv::NodeId node_id,
00176       crypto::Sha256Hash& root,
00177       uint32_t sig_size,
00178       uint8_t* sig) override
00179     {
00180       kv::Tx tx(&store);
00181       auto ni_tv = tx.get_view(nodes);
00182 
00183       auto ni = ni_tv->get(node_id);
00184       if (!ni.has_value())
00185       {
00186         LOG_FAIL_FMT(
00187           "No node info, and therefore no cert for node {}", node_id);
00188         return false;
00189       }
00190       tls::VerifierPtr from_cert = tls::make_verifier(ni.value().cert);
00191       return from_cert->verify_hash(
00192         root.h.data(), root.h.size(), sig, sig_size);
00193     }
00194 
00195     void sign_view_change_request(
00196       ViewChangeRequest& view_change,
00197       kv::Consensus::View view,
00198       kv::Consensus::SeqNo seqno) override
00199     {
00200       crypto::Sha256Hash h = hash_view_change(view_change, view, seqno);
00201       view_change.signature = kp.sign_hash(h.h.data(), h.h.size());
00202     }
00203 
00204     bool verify_view_change_request(
00205       ViewChangeRequest& view_change,
00206       kv::NodeId from,
00207       kv::Consensus::View view,
00208       kv::Consensus::SeqNo seqno) override
00209     {
00210       crypto::Sha256Hash h = hash_view_change(view_change, view, seqno);
00211 
00212       kv::Tx tx(&store);
00213       auto ni_tv = tx.get_view(nodes);
00214 
00215       auto ni = ni_tv->get(from);
00216       if (!ni.has_value())
00217       {
00218         LOG_FAIL_FMT("No node info, and therefore no cert for node {}", from);
00219         return false;
00220       }
00221       tls::VerifierPtr from_cert = tls::make_verifier(ni.value().cert);
00222       return from_cert->verify_hash(
00223         h.h.data(),
00224         h.h.size(),
00225         view_change.signature.data(),
00226         view_change.signature.size());
00227     }
00228 
00229     bool verify_view_change_request_confirmation(
00230       ViewChangeConfirmation& new_view, kv::NodeId from) override
00231     {
00232       kv::Tx tx(&store);
00233       auto ni_tv = tx.get_view(nodes);
00234 
00235       auto ni = ni_tv->get(from);
00236       if (!ni.has_value())
00237       {
00238         LOG_FAIL_FMT("No node info, and therefore no cert for node {}", from);
00239         return false;
00240       }
00241       tls::VerifierPtr from_cert = tls::make_verifier(ni.value().cert);
00242       auto h = hash_new_view(new_view);
00243       return from_cert->verify_hash(
00244         h.h.data(),
00245         h.h.size(),
00246         new_view.signature.data(),
00247         new_view.signature.size());
00248     }
00249 
00250     kv::Consensus::SeqNo write_view_change_confirmation(
00251       ccf::ViewChangeConfirmation& new_view) override
00252     {
00253       kv::Tx tx(&store);
00254       auto new_views_tv = tx.get_view(new_views);
00255 
00256       crypto::Sha256Hash h = hash_new_view(new_view);
00257       new_view.signature = kp.sign_hash(h.h.data(), h.h.size());
00258 
00259       new_views_tv->put(0, new_view);
00260       auto r = tx.commit();
00261       if (r != kv::CommitSuccess::OK)
00262       {
00263         LOG_FAIL_FMT(
00264           "Failed to write new_view, view:{}, seqno:{}",
00265           new_view.view,
00266           new_view.seqno);
00267         throw ccf::ccf_logic_error(fmt::format(
00268           "Failed to write new_view, view:{}, seqno:{}",
00269           new_view.view,
00270           new_view.seqno));
00271       }
00272 
00273       return tx.commit_version();
00274     }
00275 
00276     crypto::Sha256Hash hash_new_view(ccf::ViewChangeConfirmation& new_view)
00277     {
00278       crypto::CSha256Hash ch;
00279       ch.update(new_view.view);
00280       ch.update(new_view.seqno);
00281 
00282       for (auto it : new_view.view_change_messages)
00283       {
00284         ch.update(it.second.signature);
00285       }
00286 
00287       return ch.finalize();
00288     }
00289 
00290   private:
00291     kv::AbstractStore& store;
00292     tls::KeyPair& kp;
00293     ccf::Nodes& nodes;
00294     ccf::BackupSignaturesMap& backup_signatures;
00295     aft::RevealedNoncesMap& revealed_nonces;
00296     ccf::NewViewsMap& new_views;
00297 
00298     crypto::Sha256Hash hash_view_change(
00299       const ViewChangeRequest& v,
00300       kv::Consensus::View view,
00301       kv::Consensus::SeqNo seqno) const
00302     {
00303       crypto::CSha256Hash ch;
00304 
00305       ch.update(view);
00306       ch.update(seqno);
00307 
00308       for (auto& s : v.signatures)
00309       {
00310         ch.update(s.sig);
00311       }
00312 
00313       return ch.finalize();
00314     }
00315   };
00316 
00317   static constexpr uint32_t get_message_threshold(uint32_t node_count)
00318   {
00319     uint32_t f = 0;
00320     for (; 3 * f + 1 < node_count; ++f)
00321       ;
00322 
00323     return 2 * f + 1;
00324   }
00325 }
00326 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/progress_tracker_types.h...
Preprocessing /data/git/CCF/src/node/proposals.h...
#include ds/json.h: not found! skipping...
#include ds/msgpack_adaptor_nlohmann.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include script.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include unordered_map: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 5365 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 namespace ccf
00016 {
00017   /** Members use proposals to propose changes to the KV store.
00018    * Active members can issue proposals through the Propose RPC.
00019    * A proposal is defined by a Lua script and a corresponding parameter.
00020    * Proposal are passed two arguments:
00021    *  (1) a table mapping KV store table names to corresponding accessors
00022    *  (2) the specified parameter (which is translated from json to Lua, this
00023    * could for example be the certificate of a to-be-added node).
00024    * Proposal scripts can read KV tables with the rights of the proposing
00025    * member, but they cannot write. Proposal scripts must return a list of
00026    * proposed function calls (ie, ::ProposedCalls). For this, they have access
00027    * to the helper class Calls. If a script returns an empty list, the vote is
00028    * aborted and it may run again at a later point. The available function calls
00029    * are defined in
00030    * ::MemberRpcFrontend and gov.lua. The following script proposes calling
00031    * "raw_puts" (defined in gov.lua) to make raw writes to the KV. It uses the
00032    * helper class Puts. (The environment for proposal scripts is defined
00033    * ./src/runtime_config/gov.lua.)
00034    *
00035    *  local tables, param = ...
00036    *  local value = tables["public:ccf.gov.values"]:get(param)
00037    *  local c = Calls:new()
00038    *  local p = Puts:new()
00039    *  -- propose writing store["table"]["key"] = value
00040    *  p:put("table", "key", value)
00041    *  c:call("raw_puts", p)
00042    *  return c
00043    *
00044    * Or more compact:
00045    *
00046    *  local tables, param = ...
00047    *  return Calls:call(Puts:put("table", "key",
00048    *    tables["public:ccf.gov.values"]:get(param))
00049    */
00050   enum class ProposalState
00051   {
00052     OPEN, //< Proposal is active and can be voted on
00053     ACCEPTED, //< Proposal passed a successful vote and was enacted
00054     WITHDRAWN, //< Proposal was removed by proposing member, will never be
00055                // enacted
00056     REJECTED, //< Proposal was rejected by vote, will never be enacted
00057     FAILED, //< Proposal passed a successful vote, but its proposed actions
00058             // failed, will never be enacted
00059   };
00060   DECLARE_JSON_ENUM(
00061     ProposalState,
00062     {{ProposalState::OPEN, "OPEN"},
00063      {ProposalState::ACCEPTED, "ACCEPTED"},
00064      {ProposalState::WITHDRAWN, "WITHDRAWN"},
00065      {ProposalState::REJECTED, "REJECTED"},
00066      {ProposalState::FAILED, "FAILED"}});
00067 
00068   struct Proposal
00069   {
00070     Script script = {};
00071     nlohmann::json parameter = {};
00072     MemberId proposer = {};
00073     ProposalState state = ProposalState::OPEN;
00074     std::unordered_map<MemberId, Script> votes = {};
00075 
00076     Proposal() = default;
00077     Proposal(const Script& s, const nlohmann::json& param, MemberId prop) :
00078       script(s),
00079       parameter(param),
00080       proposer(prop),
00081       state(ProposalState::OPEN)
00082     {}
00083 
00084     bool operator==(const Proposal& o) const
00085     {
00086       return script == o.script && parameter == o.parameter &&
00087         proposer == o.proposer && state == o.state && votes == o.votes;
00088     }
00089 
00090     MSGPACK_DEFINE(script, parameter, proposer, state, votes);
00091   };
00092 
00093   DECLARE_JSON_REQUIRED_FIELDS(
00094     Proposal, script, parameter, proposer, state, votes)
00095 
00096   using Proposals = kv::Map<ObjectId, Proposal>;
00097 
00098   struct ProposalInfo
00099   {
00100     ObjectId proposal_id;
00101     MemberId proposer_id;
00102     ProposalState state;
00103   };
00104 
00105   DECLARE_JSON_REQUIRED_FIELDS(ProposalInfo, proposal_id, proposer_id, state);
00106 
00107   struct Vote
00108   {
00109     Script ballot;
00110   };
00111 
00112 
00113 
00114   //! A call proposed by a proposal script
00115   struct ProposedCall
00116   {
00117     //! the name of the function to call
00118     std::string func;
00119     //! the corresponding arguments
00120     nlohmann::json args;
00121   };
00122 
00123 
00124 
00125 
00126   struct Propose
00127   {
00128     //! arguments for propose RPC
00129     struct In
00130     {
00131       //! script that proposes changes
00132       Script script;
00133       //! fixed parameter for the script
00134       nlohmann::json parameter = nullptr;
00135     };
00136 
00137     //! results from propose RPC
00138     using Out = ProposalInfo;
00139   };
00140 
00141 
00142 
00143 
00144   /** A list of calls proposed (and returned) by a proposal script
00145    * Every proposal script must return a compatible data structure.
00146    */
00147   using ProposedCalls = std::vector<ProposedCall>;
00148 
00149   struct KVRead
00150   {
00151     struct In
00152     {
00153       std::string table = {};
00154       nlohmann::json key = {};
00155     };
00156 
00157     using Out = nlohmann::json;
00158   };
00159 
00160   DECLARE_JSON_REQUIRED_FIELDS(KVRead::In, table, key);
00161 
00162   enum CompletionResult
00163   {
00164     PASSED = 1,
00165     PENDING = 0,
00166     REJECTED = -1
00167   };
00168 }
00169 
00170 MSGPACK_ADD_ENUM(ccf::ProposalState);
00171 
00172 FMT_BEGIN_NAMESPACE
00173 template <>
00174 struct formatter<ccf::ProposalState>
00175 {
00176   template <typename ParseContext>
00177   auto parse(ParseContext& ctx)
00178   {
00179     return ctx.begin();
00180   }
00181 
00182   template <typename FormatContext>
00183   auto format(const ccf::ProposalState& state, FormatContext& ctx)
00184     -> decltype(ctx.out())
00185   {
00186     switch (state)
00187     {
00188       case (ccf::ProposalState::OPEN):
00189       {
00190         return format_to(ctx.out(), "open");
00191       }
00192       case (ccf::ProposalState::ACCEPTED):
00193       {
00194         return format_to(ctx.out(), "accepted");
00195       }
00196       case (ccf::ProposalState::WITHDRAWN):
00197       {
00198         return format_to(ctx.out(), "withdrawn");
00199       }
00200       case (ccf::ProposalState::REJECTED):
00201       {
00202         return format_to(ctx.out(), "reject");
00203       }
00204       default:
00205       {
00206         return format_to(ctx.out(), "UNKNOWN");
00207       }
00208     }
00209   }
00210 };
00211 FMT_END_NAMESPACE
00212 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/proposals.h...
Preprocessing /data/git/CCF/src/node/quote.h...
Preprocessor output (size: 305 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055 
00056 
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 
00065 
00066 
00067 
00068 
00069 
00070 
00071 
00072 
00073 
00074 
00075 
00076 
00077 
00078 
00079 
00080 
00081 
00082 
00083 
00084 
00085 
00086 
00087 
00088 
00089 
00090 
00091 
00092 
00093 
00094 
00095 
00096 
00097 
00098 
00099 
00100 
00101 
00102 
00103 
00104 
00105 
00106 
00107 
00108 
00109 
00110 
00111 
00112 
00113 
00114 
00115 
00116 
00117 
00118 
00119 
00120 
00121 
00122 
00123 
00124 
00125 
00126 
00127 
00128 
00129 
00130 
00131 
00132 
00133 
00134 
00135 
00136 
00137 
00138 
00139 
00140 
00141 
00142 
00143 
00144 
00145 
00146 
00147 
00148 
00149 
00150 
00151 
00152 
00153 
00154 
00155 
00156 
00157 
00158 
00159 
00160 
00161 
00162 
00163 
00164 
00165 
00166 
00167 
00168 
00169 
00170 
00171 
00172 
00173 
00174 
00175 
00176 
00177 
00178 
00179 
00180 
00181 
00182 
00183 
00184 
00185 
00186 
00187 
00188 
00189 
00190 
00191 
00192 
00193 
00194 
00195 
00196 
00197 
00198 
00199 
00200 
00201 
00202 
00203 
00204 
00205 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/quote.h...
Preprocessing /data/git/CCF/src/node/request_tracker.h...
#include crypto/hash.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/dl_list.h: not found! skipping...
#include array: not found! skipping...
#include chrono: not found! skipping...
#include optional: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 5075 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace aft
00014 {
00015   class RequestTracker
00016   {
00017     struct Request
00018     {
00019       Request(
00020         const crypto::Sha256Hash& hash_, std::chrono::milliseconds time_) :
00021         hash(hash_),
00022         time(time_)
00023       {}
00024 
00025       Request(const crypto::Sha256Hash& hash_) : hash(hash_) {}
00026 
00027       crypto::Sha256Hash hash;
00028       std::chrono::milliseconds time;
00029 
00030       Request* next = nullptr;
00031       Request* prev = nullptr;
00032     };
00033 
00034     struct RequestComp
00035     {
00036       bool operator()(const Request* lhs, const Request* rhs) const
00037       {
00038         const std::array<uint64_t, 4>& lhs_hash =
00039           (std::array<uint64_t, 4>&)lhs->hash;
00040         const std::array<uint64_t, 4>& rhs_hash =
00041           (std::array<uint64_t, 4>&)rhs->hash;
00042 
00043         for (uint32_t i = 0; i < 4; ++i)
00044         {
00045           if (lhs_hash[i] == rhs_hash[i])
00046           {
00047             continue;
00048           }
00049           return lhs_hash[i] > rhs_hash[i];
00050         }
00051         return false;
00052       }
00053     };
00054 
00055     static constexpr std::chrono::seconds retail_unmatched_deleted_hashes =
00056       std::chrono::seconds(1);
00057 
00058   public:
00059     void insert(const crypto::Sha256Hash& hash, std::chrono::milliseconds time)
00060     {
00061       if (remove(hash, hashes_without_requests, hashes_without_requests_list))
00062       {
00063         return;
00064       }
00065       insert(hash, time, requests, requests_list);
00066     }
00067 
00068     void insert_deleted(
00069       const crypto::Sha256Hash& hash, std::chrono::milliseconds time)
00070     {
00071 
00072       Request r(hash);
00073       CCF_ASSERT_FMT(
00074         requests.find(&r) == requests.end(),
00075         "cannot add deleted request that is a known request, hash:{}",
00076         hash);
00077 
00078       insert(hash, time, hashes_without_requests, hashes_without_requests_list);
00079     }
00080 
00081     bool remove(const crypto::Sha256Hash& hash)
00082     {
00083       return remove(hash, requests, requests_list);
00084     }
00085 
00086     void tick(std::chrono::milliseconds current_time)
00087     {
00088       if (current_time < retail_unmatched_deleted_hashes)
00089       {
00090         return;
00091       }
00092       current_time += retail_unmatched_deleted_hashes;
00093 
00094       while (!hashes_without_requests_list.is_empty() &&
00095              hashes_without_requests_list.get_head()->time < current_time)
00096       {
00097         Request* req = hashes_without_requests_list.get_head();
00098         remove(
00099           req->hash, hashes_without_requests, hashes_without_requests_list);
00100       }
00101     }
00102 
00103     std::optional<std::chrono::milliseconds> oldest_entry()
00104     {
00105       if (requests_list.is_empty())
00106       {
00107         return std::nullopt;
00108       }
00109       return requests_list.get_head()->time;
00110     }
00111 
00112     bool is_empty()
00113     {
00114       return requests.empty() && requests_list.is_empty() &&
00115         hashes_without_requests.empty() &&
00116         hashes_without_requests_list.is_empty();
00117     }
00118 
00119     void insert_signed_request(
00120       kv::Consensus::SeqNo seqno, std::chrono::milliseconds time)
00121     {
00122       if (seqno > seqno_last_signature)
00123       {
00124         seqno_last_signature = seqno;
00125         time_last_signature = time;
00126       }
00127     }
00128 
00129     std::tuple<kv::Consensus::SeqNo, std::chrono::milliseconds>
00130     get_seqno_time_last_request() const
00131     {
00132       return {seqno_last_signature, time_last_signature};
00133     }
00134 
00135     void clear()
00136     {
00137       requests.clear();
00138       requests_list.clear();
00139 
00140       hashes_without_requests.clear();
00141       hashes_without_requests_list.clear();
00142     }
00143 
00144   private:
00145     std::multiset<Request*, RequestComp> requests;
00146     snmalloc::DLList<Request, std::nullptr_t, true> requests_list;
00147 
00148     std::multiset<Request*, RequestComp> hashes_without_requests;
00149     snmalloc::DLList<Request, std::nullptr_t, true>
00150       hashes_without_requests_list;
00151 
00152     kv::Consensus::SeqNo seqno_last_signature = -1;
00153     std::chrono::milliseconds time_last_signature =
00154       std::chrono::milliseconds(0);
00155 
00156     void insert(
00157       const crypto::Sha256Hash& hash,
00158       std::chrono::milliseconds time,
00159       std::multiset<Request*, RequestComp>& requests_,
00160       snmalloc::DLList<Request, std::nullptr_t, true>& requests_list_)
00161     {
00162       CCF_ASSERT_FMT(
00163         requests_list_.get_tail() == nullptr ||
00164           requests_list_.get_tail()->time <= time,
00165         "items not entered in the correct order. last:{}, time:{}",
00166         requests_list_.get_tail()->time,
00167         time);
00168       auto r = std::make_unique<Request>(hash, time);
00169       requests_.insert(r.get());
00170       requests_list_.insert_back(r.release());
00171     }
00172 
00173     bool remove(
00174       const crypto::Sha256Hash& hash,
00175       std::multiset<Request*, RequestComp>& requests_,
00176       snmalloc::DLList<Request, std::nullptr_t, true>& requests_list_)
00177     {
00178       Request r(hash);
00179       auto ret = requests_.equal_range(&r);
00180       if (ret.first == ret.second)
00181       {
00182         return false;
00183       }
00184 
00185       auto it = ret.first;
00186       for (auto c = ret.first; c != ret.second; ++c)
00187       {
00188         if ((*it)->time > (*c)->time)
00189         {
00190           it = c;
00191         }
00192       }
00193 
00194       std::unique_ptr<Request> req(*it);
00195       requests_.erase(it);
00196       requests_list_.remove(req.get());
00197       return true;
00198     }
00199   };
00200 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/request_tracker.h...
Preprocessing /data/git/CCF/src/node/rpc/call_types.h...
#include ds/json_schema.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/code_id.h: not found! skipping...
#include node/identity.h: not found! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node_call_types.h: already included! skipping...
#include ds/json.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 2495 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 # 11 "/data/git/CCF/src/node/rpc/call_types.h" 2
00012 
00013 
00014 
00015 namespace ccf
00016 {
00017   struct GetCommit
00018   {
00019     struct Out
00020     {
00021       kv::Consensus::View view;
00022       kv::Consensus::SeqNo seqno;
00023     };
00024   };
00025 
00026   struct GetTxStatus
00027   {
00028     struct In
00029     {
00030       kv::Consensus::View view;
00031       kv::Consensus::SeqNo seqno;
00032     };
00033 
00034     struct Out
00035     {
00036       TxStatus status;
00037     };
00038   };
00039 
00040   struct GetMetrics
00041   {
00042     struct HistogramResults
00043     {
00044       int low = {};
00045       int high = {};
00046       size_t overflow = {};
00047       size_t underflow = {};
00048       nlohmann::json buckets = {};
00049     };
00050 
00051     struct Out
00052     {
00053       HistogramResults histogram;
00054       nlohmann::json tx_rates;
00055     };
00056   };
00057 
00058   struct GetPrimaryInfo
00059   {
00060     struct Out
00061     {
00062       NodeId primary_id;
00063       std::string primary_host;
00064       std::string primary_port;
00065       kv::Consensus::View current_view;
00066     };
00067   };
00068 
00069   struct GetCode
00070   {
00071     struct Version
00072     {
00073       std::string digest;
00074       ccf::CodeStatus status;
00075     };
00076 
00077     struct Out
00078     {
00079       std::vector<GetCode::Version> versions = {};
00080     };
00081   };
00082 
00083   struct GetNetworkInfo
00084   {
00085     struct NodeInfo
00086     {
00087       NodeId node_id;
00088       std::string host;
00089       std::string port;
00090     };
00091 
00092     struct Out
00093     {
00094       std::vector<NodeInfo> nodes = {};
00095       std::optional<NodeId> primary_id = std::nullopt;
00096     };
00097   };
00098 
00099   struct GetNodesByRPCAddress
00100   {
00101     struct NodeInfo
00102     {
00103       NodeId node_id;
00104       NodeStatus status;
00105     };
00106 
00107     struct In
00108     {
00109       std::string host;
00110       std::string port;
00111       bool retired = false;
00112     };
00113 
00114     struct Out
00115     {
00116       std::vector<NodeInfo> nodes = {};
00117     };
00118   };
00119 
00120   struct CallerInfo
00121   {
00122     CallerId caller_id;
00123   };
00124 
00125   struct GetUserId
00126   {
00127     struct In
00128     {
00129       std::string cert;
00130     };
00131 
00132     using Out = CallerInfo;
00133   };
00134 
00135   struct GetAPI
00136   {
00137     using Out = nlohmann::json;
00138   };
00139 
00140   struct EndpointMetrics
00141   {
00142     struct Metric
00143     {
00144       size_t calls = 0;
00145       size_t errors = 0;
00146       size_t failures = 0;
00147     };
00148 
00149     struct Out
00150     {
00151       std::map<std::string, std::map<std::string, Metric>> metrics;
00152     };
00153   };
00154 
00155   struct GetReceipt
00156   {
00157     struct In
00158     {
00159       int64_t commit = 0;
00160     };
00161 
00162     struct Out
00163     {
00164       std::vector<std::uint8_t> receipt = {};
00165     };
00166   };
00167 
00168   struct VerifyReceipt
00169   {
00170     struct In
00171     {
00172       std::vector<std::uint8_t> receipt = {};
00173     };
00174 
00175     struct Out
00176     {
00177       bool valid = false;
00178     };
00179   };
00180 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/call_types.h...
Preprocessing /data/git/CCF/src/node/rpc/common_endpoint_registry.h...
#include endpoint_registry.h: already included! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
#include json_handler.h: already included! skipping...
#include metrics.h: already included! skipping...
#include node/code_id.h: not found! skipping...
Preprocessor output (size: 11473 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   /*
00015    * Extends the basic EndpointRegistry with methods which should be present
00016    * on all frontends
00017    */
00018   class CommonEndpointRegistry : public EndpointRegistry
00019   {
00020   private:
00021     metrics::Metrics metrics;
00022 
00023   protected:
00024     kv::Store* tables = nullptr;
00025 
00026   public:
00027     CommonEndpointRegistry(
00028       const std::string& method_prefix_,
00029       kv::Store& store,
00030       const std::string& certs_table_name = "",
00031       const std::string& digests_table_name = "") :
00032       EndpointRegistry(
00033         method_prefix_, store, certs_table_name, digests_table_name),
00034       tables(&store)
00035     {}
00036 
00037     void init_handlers(kv::Store& t) override
00038     {
00039       EndpointRegistry::init_handlers(t);
00040 
00041       auto get_commit = [this](auto&, nlohmann::json&&) {
00042         if (consensus != nullptr)
00043         {
00044           auto [view, seqno] = consensus->get_committed_txid();
00045           return make_success(GetCommit::Out{view, seqno});
00046         }
00047 
00048         return make_error(
00049           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00050           ccf::errors::InternalError,
00051           "Failed to get commit info from Consensus.");
00052       };
00053       make_command_endpoint(
00054         "commit", HTTP_GET, json_command_adapter(get_commit), no_auth_required)
00055         .set_execute_locally(true)
00056         .set_auto_schema<void, GetCommit::Out>()
00057         .install();
00058 
00059       auto get_tx_status = [this](auto&, nlohmann::json&& params) {
00060         const auto in = params.get<GetTxStatus::In>();
00061 
00062         if (consensus != nullptr)
00063         {
00064           const auto tx_view = consensus->get_view(in.seqno);
00065           const auto committed_seqno = consensus->get_committed_seqno();
00066           const auto committed_view = consensus->get_view(committed_seqno);
00067 
00068           GetTxStatus::Out out;
00069           out.status = ccf::get_tx_status(
00070             in.view, in.seqno, tx_view, committed_view, committed_seqno);
00071           return make_success(out);
00072         }
00073 
00074         return make_error(
00075           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00076           ccf::errors::InternalError,
00077           "Consensus is not yet configured.");
00078       };
00079       make_command_endpoint(
00080         "tx", HTTP_GET, json_command_adapter(get_tx_status), no_auth_required)
00081         .set_auto_schema<GetTxStatus>()
00082         .install();
00083 
00084       make_command_endpoint(
00085         "local_tx",
00086         HTTP_GET,
00087         json_command_adapter(get_tx_status),
00088         no_auth_required)
00089         .set_auto_schema<GetTxStatus>()
00090         .set_execute_locally(true)
00091         .install();
00092 
00093       auto get_metrics = [this](auto&, nlohmann::json&&) {
00094         auto result = metrics.get_metrics();
00095         return make_success(result);
00096       };
00097       make_command_endpoint(
00098         "metrics",
00099         HTTP_GET,
00100         json_command_adapter(get_metrics),
00101         no_auth_required)
00102         .set_auto_schema<void, GetMetrics::Out>()
00103         .set_execute_locally(true)
00104         .install();
00105 
00106       auto user_id = [this](auto& args, nlohmann::json&& params) {
00107         GetUserId::Out out;
00108 
00109         if (!params.is_null())
00110         {
00111           const GetUserId::In in = params;
00112           auto certs_view =
00113             args.tx.template get_read_only_view<CertDERs>(certs_table_name);
00114           std::vector<uint8_t> pem(in.cert.begin(), in.cert.end());
00115           std::vector<uint8_t> der = tls::make_verifier(pem)->der_cert_data();
00116           auto caller_id_opt = certs_view->get(der);
00117 
00118           if (!caller_id_opt.has_value())
00119           {
00120             return make_error(
00121               HTTP_STATUS_BAD_REQUEST,
00122               ccf::errors::UnknownCertificate,
00123               "Certificate not recognised.");
00124           }
00125 
00126           out.caller_id = caller_id_opt.value();
00127         }
00128         else if (
00129           auto user_cert_ident =
00130             args.template try_get_caller<ccf::UserCertAuthnIdentity>())
00131         {
00132           out.caller_id = user_cert_ident->user_id;
00133         }
00134         else if (
00135           auto member_cert_ident =
00136             args.template try_get_caller<ccf::MemberCertAuthnIdentity>())
00137         {
00138           out.caller_id = member_cert_ident->member_id;
00139         }
00140         else if (
00141           auto user_sig_ident =
00142             args.template try_get_caller<ccf::UserSignatureAuthnIdentity>())
00143         {
00144           out.caller_id = user_cert_ident->user_id;
00145         }
00146         else if (
00147           auto member_sig_ident =
00148             args.template try_get_caller<ccf::MemberSignatureAuthnIdentity>())
00149         {
00150           out.caller_id = member_cert_ident->member_id;
00151         }
00152 
00153         return make_success(out);
00154       };
00155       make_read_only_endpoint(
00156         "user_id",
00157         HTTP_GET,
00158         json_read_only_adapter(user_id),
00159         {user_cert_auth_policy,
00160          user_signature_auth_policy,
00161          member_cert_auth_policy,
00162          member_signature_auth_policy})
00163         .set_auto_schema<GetUserId::In, GetUserId::Out>()
00164         .install();
00165 
00166       auto get_primary_info = [this](auto& args, nlohmann::json&&) {
00167         if (consensus != nullptr)
00168         {
00169           NodeId primary_id = consensus->primary();
00170           auto current_view = consensus->get_view();
00171 
00172           auto nodes_view =
00173             args.tx.template get_read_only_view<Nodes>(Tables::NODES);
00174           auto info = nodes_view->get(primary_id);
00175 
00176           if (info)
00177           {
00178             GetPrimaryInfo::Out out;
00179             out.primary_id = primary_id;
00180             out.primary_host = info->pubhost;
00181             out.primary_port = info->pubport;
00182             out.current_view = current_view;
00183             return make_success(out);
00184           }
00185         }
00186 
00187         return make_error(
00188           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00189           ccf::errors::InternalError,
00190           "Primary unknown.");
00191       };
00192       make_read_only_endpoint(
00193         "primary_info",
00194         HTTP_GET,
00195         json_read_only_adapter(get_primary_info),
00196         no_auth_required)
00197         .set_auto_schema<void, GetPrimaryInfo::Out>()
00198         .install();
00199 
00200       auto get_network_info = [this](auto& args, nlohmann::json&&) {
00201         GetNetworkInfo::Out out;
00202         if (consensus != nullptr)
00203         {
00204           out.primary_id = consensus->primary();
00205         }
00206 
00207         auto nodes_view =
00208           args.tx.template get_read_only_view<Nodes>(Tables::NODES);
00209         nodes_view->foreach([&out](const NodeId& nid, const NodeInfo& ni) {
00210           if (ni.status == ccf::NodeStatus::TRUSTED)
00211           {
00212             out.nodes.push_back({nid, ni.pubhost, ni.pubport});
00213           }
00214           return true;
00215         });
00216 
00217         return make_success(out);
00218       };
00219       make_read_only_endpoint(
00220         "network_info",
00221         HTTP_GET,
00222         json_read_only_adapter(get_network_info),
00223         no_auth_required)
00224         .set_auto_schema<void, GetNetworkInfo::Out>()
00225         .install();
00226 
00227       auto get_code = [](auto& args, nlohmann::json&&) {
00228         GetCode::Out out;
00229 
00230         auto code_view =
00231           args.tx.template get_read_only_view<CodeIDs>(Tables::NODE_CODE_IDS);
00232         code_view->foreach(
00233           [&out](const ccf::CodeDigest& cd, const ccf::CodeStatus& cs) {
00234             auto digest = fmt::format("{:02x}", fmt::join(cd, ""));
00235             out.versions.push_back({digest, cs});
00236             return true;
00237           });
00238 
00239         return make_success(out);
00240       };
00241       make_read_only_endpoint(
00242         "code", HTTP_GET, json_read_only_adapter(get_code), no_auth_required)
00243         .set_auto_schema<void, GetCode::Out>()
00244         .install();
00245 
00246       auto get_nodes_by_rpc_address = [](auto& args, nlohmann::json&& params) {
00247         const auto in = params.get<GetNodesByRPCAddress::In>();
00248 
00249         GetNodesByRPCAddress::Out out;
00250         auto nodes_view =
00251           args.tx.template get_read_only_view<Nodes>(Tables::NODES);
00252         nodes_view->foreach([&in, &out](const NodeId& nid, const NodeInfo& ni) {
00253           if (ni.pubhost == in.host && ni.pubport == in.port)
00254           {
00255             if (ni.status != ccf::NodeStatus::RETIRED || in.retired)
00256             {
00257               out.nodes.push_back({nid, ni.status});
00258             }
00259           }
00260           return true;
00261         });
00262 
00263         return make_success(out);
00264       };
00265       make_read_only_endpoint(
00266         "node/ids",
00267         HTTP_GET,
00268         json_read_only_adapter(get_nodes_by_rpc_address),
00269         no_auth_required)
00270         .set_auto_schema<GetNodesByRPCAddress::In, GetNodesByRPCAddress::Out>()
00271         .install();
00272 
00273       auto openapi = [this](kv::Tx& tx, nlohmann::json&&) {
00274         auto document = ds::openapi::create_document(
00275           openapi_info.title,
00276           openapi_info.description,
00277           openapi_info.document_version);
00278         build_api(document, tx);
00279         return make_success(document);
00280       };
00281       make_endpoint("api", HTTP_GET, json_adapter(openapi), no_auth_required)
00282         .set_auto_schema<void, GetAPI::Out>()
00283         .install();
00284 
00285       auto endpoint_metrics_fn = [this](kv::Tx& tx, nlohmann::json&&) {
00286         EndpointMetrics::Out out;
00287         endpoint_metrics(tx, out);
00288 
00289         return make_success(out);
00290       };
00291       make_endpoint(
00292         "endpoint_metrics",
00293         HTTP_GET,
00294         json_adapter(endpoint_metrics_fn),
00295         no_auth_required)
00296         .set_auto_schema<void, EndpointMetrics::Out>()
00297         .install();
00298 
00299       auto get_receipt = [this](auto&, nlohmann::json&& params) {
00300         const auto in = params.get<GetReceipt::In>();
00301 
00302         if (history != nullptr)
00303         {
00304           try
00305           {
00306             auto p = history->get_receipt(in.commit);
00307             const GetReceipt::Out out{p};
00308 
00309             return make_success(out);
00310           }
00311           catch (const std::exception& e)
00312           {
00313             return make_error(
00314               HTTP_STATUS_INTERNAL_SERVER_ERROR,
00315               ccf::errors::InternalError,
00316               fmt::format(
00317                 "Unable to produce receipt for commit {} : {}.",
00318                 in.commit,
00319                 e.what()));
00320           }
00321         }
00322 
00323         return make_error(
00324           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00325           ccf::errors::InternalError,
00326           "Unable to produce receipt.");
00327       };
00328       make_command_endpoint(
00329         "receipt",
00330         HTTP_GET,
00331         json_command_adapter(get_receipt),
00332         no_auth_required)
00333         .set_auto_schema<GetReceipt>()
00334         .install();
00335 
00336       auto verify_receipt = [this](auto&, nlohmann::json&& params) {
00337         const auto in = params.get<VerifyReceipt::In>();
00338 
00339         if (history != nullptr)
00340         {
00341           try
00342           {
00343             bool v = history->verify_receipt(in.receipt);
00344             const VerifyReceipt::Out out{v};
00345 
00346             return make_success(out);
00347           }
00348           catch (const std::exception& e)
00349           {
00350             return make_error(
00351               HTTP_STATUS_BAD_REQUEST,
00352               ccf::errors::InvalidInput,
00353               fmt::format("Unable to verify receipt: {}", e.what()));
00354           }
00355         }
00356 
00357         return make_error(
00358           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00359           ccf::errors::InternalError,
00360           "Unable to verify receipt.");
00361       };
00362       make_command_endpoint(
00363         "receipt/verify",
00364         HTTP_POST,
00365         json_command_adapter(verify_receipt),
00366         no_auth_required)
00367         .set_auto_schema<VerifyReceipt>()
00368         .install();
00369     }
00370 
00371     void tick(
00372       std::chrono::milliseconds elapsed,
00373       kv::Consensus::Statistics stats) override
00374     {
00375       metrics.track_tx_rates(elapsed, stats);
00376 
00377       EndpointRegistry::tick(elapsed, stats);
00378     }
00379   };
00380 }
00381 
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/common_endpoint_registry.h...
Preprocessing /data/git/CCF/src/node/rpc/endpoint.h...
#include ds/json.h: not found! skipping...
#include http/authentication/authentication_types.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include string: not found! skipping...
#include utility: not found! skipping...
Preprocessor output (size: 3177 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   namespace endpoints
00015   {
00016     using URI = std::string;
00017 
00018     struct EndpointKey
00019     {
00020       URI uri_path;
00021       RESTVerb verb = HTTP_POST;
00022 
00023       MSGPACK_DEFINE(uri_path, verb);
00024     };
00025 
00026     DECLARE_JSON_TYPE(EndpointKey);
00027     DECLARE_JSON_REQUIRED_FIELDS(EndpointKey, uri_path, verb);
00028 
00029     enum class ForwardingRequired
00030     {
00031       Sometimes,
00032       Always,
00033       Never
00034     };
00035   }
00036 }
00037 
00038 MSGPACK_ADD_ENUM(ccf::endpoints::ForwardingRequired);
00039 
00040 namespace ccf
00041 {
00042   namespace endpoints
00043   {
00044     DECLARE_JSON_ENUM(
00045       ForwardingRequired,
00046       {{ForwardingRequired::Sometimes, "sometimes"},
00047        {ForwardingRequired::Always, "always"},
00048        {ForwardingRequired::Never, "never"}});
00049 
00050     using AuthnPolicies = std::vector<std::shared_ptr<AuthnPolicy>>;
00051 
00052     struct EndpointProperties
00053     {
00054       ForwardingRequired forwarding_required = ForwardingRequired::Always;
00055       bool execute_locally = false;
00056       bool require_client_signature = false;
00057       bool require_client_identity = true;
00058       bool require_jwt_authentication = false;
00059 
00060       nlohmann::json openapi;
00061       bool openapi_hidden = false;
00062 
00063       MSGPACK_DEFINE(
00064         forwarding_required,
00065         execute_locally,
00066         require_client_signature,
00067         require_client_identity,
00068         require_jwt_authentication,
00069         openapi,
00070         openapi_hidden);
00071     };
00072 
00073     DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(EndpointProperties);
00074     DECLARE_JSON_REQUIRED_FIELDS(
00075       EndpointProperties,
00076       forwarding_required,
00077       execute_locally,
00078       require_client_signature,
00079       require_client_identity);
00080     DECLARE_JSON_OPTIONAL_FIELDS(
00081       EndpointProperties, require_jwt_authentication, openapi, openapi_hidden);
00082 
00083     struct EndpointDefinition
00084     {
00085       virtual ~EndpointDefinition() = default;
00086 
00087       EndpointKey dispatch;
00088       EndpointProperties properties;
00089 
00090       /** List of authentication policies which will be checked before executing
00091        * this endpoint.
00092        *
00093        * When multiple policies are specified, any single successful check is
00094        * sufficient to grant access, even if others fail. If all policies fail,
00095        * the last will set an error status on the response, and the endpoint
00096        * will not be invoked. If no policies are specified then the default
00097        * behaviour is that the endpoint accepts all requests, without any
00098        * authentication checks.
00099        *
00100        * If an auth policy passes, it may construct an object describing the
00101        * Identity of the caller to be used by the endpoint. This can be
00102        * retrieved inside the endpoint with ctx.get_caller<IdentType>(),
00103        * @see ccf::UserCertAuthnIdentity
00104        * @see ccf::JwtAuthnIdentity
00105        * @see ccf::UserSignatureAuthnIdentity
00106        *
00107        * @see ccf::empty_auth_policy
00108        * @see ccf::user_cert_auth_policy
00109        * @see ccf::user_signature_auth_policy
00110        */
00111       AuthnPolicies authn_policies;
00112     };
00113 
00114     using EndpointDefinitionPtr = std::shared_ptr<const EndpointDefinition>;
00115 
00116     using EndpointsMap = kv::Map<EndpointKey, EndpointProperties>;
00117   }
00118 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/endpoint.h...
Preprocessing /data/git/CCF/src/node/rpc/endpoint_registry.h...
#include ds/ccf_deprecated.h: not found! skipping...
#include ds/json_schema.h: not found! skipping...
#include ds/openapi.h: not found! skipping...
#include enclave/rpc_context.h: not found! skipping...
#include endpoint.h: already included! skipping...
#include http/authentication/cert_auth.h: not found! skipping...
#include http/authentication/jwt_auth.h: not found! skipping...
#include http/authentication/sig_auth.h: not found! skipping...
#include http/http_consts.h: not found! skipping...
#include http/ws_consts.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/certs.h: not found! skipping...
#include serialization.h: already included! skipping...
#include functional: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include regex: not found! skipping...
#include set: not found! skipping...
Preprocessor output (size: 27342 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 namespace ccf
00027 {
00028   using namespace endpoints;
00029 
00030   // to be exposed in EndpointContext or similar
00031   struct Jwt
00032   {
00033     std::string key_issuer;
00034     nlohmann::json header;
00035     nlohmann::json payload;
00036   };
00037 
00038   // Commands are endpoints which do not interact with the kv, even to read
00039   struct CommandEndpointContext
00040   {
00041     CommandEndpointContext(
00042       const std::shared_ptr<enclave::RpcContext>& r,
00043       std::unique_ptr<AuthnIdentity>&& c) :
00044       rpc_ctx(r),
00045       caller(std::move(c))
00046     {}
00047 
00048     std::shared_ptr<enclave::RpcContext> rpc_ctx;
00049     std::unique_ptr<AuthnIdentity> caller;
00050 
00051     template <typename T>
00052     const T* try_get_caller()
00053     {
00054       return dynamic_cast<const T*>(caller.get());
00055     }
00056 
00057     template <typename T>
00058     const T& get_caller()
00059     {
00060       const T* ident = try_get_caller<T>();
00061       if (ident == nullptr)
00062       {
00063         throw std::logic_error("Asked for unprovided identity type");
00064       }
00065       return *ident;
00066     }
00067   };
00068   using CommandEndpointFunction =
00069     std::function<void(CommandEndpointContext& args)>;
00070 
00071   struct EndpointContext : public CommandEndpointContext
00072   {
00073     EndpointContext(
00074       const std::shared_ptr<enclave::RpcContext>& r,
00075       std::unique_ptr<AuthnIdentity>&& c,
00076       kv::Tx& t) :
00077       CommandEndpointContext(r, std::move(c)),
00078       tx(t)
00079     {}
00080 
00081     kv::Tx& tx;
00082   };
00083   using EndpointFunction = std::function<void(EndpointContext& args)>;
00084 
00085   // Read-only endpoints can only get values from the kv, they cannot write
00086   struct ReadOnlyEndpointContext : public CommandEndpointContext
00087   {
00088     ReadOnlyEndpointContext(
00089       const std::shared_ptr<enclave::RpcContext>& r,
00090       std::unique_ptr<AuthnIdentity>&& c,
00091       kv::ReadOnlyTx& t) :
00092       CommandEndpointContext(r, std::move(c)),
00093       tx(t)
00094     {}
00095 
00096     kv::ReadOnlyTx& tx;
00097   };
00098   using ReadOnlyEndpointFunction =
00099     std::function<void(ReadOnlyEndpointContext& args)>;
00100 
00101   // Auth policies
00102   /** Perform no authentication */
00103   static std::shared_ptr<EmptyAuthnPolicy> empty_auth_policy =
00104     std::make_shared<EmptyAuthnPolicy>();
00105   /** Authenticate using TLS session identity, and @c public:ccf.gov.users
00106    * table */
00107   static std::shared_ptr<UserCertAuthnPolicy> user_cert_auth_policy =
00108     std::make_shared<UserCertAuthnPolicy>();
00109   /** Authenticate using HTTP request signature, and @c public:ccf.gov.users
00110    * table */
00111   static std::shared_ptr<UserSignatureAuthnPolicy> user_signature_auth_policy =
00112     std::make_shared<UserSignatureAuthnPolicy>();
00113   /** Authenticate using TLS session identity, and @c public:ccf.gov.members
00114    * table */
00115   static std::shared_ptr<MemberCertAuthnPolicy> member_cert_auth_policy =
00116     std::make_shared<MemberCertAuthnPolicy>();
00117   /** Authenticate using HTTP request signature, and @c public:ccf.gov.members
00118    * table */
00119   static std::shared_ptr<MemberSignatureAuthnPolicy>
00120     member_signature_auth_policy =
00121       std::make_shared<MemberSignatureAuthnPolicy>();
00122   /** Authenticate using JWT, validating the token using the
00123    * @c public:ccf.gov.jwt_public_signing_key_issue and
00124    * @c public:ccf.gov.jwt_public_signing_keys tables */
00125   static std::shared_ptr<JwtAuthnPolicy> jwt_auth_policy =
00126     std::make_shared<JwtAuthnPolicy>();
00127 
00128   static AuthnPolicies no_auth_required = {};
00129 
00130   /** The EndpointRegistry records the user-defined endpoints for a given
00131    * CCF application.
00132    */
00133   class EndpointRegistry
00134   {
00135   public:
00136     enum ReadWrite
00137     {
00138       Read,
00139       Write
00140     };
00141 
00142     const std::string method_prefix;
00143 
00144     struct OpenApiInfo
00145     {
00146       std::string title = "Empty title";
00147       std::string description = "Empty description";
00148       std::string document_version = "0.0.1";
00149     } openapi_info;
00150 
00151     struct Metrics
00152     {
00153       size_t calls = 0;
00154       size_t errors = 0;
00155       size_t failures = 0;
00156     };
00157 
00158     struct Endpoint;
00159     using EndpointPtr = std::shared_ptr<const Endpoint>;
00160 
00161     using SchemaBuilderFn =
00162       std::function<void(nlohmann::json&, const EndpointPtr&)>;
00163 
00164     /** An Endpoint represents a user-defined resource that can be invoked by
00165      * authorised users via HTTP requests, over TLS. An Endpoint is accessible
00166      * at a specific verb and URI, e.g. POST /app/accounts or GET /app/records.
00167      *
00168      * Endpoints can read from and mutate the state of the replicated key-value
00169      * store.
00170      *
00171      * A CCF application is a collection of Endpoints recorded in the
00172      * application's EndpointRegistry.
00173      */
00174     struct Endpoint : public EndpointDefinition
00175     {
00176       EndpointFunction func = {};
00177       EndpointRegistry* registry = nullptr;
00178 
00179       std::vector<SchemaBuilderFn> schema_builders = {};
00180 
00181       bool openapi_hidden = false;
00182 
00183       /** Whether the endpoint should be omitted from the OpenAPI document.
00184        *
00185        * @return This Endpoint for further modification
00186        */
00187       Endpoint& set_openapi_hidden(bool hidden)
00188       {
00189         openapi_hidden = hidden;
00190         return *this;
00191       }
00192 
00193       nlohmann::json params_schema = nullptr;
00194 
00195       /** Sets the JSON schema that the request parameters must comply with.
00196        *
00197        * @param j Request parameters JSON schema
00198        * @return This Endpoint for further modification
00199        */
00200       Endpoint& set_params_schema(const nlohmann::json& j)
00201       {
00202         params_schema = j;
00203 
00204         schema_builders.push_back([](
00205                                     nlohmann::json& document,
00206                                     const EndpointPtr& endpoint) {
00207           const auto http_verb = endpoint->dispatch.verb.get_http_method();
00208           if (!http_verb.has_value())
00209           {
00210             return;
00211           }
00212 
00213           using namespace ds::openapi;
00214 
00215           if (http_verb.value() == HTTP_GET || http_verb.value() == HTTP_DELETE)
00216           {
00217             add_query_parameters(
00218               document,
00219               endpoint->dispatch.uri_path,
00220               endpoint->params_schema,
00221               http_verb.value());
00222           }
00223           else
00224           {
00225             auto& rb = request_body(path_operation(
00226               ds::openapi::path(document, endpoint->dispatch.uri_path),
00227               http_verb.value()));
00228             schema(media_type(rb, http::headervalues::contenttype::JSON)) =
00229               endpoint->params_schema;
00230           }
00231         });
00232 
00233         return *this;
00234       }
00235 
00236       nlohmann::json result_schema = nullptr;
00237 
00238       /** Sets the JSON schema that the request response must comply with.
00239        *
00240        * @param j Request response JSON schema
00241        * @return This Endpoint for further modification
00242        */
00243       Endpoint& set_result_schema(const nlohmann::json& j)
00244       {
00245         result_schema = j;
00246 
00247         schema_builders.push_back(
00248           [j](nlohmann::json& document, const EndpointPtr& endpoint) {
00249             const auto http_verb = endpoint->dispatch.verb.get_http_method();
00250             if (!http_verb.has_value())
00251             {
00252               return;
00253             }
00254 
00255             using namespace ds::openapi;
00256             auto& r = response(
00257               path_operation(
00258                 ds::openapi::path(document, endpoint->dispatch.uri_path),
00259                 http_verb.value()),
00260               HTTP_STATUS_OK);
00261 
00262             if (endpoint->result_schema != nullptr)
00263             {
00264               schema(media_type(r, http::headervalues::contenttype::JSON)) =
00265                 endpoint->result_schema;
00266             }
00267           });
00268 
00269         return *this;
00270       }
00271 
00272       /** Sets the schema that the request parameters and response must comply
00273        * with based on JSON-serialisable data structures.
00274        *
00275        * \verbatim embed:rst:leading-asterisk
00276        * .. note::
00277        *  See ``DECLARE_JSON_`` serialisation macros for serialising
00278        *  user-defined data structures.
00279        * \endverbatim
00280        *
00281        * @tparam In Request parameters JSON-serialisable data structure
00282        * @tparam Out Request response JSON-serialisable data structure
00283        * @return This Endpoint for further modification
00284        */
00285       template <typename In, typename Out>
00286       Endpoint& set_auto_schema()
00287       {
00288         if constexpr (!std::is_same_v<In, void>)
00289         {
00290           params_schema =
00291             ds::json::build_schema<In>(dispatch.uri_path + "/params");
00292 
00293           schema_builders.push_back(
00294             [](nlohmann::json& document, const EndpointPtr& endpoint) {
00295               const auto http_verb = endpoint->dispatch.verb.get_http_method();
00296               if (!http_verb.has_value())
00297               {
00298                 // Non-HTTP (ie WebSockets) endpoints are not documented
00299                 return;
00300               }
00301 
00302               if (
00303                 http_verb.value() == HTTP_GET ||
00304                 http_verb.value() == HTTP_DELETE)
00305               {
00306                 add_query_parameters(
00307                   document,
00308                   endpoint->dispatch.uri_path,
00309                   endpoint->params_schema,
00310                   http_verb.value());
00311               }
00312               else
00313               {
00314                 ds::openapi::add_request_body_schema<In>(
00315                   document,
00316                   endpoint->dispatch.uri_path,
00317                   http_verb.value(),
00318                   http::headervalues::contenttype::JSON);
00319               }
00320             });
00321         }
00322         else
00323         {
00324           params_schema = nullptr;
00325         }
00326 
00327         if constexpr (!std::is_same_v<Out, void>)
00328         {
00329           result_schema =
00330             ds::json::build_schema<Out>(dispatch.uri_path + "/result");
00331 
00332           schema_builders.push_back(
00333             [](nlohmann::json& document, const EndpointPtr& endpoint) {
00334               const auto http_verb = endpoint->dispatch.verb.get_http_method();
00335               if (!http_verb.has_value())
00336               {
00337                 return;
00338               }
00339 
00340               ds::openapi::add_response_schema<Out>(
00341                 document,
00342                 endpoint->dispatch.uri_path,
00343                 http_verb.value(),
00344                 HTTP_STATUS_OK,
00345                 http::headervalues::contenttype::JSON);
00346             });
00347         }
00348         else
00349         {
00350           result_schema = nullptr;
00351         }
00352 
00353         return *this;
00354       }
00355 
00356       /** Sets the schema that the request parameters and response must comply
00357        * with, based on a single JSON-serialisable data structure.
00358        *
00359        * \verbatim embed:rst:leading-asterisk
00360        * .. note::
00361        *   ``T`` data structure should contain two nested ``In`` and ``Out``
00362        *   structures for request parameters and response format, respectively.
00363        * \endverbatim
00364        *
00365        * @tparam T Request parameters and response JSON-serialisable data
00366        * structure
00367        * @return This Endpoint for further modification
00368        */
00369       template <typename T>
00370       Endpoint& set_auto_schema()
00371       {
00372         return set_auto_schema<typename T::In, typename T::Out>();
00373       }
00374 
00375       /** Overrides whether a Endpoint is always forwarded, or whether it is
00376        * safe to sometimes execute on followers.
00377        *
00378        * @param fr Enum value with desired status
00379        * @return This Endpoint for further modification
00380        */
00381       Endpoint& set_forwarding_required(ForwardingRequired fr)
00382       {
00383         properties.forwarding_required = fr;
00384         return *this;
00385       }
00386 
00387       /** Indicates that the execution of the Endpoint does not require
00388        * consensus from other nodes in the network.
00389        *
00390        * By default, endpoints are not executed locally.
00391        *
00392        * \verbatim embed:rst:leading-asterisk
00393        * .. warning::
00394        *  Use with caution. This should only be used for non-critical endpoints
00395        *  that do not read or mutate the state of the key-value store.
00396        * \endverbatim
00397        *
00398        * @param v Boolean indicating whether the Endpoint is executed locally,
00399        * on the node receiving the request
00400        * @return This Endpoint for further modification
00401        */
00402       Endpoint& set_execute_locally(bool v)
00403       {
00404         properties.execute_locally = v;
00405         return *this;
00406       }
00407 
00408       /** Finalise and install this endpoint
00409        */
00410       void install()
00411       {
00412         if (registry == nullptr)
00413         {
00414           LOG_FATAL_FMT(
00415             "Can't install this endpoint ({}) - it is not associated with a "
00416             "registry",
00417             dispatch.uri_path);
00418         }
00419         else
00420         {
00421           registry->install(*this);
00422         }
00423       }
00424     };
00425 
00426     struct PathTemplateSpec
00427     {
00428       std::regex template_regex;
00429       std::vector<std::string> template_component_names;
00430     };
00431 
00432     struct PathTemplatedEndpoint : public Endpoint
00433     {
00434       PathTemplatedEndpoint(const Endpoint& e) : Endpoint(e) {}
00435 
00436       PathTemplateSpec spec;
00437     };
00438 
00439     static std::optional<PathTemplateSpec> parse_path_template(
00440       const std::string& uri)
00441     {
00442       auto template_start = uri.find_first_of('{');
00443       if (template_start == std::string::npos)
00444       {
00445         return std::nullopt;
00446       }
00447 
00448       PathTemplateSpec spec;
00449 
00450       std::string regex_s = uri;
00451       template_start = regex_s.find_first_of('{');
00452       while (template_start != std::string::npos)
00453       {
00454         const auto template_end = regex_s.find_first_of('}', template_start);
00455         if (template_end == std::string::npos)
00456         {
00457           throw std::logic_error(fmt::format(
00458             "Invalid templated path - missing closing '}': {}", uri));
00459         }
00460 
00461         spec.template_component_names.push_back(regex_s.substr(
00462           template_start + 1, template_end - template_start - 1));
00463         regex_s.replace(
00464           template_start, template_end - template_start + 1, "([^/]+)");
00465         template_start = regex_s.find_first_of('{', template_start + 1);
00466       }
00467 
00468       LOG_TRACE_FMT("Parsed a templated endpoint: {} became {}", uri, regex_s);
00469       LOG_TRACE_FMT(
00470         "Component names are: {}",
00471         fmt::join(spec.template_component_names, ", "));
00472       spec.template_regex = std::regex(regex_s);
00473 
00474       return spec;
00475     }
00476 
00477   protected:
00478     EndpointPtr default_endpoint;
00479     std::map<std::string, std::map<RESTVerb, EndpointPtr>>
00480       fully_qualified_endpoints;
00481     std::map<
00482       std::string,
00483       std::map<RESTVerb, std::shared_ptr<PathTemplatedEndpoint>>>
00484       templated_endpoints;
00485 
00486     std::map<std::string, std::map<std::string, Metrics>> metrics;
00487 
00488     kv::Consensus* consensus = nullptr;
00489     kv::TxHistory* history = nullptr;
00490 
00491     std::string certs_table_name;
00492     std::string digests_table_name;
00493 
00494     static void add_query_parameters(
00495       nlohmann::json& document,
00496       const std::string& uri,
00497       const nlohmann::json& schema,
00498       llhttp_method verb)
00499     {
00500       if (schema["type"] != "object")
00501       {
00502         throw std::logic_error(
00503           fmt::format("Unexpected params schema type: {}", schema.dump()));
00504       }
00505 
00506       const auto& required_parameters = schema["required"];
00507       for (const auto& [name, schema] : schema["properties"].items())
00508       {
00509         auto parameter = nlohmann::json::object();
00510         parameter["name"] = name;
00511         parameter["in"] = "query";
00512         parameter["required"] =
00513           required_parameters.find(name) != required_parameters.end();
00514         parameter["schema"] = schema;
00515         ds::openapi::add_request_parameter_schema(
00516           document, uri, verb, parameter);
00517       }
00518     }
00519 
00520   public:
00521     EndpointRegistry(
00522       const std::string& method_prefix_,
00523       kv::Store&,
00524       const std::string& certs_table_name_ = "",
00525       const std::string& digests_table_name_ = "") :
00526       method_prefix(method_prefix_),
00527       certs_table_name(certs_table_name_),
00528       digests_table_name(digests_table_name_)
00529     {}
00530 
00531     virtual ~EndpointRegistry() {}
00532 
00533     /** Create a new endpoint.
00534      *
00535      * Caller should set any additional properties on the returned Endpoint
00536      * object, and finally call Endpoint::install() to install it.
00537      *
00538      * @param method The URI at which this endpoint will be installed
00539      * @param verb The HTTP verb which this endpoint will respond to
00540      * @param f Functor which will be invoked for requests to VERB /method
00541      * @param ap Policies which will be checked against each request before the
00542      * endpoint is executed. @see
00543      * ccf::endpoints::EndpointDefinition::authn_policies
00544      * @return The new Endpoint for further modification
00545      */
00546     Endpoint make_endpoint(
00547       const std::string& method,
00548       RESTVerb verb,
00549       const EndpointFunction& f,
00550       const AuthnPolicies& ap)
00551     {
00552       Endpoint endpoint;
00553       endpoint.dispatch.uri_path = method;
00554       endpoint.dispatch.verb = verb;
00555       endpoint.func = f;
00556       endpoint.authn_policies = ap;
00557       // By default, all write transactions are forwarded
00558       endpoint.properties.forwarding_required = ForwardingRequired::Always;
00559       endpoint.registry = this;
00560       return endpoint;
00561     }
00562 
00563     /** Create a read-only endpoint.
00564      */
00565     Endpoint make_read_only_endpoint(
00566       const std::string& method,
00567       RESTVerb verb,
00568       const ReadOnlyEndpointFunction& f,
00569       const AuthnPolicies& ap)
00570     {
00571       return make_endpoint(
00572                method,
00573                verb,
00574                [f](EndpointContext& args) {
00575                  ReadOnlyEndpointContext ro_args(
00576                    args.rpc_ctx, std::move(args.caller), args.tx);
00577                  f(ro_args);
00578                },
00579                ap)
00580         .set_forwarding_required(ForwardingRequired::Sometimes);
00581     }
00582 
00583     /** Create a new command endpoint.
00584      *
00585      * Commands are endpoints which do not read or write from the KV. See
00586      * make_endpoint().
00587      */
00588     Endpoint make_command_endpoint(
00589       const std::string& method,
00590       RESTVerb verb,
00591       const CommandEndpointFunction& f,
00592       const AuthnPolicies& ap)
00593     {
00594       return make_endpoint(
00595                method, verb, [f](EndpointContext& args) { f(args); }, ap)
00596         .set_forwarding_required(ForwardingRequired::Sometimes);
00597     }
00598 
00599     /** Install the given endpoint, using its method and verb
00600      *
00601      * If an implementation is already installed for this method and verb, it
00602      * will be replaced.
00603      * @param endpoint Endpoint object describing the new resource to install
00604      */
00605     void install(Endpoint& endpoint)
00606     {
00607       // A single empty auth policy is semantically equivalent to no policy, but
00608       // no policy is faster
00609       if (
00610         endpoint.authn_policies.size() == 1 &&
00611         endpoint.authn_policies.back() == empty_auth_policy)
00612       {
00613         endpoint.authn_policies.pop_back();
00614       }
00615 
00616       const auto template_spec =
00617         parse_path_template(endpoint.dispatch.uri_path);
00618       if (template_spec.has_value())
00619       {
00620         auto templated_endpoint =
00621           std::make_shared<PathTemplatedEndpoint>(endpoint);
00622         templated_endpoint->spec = std::move(template_spec.value());
00623         templated_endpoints[endpoint.dispatch.uri_path]
00624                            [endpoint.dispatch.verb] = templated_endpoint;
00625       }
00626       else
00627       {
00628         fully_qualified_endpoints[endpoint.dispatch.uri_path]
00629                                  [endpoint.dispatch.verb] =
00630                                    std::make_shared<Endpoint>(endpoint);
00631       }
00632     }
00633 
00634     /** Set a default EndpointFunction
00635      *
00636      * The default EndpointFunction is only invoked if no specific
00637      * EndpointFunction was found.
00638      *
00639      * @param f Method implementation
00640      */
00641     void set_default(EndpointFunction f, const AuthnPolicies& ap)
00642     {
00643       auto tmp = std::make_shared<Endpoint>();
00644       tmp->func = f;
00645       tmp->authn_policies = ap;
00646 
00647       default_endpoint = std::move(tmp);
00648     }
00649 
00650     static void add_endpoint_to_api_document(
00651       nlohmann::json& document, const EndpointPtr& endpoint)
00652     {
00653       if (endpoint->schema_builders.empty())
00654       {
00655         // If we have no more specific schema information, make sure the
00656         // endpoint is still minimally documented (NB: this claims the endpoint
00657         // will sometimes return a 200 status code, which may not be true!)
00658         const auto http_verb = endpoint->dispatch.verb.get_http_method();
00659         if (!http_verb.has_value())
00660         {
00661           return;
00662         }
00663 
00664         ds::openapi::response(
00665           ds::openapi::path_operation(
00666             ds::openapi::path(document, endpoint->dispatch.uri_path),
00667             http_verb.value()),
00668           HTTP_STATUS_OK);
00669       }
00670       else
00671       {
00672         for (const auto& builder_fn : endpoint->schema_builders)
00673         {
00674           builder_fn(document, endpoint);
00675         }
00676       }
00677     }
00678 
00679     /** Populate document with all supported methods
00680      *
00681      * This is virtual since derived classes may do their own dispatch
00682      * internally, so must be able to populate the document
00683      * with the supported endpoints however it defines them.
00684      */
00685     virtual void build_api(nlohmann::json& document, kv::Tx&)
00686     {
00687       ds::openapi::server(document, fmt::format("/{}", method_prefix));
00688 
00689       for (const auto& [path, verb_endpoints] : fully_qualified_endpoints)
00690       {
00691         for (const auto& [verb, endpoint] : verb_endpoints)
00692         {
00693           if (endpoint->openapi_hidden)
00694             continue;
00695           add_endpoint_to_api_document(document, endpoint);
00696         }
00697       }
00698 
00699       for (const auto& [path, verb_endpoints] : templated_endpoints)
00700       {
00701         for (const auto& [verb, endpoint] : verb_endpoints)
00702         {
00703           if (endpoint->openapi_hidden)
00704             continue;
00705           add_endpoint_to_api_document(document, endpoint);
00706 
00707           for (const auto& name : endpoint->spec.template_component_names)
00708           {
00709             auto parameter = nlohmann::json::object();
00710             parameter["name"] = name;
00711             parameter["in"] = "path";
00712             parameter["required"] = true;
00713             parameter["schema"] = {{"type", "string"}};
00714             ds::openapi::add_path_parameter_schema(
00715               document, endpoint->dispatch.uri_path, parameter);
00716           }
00717         }
00718       }
00719     }
00720 
00721     virtual void endpoint_metrics(kv::Tx&, EndpointMetrics::Out& out)
00722     {
00723       for (const auto& [path, verb_metrics] : metrics)
00724       {
00725         for (const auto& [verb, metric] : verb_metrics)
00726         {
00727           std::string v(verb.c_str());
00728           out.metrics[path][v] = {metric.calls, metric.errors, metric.failures};
00729         }
00730       }
00731     }
00732 
00733     Metrics& get_metrics(const EndpointDefinitionPtr& e)
00734     {
00735       return metrics[e->dispatch.uri_path][e->dispatch.verb.c_str()];
00736     }
00737 
00738     virtual void init_handlers(kv::Store&) {}
00739 
00740     virtual EndpointDefinitionPtr find_endpoint(
00741       kv::Tx&, enclave::RpcContext& rpc_ctx)
00742     {
00743       auto method = rpc_ctx.get_method();
00744       method = method.substr(method.find_first_not_of('/'));
00745 
00746       auto endpoints_for_exact_method = fully_qualified_endpoints.find(method);
00747       if (endpoints_for_exact_method != fully_qualified_endpoints.end())
00748       {
00749         auto& verb_endpoints = endpoints_for_exact_method->second;
00750         auto endpoints_for_verb =
00751           verb_endpoints.find(rpc_ctx.get_request_verb());
00752         if (endpoints_for_verb != verb_endpoints.end())
00753         {
00754           return endpoints_for_verb->second;
00755         }
00756       }
00757 
00758       // If that doesn't exist, look through the templated endpoints to find
00759       // templated matches. Exactly one is a returnable match, more is an error,
00760       // fewer is fallthrough.
00761       {
00762         std::vector<EndpointDefinitionPtr> matches;
00763 
00764         std::smatch match;
00765         for (auto& [original_method, verb_endpoints] : templated_endpoints)
00766         {
00767           auto templated_endpoints_for_verb =
00768             verb_endpoints.find(rpc_ctx.get_request_verb());
00769           if (templated_endpoints_for_verb != verb_endpoints.end())
00770           {
00771             auto& endpoint = templated_endpoints_for_verb->second;
00772             if (std::regex_match(method, match, endpoint->spec.template_regex))
00773             {
00774               // Populate the request_path_params the first-time through. If we
00775               // get a second match, we're just building up a list for
00776               // error-reporting
00777               if (matches.size() == 0)
00778               {
00779                 auto& path_params = rpc_ctx.get_request_path_params();
00780                 for (size_t i = 0;
00781                      i < endpoint->spec.template_component_names.size();
00782                      ++i)
00783                 {
00784                   const auto& template_name =
00785                     endpoint->spec.template_component_names[i];
00786                   const auto& template_value = match[i + 1].str();
00787                   path_params[template_name] = template_value;
00788                 }
00789               }
00790 
00791               matches.push_back(endpoint);
00792             }
00793           }
00794         }
00795 
00796         if (matches.size() > 1)
00797         {
00798           report_ambiguous_templated_path(method, matches);
00799         }
00800         else if (matches.size() == 1)
00801         {
00802           return matches[0];
00803         }
00804       }
00805 
00806       if (default_endpoint != nullptr)
00807       {
00808         return default_endpoint;
00809       }
00810 
00811       return nullptr;
00812     }
00813 
00814     virtual void execute_endpoint(
00815       EndpointDefinitionPtr e, EndpointContext& args)
00816     {
00817       auto endpoint = dynamic_cast<const Endpoint*>(e.get());
00818       if (endpoint == nullptr)
00819       {
00820         throw std::logic_error(
00821           "Base execute_endpoint called on incorrect Endpoint type - expected "
00822           "derived implementation to handle derived endpoint instances");
00823       }
00824 
00825       endpoint->func(args);
00826     }
00827 
00828     virtual std::set<RESTVerb> get_allowed_verbs(
00829       const enclave::RpcContext& rpc_ctx)
00830     {
00831       auto method = rpc_ctx.get_method();
00832       method = method.substr(method.find_first_not_of('/'));
00833 
00834       std::set<RESTVerb> verbs;
00835 
00836       auto search = fully_qualified_endpoints.find(method);
00837       if (search != fully_qualified_endpoints.end())
00838       {
00839         for (const auto& [verb, endpoint] : search->second)
00840         {
00841           verbs.insert(verb);
00842         }
00843       }
00844 
00845       std::smatch match;
00846       for (const auto& [original_method, verb_endpoints] : templated_endpoints)
00847       {
00848         for (const auto& [verb, endpoint] : verb_endpoints)
00849         {
00850           if (std::regex_match(method, match, endpoint->spec.template_regex))
00851           {
00852             verbs.insert(verb);
00853           }
00854         }
00855       }
00856 
00857       return verbs;
00858     }
00859 
00860     virtual void report_ambiguous_templated_path(
00861       const std::string& path,
00862       const std::vector<EndpointDefinitionPtr>& matches)
00863     {
00864       // Log low-information error
00865       LOG_FAIL_FMT(
00866         "Found multiple potential templated matches for request path");
00867 
00868       auto error_string =
00869         fmt::format("Multiple potential matches for path: {}", path);
00870       for (const auto& match : matches)
00871       {
00872         error_string += fmt::format("\n  {}", match->dispatch.uri_path);
00873       }
00874       LOG_DEBUG_FMT("{}", error_string);
00875 
00876       // Assume this exception is caught and reported in a useful fashion.
00877       // There's probably nothing the caller can do, ideally this ambiguity
00878       // would be caught when the endpoints were defined.
00879       throw std::logic_error(error_string);
00880     }
00881 
00882     virtual void tick(std::chrono::milliseconds, kv::Consensus::Statistics) {}
00883 
00884     bool has_digests()
00885     {
00886       return !digests_table_name.empty();
00887     }
00888 
00889     void set_consensus(kv::Consensus* c)
00890     {
00891       consensus = c;
00892     }
00893 
00894     void set_history(kv::TxHistory* h)
00895     {
00896       history = h;
00897     }
00898   };
00899 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/endpoint_registry.h...
Preprocessing /data/git/CCF/src/node/rpc/error.h...
#include ds/json.h: not found! skipping...
#include http/http_status.h: not found! skipping...
Preprocessor output (size: 870 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace ccf
00009 {
00010   struct ODataError
00011   {
00012     std::string code;
00013     std::string message;
00014   };
00015 
00016   DECLARE_JSON_TYPE(ODataError);
00017   DECLARE_JSON_REQUIRED_FIELDS(ODataError, code, message);
00018 
00019   struct ODataErrorResponse
00020   {
00021     ODataError error;
00022   };
00023 
00024   DECLARE_JSON_TYPE(ODataErrorResponse);
00025   DECLARE_JSON_REQUIRED_FIELDS(ODataErrorResponse, error);
00026 
00027   struct ErrorDetails
00028   {
00029     http_status status;
00030     std::string code;
00031     std::string msg;
00032   };
00033 
00034   namespace errors
00035   {
00036 #define ERROR(code) 
00037 
00038     // For inspiration, see:
00039     // https://docs.microsoft.com/en-us/rest/api/storageservices/common-rest-api-error-codes
00040 
00041     // Generic errors
00042 
00043 
00044 
00045 
00046 
00047 
00048 
00049 
00050 
00051 
00052 
00053 
00054 
00055     // CCF-specific errors
00056     // client-facing:
00057 
00058 
00059 
00060 
00061 
00062 
00063 
00064 
00065 
00066 
00067 
00068 
00069     // node-to-node (/join and /create):
00070 
00071 
00072 
00073 
00074 
00075 
00076   }
00077 }
---------
Macros accessible in this file:
---------
ERROR 
---------
Parsing file /data/git/CCF/src/node/rpc/error.h...
Preprocessing /data/git/CCF/src/node/rpc/forwarder.h...
#include enclave/forwarder_types.h: not found! skipping...
#include enclave/rpc_map.h: not found! skipping...
#include http/http_rpc_context.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/node_to_node.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
Preprocessor output (size: 10274 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   class ForwardedRpcHandler
00015   {
00016   public:
00017     virtual ~ForwardedRpcHandler() {}
00018 
00019     virtual std::vector<uint8_t> process_forwarded(
00020       std::shared_ptr<enclave::RpcContext> fwd_ctx) = 0;
00021   };
00022 
00023   template <typename ChannelProxy>
00024   class Forwarder : public enclave::AbstractForwarder
00025   {
00026   private:
00027     std::shared_ptr<enclave::AbstractRPCResponder> rpcresponder;
00028     std::shared_ptr<ChannelProxy> n2n_channels;
00029     std::shared_ptr<enclave::RPCMap> rpc_map;
00030     std::shared_ptr<aft::RequestTracker> request_tracker;
00031     ConsensusType consensus_type;
00032     NodeId self;
00033 
00034     using IsCallerCertForwarded = bool;
00035 
00036   public:
00037     Forwarder(
00038       std::shared_ptr<enclave::AbstractRPCResponder> rpcresponder,
00039       std::shared_ptr<ChannelProxy> n2n_channels,
00040       std::shared_ptr<enclave::RPCMap> rpc_map_,
00041       ConsensusType consensus_type_) :
00042       rpcresponder(rpcresponder),
00043       n2n_channels(n2n_channels),
00044       rpc_map(rpc_map_),
00045       consensus_type(consensus_type_)
00046     {}
00047 
00048     void initialize(NodeId self_)
00049     {
00050       self = self_;
00051     }
00052 
00053     void set_request_tracker(
00054       std::shared_ptr<aft::RequestTracker> request_tracker_)
00055     {
00056       request_tracker = request_tracker_;
00057     }
00058 
00059     bool forward_command(
00060       std::shared_ptr<enclave::RpcContext> rpc_ctx,
00061       NodeId to,
00062       std::set<NodeId> nodes,
00063       const std::vector<uint8_t>& caller_cert)
00064     {
00065       IsCallerCertForwarded include_caller = false;
00066       const auto method = rpc_ctx->get_method();
00067       const auto& raw_request = rpc_ctx->get_serialised_request();
00068       size_t size = sizeof(rpc_ctx->session->client_session_id) +
00069         sizeof(IsCallerCertForwarded) + raw_request.size();
00070       if (!caller_cert.empty())
00071       {
00072         size += sizeof(size_t) + caller_cert.size();
00073         include_caller = true;
00074       }
00075 
00076       std::vector<uint8_t> plain(size);
00077       auto data_ = plain.data();
00078       auto size_ = plain.size();
00079       serialized::write(data_, size_, rpc_ctx->session->client_session_id);
00080       serialized::write(data_, size_, include_caller);
00081       if (include_caller)
00082       {
00083         serialized::write(data_, size_, caller_cert.size());
00084         serialized::write(data_, size_, caller_cert.data(), caller_cert.size());
00085       }
00086       serialized::write(data_, size_, raw_request.data(), raw_request.size());
00087 
00088       ForwardedHeader msg = {
00089         ForwardedMsg::forwarded_cmd, self, rpc_ctx->frame_format()};
00090 
00091       if (consensus_type == ConsensusType::BFT)
00092       {
00093         send_request_hash_to_nodes(rpc_ctx, nodes, to);
00094       }
00095 
00096       return n2n_channels->send_encrypted(
00097         NodeMsgType::forwarded_msg, to, plain, msg);
00098     }
00099 
00100     void send_request_hash_to_nodes(
00101       std::shared_ptr<enclave::RpcContext> rpc_ctx,
00102       std::set<NodeId> nodes,
00103       NodeId skip_node)
00104     {
00105       const auto& raw_request = rpc_ctx->get_serialised_request();
00106       auto data_ = raw_request.data();
00107       auto size_ = raw_request.size();
00108 
00109       MessageHash msg(ForwardedMsg::request_hash, self);
00110       tls::do_hash(data_, size_, msg.hash.h, MBEDTLS_MD_SHA256);
00111 
00112       for (auto to : nodes)
00113       {
00114         if (self != to && skip_node != to)
00115         {
00116           n2n_channels->send_authenticated(NodeMsgType::forwarded_msg, to, msg);
00117         }
00118       }
00119 
00120       request_tracker->insert(
00121         msg.hash,
00122         threading::ThreadMessaging::thread_messaging.get_current_time_offset());
00123     }
00124 
00125     std::optional<std::tuple<std::shared_ptr<enclave::RpcContext>, NodeId>>
00126     recv_forwarded_command(const uint8_t* data, size_t size)
00127     {
00128       std::pair<ForwardedHeader, std::vector<uint8_t>> r;
00129       try
00130       {
00131         r = n2n_channels->template recv_encrypted<ForwardedHeader>(data, size);
00132       }
00133       catch (const std::logic_error& err)
00134       {
00135         LOG_FAIL_FMT("Invalid forwarded command");
00136         LOG_DEBUG_FMT("Invalid forwarded command: {}", err.what());
00137         return std::nullopt;
00138       }
00139 
00140       std::vector<uint8_t> caller_cert;
00141       const auto& plain_ = r.second;
00142       auto data_ = plain_.data();
00143       auto size_ = plain_.size();
00144       auto client_session_id = serialized::read<size_t>(data_, size_);
00145       auto includes_caller =
00146         serialized::read<IsCallerCertForwarded>(data_, size_);
00147       if (includes_caller)
00148       {
00149         auto caller_size = serialized::read<size_t>(data_, size_);
00150         caller_cert = serialized::read(data_, size_, caller_size);
00151       }
00152       std::vector<uint8_t> raw_request = serialized::read(data_, size_, size_);
00153 
00154       auto session = std::make_shared<enclave::SessionContext>(
00155         client_session_id, caller_cert);
00156       session->is_forwarded = true;
00157 
00158       try
00159       {
00160         auto context = enclave::make_fwd_rpc_context(
00161           session, raw_request, r.first.frame_format);
00162         return std::make_tuple(context, r.first.from_node);
00163       }
00164       catch (const std::exception& err)
00165       {
00166         LOG_FAIL_FMT("Invalid forwarded request");
00167         LOG_DEBUG_FMT("Invalid forwarded request: {}", err.what());
00168         return std::nullopt;
00169       }
00170     }
00171 
00172     bool send_forwarded_response(
00173       size_t client_session_id,
00174       NodeId from_node,
00175       const std::vector<uint8_t>& data)
00176     {
00177       std::vector<uint8_t> plain(sizeof(client_session_id) + data.size());
00178       auto data_ = plain.data();
00179       auto size_ = plain.size();
00180       serialized::write(data_, size_, client_session_id);
00181       serialized::write(data_, size_, data.data(), data.size());
00182 
00183       // frame_format is deliberately unset, the forwarder ignores it
00184       // and expects the same format they forwarded.
00185       ForwardedHeader msg = {ForwardedMsg::forwarded_response, self};
00186 
00187       return n2n_channels->send_encrypted(
00188         NodeMsgType::forwarded_msg, from_node, plain, msg);
00189     }
00190 
00191     std::optional<std::pair<size_t, std::vector<uint8_t>>>
00192     recv_forwarded_response(const uint8_t* data, size_t size)
00193     {
00194       std::pair<ForwardedHeader, std::vector<uint8_t>> r;
00195       try
00196       {
00197         r = n2n_channels->template recv_encrypted<ForwardedHeader>(data, size);
00198       }
00199       catch (const std::logic_error& err)
00200       {
00201         LOG_FAIL_FMT("Invalid forwarded response");
00202         LOG_DEBUG_FMT("Invalid forwarded response: {}", err.what());
00203         return std::nullopt;
00204       }
00205 
00206       const auto& plain_ = r.second;
00207       auto data_ = plain_.data();
00208       auto size_ = plain_.size();
00209       auto client_session_id = serialized::read<size_t>(data_, size_);
00210       std::vector<uint8_t> rpc = serialized::read(data_, size_, size_);
00211 
00212       return std::make_pair(client_session_id, rpc);
00213     }
00214 
00215     std::optional<MessageHash> recv_request_hash(
00216       const uint8_t* data, size_t size)
00217     {
00218       MessageHash m;
00219 
00220       try
00221       {
00222         m = n2n_channels->template recv_authenticated<MessageHash>(data, size);
00223       }
00224       catch (const std::logic_error& err)
00225       {
00226         LOG_FAIL_FMT("Invalid forwarded hash");
00227         LOG_DEBUG_FMT("Invalid forwarded hash: {}", err.what());
00228         return std::nullopt;
00229       }
00230       return m;
00231     }
00232 
00233     void recv_message(const uint8_t* data, size_t size)
00234     {
00235       serialized::skip(data, size, sizeof(NodeMsgType));
00236 
00237       auto forwarded_msg = serialized::peek<ForwardedMsg>(data, size);
00238 
00239       switch (forwarded_msg)
00240       {
00241         case ForwardedMsg::forwarded_cmd:
00242         {
00243           if (rpc_map)
00244           {
00245             auto r = recv_forwarded_command(data, size);
00246             if (!r.has_value())
00247             {
00248               LOG_FAIL_FMT("Failed to receive forwarded command");
00249               return;
00250             }
00251 
00252             auto [ctx, from_node] = std::move(r.value());
00253 
00254             const auto actor_opt = http::extract_actor(*ctx);
00255             if (!actor_opt.has_value())
00256             {
00257               LOG_FAIL_FMT("Failed to extract actor from forwarded context.");
00258               LOG_DEBUG_FMT(
00259                 "Failed to extract actor from forwarded context. Method is "
00260                 "'{}'",
00261                 ctx->get_method());
00262             }
00263 
00264             const auto& actor_s = actor_opt.value();
00265             auto actor = rpc_map->resolve(actor_s);
00266             auto handler = rpc_map->find(actor);
00267             if (actor == ccf::ActorsType::unknown || !handler.has_value())
00268             {
00269               LOG_FAIL_FMT(
00270                 "Failed to process forwarded command: unknown actor");
00271               LOG_DEBUG_FMT(
00272                 "Failed to process forwarded command: unknown actor {}",
00273                 actor_s);
00274               return;
00275             }
00276 
00277             auto fwd_handler =
00278               dynamic_cast<ForwardedRpcHandler*>(handler.value().get());
00279             if (!fwd_handler)
00280             {
00281               LOG_FAIL_FMT(
00282                 "Failed to process forwarded command: handler is not a "
00283                 "ForwardedRpcHandler");
00284               return;
00285             }
00286 
00287             if (!send_forwarded_response(
00288                   ctx->session->client_session_id,
00289                   from_node,
00290                   fwd_handler->process_forwarded(ctx)))
00291             {
00292               LOG_FAIL_FMT(
00293                 "Could not send forwarded response to {}", from_node);
00294             }
00295             else
00296             {
00297               LOG_DEBUG_FMT("Sending forwarded response to {}", from_node);
00298             }
00299           }
00300           break;
00301         }
00302 
00303         case ForwardedMsg::forwarded_response:
00304         {
00305           auto rep = recv_forwarded_response(data, size);
00306           if (!rep.has_value())
00307             return;
00308 
00309           LOG_DEBUG_FMT(
00310             "Sending forwarded response to RPC endpoint {}", rep->first);
00311 
00312           if (!rpcresponder->reply_async(rep->first, std::move(rep->second)))
00313           {
00314             return;
00315           }
00316 
00317           break;
00318         }
00319 
00320         case ForwardedMsg::request_hash:
00321         {
00322           auto hash = recv_request_hash(data, size);
00323           if (!hash.has_value())
00324           {
00325             return;
00326           }
00327 
00328           request_tracker->insert(
00329             hash->hash,
00330             threading::ThreadMessaging::thread_messaging
00331               .get_current_time_offset());
00332           break;
00333         }
00334 
00335         default:
00336         {
00337           LOG_FAIL_FMT("Unknown frontend msg type: {}", forwarded_msg);
00338           break;
00339         }
00340       }
00341     }
00342   };
00343 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/forwarder.h...
Preprocessing /data/git/CCF/src/node/rpc/frontend.h...
#include common_endpoint_registry.h: already included! skipping...
#include consensus/aft/request.h: not found! skipping...
#include ds/buffer.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include enclave/rpc_handler.h: not found! skipping...
#include forwarder.h: already included! skipping...
#include http/http_jwt.h: not found! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/jwt.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/service.h: not found! skipping...
#include rpc_exception.h: already included! skipping...
#include tls/verifier.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mutex: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 18930 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 #define FMT_HEADER_ONLY
00019 
00020 
00021 
00022 
00023 
00024 namespace ccf
00025 {
00026   class RpcFrontend : public enclave::RpcHandler, public ForwardedRpcHandler
00027   {
00028   protected:
00029     kv::Store& tables;
00030     EndpointRegistry& endpoints;
00031 
00032     void disable_request_storing()
00033     {
00034       request_storing_disabled = true;
00035     }
00036 
00037   private:
00038     SpinLock verifiers_lock;
00039     std::map<std::vector<uint8_t>, tls::VerifierPtr> verifiers;
00040 
00041     SpinLock open_lock;
00042     bool is_open_ = false;
00043 
00044     kv::Consensus* consensus;
00045     std::shared_ptr<enclave::AbstractForwarder> cmd_forwarder;
00046     kv::TxHistory* history;
00047 
00048     size_t sig_tx_interval = 5000;
00049     std::atomic<size_t> tx_count = 0;
00050     std::chrono::milliseconds sig_ms_interval = std::chrono::milliseconds(1000);
00051     std::chrono::milliseconds ms_to_sig = std::chrono::milliseconds(1000);
00052     bool request_storing_disabled = false;
00053     tls::Pem* service_identity = nullptr;
00054 
00055     using PreExec = std::function<void(kv::Tx& tx, enclave::RpcContext& ctx)>;
00056 
00057     void update_consensus()
00058     {
00059       auto c = tables.get_consensus().get();
00060 
00061       if (consensus != c)
00062       {
00063         consensus = c;
00064         endpoints.set_consensus(consensus);
00065       }
00066     }
00067 
00068     void update_history()
00069     {
00070       history = tables.get_history().get();
00071       endpoints.set_history(history);
00072     }
00073 
00074     void update_metrics(
00075       const std::shared_ptr<enclave::RpcContext> ctx,
00076       EndpointRegistry::Metrics& m)
00077     {
00078       int cat = ctx->get_response_status() / 100;
00079       switch (cat)
00080       {
00081         case 4:
00082           m.errors++;
00083           return;
00084         case 5:
00085           m.failures++;
00086           return;
00087       }
00088     }
00089 
00090     std::optional<std::vector<uint8_t>> forward_or_redirect_json(
00091       std::shared_ptr<enclave::RpcContext> ctx,
00092       const EndpointDefinitionPtr& endpoint)
00093     {
00094       auto& metrics = endpoints.get_metrics(endpoint);
00095 
00096       if (cmd_forwarder && !ctx->session->is_forwarded)
00097       {
00098         if (consensus != nullptr)
00099         {
00100           auto primary_id = consensus->primary();
00101 
00102           if (
00103             primary_id != NoNode &&
00104             cmd_forwarder->forward_command(
00105               ctx,
00106               primary_id,
00107               consensus->active_nodes(),
00108               ctx->session->caller_cert))
00109           {
00110             // Indicate that the RPC has been forwarded to primary
00111             LOG_TRACE_FMT("RPC forwarded to primary {}", primary_id);
00112             return std::nullopt;
00113           }
00114         }
00115         ctx->set_error(
00116           HTTP_STATUS_INTERNAL_SERVER_ERROR,
00117           ccf::errors::InternalError,
00118           "RPC could not be forwarded to unknown primary.");
00119         update_metrics(ctx, metrics);
00120         return ctx->serialise_response();
00121       }
00122       else
00123       {
00124         // If this frontend is not allowed to forward or the command has already
00125         // been forwarded, redirect to the current primary
00126         ctx->set_response_status(HTTP_STATUS_TEMPORARY_REDIRECT);
00127         if (consensus != nullptr)
00128         {
00129           NodeId primary_id = consensus->primary();
00130           auto tx = tables.create_tx();
00131           auto nodes_view = tx.get_view<Nodes>(Tables::NODES);
00132           auto info = nodes_view->get(primary_id);
00133 
00134           if (info)
00135           {
00136             ctx->set_response_header(
00137               http::headers::LOCATION,
00138               fmt::format("{}:{}", info->pubhost, info->pubport));
00139           }
00140         }
00141 
00142         update_metrics(ctx, metrics);
00143         return ctx->serialise_response();
00144       }
00145     }
00146 
00147     std::optional<std::vector<uint8_t>> process_command(
00148       std::shared_ptr<enclave::RpcContext> ctx,
00149       kv::Tx& tx,
00150       const PreExec& pre_exec = {})
00151     {
00152       const auto endpoint = endpoints.find_endpoint(tx, *ctx);
00153       if (endpoint == nullptr)
00154       {
00155         const auto allowed_verbs = endpoints.get_allowed_verbs(*ctx);
00156         if (allowed_verbs.empty())
00157         {
00158           ctx->set_error(
00159             HTTP_STATUS_NOT_FOUND,
00160             ccf::errors::ResourceNotFound,
00161             fmt::format("Unknown path: {}.", ctx->get_method()));
00162           return ctx->serialise_response();
00163         }
00164         else
00165         {
00166           std::vector<char const*> allowed_verb_strs;
00167           for (auto verb : allowed_verbs)
00168           {
00169             allowed_verb_strs.push_back(verb.c_str());
00170           }
00171           const std::string allow_header_value =
00172             fmt::format("{}", fmt::join(allowed_verb_strs, ", "));
00173           // List allowed methods in 2 places:
00174           // - ALLOW header for standards compliance + machine parsing
00175           // - Body for visiblity + human readability
00176           ctx->set_response_header(http::headers::ALLOW, allow_header_value);
00177           ctx->set_error(
00178             HTTP_STATUS_METHOD_NOT_ALLOWED,
00179             ccf::errors::UnsupportedHttpVerb,
00180             fmt::format(
00181               "Allowed methods for '{}' are: {}.",
00182               ctx->get_method(),
00183               allow_header_value));
00184           return ctx->serialise_response();
00185         }
00186       }
00187 
00188       // Note: calls that could not be dispatched (cases handled above)
00189       // are not counted against any particular endpoint.
00190       auto& metrics = endpoints.get_metrics(endpoint);
00191       metrics.calls++;
00192 
00193       std::unique_ptr<AuthnIdentity> identity = nullptr;
00194 
00195       // If any auth policy was required, check that at least one is accepted
00196       if (!endpoint->authn_policies.empty())
00197       {
00198         std::string auth_error_reason;
00199         for (const auto& policy : endpoint->authn_policies)
00200         {
00201           identity = policy->authenticate(tx, ctx, auth_error_reason);
00202           if (identity != nullptr)
00203           {
00204             break;
00205           }
00206         }
00207 
00208         if (identity == nullptr)
00209         {
00210           // If none were accepted, let the last set an error
00211           endpoint->authn_policies.back()->set_unauthenticated_error(
00212             ctx, std::move(auth_error_reason));
00213           update_metrics(ctx, metrics);
00214           return ctx->serialise_response();
00215         }
00216       }
00217 
00218       update_history();
00219 
00220       const bool is_primary = (consensus == nullptr) ||
00221         consensus->is_primary() || ctx->is_create_request;
00222       const bool forwardable = (consensus != nullptr) &&
00223         (consensus->type() == ConsensusType::CFT ||
00224          (consensus->type() != ConsensusType::CFT && !ctx->execute_on_node));
00225 
00226       if (!is_primary && forwardable)
00227       {
00228         switch (endpoint->properties.forwarding_required)
00229         {
00230           case ForwardingRequired::Never:
00231           {
00232             break;
00233           }
00234 
00235           case ForwardingRequired::Sometimes:
00236           {
00237             if (
00238               (ctx->session->is_forwarding &&
00239                consensus->type() == ConsensusType::CFT) ||
00240               (consensus->type() != ConsensusType::CFT &&
00241                !ctx->execute_on_node &&
00242                (endpoint == nullptr ||
00243                 (endpoint != nullptr &&
00244                  !endpoint->properties.execute_locally))))
00245             {
00246               ctx->session->is_forwarding = true;
00247               return forward_or_redirect_json(ctx, endpoint);
00248             }
00249             break;
00250           }
00251 
00252           case ForwardingRequired::Always:
00253           {
00254             ctx->session->is_forwarding = true;
00255             return forward_or_redirect_json(ctx, endpoint);
00256           }
00257         }
00258       }
00259 
00260       auto args = EndpointContext(ctx, std::move(identity), tx);
00261 
00262       tx_count++;
00263 
00264       size_t attempts = 0;
00265       constexpr auto max_attempts = 30;
00266 
00267       while (attempts < max_attempts)
00268       {
00269         ++attempts;
00270 
00271         try
00272         {
00273           if (pre_exec)
00274           {
00275             pre_exec(tx, *ctx.get());
00276           }
00277 
00278           endpoints.execute_endpoint(endpoint, args);
00279 
00280           if (!ctx->should_apply_writes())
00281           {
00282             update_metrics(ctx, metrics);
00283             return ctx->serialise_response();
00284           }
00285 
00286           switch (tx.commit())
00287           {
00288             case kv::CommitSuccess::OK:
00289             {
00290               auto cv = tx.commit_version();
00291               if (cv == 0)
00292                 cv = tx.get_read_version();
00293               if (consensus != nullptr)
00294               {
00295                 if (cv != kv::NoVersion)
00296                 {
00297                   ctx->set_seqno(cv);
00298                   ctx->set_view(tx.commit_term());
00299                 }
00300                 // Deprecated, this will be removed in future releases
00301                 ctx->set_global_commit(consensus->get_committed_seqno());
00302 
00303                 if (history != nullptr && consensus->is_primary())
00304                 {
00305                   history->try_emit_signature();
00306                 }
00307               }
00308 
00309               update_metrics(ctx, metrics);
00310               return ctx->serialise_response();
00311             }
00312 
00313             case kv::CommitSuccess::CONFLICT:
00314             {
00315               break;
00316             }
00317 
00318             case kv::CommitSuccess::NO_REPLICATE:
00319             {
00320               ctx->set_error(
00321                 HTTP_STATUS_SERVICE_UNAVAILABLE,
00322                 ccf::errors::TransactionReplicationFailed,
00323                 "Transaction failed to replicate.");
00324               update_metrics(ctx, metrics);
00325               return ctx->serialise_response();
00326             }
00327           }
00328         }
00329         catch (const kv::CompactedVersionConflict& e)
00330         {
00331           // The executing transaction failed because of a conflicting
00332           // compaction. Reset and retry
00333           LOG_DEBUG_FMT(
00334             "Transaction execution conflicted with compaction: {}", e.what());
00335           tx.reset();
00336           continue;
00337         }
00338         catch (RpcException& e)
00339         {
00340           ctx->set_error(std::move(e.error));
00341           update_metrics(ctx, metrics);
00342           return ctx->serialise_response();
00343         }
00344         catch (JsonParseError& e)
00345         {
00346           ctx->set_error(
00347             HTTP_STATUS_BAD_REQUEST,
00348             ccf::errors::InvalidInput,
00349             fmt::format("At {}: {}", e.pointer(), e.what()));
00350           update_metrics(ctx, metrics);
00351           return ctx->serialise_response();
00352         }
00353         catch (const nlohmann::json::exception& e)
00354         {
00355           ctx->set_error(
00356             HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidInput, e.what());
00357           update_metrics(ctx, metrics);
00358           return ctx->serialise_response();
00359         }
00360         catch (const UrlQueryParseError& e)
00361         {
00362           ctx->set_error(
00363             HTTP_STATUS_BAD_REQUEST,
00364             ccf::errors::InvalidQueryParameterValue,
00365             e.what());
00366           update_metrics(ctx, metrics);
00367           return ctx->serialise_response();
00368         }
00369         catch (const kv::KvSerialiserException& e)
00370         {
00371           // If serialising the committed transaction fails, there is no way
00372           // to recover safely (https://github.com/microsoft/CCF/issues/338).
00373           // Better to abort.
00374           LOG_DEBUG_FMT("Failed to serialise: {}", e.what());
00375           LOG_FATAL_FMT("Failed to serialise");
00376           abort();
00377         }
00378         catch (const std::exception& e)
00379         {
00380           ctx->set_error(
00381             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00382             ccf::errors::InternalError,
00383             e.what());
00384           update_metrics(ctx, metrics);
00385           return ctx->serialise_response();
00386         }
00387       }
00388 
00389       ctx->set_error(
00390         HTTP_STATUS_SERVICE_UNAVAILABLE,
00391         ccf::errors::TransactionCommitAttemptsExceedLimit,
00392         fmt::format(
00393           "Transaction continued to conflict after {} attempts. Retry later.",
00394           max_attempts));
00395       static constexpr size_t retry_after_seconds = 3;
00396       ctx->set_response_header(http::headers::RETRY_AFTER, retry_after_seconds);
00397       return ctx->serialise_response();
00398     }
00399 
00400   public:
00401     RpcFrontend(kv::Store& tables_, EndpointRegistry& handlers_) :
00402       tables(tables_),
00403       endpoints(handlers_),
00404       consensus(nullptr),
00405       history(nullptr)
00406     {}
00407 
00408     void set_sig_intervals(
00409       size_t sig_tx_interval_, size_t sig_ms_interval_) override
00410     {
00411       sig_tx_interval = sig_tx_interval_;
00412       sig_ms_interval = std::chrono::milliseconds(sig_ms_interval_);
00413       ms_to_sig = sig_ms_interval;
00414     }
00415 
00416     void set_cmd_forwarder(
00417       std::shared_ptr<enclave::AbstractForwarder> cmd_forwarder_) override
00418     {
00419       cmd_forwarder = cmd_forwarder_;
00420     }
00421 
00422     void open(std::optional<tls::Pem*> identity = std::nullopt) override
00423     {
00424       std::lock_guard<SpinLock> mguard(open_lock);
00425       // open() without an identity unconditionally opens the frontend.
00426       // If an identity is passed, the frontend must instead wait for
00427       // the KV to read that this is identity is present and open,
00428       // see is_open()
00429       if (identity.has_value())
00430       {
00431         service_identity = identity.value();
00432       }
00433       else
00434       {
00435         if (!is_open_)
00436         {
00437           is_open_ = true;
00438           endpoints.init_handlers(tables);
00439         }
00440       }
00441     }
00442 
00443     bool is_open(kv::Tx& tx) override
00444     {
00445       std::lock_guard<SpinLock> mguard(open_lock);
00446       if (!is_open_)
00447       {
00448         auto sv = tx.get_view<Service>(Tables::SERVICE);
00449         auto s = sv->get_globally_committed(0);
00450         if (
00451           s.has_value() && s.value().status == ServiceStatus::OPEN &&
00452           service_identity != nullptr && s.value().cert == *service_identity)
00453         {
00454           LOG_INFO_FMT(
00455             "Service state is OPEN, now accepting user transactions");
00456           is_open_ = true;
00457           endpoints.init_handlers(tables);
00458         }
00459       }
00460       return is_open_;
00461     }
00462 
00463     /** Process a serialised command with the associated RPC context
00464      *
00465      * If an RPC that requires writing to the kv store is processed on a
00466      * backup, the serialised RPC is forwarded to the current network primary.
00467      *
00468      * @param ctx Context for this RPC
00469      * @returns nullopt if the result is pending (to be forwarded, or still
00470      * to-be-executed by consensus), else the response (may contain error)
00471      */
00472     std::optional<std::vector<uint8_t>> process(
00473       std::shared_ptr<enclave::RpcContext> ctx) override
00474     {
00475       update_consensus();
00476 
00477       auto tx = tables.create_tx();
00478       if (!is_open(tx))
00479       {
00480         ctx->set_error(
00481           HTTP_STATUS_NOT_FOUND,
00482           ccf::errors::FrontendNotOpen,
00483           "Frontend is not open.");
00484         return ctx->serialise_response();
00485       }
00486 
00487       auto endpoint = endpoints.find_endpoint(tx, *ctx);
00488 
00489       const bool is_bft =
00490         consensus != nullptr && consensus->type() == ConsensusType::BFT;
00491       const bool is_local =
00492         endpoint != nullptr && endpoint->properties.execute_locally;
00493       const bool should_bft_distribute = is_bft && !is_local &&
00494         (ctx->execute_on_node || consensus->is_primary());
00495 
00496       // This decision is based on several things read from the KV
00497       // (request->is_local) which are true _now_ but may not
00498       // be true when this is actually received/executed. We should revisit this
00499       // once we have general KV-defined dispatch, to ensure this is safe. For
00500       // forwarding we will need to pass a digest of the endpoint definition,
00501       // and that should also work here
00502       if (should_bft_distribute)
00503       {
00504         update_history();
00505         if (history)
00506         {
00507           const kv::TxHistory::RequestID reqid = {
00508             ctx->session->client_session_id, ctx->get_request_index()};
00509           if (!history->add_request(
00510                 reqid,
00511                 ctx->session->caller_cert,
00512                 ctx->get_serialised_request(),
00513                 ctx->frame_format()))
00514           {
00515             LOG_FAIL_FMT("Adding request failed");
00516             LOG_DEBUG_FMT(
00517               "Adding request failed: {}, {}",
00518               std::get<0>(reqid),
00519               std::get<1>(reqid));
00520             ctx->set_error(
00521               HTTP_STATUS_INTERNAL_SERVER_ERROR,
00522               ccf::errors::InternalError,
00523               "Could not process request.");
00524             return ctx->serialise_response();
00525           }
00526           tx.set_req_id(reqid);
00527           return std::nullopt;
00528         }
00529         else
00530         {
00531           ctx->set_error(
00532             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00533             ccf::errors::InternalError,
00534             "Consensus is not yet ready.");
00535           return ctx->serialise_response();
00536         }
00537       }
00538 
00539       return process_command(ctx, tx);
00540     }
00541 
00542     /** Process a serialised command with the associated RPC context via BFT
00543      *
00544      * @param ctx Context for this RPC
00545      */
00546     ProcessBftResp process_bft(
00547       std::shared_ptr<enclave::RpcContext> ctx) override
00548     {
00549       auto tx = tables.create_tx();
00550       // Note: this can only happen if the primary is malicious,
00551       // and has executed a user transaction when the service wasn't
00552       // open. The backup should ideally trigger a view change here.
00553       if (!is_open(tx))
00554       {
00555         throw std::logic_error("Transaction failed");
00556       }
00557 
00558       kv::Version version = kv::NoVersion;
00559 
00560       update_consensus();
00561 
00562       PreExec fn = [](kv::Tx& tx, enclave::RpcContext& ctx) {
00563         auto req_view =
00564           tx.get_view<aft::RequestsMap>(ccf::Tables::AFT_REQUESTS);
00565         req_view->put(
00566           0,
00567           {tx.get_req_id(),
00568            ctx.session->caller_cert,
00569            ctx.get_serialised_request(),
00570            ctx.frame_format()});
00571       };
00572 
00573       auto rep = process_command(ctx, tx, fn);
00574 
00575       version = tx.get_version();
00576       return {std::move(rep.value()), version};
00577     }
00578 
00579     void update_merkle_tree() override
00580     {
00581       if (history != nullptr)
00582       {
00583         history->flush_pending();
00584       }
00585     }
00586 
00587     /** Process a serialised input forwarded from another node
00588      *
00589      * @param ctx Context for this forwarded RPC
00590      *
00591      * @return Serialised reply to send back to forwarder node
00592      */
00593     std::vector<uint8_t> process_forwarded(
00594       std::shared_ptr<enclave::RpcContext> ctx) override
00595     {
00596       if (!ctx->session->is_forwarded)
00597       {
00598         throw std::logic_error(
00599           "Processing forwarded command with unitialised forwarded context");
00600       }
00601 
00602       update_consensus();
00603 
00604       if (consensus->type() == ConsensusType::CFT)
00605       {
00606         auto tx = tables.create_tx();
00607         auto rep = process_command(ctx, tx);
00608         if (!rep.has_value())
00609         {
00610           // This should never be called when process_command is called with a
00611           // forwarded RPC context
00612           throw std::logic_error("Forwarded RPC cannot be forwarded");
00613         }
00614 
00615         return rep.value();
00616       }
00617       else
00618       {
00619         auto rep = process_bft(ctx);
00620         return rep.result;
00621       }
00622     }
00623 
00624     void tick(std::chrono::milliseconds elapsed) override
00625     {
00626       update_consensus();
00627 
00628       kv::Consensus::Statistics stats;
00629 
00630       if (consensus != nullptr)
00631       {
00632         stats = consensus->get_statistics();
00633       }
00634       stats.tx_count = tx_count;
00635 
00636       endpoints.tick(elapsed, stats);
00637 
00638       // reset tx_counter for next tick interval
00639       tx_count = 0;
00640     }
00641   };
00642 }
00643 
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN FMT_HEADER_ONLY HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/frontend.h...
Preprocessing /data/git/CCF/src/node/rpc/json_handler.h...
#include enclave/rpc_context.h: not found! skipping...
#include endpoint_registry.h: already included! skipping...
#include http/http_consts.h: not found! skipping...
#include node/rpc/error.h: not found! skipping...
#include node/rpc/rpc_exception.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include llhttp/llhttp.h: not found! skipping...
Preprocessor output (size: 10357 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace ccf
00015 {
00016   /*
00017    * For simple app methods which expect a JSON request, potentially msgpack'd,
00018    * these functions do the common decoding of the input and setting of response
00019    * fields, to reduce handler complexity and repetition.
00020    *
00021    * Rather than:
00022    * auto foo = [](auto& args) {
00023    *   nlohmann::json params;
00024    *   serdes::Pack pack_type;
00025    *   if (<content-type is JSON>)
00026    *   {
00027    *     params = unpack(args.rpc_ctx->get_request_body());
00028    *     pack_type = Text;
00029    *   }
00030    *   else
00031    *   {
00032    *     ...
00033    *   }
00034    *   auto result = fn(params);
00035    *   if (is_error(result))
00036    *   {
00037    *     args.rpc_ctx->set_response_status(SOME_ERROR);
00038    *     args.rpc_ctx->set_response_header(content_type, Text);
00039    *     args.rpc_ctx->set_response_body(error_msg(result));
00040    *   }
00041    *   if (pack_type == Text)
00042    *   {
00043    *     args.rpc_ctx->set_response_header(content_type, JSON);
00044    *     args.rpc_ctx->set_response_body(pack(result, Text));
00045    *   }
00046    *   else
00047    *   {
00048    *     ...
00049    *   }
00050    * };
00051    *
00052    * it is possible to write the shorter, clearer, return-based lambda:
00053    * auto foo = json_adapter([](kv::Tx& tx, nlohmann::json&& params)
00054    * {
00055    *    auto result = fn(params);
00056    *    if (is_error(result))
00057    *    {
00058    *      return make_error(SOME_ERROR, error_msg(result));
00059    *    }
00060    *    else
00061    *    {
00062    *      return make_success(result);
00063    *    }
00064    * });
00065    */
00066 
00067   class UrlQueryParseError : public std::invalid_argument
00068   {
00069   public:
00070     using std::invalid_argument::invalid_argument;
00071   };
00072 
00073   namespace jsonhandler
00074   {
00075     using JsonAdapterResponse = std::variant<ErrorDetails, nlohmann::json>;
00076 
00077     static constexpr char const* pack_to_content_type(serdes::Pack p)
00078     {
00079       switch (p)
00080       {
00081         case serdes::Pack::Text:
00082         {
00083           return http::headervalues::contenttype::JSON;
00084         }
00085         case serdes::Pack::MsgPack:
00086         {
00087           return http::headervalues::contenttype::MSGPACK;
00088         }
00089         default:
00090         {
00091           return nullptr;
00092         }
00093       }
00094     }
00095 
00096     static serdes::Pack detect_json_pack(
00097       const std::shared_ptr<enclave::RpcContext>& ctx)
00098     {
00099       std::optional<serdes::Pack> packing = std::nullopt;
00100 
00101       const auto content_type_it =
00102         ctx->get_request_header(http::headers::CONTENT_TYPE);
00103       if (content_type_it.has_value())
00104       {
00105         const auto& content_type = content_type_it.value();
00106         if (content_type == http::headervalues::contenttype::JSON)
00107         {
00108           packing = serdes::Pack::Text;
00109         }
00110         else if (content_type == http::headervalues::contenttype::MSGPACK)
00111         {
00112           packing = serdes::Pack::MsgPack;
00113         }
00114         else
00115         {
00116           throw RpcException(
00117             HTTP_STATUS_UNSUPPORTED_MEDIA_TYPE,
00118             ccf::errors::UnsupportedContentType,
00119             fmt::format(
00120               "Unsupported content type {}. Only {} and {} are currently "
00121               "supported",
00122               content_type,
00123               http::headervalues::contenttype::JSON,
00124               http::headervalues::contenttype::MSGPACK));
00125         }
00126       }
00127       else
00128       {
00129         packing = serdes::detect_pack(ctx->get_request_body());
00130       }
00131 
00132       return packing.value_or(serdes::Pack::Text);
00133     }
00134 
00135     static serdes::Pack get_response_pack(
00136       const std::shared_ptr<enclave::RpcContext>& ctx,
00137       serdes::Pack request_pack)
00138     {
00139       serdes::Pack packing = request_pack;
00140 
00141       const auto accept_it = ctx->get_request_header(http::headers::ACCEPT);
00142       if (accept_it.has_value())
00143       {
00144         const auto& accept = accept_it.value();
00145         if (accept == http::headervalues::contenttype::JSON)
00146         {
00147           packing = serdes::Pack::Text;
00148         }
00149         else if (accept == http::headervalues::contenttype::MSGPACK)
00150         {
00151           packing = serdes::Pack::MsgPack;
00152         }
00153         else if (accept == "*/*")
00154         {
00155           packing = request_pack;
00156         }
00157         else
00158         {
00159           throw RpcException(
00160             HTTP_STATUS_NOT_ACCEPTABLE,
00161             ccf::errors::UnsupportedContentType,
00162             fmt::format(
00163               "Unsupported content type {} in accept header. Only {} and {} "
00164               "are currently supported",
00165               accept,
00166               http::headervalues::contenttype::JSON,
00167               http::headervalues::contenttype::MSGPACK));
00168         }
00169       }
00170 
00171       return packing;
00172     }
00173 
00174     static nlohmann::json get_params_from_body(
00175       const std::shared_ptr<enclave::RpcContext>& ctx, serdes::Pack pack)
00176     {
00177       return serdes::unpack(ctx->get_request_body(), pack);
00178     }
00179 
00180     static nlohmann::json get_params_from_query(
00181       const std::shared_ptr<enclave::RpcContext>& ctx)
00182     {
00183       std::string_view query = ctx->get_request_query();
00184       auto params = nlohmann::json::object();
00185 
00186       while (true)
00187       {
00188         const auto next_split = query.find('&');
00189 
00190         const std::string_view this_entry = query.substr(0, next_split);
00191         const auto field_split = this_entry.find('=');
00192         if (field_split == std::string::npos)
00193         {
00194           throw UrlQueryParseError(
00195             fmt::format("No k=v in URL query fragment: {}", query));
00196         }
00197 
00198         const std::string_view key = this_entry.substr(0, field_split);
00199         const std::string_view value = this_entry.substr(field_split + 1);
00200         try
00201         {
00202           params[std::string(key)] = nlohmann::json::parse(value);
00203         }
00204         catch (const std::exception& e)
00205         {
00206           throw UrlQueryParseError(fmt::format(
00207             "Unable to parse URL query value: {} ({})", query, e.what()));
00208         }
00209 
00210         if (next_split == std::string::npos)
00211         {
00212           break;
00213         }
00214         else
00215         {
00216           query.remove_prefix(next_split + 1);
00217         }
00218       }
00219 
00220       return params;
00221     }
00222 
00223     static std::pair<serdes::Pack, nlohmann::json> get_json_params(
00224       const std::shared_ptr<enclave::RpcContext>& ctx)
00225     {
00226       const auto pack = detect_json_pack(ctx);
00227 
00228       nlohmann::json params = nullptr;
00229       if (
00230         !ctx->get_request_body().empty()
00231         // Body of GET is ignored
00232         && ctx->get_request_verb() != HTTP_GET)
00233       {
00234         params = get_params_from_body(ctx, pack);
00235       }
00236       else if (!ctx->get_request_query().empty())
00237       {
00238         params = get_params_from_query(ctx);
00239       }
00240 
00241       return std::make_pair(pack, params);
00242     }
00243 
00244     static void set_response(
00245       JsonAdapterResponse&& res,
00246       std::shared_ptr<enclave::RpcContext>& ctx,
00247       serdes::Pack request_packing)
00248     {
00249       auto error = std::get_if<ErrorDetails>(&res);
00250       if (error != nullptr)
00251       {
00252         ctx->set_error(std::move(*error));
00253       }
00254       else
00255       {
00256         const auto packing = get_response_pack(ctx, request_packing);
00257         const auto body = std::get_if<nlohmann::json>(&res);
00258         ctx->set_response_status(HTTP_STATUS_OK);
00259         switch (packing)
00260         {
00261           case serdes::Pack::Text:
00262           {
00263             const auto s = body->dump();
00264             ctx->set_response_body(std::vector<uint8_t>(s.begin(), s.end()));
00265             break;
00266           }
00267           case serdes::Pack::MsgPack:
00268           {
00269             ctx->set_response_body(nlohmann::json::to_msgpack(*body));
00270             break;
00271           }
00272           default:
00273           {
00274             throw std::logic_error("Unhandled serdes::Pack");
00275           }
00276         }
00277         ctx->set_response_header(
00278           http::headers::CONTENT_TYPE, pack_to_content_type(packing));
00279       }
00280     }
00281   }
00282 
00283   static jsonhandler::JsonAdapterResponse make_success(
00284     nlohmann::json&& result_payload)
00285   {
00286     return std::move(result_payload);
00287   }
00288 
00289   static jsonhandler::JsonAdapterResponse make_success(
00290     const nlohmann::json& result_payload)
00291   {
00292     return result_payload;
00293   }
00294 
00295   static inline jsonhandler::JsonAdapterResponse make_error(
00296     http_status status, const std::string& code, const std::string& msg)
00297   {
00298     return ErrorDetails{status, code, msg};
00299   }
00300 
00301 // -Wunused-function seems to _wrongly_ flag the following functions as unused
00302 
00303 
00304 
00305   using HandlerTxOnly =
00306     std::function<jsonhandler::JsonAdapterResponse(kv::Tx& tx)>;
00307 
00308   static EndpointFunction json_adapter(const HandlerTxOnly& f)
00309   {
00310     return [f](EndpointContext& args) {
00311       const auto [packing, params] = jsonhandler::get_json_params(args.rpc_ctx);
00312       jsonhandler::set_response(f(args.tx), args.rpc_ctx, packing);
00313     };
00314   }
00315 
00316   using HandlerJsonParamsOnly = std::function<jsonhandler::JsonAdapterResponse(
00317     kv::Tx& tx, nlohmann::json&& params)>;
00318   static EndpointFunction json_adapter(const HandlerJsonParamsOnly& f)
00319   {
00320     return [f](EndpointContext& args) {
00321       auto [packing, params] = jsonhandler::get_json_params(args.rpc_ctx);
00322       jsonhandler::set_response(
00323         f(args.tx, std::move(params)), args.rpc_ctx, packing);
00324     };
00325   }
00326 
00327   using HandlerJsonParamsAndForward =
00328     std::function<jsonhandler::JsonAdapterResponse(
00329       EndpointContext& args, nlohmann::json&& params)>;
00330 
00331   static EndpointFunction json_adapter(const HandlerJsonParamsAndForward& f)
00332   {
00333     return [f](EndpointContext& args) {
00334       auto [packing, params] = jsonhandler::get_json_params(args.rpc_ctx);
00335       jsonhandler::set_response(
00336         f(args, std::move(params)), args.rpc_ctx, packing);
00337     };
00338   }
00339 
00340   using ReadOnlyHandlerWithJson =
00341     std::function<jsonhandler::JsonAdapterResponse(
00342       ReadOnlyEndpointContext& args, nlohmann::json&& params)>;
00343 
00344   static ReadOnlyEndpointFunction json_read_only_adapter(
00345     const ReadOnlyHandlerWithJson& f)
00346   {
00347     return [f](ReadOnlyEndpointContext& args) {
00348       auto [packing, params] = jsonhandler::get_json_params(args.rpc_ctx);
00349       jsonhandler::set_response(
00350         f(args, std::move(params)), args.rpc_ctx, packing);
00351     };
00352   }
00353 
00354 
00355   using CommandHandlerWithJson = std::function<jsonhandler::JsonAdapterResponse(
00356     CommandEndpointContext& args, nlohmann::json&& params)>;
00357 
00358   static CommandEndpointFunction json_command_adapter(
00359     const CommandHandlerWithJson& f)
00360   {
00361     return [f](CommandEndpointContext& args) {
00362       auto [packing, params] = jsonhandler::get_json_params(args.rpc_ctx);
00363       jsonhandler::set_response(
00364         f(args, std::move(params)), args.rpc_ctx, packing);
00365     };
00366   }
00367 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/json_handler.h...
Preprocessing /data/git/CCF/src/node/rpc/member_frontend.h...
#include ds/nonstd.h: not found! skipping...
#include frontend.h: already included! skipping...
#include lua_interp/lua_json.h: not found! skipping...
#include lua_interp/tx_script_runner.h: not found! skipping...
#include node/genesis_gen.h: not found! skipping...
#include node/jwt.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/quote.h: not found! skipping...
#include node/secret_share.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
#include node_interface.h: already included! skipping...
#include tls/base64.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include charconv: not found! skipping...
#include exception: not found! skipping...
#include initializer_list: not found! skipping...
#include map: not found! skipping...
#include memory: not found! skipping...
#include openenclave/attestation/verifier.h: not found! skipping...
#include set: not found! skipping...
#include sstream: not found! skipping...
#include openenclave/host_verify.h: not found! skipping...
Preprocessor output (size: 62806 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 namespace ccf
00034 {
00035   static oe_result_t oe_verify_attestation_certificate_with_evidence_cb(
00036     oe_claim_t* claims, size_t claims_length, void* arg)
00037   {
00038     auto claims_map = (std::map<std::string, std::vector<uint8_t>>*)arg;
00039     for (size_t i = 0; i < claims_length; i++)
00040     {
00041       std::string claim_name(claims[i].name);
00042       std::vector<uint8_t> claim_value(
00043         claims[i].value, claims[i].value + claims[i].value_size);
00044       claims_map->emplace(std::move(claim_name), std::move(claim_value));
00045     }
00046     return OE_OK;
00047   }
00048 
00049   class MemberTsr : public lua::TxScriptRunner
00050   {
00051     void setup_environment(
00052       lua::Interpreter& li,
00053       const std::optional<Script>& env_script) const override
00054     {
00055       TxScriptRunner::setup_environment(li, env_script);
00056     }
00057 
00058   public:
00059     MemberTsr(NetworkTables& network) : TxScriptRunner(network) {}
00060   };
00061 
00062   struct SetMemberData
00063   {
00064     MemberId member_id;
00065     nlohmann::json member_data = nullptr;
00066   };
00067 
00068 
00069 
00070 
00071   struct SetUserData
00072   {
00073     UserId user_id;
00074     nlohmann::json user_data = nullptr;
00075   };
00076 
00077 
00078 
00079 
00080   struct SetModule
00081   {
00082     std::string name;
00083     Module module;
00084   };
00085 
00086 
00087 
00088   struct JsBundleEndpointMethod : public ccf::endpoints::EndpointProperties
00089   {
00090     std::string js_module;
00091     std::string js_function;
00092   };
00093   DECLARE_JSON_TYPE_WITH_BASE(
00094     JsBundleEndpointMethod, ccf::endpoints::EndpointProperties)
00095 
00096 
00097   using JsBundleEndpoint = std::map<std::string, JsBundleEndpointMethod>;
00098 
00099   struct JsBundleMetadata
00100   {
00101     std::map<std::string, JsBundleEndpoint> endpoints;
00102   };
00103 
00104 
00105 
00106   struct JsBundle
00107   {
00108     JsBundleMetadata metadata;
00109     std::vector<SetModule> modules;
00110   };
00111 
00112 
00113 
00114   struct DeployJsApp
00115   {
00116     JsBundle bundle;
00117   };
00118 
00119 
00120 
00121   struct JsonWebKey
00122   {
00123     std::vector<std::string> x5c;
00124     std::string kid;
00125     std::string kty;
00126 
00127     bool operator==(const JsonWebKey& rhs) const
00128     {
00129       return x5c == rhs.x5c && kid == rhs.kid && kty == rhs.kty;
00130     }
00131   };
00132 
00133 
00134 
00135   struct JsonWebKeySet
00136   {
00137     std::vector<JsonWebKey> keys;
00138 
00139     bool operator!=(const JsonWebKeySet& rhs) const
00140     {
00141       return keys != rhs.keys;
00142     }
00143   };
00144 
00145 
00146 
00147   struct SetJwtIssuer : public ccf::JwtIssuerMetadata
00148   {
00149     std::string issuer;
00150     std::optional<JsonWebKeySet> jwks;
00151   };
00152   DECLARE_JSON_TYPE_WITH_BASE_AND_OPTIONAL_FIELDS(
00153     SetJwtIssuer, ccf::JwtIssuerMetadata)
00154 
00155 
00156 
00157   struct RemoveJwtIssuer
00158   {
00159     std::string issuer;
00160   };
00161 
00162 
00163 
00164   struct SetJwtPublicSigningKeys
00165   {
00166     std::string issuer;
00167     JsonWebKeySet jwks;
00168   };
00169 
00170 
00171 
00172   struct SetCaCert
00173   {
00174     std::string name;
00175     std::string cert;
00176   };
00177 
00178 
00179 
00180   class MemberEndpoints : public CommonEndpointRegistry
00181   {
00182   private:
00183     Script get_script(kv::Tx& tx, std::string name)
00184     {
00185       const auto s = tx.get_view(network.gov_scripts)->get(name);
00186       if (!s)
00187       {
00188         throw std::logic_error(
00189           fmt::format("Could not find gov script: {}", name));
00190       }
00191       return *s;
00192     }
00193 
00194     void set_app_scripts(kv::Tx& tx, std::map<std::string, std::string> scripts)
00195     {
00196       auto tx_scripts = tx.get_view(network.app_scripts);
00197 
00198       // First, remove all existing handlers
00199       tx_scripts->foreach(
00200         [&tx_scripts](const std::string& name, const Script&) {
00201           tx_scripts->remove(name);
00202           return true;
00203         });
00204 
00205       for (auto& rs : scripts)
00206       {
00207         tx_scripts->put(rs.first, lua::compile(rs.second));
00208       }
00209     }
00210 
00211     void set_js_scripts(kv::Tx& tx, std::map<std::string, std::string> scripts)
00212     {
00213       auto tx_scripts = tx.get_view(network.app_scripts);
00214 
00215       // First, remove all existing handlers
00216       tx_scripts->foreach(
00217         [&tx_scripts](const std::string& name, const Script&) {
00218           tx_scripts->remove(name);
00219           return true;
00220         });
00221 
00222       for (auto& rs : scripts)
00223       {
00224         tx_scripts->put(rs.first, {rs.second});
00225       }
00226     }
00227 
00228     bool deploy_js_app(kv::Tx& tx, const JsBundle& bundle)
00229     {
00230       std::string module_prefix = "/";
00231       remove_modules(tx, module_prefix);
00232       set_modules(tx, module_prefix, bundle.modules);
00233 
00234       remove_endpoints(tx);
00235 
00236       auto endpoints_view =
00237         tx.get_view<ccf::endpoints::EndpointsMap>(ccf::Tables::ENDPOINTS);
00238 
00239       std::map<std::string, std::string> scripts;
00240       for (auto& [url, endpoint] : bundle.metadata.endpoints)
00241       {
00242         for (auto& [method, info] : endpoint)
00243         {
00244           const std::string& js_module = info.js_module;
00245           if (std::none_of(
00246                 bundle.modules.cbegin(),
00247                 bundle.modules.cend(),
00248                 [&js_module](const SetModule& item) {
00249                   return item.name == js_module;
00250                 }))
00251           {
00252             LOG_FAIL_FMT(
00253               "{} {}: module '{}' not found in bundle",
00254               method,
00255               url,
00256               info.js_module);
00257             return false;
00258           }
00259 
00260           auto verb = nlohmann::json(method).get<RESTVerb>();
00261           endpoints_view->put(ccf::endpoints::EndpointKey{url, verb}, info);
00262 
00263           // CCF currently requires each endpoint to have an inline JS module.
00264           std::string method_uppercase = method;
00265           nonstd::to_upper(method_uppercase);
00266           std::string url_without_leading_slash = url.substr(1);
00267           std::string key =
00268             fmt::format("{} {}", method_uppercase, url_without_leading_slash);
00269           std::string script = fmt::format(
00270             "import {{ {} as f }} from '.{}{}'; export default (r) => f(r);",
00271             info.js_function,
00272             module_prefix,
00273             info.js_module);
00274           scripts.emplace(key, script);
00275         }
00276       }
00277 
00278       set_js_scripts(tx, scripts);
00279 
00280       return true;
00281     }
00282 
00283     bool remove_js_app(kv::Tx& tx)
00284     {
00285       remove_modules(tx, "/");
00286       set_js_scripts(tx, {});
00287 
00288       return true;
00289     }
00290 
00291     void set_modules(
00292       kv::Tx& tx, std::string prefix, const std::vector<SetModule>& modules)
00293     {
00294       for (auto& set_module_ : modules)
00295       {
00296         std::string full_name = prefix + set_module_.name;
00297         if (!set_module(tx, full_name, set_module_.module))
00298         {
00299           throw std::logic_error(
00300             fmt::format("Unexpected error while setting module {}", full_name));
00301         }
00302       }
00303     }
00304 
00305     bool set_module(kv::Tx& tx, std::string name, Module module)
00306     {
00307       if (name.empty() || name[0] != '/')
00308       {
00309         LOG_FAIL_FMT("module names must start with /");
00310         return false;
00311       }
00312       auto tx_modules = tx.get_view(network.modules);
00313       tx_modules->put(name, module);
00314       return true;
00315     }
00316 
00317     void remove_modules(kv::Tx& tx, std::string prefix)
00318     {
00319       auto tx_modules = tx.get_view(network.modules);
00320       tx_modules->foreach(
00321         [&tx_modules, &prefix](const std::string& name, const Module&) {
00322           if (nonstd::starts_with(name, prefix))
00323           {
00324             if (!tx_modules->remove(name))
00325             {
00326               throw std::logic_error(
00327                 fmt::format("Unexpected error while removing module {}", name));
00328             }
00329           }
00330           return true;
00331         });
00332     }
00333 
00334     bool remove_module(kv::Tx& tx, std::string name)
00335     {
00336       auto tx_modules = tx.get_view(network.modules);
00337       return tx_modules->remove(name);
00338     }
00339 
00340     void remove_jwt_keys(kv::Tx& tx, std::string issuer)
00341     {
00342       auto keys = tx.get_view(this->network.jwt_public_signing_keys);
00343       auto key_issuer =
00344         tx.get_view(this->network.jwt_public_signing_key_issuer);
00345 
00346       key_issuer->foreach(
00347         [&issuer, &keys, &key_issuer](const auto& k, const auto& v) {
00348           if (v == issuer)
00349           {
00350             keys->remove(k);
00351             key_issuer->remove(k);
00352           }
00353           return true;
00354         });
00355     }
00356 
00357     bool set_jwt_public_signing_keys(
00358       kv::Tx& tx,
00359       ObjectId proposal_id,
00360       std::string issuer,
00361       const JwtIssuerMetadata& issuer_metadata,
00362       const JsonWebKeySet& jwks)
00363     {
00364       auto keys = tx.get_view(this->network.jwt_public_signing_keys);
00365       auto key_issuer =
00366         tx.get_view(this->network.jwt_public_signing_key_issuer);
00367 
00368       auto log_prefix = proposal_id != INVALID_ID ?
00369         fmt::format("Proposal {}", proposal_id) :
00370         "JWT key auto-refresh";
00371 
00372       // add keys
00373       if (jwks.keys.empty())
00374       {
00375         LOG_FAIL_FMT("{}: JWKS has no keys", log_prefix, proposal_id);
00376         return false;
00377       }
00378       std::map<std::string, std::vector<uint8_t>> new_keys;
00379       for (auto& jwk : jwks.keys)
00380       {
00381         if (keys->has(jwk.kid) && key_issuer->get(jwk.kid).value() != issuer)
00382         {
00383           LOG_FAIL_FMT(
00384             "{}: key id {} already added for different issuer",
00385             log_prefix,
00386             jwk.kid);
00387           return false;
00388         }
00389         if (jwk.x5c.empty())
00390         {
00391           LOG_FAIL_FMT("{}: JWKS is invalid (empty x5c)", log_prefix);
00392           return false;
00393         }
00394 
00395         auto& der_base64 = jwk.x5c[0];
00396         ccf::Cert der;
00397         try
00398         {
00399           der = tls::raw_from_b64(der_base64);
00400         }
00401         catch (const std::invalid_argument& e)
00402         {
00403           LOG_FAIL_FMT(
00404             "{}: Could not parse x5c of key id {}: {}",
00405             log_prefix,
00406             jwk.kid,
00407             e.what());
00408           return false;
00409         }
00410 
00411         std::map<std::string, std::vector<uint8_t>> claims;
00412         bool has_key_policy_sgx_claims =
00413           issuer_metadata.key_policy.has_value() &&
00414           issuer_metadata.key_policy.value().sgx_claims.has_value() &&
00415           !issuer_metadata.key_policy.value().sgx_claims.value().empty();
00416         if (
00417           issuer_metadata.key_filter == JwtIssuerKeyFilter::SGX ||
00418           has_key_policy_sgx_claims)
00419         {
00420           oe_verifier_initialize();
00421           oe_verify_attestation_certificate_with_evidence(
00422             der.data(),
00423             der.size(),
00424             oe_verify_attestation_certificate_with_evidence_cb,
00425             &claims);
00426         }
00427 
00428         if (
00429           issuer_metadata.key_filter == JwtIssuerKeyFilter::SGX &&
00430           claims.empty())
00431         {
00432           LOG_INFO_FMT(
00433             "{}: Skipping JWT signing key with kid {} (not OE "
00434             "attested)",
00435             log_prefix,
00436             jwk.kid);
00437           continue;
00438         }
00439 
00440         if (has_key_policy_sgx_claims)
00441         {
00442           for (auto& [claim_name, expected_claim_val_hex] :
00443                issuer_metadata.key_policy.value().sgx_claims.value())
00444           {
00445             if (claims.find(claim_name) == claims.end())
00446             {
00447               LOG_FAIL_FMT(
00448                 "{}: JWKS kid {} is missing the {} SGX claim",
00449                 log_prefix,
00450                 jwk.kid,
00451                 claim_name);
00452               return false;
00453             }
00454             auto& actual_claim_val = claims[claim_name];
00455             auto actual_claim_val_hex =
00456               fmt::format("{:02x}", fmt::join(actual_claim_val, ""));
00457             if (expected_claim_val_hex != actual_claim_val_hex)
00458             {
00459               LOG_FAIL_FMT(
00460                 "{}: JWKS kid {} has a mismatching {} SGX claim",
00461                 log_prefix,
00462                 jwk.kid,
00463                 claim_name);
00464               return false;
00465             }
00466           }
00467         }
00468         else
00469         {
00470           try
00471           {
00472             tls::check_is_cert(der);
00473           }
00474           catch (std::invalid_argument& exc)
00475           {
00476             LOG_FAIL_FMT(
00477               "{}: JWKS kid {} has an invalid X.509 certificate: {}",
00478               log_prefix,
00479               jwk.kid,
00480               exc.what());
00481             return false;
00482           }
00483         }
00484         LOG_INFO_FMT(
00485           "{}: Storing JWT signing key with kid {}", log_prefix, jwk.kid);
00486         new_keys.emplace(jwk.kid, der);
00487       }
00488       if (new_keys.empty())
00489       {
00490         LOG_FAIL_FMT("{}: no keys left after applying filter", log_prefix);
00491         return false;
00492       }
00493 
00494       remove_jwt_keys(tx, issuer);
00495       for (auto& [kid, der] : new_keys)
00496       {
00497         keys->put(kid, der);
00498         key_issuer->put(kid, issuer);
00499       }
00500 
00501       return true;
00502     }
00503 
00504     void remove_endpoints(kv::Tx& tx)
00505     {
00506       auto endpoints_view =
00507         tx.get_view<ccf::endpoints::EndpointsMap>(ccf::Tables::ENDPOINTS);
00508       endpoints_view->foreach([&endpoints_view](const auto& k, const auto&) {
00509         endpoints_view->remove(k);
00510         return true;
00511       });
00512     }
00513 
00514     bool add_new_code_id(
00515       kv::Tx& tx,
00516       const CodeDigest& new_code_id,
00517       CodeIDs& code_id_table,
00518       ObjectId proposal_id)
00519     {
00520       auto code_ids = tx.get_view(code_id_table);
00521       auto existing_code_id = code_ids->get(new_code_id);
00522       if (existing_code_id)
00523       {
00524         LOG_FAIL_FMT(
00525           "Proposal {}: Code signature already exists with digest: {:02x}",
00526           proposal_id,
00527           fmt::join(new_code_id, ""));
00528         return false;
00529       }
00530       code_ids->put(new_code_id, CodeStatus::ALLOWED_TO_JOIN);
00531       return true;
00532     }
00533 
00534     bool retire_code_id(
00535       kv::Tx& tx,
00536       const CodeDigest& code_id,
00537       CodeIDs& code_id_table,
00538       ObjectId proposal_id)
00539     {
00540       auto code_ids = tx.get_view(code_id_table);
00541       auto existing_code_id = code_ids->get(code_id);
00542       if (!existing_code_id)
00543       {
00544         LOG_FAIL_FMT(
00545           "Proposal {}: No such code id in table: {:02x}",
00546           proposal_id,
00547           fmt::join(code_id, ""));
00548         return false;
00549       }
00550       code_ids->remove(code_id);
00551       return true;
00552     }
00553 
00554     //! Table of functions that proposal scripts can propose to invoke
00555     const std::unordered_map<
00556       std::string,
00557       std::function<bool(ObjectId, kv::Tx&, const nlohmann::json&)>>
00558       hardcoded_funcs = {
00559         // set the js application script
00560         {"set_js_app",
00561          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00562            const std::string app = args;
00563            set_js_scripts(tx, lua::Interpreter().invoke<nlohmann::json>(app));
00564            return true;
00565          }},
00566         // deploy the js application bundle
00567         {"deploy_js_app",
00568          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00569            const auto parsed = args.get<DeployJsApp>();
00570            return deploy_js_app(tx, parsed.bundle);
00571          }},
00572         // undeploy/remove the js application
00573         {"remove_js_app",
00574          [this](ObjectId, kv::Tx& tx, const nlohmann::json&) {
00575            return remove_js_app(tx);
00576          }},
00577         // add/update a module
00578         {"set_module",
00579          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00580            const auto parsed = args.get<SetModule>();
00581            return set_module(tx, parsed.name, parsed.module);
00582          }},
00583         // remove a module
00584         {"remove_module",
00585          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00586            const auto name = args.get<std::string>();
00587            return remove_module(tx, name);
00588          }},
00589         // add a new member
00590         {"new_member",
00591          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00592            const auto parsed = args.get<MemberPubInfo>();
00593            GenesisGenerator g(this->network, tx);
00594            g.add_member(parsed);
00595 
00596            return true;
00597          }},
00598         // retire an existing member
00599         {"retire_member",
00600          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00601            const auto member_id = args.get<MemberId>();
00602 
00603            GenesisGenerator g(this->network, tx);
00604 
00605            auto member_info = g.get_member_info(member_id);
00606            if (!member_info.has_value())
00607            {
00608              return false;
00609            }
00610 
00611            if (!g.retire_member(member_id))
00612            {
00613              return false;
00614            }
00615 
00616            if (
00617              member_info->status == MemberStatus::ACTIVE &&
00618              member_info->is_recovery())
00619            {
00620              // A retired member with recovery share should not have access to
00621              // the private ledger going forward so rekey ledger, issuing new
00622              // share to remaining active members
00623              if (!node.rekey_ledger(tx))
00624              {
00625                return false;
00626              }
00627            }
00628 
00629            return true;
00630          }},
00631         {"set_member_data",
00632          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00633            const auto parsed = args.get<SetMemberData>();
00634            auto members_view = tx.get_view(this->network.members);
00635            auto member_info = members_view->get(parsed.member_id);
00636            if (!member_info.has_value())
00637            {
00638              LOG_FAIL_FMT(
00639                "Proposal {}: {} is not a valid member ID",
00640                proposal_id,
00641                parsed.member_id);
00642              return false;
00643            }
00644 
00645            member_info->member_data = parsed.member_data;
00646            members_view->put(parsed.member_id, member_info.value());
00647            return true;
00648          }},
00649         {"new_user",
00650          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00651            const auto user_info = args.get<ccf::UserInfo>();
00652 
00653            GenesisGenerator g(this->network, tx);
00654            g.add_user(user_info);
00655 
00656            return true;
00657          }},
00658         {"remove_user",
00659          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00660            const UserId user_id = args;
00661 
00662            GenesisGenerator g(this->network, tx);
00663            auto r = g.remove_user(user_id);
00664            if (!r)
00665            {
00666              LOG_FAIL_FMT(
00667                "Proposal {}: {} is not a valid user ID", proposal_id, user_id);
00668            }
00669 
00670            return r;
00671          }},
00672         {"set_user_data",
00673          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00674            const auto parsed = args.get<SetUserData>();
00675            auto users_view = tx.get_view(this->network.users);
00676            auto user_info = users_view->get(parsed.user_id);
00677            if (!user_info.has_value())
00678            {
00679              LOG_FAIL_FMT(
00680                "Proposal {}: {} is not a valid user ID",
00681                proposal_id,
00682                parsed.user_id);
00683              return false;
00684            }
00685 
00686            user_info->user_data = parsed.user_data;
00687            users_view->put(parsed.user_id, user_info.value());
00688            return true;
00689          }},
00690         {"set_ca_cert",
00691          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00692            const auto parsed = args.get<SetCaCert>();
00693            auto ca_certs = tx.get_view(this->network.ca_certs);
00694            std::vector<uint8_t> cert_der;
00695            try
00696            {
00697              cert_der = tls::cert_pem_to_der(parsed.cert);
00698            }
00699            catch (const std::invalid_argument& e)
00700            {
00701              LOG_FAIL_FMT(
00702                "Proposal {}: certificate is not a valid X.509 certificate in "
00703                "PEM format: {}",
00704                proposal_id,
00705                e.what());
00706              return false;
00707            }
00708            ca_certs->put(parsed.name, cert_der);
00709            return true;
00710          }},
00711         {"remove_ca_cert",
00712          [this](ObjectId, kv::Tx& tx, const nlohmann::json& args) {
00713            const auto cert_name = args.get<std::string>();
00714            auto ca_certs = tx.get_view(this->network.ca_certs);
00715            ca_certs->remove(cert_name);
00716            return true;
00717          }},
00718         {"set_jwt_issuer",
00719          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00720            const auto parsed = args.get<SetJwtIssuer>();
00721            auto issuers = tx.get_view(this->network.jwt_issuers);
00722            auto ca_certs = tx.get_read_only_view(this->network.ca_certs);
00723 
00724            if (parsed.auto_refresh)
00725            {
00726              if (!parsed.ca_cert_name.has_value())
00727              {
00728                LOG_FAIL_FMT(
00729                  "Proposal {}: ca_cert_name is missing but required if "
00730                  "auto_refresh is true",
00731                  proposal_id);
00732                return false;
00733              }
00734              if (!ca_certs->has(parsed.ca_cert_name.value()))
00735              {
00736                LOG_FAIL_FMT(
00737                  "Proposal {}: No CA cert found with name '{}'",
00738                  proposal_id,
00739                  parsed.ca_cert_name.value());
00740                return false;
00741              }
00742              http::URL issuer_url;
00743              try
00744              {
00745                issuer_url = http::parse_url_full(parsed.issuer);
00746              }
00747              catch (const std::runtime_error&)
00748              {
00749                LOG_FAIL_FMT(
00750                  "Proposal {}: issuer must be a URL if auto_refresh is true",
00751                  proposal_id);
00752                return false;
00753              }
00754              if (issuer_url.scheme != "https")
00755              {
00756                LOG_FAIL_FMT(
00757                  "Proposal {}: issuer must be a URL starting with https:// if "
00758                  "auto_refresh is true",
00759                  proposal_id);
00760                return false;
00761              }
00762              if (!issuer_url.query.empty() || !issuer_url.fragment.empty())
00763              {
00764                LOG_FAIL_FMT(
00765                  "Proposal {}: issuer must be a URL without query/fragment if "
00766                  "auto_refresh is true",
00767                  proposal_id);
00768                return false;
00769              }
00770            }
00771 
00772            bool success = true;
00773            if (parsed.jwks.has_value())
00774            {
00775              success = set_jwt_public_signing_keys(
00776                tx, proposal_id, parsed.issuer, parsed, parsed.jwks.value());
00777            }
00778            if (success)
00779            {
00780              issuers->put(parsed.issuer, parsed);
00781            }
00782 
00783            return success;
00784          }},
00785         {"remove_jwt_issuer",
00786          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00787            const auto parsed = args.get<RemoveJwtIssuer>();
00788            const auto issuer = parsed.issuer;
00789            auto issuers = tx.get_view(this->network.jwt_issuers);
00790 
00791            if (!issuers->remove(issuer))
00792            {
00793              LOG_FAIL_FMT(
00794                "Proposal {}: {} is not a valid issuer", proposal_id, issuer);
00795              return false;
00796            }
00797 
00798            remove_jwt_keys(tx, issuer);
00799 
00800            return true;
00801          }},
00802         {"set_jwt_public_signing_keys",
00803          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00804            const auto parsed = args.get<SetJwtPublicSigningKeys>();
00805 
00806            auto issuers = tx.get_view(this->network.jwt_issuers);
00807            auto issuer_metadata_ = issuers->get(parsed.issuer);
00808            if (!issuer_metadata_.has_value())
00809            {
00810              LOG_FAIL_FMT(
00811                "Proposal {}: {} is not a valid issuer",
00812                proposal_id,
00813                parsed.issuer);
00814              return false;
00815            }
00816            auto& issuer_metadata = issuer_metadata_.value();
00817 
00818            return set_jwt_public_signing_keys(
00819              tx, proposal_id, parsed.issuer, issuer_metadata, parsed.jwks);
00820          }},
00821         // accept a node
00822         {"trust_node",
00823          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00824            const auto id = args.get<NodeId>();
00825            auto nodes = tx.get_view(this->network.nodes);
00826            auto node_info = nodes->get(id);
00827            if (!node_info.has_value())
00828            {
00829              LOG_FAIL_FMT(
00830                "Proposal {}: Node {} does not exist", proposal_id, id);
00831              return false;
00832            }
00833            if (node_info->status == NodeStatus::RETIRED)
00834            {
00835              LOG_FAIL_FMT(
00836                "Proposal {}: Node {} is already retired", proposal_id, id);
00837              return false;
00838            }
00839            node_info->status = NodeStatus::TRUSTED;
00840            nodes->put(id, node_info.value());
00841            LOG_INFO_FMT("Node {} is now {}", id, node_info->status);
00842            return true;
00843          }},
00844         // retire a node
00845         {"retire_node",
00846          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00847            const auto id = args.get<NodeId>();
00848            auto nodes = tx.get_view(this->network.nodes);
00849            auto node_info = nodes->get(id);
00850            if (!node_info.has_value())
00851            {
00852              LOG_FAIL_FMT(
00853                "Proposal {}: Node {} does not exist", proposal_id, id);
00854              return false;
00855            }
00856            if (node_info->status == NodeStatus::RETIRED)
00857            {
00858              LOG_FAIL_FMT(
00859                "Proposal {}: Node {} is already retired", proposal_id, id);
00860              return false;
00861            }
00862            node_info->status = NodeStatus::RETIRED;
00863            nodes->put(id, node_info.value());
00864            LOG_INFO_FMT("Node {} is now {}", id, node_info->status);
00865            return true;
00866          }},
00867         // accept new node code ID
00868         {"new_node_code",
00869          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00870            return this->add_new_code_id(
00871              tx,
00872              args.get<CodeDigest>(),
00873              this->network.node_code_ids,
00874              proposal_id);
00875          }},
00876         // retire node code ID
00877         {"retire_node_code",
00878          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00879            return this->retire_code_id(
00880              tx,
00881              args.get<CodeDigest>(),
00882              this->network.node_code_ids,
00883              proposal_id);
00884          }},
00885         {"accept_recovery",
00886          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json&) {
00887            if (node.is_part_of_public_network())
00888            {
00889              const auto accept_recovery = node.accept_recovery(tx);
00890              if (!accept_recovery)
00891              {
00892                LOG_FAIL_FMT("Proposal {}: Accept recovery failed", proposal_id);
00893              }
00894              return accept_recovery;
00895            }
00896            else
00897            {
00898              LOG_FAIL_FMT(
00899                "Proposal {}: Node is not part of public network", proposal_id);
00900              return false;
00901            }
00902          }},
00903         {"open_network",
00904          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json&) {
00905            // On network open, the service checks that a sufficient number of
00906            // recovery members have become active. If so, recovery shares are
00907            // allocated to each recovery member
00908            try
00909            {
00910              share_manager.issue_shares(tx);
00911            }
00912            catch (const std::logic_error& e)
00913            {
00914              LOG_FAIL_FMT(
00915                "Proposal {}: Issuing recovery shares failed when opening the "
00916                "network: {}",
00917                proposal_id,
00918                e.what());
00919              return false;
00920            }
00921 
00922            GenesisGenerator g(this->network, tx);
00923            const auto network_opened = g.open_service();
00924            if (!network_opened)
00925            {
00926              LOG_FAIL_FMT("Proposal {}: Open network failed", proposal_id);
00927            }
00928            else
00929            {
00930              node.open_user_frontend();
00931            }
00932            return network_opened;
00933          }},
00934         {"rekey_ledger",
00935          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json&) {
00936            const auto ledger_rekeyed = node.rekey_ledger(tx);
00937            if (!ledger_rekeyed)
00938            {
00939              LOG_FAIL_FMT("Proposal {}: Ledger rekey failed", proposal_id);
00940            }
00941            return ledger_rekeyed;
00942          }},
00943         {"update_recovery_shares",
00944          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json&) {
00945            try
00946            {
00947              share_manager.issue_shares(tx);
00948            }
00949            catch (const std::logic_error& e)
00950            {
00951              LOG_FAIL_FMT(
00952                "Proposal {}: Updating recovery shares failed: {}",
00953                proposal_id,
00954                e.what());
00955              return false;
00956            }
00957            return true;
00958          }},
00959         {"set_recovery_threshold",
00960          [this](ObjectId proposal_id, kv::Tx& tx, const nlohmann::json& args) {
00961            const auto new_recovery_threshold = args.get<size_t>();
00962 
00963            GenesisGenerator g(this->network, tx);
00964 
00965            if (new_recovery_threshold == g.get_recovery_threshold())
00966            {
00967              // If the recovery threshold is the same as before, return with no
00968              // effect
00969              return true;
00970            }
00971 
00972            if (!g.set_recovery_threshold(new_recovery_threshold))
00973            {
00974              return false;
00975            }
00976 
00977            // Update recovery shares (same number of shares)
00978            try
00979            {
00980              share_manager.issue_shares(tx);
00981            }
00982            catch (const std::logic_error& e)
00983            {
00984              LOG_FAIL_FMT(
00985                "Proposal {}: Setting recovery threshold failed: {}",
00986                proposal_id,
00987                e.what());
00988              return false;
00989            }
00990            return true;
00991          }},
00992       };
00993 
00994     ProposalInfo complete_proposal(
00995       kv::Tx& tx, const ObjectId proposal_id, Proposal& proposal)
00996     {
00997       if (proposal.state != ProposalState::OPEN)
00998       {
00999         throw std::logic_error(fmt::format(
01000           "Cannot complete non-open proposal - current state is {}",
01001           proposal.state));
01002       }
01003 
01004       auto proposals = tx.get_view(this->network.proposals);
01005 
01006       // run proposal script
01007       const auto proposed_calls = tsr.run<nlohmann::json>(
01008         tx,
01009         {proposal.script,
01010          {}, // can't write
01011          WlIds::MEMBER_CAN_READ,
01012          get_script(tx, GovScriptIds::ENV_PROPOSAL)},
01013         // vvv arguments to script vvv
01014         proposal.parameter);
01015 
01016       nlohmann::json votes = nlohmann::json::object();
01017       // Collect all member votes
01018       for (const auto& vote : proposal.votes)
01019       {
01020         // valid voter
01021         if (!check_member_active(tx, vote.first))
01022         {
01023           continue;
01024         }
01025 
01026         // does the voter agree?
01027         votes[std::to_string(vote.first)] = tsr.run<bool>(
01028           tx,
01029           {vote.second,
01030            {}, // can't write
01031            WlIds::MEMBER_CAN_READ,
01032            {}},
01033           proposed_calls);
01034       }
01035 
01036       const auto pass = tsr.run<int>(
01037         tx,
01038         {get_script(tx, GovScriptIds::PASS),
01039          {}, // can't write
01040          WlIds::MEMBER_CAN_READ,
01041          {}},
01042         // vvv arguments to script vvv
01043         proposed_calls,
01044         votes,
01045         proposal.proposer);
01046 
01047       switch (pass)
01048       {
01049         case CompletionResult::PASSED:
01050         {
01051           // vote passed, go on to update the state
01052           break;
01053         }
01054         case CompletionResult::PENDING:
01055         {
01056           // vote is pending, return false but do not update state
01057           return get_proposal_info(proposal_id, proposal);
01058         }
01059         case CompletionResult::REJECTED:
01060         {
01061           // vote unsuccessful, update the proposal's state
01062           proposal.state = ProposalState::REJECTED;
01063           proposals->put(proposal_id, proposal);
01064           return get_proposal_info(proposal_id, proposal);
01065         }
01066         default:
01067         {
01068           throw std::logic_error(fmt::format(
01069             "Invalid completion result ({}) for proposal {}",
01070             pass,
01071             proposal_id));
01072         }
01073       };
01074 
01075       // execute proposed calls
01076       ProposedCalls pc = proposed_calls;
01077       for (const auto& call : pc)
01078       {
01079         // proposing a hardcoded C++ function?
01080         const auto f = hardcoded_funcs.find(call.func);
01081         if (f != hardcoded_funcs.end())
01082         {
01083           if (!f->second(proposal_id, tx, call.args))
01084           {
01085             proposal.state = ProposalState::FAILED;
01086             proposals->put(proposal_id, proposal);
01087             return get_proposal_info(proposal_id, proposal);
01088           }
01089           continue;
01090         }
01091 
01092         // proposing a script function?
01093         const auto s = tx.get_view(network.gov_scripts)->get(call.func);
01094         if (!s.has_value())
01095         {
01096           continue;
01097         }
01098         tsr.run<void>(
01099           tx,
01100           {s.value(),
01101            WlIds::MEMBER_CAN_PROPOSE, // can write!
01102            {},
01103            {}},
01104           call.args);
01105       }
01106 
01107       // if the vote was successful, update the proposal's state
01108       proposal.state = ProposalState::ACCEPTED;
01109       proposals->put(proposal_id, proposal);
01110 
01111       return get_proposal_info(proposal_id, proposal);
01112     }
01113 
01114     bool check_member_active(kv::ReadOnlyTx& tx, MemberId id)
01115     {
01116       return check_member_status(tx, id, {MemberStatus::ACTIVE});
01117     }
01118 
01119     bool check_member_accepted(kv::ReadOnlyTx& tx, MemberId id)
01120     {
01121       return check_member_status(
01122         tx, id, {MemberStatus::ACTIVE, MemberStatus::ACCEPTED});
01123     }
01124 
01125     bool check_member_status(
01126       kv::ReadOnlyTx& tx,
01127       MemberId id,
01128       std::initializer_list<MemberStatus> allowed)
01129     {
01130       auto member = tx.get_read_only_view(this->network.members)->get(id);
01131       if (!member)
01132       {
01133         return false;
01134       }
01135       for (const auto s : allowed)
01136       {
01137         if (member->status == s)
01138         {
01139           return true;
01140         }
01141       }
01142       return false;
01143     }
01144 
01145     void record_voting_history(
01146       kv::Tx& tx, MemberId caller_id, const SignedReq& signed_request)
01147     {
01148       auto governance_history = tx.get_view(network.governance_history);
01149       governance_history->put(caller_id, {signed_request});
01150     }
01151 
01152     static ProposalInfo get_proposal_info(
01153       ObjectId proposal_id, const Proposal& proposal)
01154     {
01155       return ProposalInfo{proposal_id, proposal.proposer, proposal.state};
01156     }
01157 
01158     template <typename T>
01159     bool get_path_param(
01160       const enclave::PathParams& params,
01161       const std::string& param_name,
01162       T& value,
01163       std::string& error)
01164     {
01165       const auto it = params.find(param_name);
01166       if (it == params.end())
01167       {
01168         error = fmt::format("No parameter named '{}' in path", param_name);
01169         return false;
01170       }
01171 
01172       const auto param_s = it->second;
01173       const auto [p, ec] =
01174         std::from_chars(param_s.data(), param_s.data() + param_s.size(), value);
01175       if (ec != std::errc())
01176       {
01177         error = fmt::format(
01178           "Unable to parse path parameter '{}' as a {}", param_s, param_name);
01179         return false;
01180       }
01181 
01182       return true;
01183     }
01184 
01185     bool get_proposal_id_from_path(
01186       const enclave::PathParams& params,
01187       ObjectId& proposal_id,
01188       std::string& error)
01189     {
01190       return get_path_param(params, "proposal_id", proposal_id, error);
01191     }
01192 
01193     bool get_member_id_from_path(
01194       const enclave::PathParams& params,
01195       MemberId& member_id,
01196       std::string& error)
01197     {
01198       return get_path_param(params, "member_id", member_id, error);
01199     }
01200 
01201     NetworkTables& network;
01202     AbstractNodeState& node;
01203     ShareManager& share_manager;
01204     const MemberTsr tsr;
01205 
01206   public:
01207     MemberEndpoints(
01208       NetworkTables& network,
01209       AbstractNodeState& node,
01210       ShareManager& share_manager) :
01211       CommonEndpointRegistry(
01212         get_actor_prefix(ActorsType::members),
01213         *network.tables,
01214         Tables::MEMBER_CERT_DERS,
01215         Tables::MEMBER_DIGESTS),
01216       network(network),
01217       node(node),
01218       share_manager(share_manager),
01219       tsr(network)
01220     {
01221       openapi_info.title = "CCF Governance API";
01222       openapi_info.description =
01223         "This API is used to submit and query proposals which affect CCF's "
01224         "public governance tables.";
01225     }
01226 
01227     static MemberId get_caller_member_id(CommandEndpointContext& ctx)
01228     {
01229       if (
01230         const auto* sig_ident =
01231           ctx.try_get_caller<ccf::MemberSignatureAuthnIdentity>())
01232       {
01233         return sig_ident->member_id;
01234       }
01235       else if (
01236         const auto* cert_ident =
01237           ctx.try_get_caller<ccf::MemberCertAuthnIdentity>())
01238       {
01239         return cert_ident->member_id;
01240       }
01241 
01242       LOG_FATAL_FMT("Request was not authenticated with a member auth policy");
01243       return INVALID_ID;
01244     }
01245 
01246     void init_handlers(kv::Store& tables_) override
01247     {
01248       CommonEndpointRegistry::init_handlers(tables_);
01249 
01250       const AuthnPolicies member_sig_only = {member_signature_auth_policy};
01251 
01252       const AuthnPolicies member_cert_or_sig = {member_cert_auth_policy,
01253                                                 member_signature_auth_policy};
01254 
01255       auto read = [this](EndpointContext& ctx, nlohmann::json&& params) {
01256         const auto member_id = get_caller_member_id(ctx);
01257         if (!check_member_status(
01258               ctx.tx,
01259               member_id,
01260               {MemberStatus::ACTIVE, MemberStatus::ACCEPTED}))
01261         {
01262           return make_error(
01263             HTTP_STATUS_FORBIDDEN,
01264             ccf::errors::AuthorizationFailed,
01265             "Member is not active or accepted.");
01266         }
01267 
01268         const auto in = params.get<KVRead::In>();
01269 
01270         const ccf::Script read_script(R"xxx(
01271         local tables, table_name, key = ...
01272         return tables[table_name]:get(key) or {}
01273         )xxx");
01274 
01275         auto value = tsr.run<nlohmann::json>(
01276           ctx.tx,
01277           {read_script, {}, WlIds::MEMBER_CAN_READ, {}},
01278           in.table,
01279           in.key);
01280         if (value.empty())
01281         {
01282           return make_error(
01283             HTTP_STATUS_BAD_REQUEST,
01284             ccf::errors::KeyNotFound,
01285             fmt::format(
01286               "Key {} does not exist in table {}.", in.key.dump(), in.table));
01287         }
01288 
01289         return make_success(value);
01290       };
01291       make_endpoint("read", HTTP_POST, json_adapter(read), member_cert_or_sig)
01292         // This can be executed locally, but can't currently take ReadOnlyTx due
01293         // to restrictions in our lua wrappers
01294         .set_forwarding_required(ForwardingRequired::Sometimes)
01295         .set_auto_schema<KVRead>()
01296         .install();
01297 
01298       auto query = [this](EndpointContext& ctx, nlohmann::json&& params) {
01299         const auto member_id = get_caller_member_id(ctx);
01300         if (!check_member_accepted(ctx.tx, member_id))
01301         {
01302           return make_error(
01303             HTTP_STATUS_FORBIDDEN,
01304             ccf::errors::AuthorizationFailed,
01305             "Member is not accepted.");
01306         }
01307 
01308         const auto script = params.get<ccf::Script>();
01309         return make_success(tsr.run<nlohmann::json>(
01310           ctx.tx, {script, {}, WlIds::MEMBER_CAN_READ, {}}));
01311       };
01312       make_endpoint("query", HTTP_POST, json_adapter(query), member_cert_or_sig)
01313         // This can be executed locally, but can't currently take ReadOnlyTx due
01314         // to restrictions in our lua wrappers
01315         .set_forwarding_required(ForwardingRequired::Sometimes)
01316         .set_auto_schema<Script, nlohmann::json>()
01317         .install();
01318 
01319       auto propose = [this](EndpointContext& ctx, nlohmann::json&& params) {
01320         const auto& caller_identity =
01321           ctx.get_caller<ccf::MemberSignatureAuthnIdentity>();
01322         if (!check_member_active(ctx.tx, caller_identity.member_id))
01323         {
01324           return make_error(
01325             HTTP_STATUS_FORBIDDEN,
01326             ccf::errors::AuthorizationFailed,
01327             "Member is not active.");
01328         }
01329 
01330         const auto in = params.get<Propose::In>();
01331         const auto proposal_id = get_next_id(
01332           ctx.tx.get_view(this->network.values), ValueIds::NEXT_PROPOSAL_ID);
01333         Proposal proposal(in.script, in.parameter, caller_identity.member_id);
01334 
01335         auto proposals = ctx.tx.get_view(this->network.proposals);
01336         proposals->put(proposal_id, proposal);
01337 
01338         record_voting_history(
01339           ctx.tx, caller_identity.member_id, caller_identity.signed_request);
01340 
01341         return make_success(
01342           Propose::Out{complete_proposal(ctx.tx, proposal_id, proposal)});
01343       };
01344       make_endpoint(
01345         "proposals", HTTP_POST, json_adapter(propose), member_sig_only)
01346         .set_auto_schema<Propose>()
01347         .install();
01348 
01349       auto get_proposal =
01350         [this](ReadOnlyEndpointContext& ctx, nlohmann::json&&) {
01351           const auto member_id = get_caller_member_id(ctx);
01352           if (!check_member_active(ctx.tx, member_id))
01353           {
01354             return make_error(
01355               HTTP_STATUS_FORBIDDEN,
01356               ccf::errors::AuthorizationFailed,
01357               "Member is not active.");
01358           }
01359 
01360           ObjectId proposal_id;
01361           std::string error;
01362           if (!get_proposal_id_from_path(
01363                 ctx.rpc_ctx->get_request_path_params(), proposal_id, error))
01364           {
01365             return make_error(
01366               HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidResourceName, error);
01367           }
01368 
01369           auto proposals = ctx.tx.get_read_only_view(this->network.proposals);
01370           auto proposal = proposals->get(proposal_id);
01371 
01372           if (!proposal)
01373           {
01374             return make_error(
01375               HTTP_STATUS_BAD_REQUEST,
01376               ccf::errors::ProposalNotFound,
01377               fmt::format("Proposal {} does not exist.", proposal_id));
01378           }
01379 
01380           return make_success(proposal.value());
01381         };
01382       make_read_only_endpoint(
01383         "proposals/{proposal_id}",
01384         HTTP_GET,
01385         json_read_only_adapter(get_proposal),
01386         member_cert_or_sig)
01387         .set_auto_schema<void, Proposal>()
01388         .install();
01389 
01390       auto withdraw = [this](EndpointContext& ctx, nlohmann::json&&) {
01391         const auto& caller_identity =
01392           ctx.get_caller<ccf::MemberSignatureAuthnIdentity>();
01393         if (!check_member_active(ctx.tx, caller_identity.member_id))
01394         {
01395           return make_error(
01396             HTTP_STATUS_FORBIDDEN,
01397             ccf::errors::AuthorizationFailed,
01398             "Member is not active.");
01399         }
01400 
01401         ObjectId proposal_id;
01402         std::string error;
01403         if (!get_proposal_id_from_path(
01404               ctx.rpc_ctx->get_request_path_params(), proposal_id, error))
01405         {
01406           return make_error(
01407             HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidResourceName, error);
01408         }
01409 
01410         auto proposals = ctx.tx.get_view(this->network.proposals);
01411         auto proposal = proposals->get(proposal_id);
01412 
01413         if (!proposal)
01414         {
01415           return make_error(
01416             HTTP_STATUS_BAD_REQUEST,
01417             ccf::errors::ProposalNotFound,
01418             fmt::format("Proposal {} does not exist.", proposal_id));
01419         }
01420 
01421         if (proposal->proposer != caller_identity.member_id)
01422         {
01423           return make_error(
01424             HTTP_STATUS_FORBIDDEN,
01425             ccf::errors::AuthorizationFailed,
01426             fmt::format(
01427               "Proposal {} can only be withdrawn by proposer {}, not caller "
01428               "{}.",
01429               proposal_id,
01430               proposal->proposer,
01431               caller_identity.member_id));
01432         }
01433 
01434         if (proposal->state != ProposalState::OPEN)
01435         {
01436           return make_error(
01437             HTTP_STATUS_BAD_REQUEST,
01438             ccf::errors::ProposalNotOpen,
01439             fmt::format(
01440               "Proposal {} is currently in state {} - only {} proposals can be "
01441               "withdrawn.",
01442               proposal_id,
01443               proposal->state,
01444               ProposalState::OPEN));
01445         }
01446 
01447         proposal->state = ProposalState::WITHDRAWN;
01448         proposals->put(proposal_id, proposal.value());
01449         record_voting_history(
01450           ctx.tx, caller_identity.member_id, caller_identity.signed_request);
01451 
01452         return make_success(get_proposal_info(proposal_id, proposal.value()));
01453       };
01454       make_endpoint(
01455         "proposals/{proposal_id}/withdraw",
01456         HTTP_POST,
01457         json_adapter(withdraw),
01458         member_sig_only)
01459         .set_auto_schema<void, ProposalInfo>()
01460         .install();
01461 
01462       auto vote = [this](EndpointContext& ctx, nlohmann::json&& params) {
01463         const auto& caller_identity =
01464           ctx.get_caller<ccf::MemberSignatureAuthnIdentity>();
01465 
01466         if (!check_member_active(ctx.tx, caller_identity.member_id))
01467         {
01468           return make_error(
01469             HTTP_STATUS_FORBIDDEN,
01470             ccf::errors::AuthorizationFailed,
01471             "Member is not active.");
01472         }
01473 
01474         ObjectId proposal_id;
01475         std::string error;
01476         if (!get_proposal_id_from_path(
01477               ctx.rpc_ctx->get_request_path_params(), proposal_id, error))
01478         {
01479           return make_error(
01480             HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidResourceName, error);
01481         }
01482 
01483         auto proposals = ctx.tx.get_view(this->network.proposals);
01484         auto proposal = proposals->get(proposal_id);
01485         if (!proposal)
01486         {
01487           return make_error(
01488             HTTP_STATUS_NOT_FOUND,
01489             ccf::errors::ProposalNotFound,
01490             fmt::format("Proposal {} does not exist.", proposal_id));
01491         }
01492 
01493         if (proposal->state != ProposalState::OPEN)
01494         {
01495           return make_error(
01496             HTTP_STATUS_BAD_REQUEST,
01497             ccf::errors::ProposalNotOpen,
01498             fmt::format(
01499               "Proposal {} is currently in state {} - only {} proposals can "
01500               "receive votes.",
01501               proposal_id,
01502               proposal->state,
01503               ProposalState::OPEN));
01504         }
01505 
01506         const auto vote = params.get<Vote>();
01507         if (
01508           proposal->votes.find(caller_identity.member_id) !=
01509           proposal->votes.end())
01510         {
01511           return make_error(
01512             HTTP_STATUS_BAD_REQUEST,
01513             ccf::errors::VoteAlreadyExists,
01514             "Vote already submitted.");
01515         }
01516         proposal->votes[caller_identity.member_id] = vote.ballot;
01517         proposals->put(proposal_id, proposal.value());
01518 
01519         record_voting_history(
01520           ctx.tx, caller_identity.member_id, caller_identity.signed_request);
01521 
01522         return make_success(
01523           complete_proposal(ctx.tx, proposal_id, proposal.value()));
01524       };
01525       make_endpoint(
01526         "proposals/{proposal_id}/votes",
01527         HTTP_POST,
01528         json_adapter(vote),
01529         member_sig_only)
01530         .set_auto_schema<Vote, ProposalInfo>()
01531         .install();
01532 
01533       auto get_vote = [this](ReadOnlyEndpointContext& ctx, nlohmann::json&&) {
01534         const auto caller_member_id = get_caller_member_id(ctx);
01535         if (!check_member_active(ctx.tx, caller_member_id))
01536         {
01537           return make_error(
01538             HTTP_STATUS_FORBIDDEN,
01539             ccf::errors::AuthorizationFailed,
01540             "Member is not active.");
01541         }
01542 
01543         std::string error;
01544         ObjectId proposal_id;
01545         if (!get_proposal_id_from_path(
01546               ctx.rpc_ctx->get_request_path_params(), proposal_id, error))
01547         {
01548           return make_error(
01549             HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidResourceName, error);
01550         }
01551 
01552         MemberId vote_member_id;
01553         if (!get_member_id_from_path(
01554               ctx.rpc_ctx->get_request_path_params(), vote_member_id, error))
01555         {
01556           return make_error(
01557             HTTP_STATUS_BAD_REQUEST, ccf::errors::InvalidResourceName, error);
01558         }
01559 
01560         auto proposals = ctx.tx.get_read_only_view(this->network.proposals);
01561         auto proposal = proposals->get(proposal_id);
01562         if (!proposal)
01563         {
01564           return make_error(
01565             HTTP_STATUS_NOT_FOUND,
01566             ccf::errors::ProposalNotFound,
01567             fmt::format("Proposal {} does not exist.", proposal_id));
01568         }
01569 
01570         const auto vote_it = proposal->votes.find(vote_member_id);
01571         if (vote_it == proposal->votes.end())
01572         {
01573           return make_error(
01574             HTTP_STATUS_NOT_FOUND,
01575             ccf::errors::VoteNotFound,
01576             fmt::format(
01577               "Member {} has not voted for proposal {}.",
01578               vote_member_id,
01579               proposal_id));
01580         }
01581 
01582         return make_success(vote_it->second);
01583       };
01584       make_read_only_endpoint(
01585         "proposals/{proposal_id}/votes/{member_id}",
01586         HTTP_GET,
01587         json_read_only_adapter(get_vote),
01588         member_cert_or_sig)
01589         .set_auto_schema<void, Vote>()
01590         .install();
01591 
01592       //! A member acknowledges state
01593       auto ack = [this](EndpointContext& ctx, nlohmann::json&& params) {
01594         const auto& caller_identity =
01595           ctx.get_caller<ccf::MemberSignatureAuthnIdentity>();
01596         const auto& signed_request = caller_identity.signed_request;
01597 
01598         auto [ma_view, sig_view, members_view] = ctx.tx.get_view(
01599           this->network.member_acks,
01600           this->network.signatures,
01601           this->network.members);
01602         const auto ma = ma_view->get(caller_identity.member_id);
01603         if (!ma)
01604         {
01605           return make_error(
01606             HTTP_STATUS_FORBIDDEN,
01607             ccf::errors::AuthorizationFailed,
01608             fmt::format(
01609               "No ACK record exists for caller {}.",
01610               caller_identity.member_id));
01611         }
01612 
01613         const auto digest = params.get<StateDigest>();
01614         if (ma->state_digest != digest.state_digest)
01615         {
01616           return make_error(
01617             HTTP_STATUS_BAD_REQUEST,
01618             ccf::errors::StateDigestMismatch,
01619             "Submitted state digest is not valid.");
01620         }
01621 
01622         const auto s = sig_view->get(0);
01623         if (!s)
01624         {
01625           ma_view->put(
01626             caller_identity.member_id, MemberAck({}, signed_request));
01627         }
01628         else
01629         {
01630           ma_view->put(
01631             caller_identity.member_id, MemberAck(s->root, signed_request));
01632         }
01633 
01634         // update member status to ACTIVE
01635         GenesisGenerator g(this->network, ctx.tx);
01636         try
01637         {
01638           g.activate_member(caller_identity.member_id);
01639         }
01640         catch (const std::logic_error& e)
01641         {
01642           return make_error(
01643             HTTP_STATUS_FORBIDDEN,
01644             ccf::errors::AuthorizationFailed,
01645             fmt::format("Error activating new member: {}", e.what()));
01646         }
01647 
01648         auto service_status = g.get_service_status();
01649         if (!service_status.has_value())
01650         {
01651           return make_error(
01652             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01653             ccf::errors::InternalError,
01654             "No service currently available.");
01655         }
01656 
01657         auto member_info = members_view->get(caller_identity.member_id);
01658         if (
01659           service_status.value() == ServiceStatus::OPEN &&
01660           member_info->is_recovery())
01661         {
01662           // When the service is OPEN and the new active member is a recovery
01663           // member, all recovery members are allocated new recovery shares
01664           try
01665           {
01666             share_manager.issue_shares(ctx.tx);
01667           }
01668           catch (const std::logic_error& e)
01669           {
01670             return make_error(
01671               HTTP_STATUS_INTERNAL_SERVER_ERROR,
01672               ccf::errors::InternalError,
01673               fmt::format("Error issuing new recovery shares: {}", e.what()));
01674           }
01675         }
01676         return make_success(true);
01677       };
01678       make_endpoint("ack", HTTP_POST, json_adapter(ack), member_sig_only)
01679         .set_auto_schema<StateDigest, bool>()
01680         .install();
01681 
01682       //! A member asks for a fresher state digest
01683       auto update_state_digest = [this](
01684                                    EndpointContext& ctx, nlohmann::json&&) {
01685         const auto member_id = get_caller_member_id(ctx);
01686         auto [ma_view, sig_view] =
01687           ctx.tx.get_view(this->network.member_acks, this->network.signatures);
01688         auto ma = ma_view->get(member_id);
01689         if (!ma)
01690         {
01691           return make_error(
01692             HTTP_STATUS_FORBIDDEN,
01693             ccf::errors::AuthorizationFailed,
01694             fmt::format("No ACK record exists for caller {}.", member_id));
01695         }
01696 
01697         auto s = sig_view->get(0);
01698         if (s)
01699         {
01700           ma->state_digest = s->root.hex_str();
01701           ma_view->put(member_id, ma.value());
01702         }
01703         nlohmann::json j;
01704         j["state_digest"] = ma->state_digest;
01705 
01706         return make_success(j);
01707       };
01708       make_endpoint(
01709         "ack/update_state_digest",
01710         HTTP_POST,
01711         json_adapter(update_state_digest),
01712         member_cert_or_sig)
01713         .set_auto_schema<void, StateDigest>()
01714         .install();
01715 
01716       auto get_encrypted_recovery_share = [this](
01717                                             EndpointContext& ctx,
01718                                             nlohmann::json&&) {
01719         const auto member_id = get_caller_member_id(ctx);
01720         if (!check_member_active(ctx.tx, member_id))
01721         {
01722           return make_error(
01723             HTTP_STATUS_FORBIDDEN,
01724             ccf::errors::AuthorizationFailed,
01725             "Only active members are given recovery shares.");
01726         }
01727 
01728         auto encrypted_share =
01729           share_manager.get_encrypted_share(ctx.tx, member_id);
01730 
01731         if (!encrypted_share.has_value())
01732         {
01733           return make_error(
01734             HTTP_STATUS_NOT_FOUND,
01735             ccf::errors::ResourceNotFound,
01736             fmt::format("Recovery share not found for member {}.", member_id));
01737         }
01738 
01739         return make_success(tls::b64_from_raw(encrypted_share.value()));
01740       };
01741       make_endpoint(
01742         "recovery_share",
01743         HTTP_GET,
01744         json_adapter(get_encrypted_recovery_share),
01745         member_cert_or_sig)
01746         .set_auto_schema<void, std::string>()
01747         .install();
01748 
01749       auto submit_recovery_share = [this](EndpointContext& ctx) {
01750         // Only active members can submit their shares for recovery
01751         const auto member_id = get_caller_member_id(ctx);
01752         if (!check_member_active(ctx.tx, member_id))
01753         {
01754           ctx.rpc_ctx->set_response_status(HTTP_STATUS_FORBIDDEN);
01755           ctx.rpc_ctx->set_response_body("Member is not active");
01756           return;
01757         }
01758 
01759         GenesisGenerator g(this->network, ctx.tx);
01760         if (
01761           g.get_service_status() != ServiceStatus::WAITING_FOR_RECOVERY_SHARES)
01762         {
01763           ctx.rpc_ctx->set_response_status(HTTP_STATUS_FORBIDDEN);
01764           ctx.rpc_ctx->set_response_body(
01765             "Service is not waiting for recovery shares");
01766           return;
01767         }
01768 
01769         if (node.is_reading_private_ledger())
01770         {
01771           ctx.rpc_ctx->set_response_status(HTTP_STATUS_FORBIDDEN);
01772           ctx.rpc_ctx->set_response_body(
01773             "Node is already recovering private ledger");
01774           return;
01775         }
01776 
01777         const auto& in = ctx.rpc_ctx->get_request_body();
01778         const auto s = std::string(in.begin(), in.end());
01779         auto raw_recovery_share = tls::raw_from_b64(s);
01780 
01781         size_t submitted_shares_count = 0;
01782         try
01783         {
01784           submitted_shares_count = share_manager.submit_recovery_share(
01785             ctx.tx, member_id, raw_recovery_share);
01786         }
01787         catch (const std::exception& e)
01788         {
01789           constexpr auto error_msg = "Error submitting recovery shares";
01790           LOG_FAIL_FMT(error_msg);
01791           LOG_DEBUG_FMT("Error: {}", e.what());
01792           ctx.rpc_ctx->set_error(
01793             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01794             errors::InternalError,
01795             error_msg);
01796           return;
01797         }
01798 
01799         if (submitted_shares_count < g.get_recovery_threshold())
01800         {
01801           // The number of shares required to re-assemble the secret has not yet
01802           // been reached
01803           ctx.rpc_ctx->set_response_status(HTTP_STATUS_OK);
01804           ctx.rpc_ctx->set_response_body(fmt::format(
01805             "{}/{} recovery shares successfully submitted.",
01806             submitted_shares_count,
01807             g.get_recovery_threshold()));
01808           return;
01809         }
01810 
01811         LOG_DEBUG_FMT(
01812           "Reached recovery threshold {}", g.get_recovery_threshold());
01813 
01814         try
01815         {
01816           node.initiate_private_recovery(ctx.tx);
01817         }
01818         catch (const std::exception& e)
01819         {
01820           // Clear the submitted shares if combination fails so that members can
01821           // start over.
01822           constexpr auto error_msg = "Failed to initiate private recovery";
01823           LOG_FAIL_FMT(error_msg);
01824           LOG_DEBUG_FMT("Error: {}", e.what());
01825           share_manager.clear_submitted_recovery_shares(ctx.tx);
01826           ctx.rpc_ctx->set_apply_writes(true);
01827           ctx.rpc_ctx->set_error(
01828             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01829             errors::InternalError,
01830             error_msg);
01831           return;
01832         }
01833 
01834         share_manager.clear_submitted_recovery_shares(ctx.tx);
01835 
01836         ctx.rpc_ctx->set_response_status(HTTP_STATUS_OK);
01837         ctx.rpc_ctx->set_response_body(fmt::format(
01838           "{}/{} recovery shares successfully submitted. End of recovery "
01839           "procedure initiated.",
01840           submitted_shares_count,
01841           g.get_recovery_threshold()));
01842       };
01843       make_endpoint(
01844         "recovery_share", HTTP_POST, submit_recovery_share, member_cert_or_sig)
01845         .set_auto_schema<std::string, std::string>()
01846         .install();
01847 
01848       auto create = [this](kv::Tx& tx, nlohmann::json&& params) {
01849         LOG_DEBUG_FMT("Processing create RPC");
01850         const auto in = params.get<CreateNetworkNodeToNode::In>();
01851 
01852         GenesisGenerator g(this->network, tx);
01853 
01854         // This endpoint can only be called once, directly from the starting
01855         // node for the genesis transaction to initialise the service
01856         if (g.is_service_created())
01857         {
01858           return make_error(
01859             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01860             ccf::errors::InternalError,
01861             "Service is already created.");
01862         }
01863 
01864         g.init_values();
01865         g.create_service(in.network_cert);
01866 
01867         for (const auto& info : in.members_info)
01868         {
01869           g.add_member(info);
01870         }
01871 
01872         // Note that it is acceptable to start a network without any member
01873         // having a recovery share. The service will check that at least one
01874         // recovery member is added before the service is opened.
01875         if (!g.set_recovery_threshold(in.recovery_threshold, true))
01876         {
01877           return make_error(
01878             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01879             ccf::errors::InternalError,
01880             fmt::format(
01881               "Could not set recovery threshold to {}.",
01882               in.recovery_threshold));
01883         }
01884 
01885         g.add_consensus(in.consensus_type);
01886 
01887         size_t self = g.add_node({in.node_info_network,
01888                                   in.node_cert,
01889                                   in.quote,
01890                                   in.public_encryption_key,
01891                                   NodeStatus::TRUSTED});
01892 
01893         LOG_INFO_FMT("Create node id: {}", self);
01894         if (self != 0)
01895         {
01896           return make_error(
01897             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01898             ccf::errors::InternalError,
01899             "Starting node ID is not 0.");
01900         }
01901 
01902 
01903 
01904 
01905 
01906 
01907 
01908 
01909 
01910 
01911 
01912 
01913 
01914         for (const auto& wl : default_whitelists)
01915         {
01916           g.set_whitelist(wl.first, wl.second);
01917         }
01918 
01919         g.set_gov_scripts(
01920           lua::Interpreter().invoke<nlohmann::json>(in.gov_script));
01921 
01922         LOG_INFO_FMT("Created service");
01923         return make_success(true);
01924       };
01925       make_endpoint("create", HTTP_POST, json_adapter(create), no_auth_required)
01926         .set_openapi_hidden(true)
01927         .install();
01928 
01929       // Only called from node. See node_state.h.
01930       auto refresh_jwt_keys = [this](
01931                                 EndpointContext& ctx, nlohmann::json&& body) {
01932         // All errors are server errors since the client is the server.
01933 
01934         if (!consensus)
01935         {
01936           LOG_FAIL_FMT("JWT key auto-refresh: no consensus available");
01937           return make_error(
01938             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01939             ccf::errors::InternalError,
01940             "No consensus available.");
01941         }
01942 
01943         auto primary_id = consensus->primary();
01944         auto nodes_view = ctx.tx.get_read_only_view(this->network.nodes);
01945         auto info = nodes_view->get(primary_id);
01946         if (!info.has_value())
01947         {
01948           LOG_FAIL_FMT(
01949             "JWT key auto-refresh: could not find node info of primary");
01950           return make_error(
01951             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01952             ccf::errors::InternalError,
01953             "Could not find node info of primary.");
01954         }
01955 
01956         auto primary_cert_pem = info.value().cert;
01957         auto cert_der = ctx.rpc_ctx->session->caller_cert;
01958         auto caller_cert_pem = tls::cert_der_to_pem(cert_der);
01959         if (caller_cert_pem != primary_cert_pem)
01960         {
01961           LOG_FAIL_FMT(
01962             "JWT key auto-refresh: request does not originate from primary");
01963           return make_error(
01964             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01965             ccf::errors::InternalError,
01966             "Request does not originate from primary.");
01967         }
01968 
01969         SetJwtPublicSigningKeys parsed;
01970         try
01971         {
01972           parsed = body.get<SetJwtPublicSigningKeys>();
01973         }
01974         catch (const JsonParseError& e)
01975         {
01976           return make_error(
01977             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01978             ccf::errors::InternalError,
01979             "Unable to parse body.");
01980         }
01981 
01982         auto issuers = ctx.tx.get_view(this->network.jwt_issuers);
01983         auto issuer_metadata_ = issuers->get(parsed.issuer);
01984         if (!issuer_metadata_.has_value())
01985         {
01986           LOG_FAIL_FMT(
01987             "JWT key auto-refresh: {} is not a valid issuer", parsed.issuer);
01988           return make_error(
01989             HTTP_STATUS_INTERNAL_SERVER_ERROR,
01990             ccf::errors::InternalError,
01991             fmt::format("{} is not a valid issuer.", parsed.issuer));
01992         }
01993         auto& issuer_metadata = issuer_metadata_.value();
01994 
01995         if (!issuer_metadata.auto_refresh)
01996         {
01997           LOG_FAIL_FMT(
01998             "JWT key auto-refresh: {} does not have auto_refresh enabled",
01999             parsed.issuer);
02000           return make_error(
02001             HTTP_STATUS_INTERNAL_SERVER_ERROR,
02002             ccf::errors::InternalError,
02003             fmt::format(
02004               "{} does not have auto_refresh enabled.", parsed.issuer));
02005         }
02006 
02007         if (!set_jwt_public_signing_keys(
02008               ctx.tx, INVALID_ID, parsed.issuer, issuer_metadata, parsed.jwks))
02009         {
02010           LOG_FAIL_FMT(
02011             "JWT key auto-refresh: error while storing signing keys for issuer "
02012             "{}",
02013             parsed.issuer);
02014           return make_error(
02015             HTTP_STATUS_INTERNAL_SERVER_ERROR,
02016             ccf::errors::InternalError,
02017             fmt::format(
02018               "Error while storing signing keys for issuer {}.",
02019               parsed.issuer));
02020         }
02021 
02022         return make_success(true);
02023       };
02024       make_endpoint(
02025         "jwt_keys/refresh",
02026         HTTP_POST,
02027         json_adapter(refresh_jwt_keys),
02028         {std::make_shared<NodeCertAuthnPolicy>()})
02029         .set_openapi_hidden(true)
02030         .install();
02031     }
02032   };
02033 
02034   class MemberRpcFrontend : public RpcFrontend
02035   {
02036   protected:
02037     MemberEndpoints member_endpoints;
02038     Members* members;
02039 
02040   public:
02041     MemberRpcFrontend(
02042       NetworkTables& network,
02043       AbstractNodeState& node,
02044       ShareManager& share_manager) :
02045       RpcFrontend(*network.tables, member_endpoints),
02046       member_endpoints(network, node, share_manager),
02047       members(&network.members)
02048     {}
02049   };
02050 } // namespace ccf
02051 
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN FMT_HEADER_ONLY HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/member_frontend.h...
Preprocessing /data/git/CCF/src/node/rpc/metrics.h...
#include ds/histogram.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include serialization.h: already included! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 3401 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define HIST_MAX
00012 #define HIST_MIN
00013 #define HIST_BUCKET_GRANULARITY
00014 #define TX_RATE_BUCKETS_LEN
00015 
00016 namespace metrics
00017 {
00018   class Metrics
00019   {
00020   private:
00021     size_t tick_count = 0;
00022     double tx_time_passed[TX_RATE_BUCKETS_LEN] = {};
00023     size_t tx_rates[TX_RATE_BUCKETS_LEN] = {};
00024     std::chrono::milliseconds rate_time_elapsed = std::chrono::milliseconds(0);
00025     using Hist =
00026       histogram::Histogram<int, HIST_MIN, HIST_MAX, HIST_BUCKET_GRANULARITY>;
00027     histogram::Global<Hist> global =
00028       histogram::Global<Hist>("histogram", __FILE__, __LINE__);
00029     Hist histogram = Hist(global);
00030     struct TxStatistics
00031     {
00032       uint32_t tx_count = 0;
00033       uint32_t cumulative_time = 0;
00034       uint32_t time_samples = 0;
00035     };
00036     std::array<TxStatistics, 100> times;
00037 
00038     ccf::GetMetrics::HistogramResults get_histogram_results()
00039     {
00040       ccf::GetMetrics::HistogramResults result;
00041       result.low = histogram.get_low();
00042       result.high = histogram.get_high();
00043       result.overflow = histogram.get_overflow();
00044       result.underflow = histogram.get_underflow();
00045       auto range_counts = histogram.get_range_count();
00046       nlohmann::json buckets;
00047       for (auto const& e : range_counts)
00048       {
00049         const auto count = e.second;
00050         if (count > 0)
00051         {
00052           buckets.push_back(e);
00053         }
00054       }
00055       result.buckets = buckets;
00056       return result;
00057     }
00058 
00059     nlohmann::json get_tx_rates()
00060     {
00061       nlohmann::json result;
00062       for (size_t i = 0; i < TX_RATE_BUCKETS_LEN; ++i)
00063       {
00064         if (tx_rates[i] > 0)
00065         {
00066           result[std::to_string(i)]["rate"] = tx_rates[i];
00067           result[std::to_string(i)]["duration"] = tx_time_passed[i];
00068         }
00069       }
00070 
00071       LOG_INFO << "Printing time series"
00072                << ", this:" << (uint64_t)this << std::endl;
00073       for (uint32_t i = 0; i < times.size(); ++i)
00074       {
00075         uint32_t latency = 0;
00076         if (times[i].time_samples != 0)
00077         {
00078           latency = (times[i].cumulative_time / times[i].time_samples);
00079         }
00080 
00081         LOG_INFO_FMT("{} - {}, {}", i, times[i].tx_count, latency);
00082       }
00083 
00084       return result;
00085     }
00086 
00087   public:
00088     ccf::GetMetrics::Out get_metrics()
00089     {
00090       nlohmann::json result;
00091       result["histogram"] = get_histogram_results();
00092       result["tx_rates"] = get_tx_rates();
00093 
00094       return result;
00095     }
00096 
00097     void track_tx_rates(
00098       const std::chrono::milliseconds& elapsed, kv::Consensus::Statistics stats)
00099     {
00100       // calculate how many tx/sec we have processed in this tick
00101       auto duration = elapsed.count() / 1000.0;
00102       auto tx_rate = stats.tx_count / duration;
00103       histogram.record(tx_rate);
00104       // keep time since beginning
00105       rate_time_elapsed += elapsed;
00106       if (tx_rate > 0)
00107       {
00108         if (tick_count < TX_RATE_BUCKETS_LEN)
00109         {
00110           auto rate_duration = rate_time_elapsed.count() / 1000.0;
00111           tx_rates[tick_count] = tx_rate;
00112           tx_time_passed[tick_count] = rate_duration;
00113         }
00114         tick_count++;
00115       }
00116       uint32_t bucket = rate_time_elapsed.count() / 1000.0;
00117       if (bucket < times.size())
00118       {
00119         times[bucket].tx_count += stats.tx_count;
00120         times[bucket].cumulative_time += stats.time_spent;
00121         times[bucket].time_samples += stats.count_num_samples;
00122       }
00123     }
00124   };
00125 }
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/metrics.h...
Preprocessing /data/git/CCF/src/node/rpc/node_call_types.h...
#include ds/json_schema.h: not found! skipping...
#include node/identity.h: not found! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include node/members.h: not found! skipping...
#include node/node_info_network.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include openenclave/advanced/mallinfo.h: not found! skipping...
Preprocessor output (size: 2970 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace ccf
00014 {
00015   enum class State
00016   {
00017     uninitialized,
00018     initialized,
00019     pending,
00020     partOfPublicNetwork,
00021     partOfNetwork,
00022     readingPublicLedger,
00023     readingPrivateLedger,
00024     verifyingSnapshot
00025   };
00026 
00027   struct GetState
00028   {
00029     using In = void;
00030 
00031     struct Out
00032     {
00033       ccf::NodeId id;
00034       ccf::State state;
00035       kv::Version last_signed_seqno;
00036 
00037       // Only on recovery
00038       std::optional<kv::Version> recovery_target_seqno;
00039       std::optional<kv::Version> last_recovered_seqno;
00040     };
00041   };
00042 
00043   struct GetQuotes
00044   {
00045     using In = void;
00046 
00047     struct Quote
00048     {
00049       NodeId node_id = {};
00050       std::string raw = {}; // < Hex-encoded
00051 
00052       std::string error = {};
00053       std::string mrenclave = {}; // < Hex-encoded
00054     };
00055 
00056     struct Out
00057     {
00058       std::vector<Quote> quotes;
00059     };
00060   };
00061 
00062   struct CreateNetworkNodeToNode
00063   {
00064     struct In
00065     {
00066       std::vector<MemberPubInfo> members_info;
00067       std::string gov_script;
00068       tls::Pem node_cert;
00069       tls::Pem network_cert;
00070       std::vector<uint8_t> quote;
00071       tls::Pem public_encryption_key;
00072       std::vector<uint8_t> code_digest;
00073       NodeInfoNetwork node_info_network;
00074       ConsensusType consensus_type = ConsensusType::CFT;
00075       size_t recovery_threshold;
00076     };
00077   };
00078 
00079   struct JoinNetworkNodeToNode
00080   {
00081     struct In
00082     {
00083       NodeInfoNetwork node_info_network;
00084       std::vector<uint8_t> quote;
00085       tls::Pem public_encryption_key;
00086       ConsensusType consensus_type = ConsensusType::CFT;
00087     };
00088 
00089     struct Out
00090     {
00091       NodeStatus node_status;
00092       NodeId node_id;
00093 
00094       // Only if the caller node is trusted
00095       struct NetworkInfo
00096       {
00097         bool public_only = false;
00098         kv::Version last_recovered_signed_idx = kv::NoVersion;
00099         ConsensusType consensus_type = ConsensusType::CFT;
00100 
00101         LedgerSecrets ledger_secrets;
00102         NetworkIdentity identity;
00103 
00104         bool operator==(const NetworkInfo& other) const
00105         {
00106           return public_only == other.public_only &&
00107             last_recovered_signed_idx == other.last_recovered_signed_idx &&
00108             consensus_type == other.consensus_type &&
00109             ledger_secrets == other.ledger_secrets &&
00110             identity == other.identity;
00111         }
00112 
00113         bool operator!=(const NetworkInfo& other) const
00114         {
00115           return !(*this == other);
00116         }
00117       };
00118 
00119       NetworkInfo network_info;
00120     };
00121   };
00122 
00123   struct MemoryUsage
00124   {
00125     using In = void;
00126 
00127     struct Out
00128     {
00129       Out(const oe_mallinfo_t& info) :
00130         max_total_heap_size(info.max_total_heap_size),
00131         current_allocated_heap_size(info.current_allocated_heap_size),
00132         peak_allocated_heap_size(info.peak_allocated_heap_size)
00133       {}
00134       Out() = default;
00135 
00136       size_t max_total_heap_size = 0;
00137       size_t current_allocated_heap_size = 0;
00138       size_t peak_allocated_heap_size = 0;
00139     };
00140   };
00141 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/node_call_types.h...
Preprocessing /data/git/CCF/src/node/rpc/node_frontend.h...
#include crypto/hash.h: not found! skipping...
#include frontend.h: already included! skipping...
#include node/entities.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/quote.h: not found! skipping...
#include node_interface.h: already included! skipping...
Preprocessor output (size: 13574 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   class NodeEndpoints : public CommonEndpointRegistry
00015   {
00016   private:
00017     NetworkState& network;
00018     AbstractNodeState& node;
00019 
00020     std::optional<NodeId> check_node_exists(
00021       kv::Tx& tx,
00022       const tls::Pem& node_pem,
00023       std::optional<NodeStatus> node_status = std::nullopt)
00024     {
00025       auto nodes_view = tx.get_view(network.nodes);
00026 
00027       std::optional<NodeId> existing_node_id;
00028       nodes_view->foreach([&existing_node_id, &node_pem, &node_status](
00029                             const NodeId& nid, const NodeInfo& ni) {
00030         if (
00031           ni.cert == node_pem &&
00032           (!node_status.has_value() || ni.status == node_status.value()))
00033         {
00034           existing_node_id = nid;
00035           return false;
00036         }
00037         return true;
00038       });
00039 
00040       return existing_node_id;
00041     }
00042 
00043     std::optional<NodeId> check_conflicting_node_network(
00044       kv::Tx& tx, const NodeInfoNetwork& node_info_network)
00045     {
00046       auto nodes_view = tx.get_view(network.nodes);
00047 
00048       std::optional<NodeId> duplicate_node_id;
00049       nodes_view->foreach([&node_info_network, &duplicate_node_id](
00050                             const NodeId& nid, const NodeInfo& ni) {
00051         if (
00052           node_info_network.nodeport == ni.nodeport &&
00053           node_info_network.nodehost == ni.nodehost &&
00054           ni.status != NodeStatus::RETIRED)
00055         {
00056           duplicate_node_id = nid;
00057           return false;
00058         }
00059         return true;
00060       });
00061 
00062       return duplicate_node_id;
00063     }
00064 
00065     auto add_node(
00066       kv::Tx& tx,
00067       const tls::Pem& caller_pem,
00068       const JoinNetworkNodeToNode::In& in,
00069       NodeStatus node_status)
00070     {
00071       auto nodes_view = tx.get_view(network.nodes);
00072 
00073       auto conflicting_node_id =
00074         check_conflicting_node_network(tx, in.node_info_network);
00075       if (conflicting_node_id.has_value())
00076       {
00077         return make_error(
00078           HTTP_STATUS_BAD_REQUEST,
00079           ccf::errors::NodeAlreadyExists,
00080           fmt::format(
00081             "A node with the same node host {} and port {} already exists "
00082             "(node id: {}).",
00083             in.node_info_network.nodehost,
00084             in.node_info_network.nodeport,
00085             conflicting_node_id.value()));
00086       }
00087 
00088 
00089 
00090 
00091 
00092 
00093 
00094 
00095 
00096 
00097 
00098 
00099 
00100 
00101 
00102 
00103 
00104 
00105       LOG_INFO_FMT("Skipped joining node quote verification");
00106 
00107 
00108       NodeId joining_node_id =
00109         get_next_id(tx.get_view(this->network.values), NEXT_NODE_ID);
00110 
00111       nodes_view->put(
00112         joining_node_id,
00113         {in.node_info_network,
00114          caller_pem,
00115          in.quote,
00116          in.public_encryption_key,
00117          node_status});
00118 
00119       LOG_INFO_FMT("Node {} added as {}", joining_node_id, node_status);
00120 
00121       JoinNetworkNodeToNode::Out rep;
00122       rep.node_status = node_status;
00123       rep.node_id = joining_node_id;
00124 
00125       if (node_status == NodeStatus::TRUSTED)
00126       {
00127         rep.network_info = JoinNetworkNodeToNode::Out::NetworkInfo{
00128           node.is_part_of_public_network(),
00129           node.get_last_recovered_signed_idx(),
00130           this->network.consensus_type,
00131           *this->network.ledger_secrets.get(),
00132           *this->network.identity.get()};
00133       }
00134       return make_success(rep);
00135     }
00136 
00137   public:
00138     NodeEndpoints(NetworkState& network, AbstractNodeState& node) :
00139       CommonEndpointRegistry(
00140         get_actor_prefix(ActorsType::nodes), *network.tables),
00141       network(network),
00142       node(node)
00143     {
00144       openapi_info.title = "CCF Public Node API";
00145       openapi_info.description =
00146         "This API provides public, uncredentialed access to service and node "
00147         "state.";
00148     }
00149 
00150     void init_handlers(kv::Store& tables_) override
00151     {
00152       CommonEndpointRegistry::init_handlers(tables_);
00153 
00154       auto accept = [this](
00155                       EndpointContext& args, const nlohmann::json& params) {
00156         const auto in = params.get<JoinNetworkNodeToNode::In>();
00157 
00158         if (
00159           !this->node.is_part_of_network() &&
00160           !this->node.is_part_of_public_network())
00161         {
00162           return make_error(
00163             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00164             ccf::errors::InternalError,
00165             "Target node should be part of network to accept new nodes.");
00166         }
00167 
00168         if (this->network.consensus_type != in.consensus_type)
00169         {
00170           return make_error(
00171             HTTP_STATUS_BAD_REQUEST,
00172             ccf::errors::ConsensusTypeMismatch,
00173             fmt::format(
00174               "Node requested to join with consensus type {} but "
00175               "current consensus type is {}.",
00176               in.consensus_type,
00177               this->network.consensus_type));
00178         }
00179 
00180         auto [nodes_view, service_view] =
00181           args.tx.get_view(this->network.nodes, this->network.service);
00182 
00183         auto active_service = service_view->get(0);
00184         if (!active_service.has_value())
00185         {
00186           return make_error(
00187             HTTP_STATUS_INTERNAL_SERVER_ERROR,
00188             ccf::errors::InternalError,
00189             "No service is available to accept new node.");
00190         }
00191 
00192         // Convert caller cert from DER to PEM as PEM certificates
00193         // are quoted
00194         auto caller_pem =
00195           tls::cert_der_to_pem(args.rpc_ctx->session->caller_cert);
00196 
00197         if (active_service->status == ServiceStatus::OPENING)
00198         {
00199           // If the service is opening, new nodes are trusted straight away
00200           NodeStatus joining_node_status = NodeStatus::TRUSTED;
00201 
00202           // If the node is already trusted, return network secrets
00203           auto existing_node_id =
00204             check_node_exists(args.tx, caller_pem, joining_node_status);
00205           if (existing_node_id.has_value())
00206           {
00207             JoinNetworkNodeToNode::Out rep;
00208             rep.node_status = joining_node_status;
00209             rep.node_id = existing_node_id.value();
00210             rep.network_info = {node.is_part_of_public_network(),
00211                                 node.get_last_recovered_signed_idx(),
00212                                 this->network.consensus_type,
00213                                 *this->network.ledger_secrets.get(),
00214                                 *this->network.identity.get()};
00215             return make_success(rep);
00216           }
00217 
00218           return add_node(args.tx, caller_pem, in, joining_node_status);
00219         }
00220 
00221         // If the service is open, new nodes are first added as pending and
00222         // then only trusted via member governance. It is expected that a new
00223         // node polls the network to retrieve the network secrets until it is
00224         // trusted
00225 
00226         auto existing_node_id = check_node_exists(args.tx, caller_pem);
00227         if (existing_node_id.has_value())
00228         {
00229           JoinNetworkNodeToNode::Out rep;
00230           rep.node_id = existing_node_id.value();
00231 
00232           // If the node already exists, return network secrets if is already
00233           // trusted. Otherwise, only return its node id
00234           auto node_status = nodes_view->get(existing_node_id.value())->status;
00235           rep.node_status = node_status;
00236           if (node_status == NodeStatus::TRUSTED)
00237           {
00238             rep.network_info = {node.is_part_of_public_network(),
00239                                 node.get_last_recovered_signed_idx(),
00240                                 this->network.consensus_type,
00241                                 *this->network.ledger_secrets.get(),
00242                                 *this->network.identity.get()};
00243             return make_success(rep);
00244           }
00245           else if (node_status == NodeStatus::PENDING)
00246           {
00247             // Only return node status and ID
00248             return make_success(rep);
00249           }
00250           else
00251           {
00252             return make_error(
00253               HTTP_STATUS_BAD_REQUEST,
00254               ccf::errors::InvalidNodeState,
00255               "Joining node is not in expected state.");
00256           }
00257         }
00258         else
00259         {
00260           // If the node does not exist, add it to the KV in state pending
00261           return add_node(args.tx, caller_pem, in, NodeStatus::PENDING);
00262         }
00263       };
00264       make_endpoint("join", HTTP_POST, json_adapter(accept), no_auth_required)
00265         .set_openapi_hidden(true)
00266         .install();
00267 
00268       auto get_state = [this](auto& args, nlohmann::json&&) {
00269         GetState::Out result;
00270         auto [s, rts, lrs] = this->node.state();
00271         result.id = this->node.get_node_id();
00272         result.state = s;
00273         result.recovery_target_seqno = rts;
00274         result.last_recovered_seqno = lrs;
00275 
00276         auto sig_view =
00277           args.tx.template get_read_only_view<Signatures>(Tables::SIGNATURES);
00278         auto sig = sig_view->get(0);
00279         if (!sig.has_value())
00280         {
00281           result.last_signed_seqno = 0;
00282         }
00283         else
00284         {
00285           result.last_signed_seqno = sig.value().seqno;
00286         }
00287 
00288         return result;
00289       };
00290       make_read_only_endpoint(
00291         "state", HTTP_GET, json_read_only_adapter(get_state), no_auth_required)
00292         .set_auto_schema<GetState>()
00293         .set_forwarding_required(ForwardingRequired::Never)
00294         .install();
00295 
00296       auto get_quote = [this](auto& args, nlohmann::json&&) {
00297         GetQuotes::Out result;
00298         std::set<NodeId> filter;
00299         filter.insert(this->node.get_node_id());
00300         this->node.node_quotes(args.tx, result, filter);
00301 
00302         if (result.quotes.size() == 1)
00303         {
00304           return make_success(result.quotes[0]);
00305         }
00306         else
00307         {
00308           return make_error(
00309             HTTP_STATUS_NOT_FOUND,
00310             ccf::errors::ResourceNotFound,
00311             "Could not find node quote.");
00312         }
00313       };
00314       make_read_only_endpoint(
00315         "quote", HTTP_GET, json_read_only_adapter(get_quote), no_auth_required)
00316         .set_auto_schema<void, GetQuotes::Quote>()
00317         .set_forwarding_required(ForwardingRequired::Never)
00318         .install();
00319 
00320       auto get_quotes = [this](auto& args, nlohmann::json&&) {
00321         GetQuotes::Out result;
00322         this->node.node_quotes(args.tx, result);
00323 
00324         return make_success(result);
00325       };
00326       make_read_only_endpoint(
00327         "quotes",
00328         HTTP_GET,
00329         json_read_only_adapter(get_quotes),
00330         no_auth_required)
00331         .set_auto_schema<GetQuotes>()
00332         .install();
00333 
00334       auto network_status = [this](auto& args, nlohmann::json&&) {
00335         auto service_view = args.tx.get_read_only_view(network.service);
00336         auto service_state = service_view->get(0);
00337         if (service_state.has_value())
00338         {
00339           return make_success(service_state.value().status);
00340         }
00341         return make_error(
00342           HTTP_STATUS_NOT_FOUND,
00343           ccf::errors::ResourceNotFound,
00344           "Network status is unknown.");
00345       };
00346       make_read_only_endpoint(
00347         "network",
00348         HTTP_GET,
00349         json_read_only_adapter(network_status),
00350         no_auth_required)
00351         .install();
00352 
00353       auto is_primary = [this](ReadOnlyEndpointContext& args) {
00354         if (this->node.is_primary())
00355         {
00356           args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00357         }
00358         else
00359         {
00360           args.rpc_ctx->set_response_status(HTTP_STATUS_PERMANENT_REDIRECT);
00361           if (consensus != nullptr)
00362           {
00363             NodeId primary_id = consensus->primary();
00364             auto nodes_view = args.tx.get_read_only_view(this->network.nodes);
00365             auto info = nodes_view->get(primary_id);
00366             if (info)
00367             {
00368               args.rpc_ctx->set_response_header(
00369                 "Location",
00370                 fmt::format(
00371                   "https://{}:{}/node/primary", info->pubhost, info->pubport));
00372             }
00373           }
00374         }
00375       };
00376       make_read_only_endpoint(
00377         "primary", HTTP_HEAD, is_primary, no_auth_required)
00378         .set_forwarding_required(ForwardingRequired::Never)
00379         .install();
00380 
00381       auto consensus_config = [this](CommandEndpointContext& args) {
00382         // Query node for configurations, separate current from pending
00383         if (consensus != nullptr)
00384         {
00385           auto cfg = consensus->get_latest_configuration();
00386           nlohmann::json c;
00387           for (auto& [nid, ninfo] : cfg)
00388           {
00389             nlohmann::json n;
00390             n["address"] = fmt::format("{}:{}", ninfo.hostname, ninfo.port);
00391             c[fmt::format("{}", nid)] = n;
00392           }
00393           args.rpc_ctx->set_response_body(c.dump());
00394         }
00395         else
00396         {
00397           args.rpc_ctx->set_response_status(HTTP_STATUS_NOT_FOUND);
00398           args.rpc_ctx->set_response_body("No configured consensus");
00399         }
00400       };
00401 
00402       make_command_endpoint(
00403         "config", HTTP_GET, consensus_config, no_auth_required)
00404         .set_forwarding_required(ForwardingRequired::Never)
00405         .install();
00406 
00407       auto memory_usage = [](CommandEndpointContext& args) {
00408 
00409 // Do not attempt to call oe_allocator_mallinfo when used from
00410 // unit tests such as the frontend_test
00411 
00412 
00413 
00414 
00415 
00416 
00417 
00418 
00419 
00420 
00421 
00422 
00423 
00424 
00425         args.rpc_ctx->set_response_status(HTTP_STATUS_INTERNAL_SERVER_ERROR);
00426         args.rpc_ctx->set_response_body("Failed to read memory usage");
00427       };
00428 
00429       make_command_endpoint("memory", HTTP_GET, memory_usage, no_auth_required)
00430         .set_forwarding_required(ForwardingRequired::Never)
00431         .set_auto_schema<MemoryUsage>()
00432         .install();
00433     }
00434   };
00435 
00436   class NodeRpcFrontend : public RpcFrontend
00437   {
00438   protected:
00439     NodeEndpoints node_endpoints;
00440 
00441   public:
00442     NodeRpcFrontend(NetworkState& network, AbstractNodeState& node) :
00443       RpcFrontend(*network.tables, node_endpoints),
00444       node_endpoints(network, node)
00445     {}
00446   };
00447 }
00448 
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN FMT_HEADER_ONLY HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/node_frontend.h...
Preprocessing /data/git/CCF/src/node/rpc/node_interface.h...
#include node/entities.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
#include node_call_types.h: already included! skipping...
Preprocessor output (size: 1187 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   using ExtendedState = std::tuple<
00012     State,
00013     std::optional<kv::Version> /* recovery_target_seqno */,
00014     std::optional<kv::Version> /* last_recovered_seqno */>;
00015 
00016   class AbstractNodeState
00017   {
00018   public:
00019     virtual ~AbstractNodeState() {}
00020     virtual bool accept_recovery(kv::Tx& tx) = 0;
00021     virtual bool rekey_ledger(kv::Tx& tx) = 0;
00022     virtual bool is_part_of_public_network() const = 0;
00023     virtual bool is_primary() const = 0;
00024     virtual bool is_reading_public_ledger() const = 0;
00025     virtual bool is_reading_private_ledger() const = 0;
00026     virtual bool is_verifying_snapshot() const = 0;
00027     virtual bool is_part_of_network() const = 0;
00028     virtual void node_quotes(
00029       kv::ReadOnlyTx& tx,
00030       GetQuotes::Out& result,
00031       const std::optional<std::set<NodeId>>& filter = std::nullopt) = 0;
00032     virtual NodeId get_node_id() const = 0;
00033     virtual kv::Version get_last_recovered_signed_idx() = 0;
00034     virtual void initiate_private_recovery(kv::Tx& tx) = 0;
00035     virtual ExtendedState state() = 0;
00036     virtual void open_user_frontend() = 0;
00037   };
00038 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/node_interface.h...
Preprocessing /data/git/CCF/src/node/rpc/rpc_exception.h...
#include node/rpc/error.h: not found! skipping...
#include exception: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 436 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   struct RpcException : public std::exception
00012   {
00013     ErrorDetails error;
00014 
00015     RpcException(
00016       http_status status, const std::string& code, std::string&& msg) :
00017       error{status, code, std::move(msg)}
00018     {}
00019 
00020     const char* what() const throw() override
00021     {
00022       return error.msg.c_str();
00023     }
00024   };
00025 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/rpc_exception.h...
Preprocessing /data/git/CCF/src/node/rpc/serdes.h...
#include ds/json.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1144 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace serdes
00011 {
00012   enum class Pack
00013   {
00014     Text,
00015     MsgPack
00016   };
00017 
00018   inline std::vector<uint8_t> pack(const nlohmann::json& j, Pack pack)
00019   {
00020     switch (pack)
00021     {
00022       case Pack::Text:
00023       {
00024         auto s = j.dump();
00025         return std::vector<uint8_t>{s.begin(), s.end()};
00026       }
00027 
00028       case Pack::MsgPack:
00029         return nlohmann::json::to_msgpack(j);
00030     }
00031 
00032     throw std::logic_error("Invalid serdes::Pack");
00033   }
00034 
00035   inline nlohmann::json unpack(const std::vector<uint8_t>& data, Pack pack)
00036   {
00037     switch (pack)
00038     {
00039       case Pack::Text:
00040         return nlohmann::json::parse(data);
00041 
00042       case Pack::MsgPack:
00043         return nlohmann::json::from_msgpack(data);
00044     }
00045 
00046     throw std::logic_error("Invalid serdes::Pack");
00047   }
00048 
00049   inline std::optional<serdes::Pack> detect_pack(
00050     const std::vector<uint8_t>& input)
00051   {
00052     if (input.size() == 0)
00053     {
00054       return std::nullopt;
00055     }
00056 
00057     if (input[0] == '{')
00058     {
00059       return serdes::Pack::Text;
00060     }
00061     else
00062     {
00063       return serdes::Pack::MsgPack;
00064     }
00065   }
00066 }
00067 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/serdes.h...
Preprocessing /data/git/CCF/src/node/rpc/serialization.h...
#include ds/json.h: not found! skipping...
#include enclave/interface.h: not found! skipping...
#include node/code_id.h: not found! skipping...
#include node/rpc/call_types.h: not found! skipping...
Preprocessor output (size: 1806 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   DECLARE_JSON_ENUM(
00012     ccf::State,
00013     {{ccf::State::uninitialized, "uninitialized"},
00014      {ccf::State::initialized, "initialized"},
00015      {ccf::State::pending, "pending"},
00016      {ccf::State::partOfPublicNetwork, "partOfPublicNetwork"},
00017      {ccf::State::partOfNetwork, "partOfNetwork"},
00018      {ccf::State::readingPublicLedger, "readingPublicLedger"},
00019      {ccf::State::readingPrivateLedger, "readingPrivateLedger"},
00020      {ccf::State::verifyingSnapshot, "verifyingSnapshot"}})
00021 
00022 
00023   DECLARE_JSON_OPTIONAL_FIELDS(
00024     GetState::Out, recovery_target_seqno, last_recovered_seqno)
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033   DECLARE_JSON_REQUIRED_FIELDS(
00034     JoinNetworkNodeToNode::In,
00035     node_info_network,
00036     quote,
00037     public_encryption_key,
00038     consensus_type)
00039 
00040 
00041 
00042 
00043 
00044 
00045 
00046   DECLARE_JSON_REQUIRED_FIELDS(
00047     LedgerSecrets::VersionedLedgerSecret, version, secret)
00048 
00049 
00050 
00051 
00052   DECLARE_JSON_REQUIRED_FIELDS(
00053     JoinNetworkNodeToNode::Out::NetworkInfo,
00054     public_only,
00055     last_recovered_signed_idx,
00056     consensus_type,
00057     ledger_secrets,
00058     identity)
00059 
00060 
00061 
00062 
00063 
00064   DECLARE_JSON_REQUIRED_FIELDS(
00065     CreateNetworkNodeToNode::In,
00066     members_info,
00067     gov_script,
00068     node_cert,
00069     network_cert,
00070     quote,
00071     public_encryption_key,
00072     code_digest,
00073     node_info_network,
00074     consensus_type,
00075     recovery_threshold)
00076 
00077 
00078 
00079 
00080 
00081 
00082 
00083 
00084 
00085 
00086   DECLARE_JSON_REQUIRED_FIELDS(
00087     GetMetrics::HistogramResults, low, high, overflow, underflow, buckets)
00088 
00089 
00090 
00091 
00092   DECLARE_JSON_REQUIRED_FIELDS(
00093     GetPrimaryInfo::Out, primary_id, primary_host, primary_port, current_view)
00094 
00095 
00096 
00097 
00098 
00099 
00100 
00101 
00102 
00103 
00104 
00105 
00106 
00107 
00108 
00109 
00110 
00111 
00112 
00113 
00114 
00115 
00116 
00117 
00118 
00119 
00120 
00121 
00122 
00123 
00124 
00125 
00126 
00127 
00128 
00129 
00130 
00131 
00132 
00133 
00134   DECLARE_JSON_REQUIRED_FIELDS(
00135     MemoryUsage::Out,
00136     max_total_heap_size,
00137     current_allocated_heap_size,
00138     peak_allocated_heap_size)
00139 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/serialization.h...
Preprocessing /data/git/CCF/src/node/rpc/test/frontend_test.cpp...
#include consensus/aft/request.h: not found! skipping...
#include ds/files.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/genesis_gen.h: not found! skipping...
#include node/history.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/rpc/json_handler.h: not found! skipping...
#include node/rpc/member_frontend.h: not found! skipping...
#include node/rpc/node_frontend.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
#include node/test/channel_stub.h: not found! skipping...
#include node/rpc/node_interface.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include iostream: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 48172 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 # 21 "/data/git/CCF/src/node/rpc/test/frontend_test.cpp" 2
00022 
00023 
00024 
00025 
00026 
00027 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00028 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00029 
00030 using namespace ccfapp;
00031 using namespace ccf;
00032 using namespace std;
00033 
00034 static constexpr auto default_pack = serdes::Pack::MsgPack;
00035 
00036 class BaseTestFrontend : public SimpleUserRpcFrontend
00037 {
00038 public:
00039   using SimpleUserRpcFrontend::SimpleUserRpcFrontend;
00040 
00041   // For testing only, we don't need to specify auth policies everywhere and
00042   // default to no auth
00043   ccf::EndpointRegistry::Endpoint make_endpoint(
00044     const std::string& method,
00045     RESTVerb verb,
00046     const EndpointFunction& f,
00047     const ccf::endpoints::AuthnPolicies& ap = no_auth_required)
00048   {
00049     return endpoints.make_endpoint(method, verb, f, ap);
00050   }
00051 };
00052 
00053 class TestUserFrontend : public BaseTestFrontend
00054 {
00055 public:
00056   TestUserFrontend(kv::Store& tables) : BaseTestFrontend(tables)
00057   {
00058     open();
00059 
00060     auto empty_function = [this](auto& args) {
00061       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00062     };
00063     make_endpoint(
00064       "empty_function", HTTP_POST, empty_function, {user_cert_auth_policy})
00065       .set_forwarding_required(ForwardingRequired::Sometimes)
00066       .install();
00067 
00068     auto empty_function_signed = [this](auto& args) {
00069       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00070     };
00071     make_endpoint(
00072       "empty_function_signed",
00073       HTTP_POST,
00074       empty_function_signed,
00075       {user_signature_auth_policy})
00076       .set_forwarding_required(ForwardingRequired::Sometimes)
00077       .install();
00078 
00079     auto empty_function_no_auth = [this](auto& args) {
00080       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00081     };
00082     make_endpoint(
00083       "empty_function_no_auth",
00084       HTTP_POST,
00085       empty_function_no_auth,
00086       no_auth_required)
00087       .set_forwarding_required(ForwardingRequired::Sometimes)
00088       .install();
00089   }
00090 };
00091 
00092 class TestReqNotStoredFrontend : public BaseTestFrontend
00093 {
00094 public:
00095   TestReqNotStoredFrontend(kv::Store& tables) : BaseTestFrontend(tables)
00096   {
00097     open();
00098 
00099     auto empty_function = [this](auto& args) {
00100       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00101     };
00102     make_endpoint(
00103       "empty_function", HTTP_POST, empty_function, {user_cert_auth_policy})
00104       .install();
00105     disable_request_storing();
00106   }
00107 };
00108 
00109 class TestMinimalEndpointFunction : public BaseTestFrontend
00110 {
00111 public:
00112   TestMinimalEndpointFunction(kv::Store& tables) : BaseTestFrontend(tables)
00113   {
00114     open();
00115 
00116     auto echo_function = [this](kv::Tx& tx, nlohmann::json&& params) {
00117       return make_success(std::move(params));
00118     };
00119     make_endpoint("echo", HTTP_POST, json_adapter(echo_function)).install();
00120 
00121     auto get_caller_function = [this](EndpointContext& ctx, nlohmann::json&&) {
00122       const auto& ident = ctx.get_caller<UserCertAuthnIdentity>();
00123       return make_success(ident.user_id);
00124     };
00125     make_endpoint(
00126       "get_caller",
00127       HTTP_POST,
00128       json_adapter(get_caller_function),
00129       {user_cert_auth_policy})
00130       .install();
00131 
00132     auto failable_function = [this](kv::Tx& tx, nlohmann::json&& params) {
00133       const auto it = params.find("error");
00134       if (it != params.end())
00135       {
00136         const http_status error_code = (*it)["code"];
00137         const std::string error_msg = (*it)["message"];
00138 
00139         return make_error((http_status)error_code, "Error", error_msg);
00140       }
00141 
00142       return make_success(true);
00143     };
00144     make_endpoint("failable", HTTP_POST, json_adapter(failable_function))
00145       .install();
00146   }
00147 };
00148 
00149 class TestRestrictedVerbsFrontend : public BaseTestFrontend
00150 {
00151 public:
00152   TestRestrictedVerbsFrontend(kv::Store& tables) : BaseTestFrontend(tables)
00153   {
00154     open();
00155 
00156     auto get_only = [this](auto& args) {
00157       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00158     };
00159     make_endpoint("get_only", HTTP_GET, get_only).install();
00160 
00161     auto post_only = [this](auto& args) {
00162       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00163     };
00164     make_endpoint("post_only", HTTP_POST, post_only).install();
00165 
00166     auto put_or_delete = [this](auto& args) {
00167       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00168     };
00169     make_endpoint("put_or_delete", HTTP_PUT, put_or_delete).install();
00170     make_endpoint("put_or_delete", HTTP_DELETE, put_or_delete).install();
00171   }
00172 };
00173 
00174 class TestExplicitCommitability : public BaseTestFrontend
00175 {
00176 public:
00177   kv::Map<size_t, size_t> values;
00178 
00179   TestExplicitCommitability(kv::Store& tables) :
00180     BaseTestFrontend(tables),
00181     values("test_values")
00182   {
00183     open();
00184 
00185     auto maybe_commit = [this](EndpointContext& args) {
00186       const auto parsed =
00187         serdes::unpack(args.rpc_ctx->get_request_body(), default_pack);
00188 
00189       const auto new_value = parsed["value"].get<size_t>();
00190       auto view = args.tx.get_view(values);
00191       view->put(0, new_value);
00192 
00193       const auto apply_it = parsed.find("apply");
00194       if (apply_it != parsed.end())
00195       {
00196         const auto should_apply = apply_it->get<bool>();
00197         args.rpc_ctx->set_apply_writes(should_apply);
00198       }
00199 
00200       const auto status = parsed["status"].get<http_status>();
00201       args.rpc_ctx->set_response_status(status);
00202     };
00203     make_endpoint("maybe_commit", HTTP_POST, maybe_commit).install();
00204   }
00205 };
00206 
00207 class TestAlternativeHandlerTypes : public BaseTestFrontend
00208 {
00209 public:
00210   TestAlternativeHandlerTypes(kv::Store& tables) : BaseTestFrontend(tables)
00211   {
00212     open();
00213 
00214     auto command = [this](CommandEndpointContext& args) {
00215       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00216     };
00217     make_command_endpoint("command", HTTP_POST, command, no_auth_required)
00218       .install();
00219 
00220     auto read_only = [this](ReadOnlyEndpointContext& args) {
00221       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00222     };
00223     make_read_only_endpoint("read_only", HTTP_POST, read_only, no_auth_required)
00224       .install();
00225     make_read_only_endpoint("read_only", HTTP_GET, read_only, no_auth_required)
00226       .install();
00227   }
00228 };
00229 
00230 class TestTemplatedPaths : public BaseTestFrontend
00231 {
00232 public:
00233   TestTemplatedPaths(kv::Store& tables) : BaseTestFrontend(tables)
00234   {
00235     open();
00236 
00237     auto endpoint = [this](auto& args) {
00238       nlohmann::json response_body = args.rpc_ctx->get_request_path_params();
00239       args.rpc_ctx->set_response_body(response_body.dump(2));
00240       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00241     };
00242     make_endpoint("{foo}/{bar}/{baz}", HTTP_POST, endpoint).install();
00243   }
00244 };
00245 
00246 class TestMemberFrontend : public MemberRpcFrontend
00247 {
00248 public:
00249   TestMemberFrontend(
00250     ccf::NetworkState& network,
00251     ccf::StubNodeState& node,
00252     ccf::ShareManager& share_manager) :
00253     MemberRpcFrontend(network, node, share_manager)
00254   {
00255     open();
00256 
00257     auto empty_function = [this](auto& args) {
00258       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00259     };
00260     member_endpoints
00261       .make_endpoint(
00262         "empty_function", HTTP_POST, empty_function, {member_cert_auth_policy})
00263       .set_forwarding_required(ForwardingRequired::Sometimes)
00264       .install();
00265   }
00266 };
00267 
00268 class TestNoCertsFrontend : public RpcFrontend
00269 {
00270   EndpointRegistry endpoints;
00271 
00272 public:
00273   TestNoCertsFrontend(kv::Store& tables) :
00274     RpcFrontend(tables, endpoints),
00275     endpoints("test", tables)
00276   {
00277     open();
00278 
00279     auto empty_function = [this](auto& args) {
00280       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00281     };
00282     endpoints
00283       .make_endpoint(
00284         "empty_function", HTTP_POST, empty_function, no_auth_required)
00285       .set_forwarding_required(ForwardingRequired::Sometimes)
00286       .install();
00287   }
00288 };
00289 
00290 //
00291 // User, Node and Member frontends used for forwarding tests
00292 //
00293 
00294 class RpcContextRecorder
00295 {
00296 public:
00297   // session->caller_cert may be DER or PEM, we always convert to PEM
00298   tls::Pem last_caller_cert;
00299   CallerId last_caller_id = INVALID_ID;
00300 
00301   void record_ctx(EndpointContext& ctx)
00302   {
00303     last_caller_cert = tls::cert_der_to_pem(ctx.rpc_ctx->session->caller_cert);
00304     if (const auto uci = ctx.try_get_caller<UserCertAuthnIdentity>())
00305     {
00306       last_caller_id = uci->user_id;
00307     }
00308     else if (const auto mci = ctx.try_get_caller<MemberCertAuthnIdentity>())
00309     {
00310       last_caller_id = mci->member_id;
00311     }
00312     else
00313     {
00314       last_caller_id = INVALID_ID;
00315     }
00316   }
00317 };
00318 
00319 class TestForwardingUserFrontEnd : public BaseTestFrontend,
00320                                    public RpcContextRecorder
00321 {
00322 public:
00323   TestForwardingUserFrontEnd(kv::Store& tables) : BaseTestFrontend(tables)
00324   {
00325     open();
00326 
00327     auto empty_function = [this](auto& args) {
00328       record_ctx(args);
00329       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00330     };
00331     // Note that this a Write function so that a backup executing this command
00332     // will forward it to the primary
00333     make_endpoint(
00334       "empty_function", HTTP_POST, empty_function, {user_cert_auth_policy})
00335       .install();
00336 
00337     auto empty_function_no_auth = [this](auto& args) {
00338       record_ctx(args);
00339       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00340     };
00341     make_endpoint("empty_function_no_auth", HTTP_POST, empty_function_no_auth)
00342       .install();
00343   }
00344 };
00345 
00346 class TestForwardingNodeFrontEnd : public NodeRpcFrontend,
00347                                    public RpcContextRecorder
00348 {
00349 public:
00350   TestForwardingNodeFrontEnd(
00351     ccf::NetworkState& network, ccf::StubNodeState& node) :
00352     NodeRpcFrontend(network, node)
00353   {
00354     open();
00355 
00356     auto empty_function = [this](auto& args) {
00357       record_ctx(args);
00358       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00359     };
00360     // Note that this a Write function so that a backup executing this command
00361     // will forward it to the primary
00362     endpoints
00363       .make_endpoint(
00364         "empty_function", HTTP_POST, empty_function, no_auth_required)
00365       .install();
00366   }
00367 };
00368 
00369 class TestForwardingMemberFrontEnd : public MemberRpcFrontend,
00370                                      public RpcContextRecorder
00371 {
00372 public:
00373   TestForwardingMemberFrontEnd(
00374     kv::Store& tables,
00375     ccf::NetworkState& network,
00376     ccf::StubNodeState& node,
00377     ccf::ShareManager& share_manager) :
00378     MemberRpcFrontend(network, node, share_manager)
00379   {
00380     open();
00381 
00382     auto empty_function = [this](auto& args) {
00383       record_ctx(args);
00384       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
00385     };
00386     // Note that this a Write function so that a backup executing this command
00387     // will forward it to the primary
00388     endpoints
00389       .make_endpoint(
00390         "empty_function", HTTP_POST, empty_function, {member_cert_auth_policy})
00391       .install();
00392   }
00393 };
00394 
00395 // used throughout
00396 auto kp = tls::make_key_pair();
00397 auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00398 
00399 NetworkState bft_network(ConsensusType::BFT);
00400 auto history_kp = tls::make_key_pair();
00401 
00402 auto history =
00403   std::make_shared<NullTxHistory>(*bft_network.tables, 0, *history_kp);
00404 
00405 auto create_simple_request(
00406   const std::string& method = "empty_function",
00407   serdes::Pack pack = default_pack)
00408 {
00409   http::Request request(method);
00410   request.set_header(
00411     http::headers::CONTENT_TYPE, ccf::jsonhandler::pack_to_content_type(pack));
00412   return request;
00413 }
00414 
00415 http::Request create_signed_request(
00416   const http::Request& r = create_simple_request(),
00417   const std::vector<uint8_t>* body = nullptr)
00418 {
00419   http::Request s(r);
00420 
00421   s.set_body(body);
00422 
00423   http::SigningDetails details;
00424   http::sign_request(s, kp, &details);
00425 
00426   return s;
00427 }
00428 
00429 http::SimpleResponseProcessor::Response parse_response(const vector<uint8_t>& v)
00430 {
00431   http::SimpleResponseProcessor processor;
00432   http::ResponseParser parser(processor);
00433 
00434   parser.execute(v.data(), v.size());
00435   REQUIRE(processor.received.size() == 1);
00436 
00437   return processor.received.front();
00438 }
00439 
00440 nlohmann::json parse_response_body(
00441   const vector<uint8_t>& body, serdes::Pack pack = default_pack)
00442 {
00443   return serdes::unpack(body, pack);
00444 }
00445 
00446 // callers used throughout
00447 auto user_caller = kp -> self_sign("CN=name");
00448 auto user_caller_der = tls::make_verifier(user_caller) -> der_cert_data();
00449 
00450 auto member_caller = kp -> self_sign("CN=name_member");
00451 auto member_caller_der = tls::make_verifier(member_caller) -> der_cert_data();
00452 
00453 auto node_caller = kp -> self_sign("CN=node");
00454 auto node_caller_der = tls::make_verifier(node_caller) -> der_cert_data();
00455 
00456 auto kp_other = tls::make_key_pair();
00457 auto invalid_caller = kp_other -> self_sign("CN=name");
00458 auto invalid_caller_der = tls::make_verifier(invalid_caller) -> der_cert_data();
00459 
00460 auto anonymous_caller_der = std::vector<uint8_t>();
00461 
00462 auto user_session = make_shared<enclave::SessionContext>(
00463   enclave::InvalidSessionId, user_caller_der);
00464 auto backup_user_session = make_shared<enclave::SessionContext>(
00465   enclave::InvalidSessionId, user_caller_der);
00466 auto invalid_session = make_shared<enclave::SessionContext>(
00467   enclave::InvalidSessionId, invalid_caller_der);
00468 auto member_session = make_shared<enclave::SessionContext>(
00469   enclave::InvalidSessionId, member_caller_der);
00470 auto anonymous_session = make_shared<enclave::SessionContext>(
00471   enclave::InvalidSessionId, anonymous_caller_der);
00472 
00473 UserId user_id = INVALID_ID;
00474 UserId invalid_user_id = INVALID_ID;
00475 
00476 MemberId member_id = INVALID_ID;
00477 MemberId invalid_member_id = INVALID_ID;
00478 
00479 void prepare_callers(NetworkState& network)
00480 {
00481   // It is necessary to set a consensus before committing the first transaction,
00482   // so that the KV batching done before calling into replicate() stays in
00483   // order.
00484   auto backup_consensus = std::make_shared<kv::PrimaryStubConsensus>();
00485   network.tables->set_consensus(backup_consensus);
00486 
00487   auto tx = network.tables->create_tx();
00488   network.tables->set_encryptor(encryptor);
00489 
00490   GenesisGenerator g(network, tx);
00491   g.init_values();
00492   g.create_service({});
00493   user_id = g.add_user({user_caller});
00494   member_id = g.add_member(member_caller);
00495   invalid_member_id = g.add_member(invalid_caller);
00496   CHECK(g.finalize() == kv::CommitSuccess::OK);
00497 }
00498 
00499 void add_callers_bft_store()
00500 {
00501   auto gen_tx = bft_network.tables->create_tx();
00502   bft_network.tables->set_encryptor(encryptor);
00503   bft_network.tables->set_history(history);
00504   auto backup_consensus =
00505     std::make_shared<kv::PrimaryStubConsensus>(ConsensusType::BFT);
00506   bft_network.tables->set_consensus(backup_consensus);
00507 
00508   GenesisGenerator g(bft_network, gen_tx);
00509   g.init_values();
00510   g.create_service({});
00511   user_id = g.add_user({user_caller});
00512   CHECK(g.finalize() == kv::CommitSuccess::OK);
00513 }
00514 
00515 TEST_CASE("process_bft")
00516 {
00517   add_callers_bft_store();
00518   TestUserFrontend frontend(*bft_network.tables);
00519   auto simple_call = create_simple_request();
00520 
00521   const nlohmann::json call_body = {{"foo", "bar"}, {"baz", 42}};
00522   const auto serialized_body = serdes::pack(call_body, default_pack);
00523   simple_call.set_body(&serialized_body);
00524 
00525   kv::TxHistory::RequestID rid = {1, 1};
00526 
00527   const auto serialized_call = simple_call.build_request();
00528   aft::Request request = {
00529     rid, user_caller_der, serialized_call, enclave::FrameFormat::http};
00530 
00531   auto session = std::make_shared<enclave::SessionContext>(
00532     enclave::InvalidSessionId, user_caller_der);
00533   auto ctx = enclave::make_rpc_context(session, request.raw);
00534   ctx->execute_on_node = true;
00535   frontend.process_bft(ctx);
00536 
00537   auto tx = bft_network.tables->create_tx();
00538   auto bft_requests_view =
00539     tx.get_view<aft::RequestsMap>(ccf::Tables::AFT_REQUESTS);
00540   auto request_value = bft_requests_view->get(0);
00541   REQUIRE(request_value.has_value());
00542 
00543   aft::Request deserialised_req = request_value.value();
00544 
00545   REQUIRE(deserialised_req.caller_cert == user_caller_der);
00546   REQUIRE(deserialised_req.raw == serialized_call);
00547   REQUIRE(deserialised_req.frame_format == enclave::FrameFormat::http);
00548 }
00549 
00550 TEST_CASE("SignedReq to and from json")
00551 {
00552   SignedReq sr;
00553   REQUIRE(sr.sig.empty());
00554   REQUIRE(sr.req.empty());
00555 
00556   nlohmann::json j = sr;
00557 
00558   sr = j;
00559   REQUIRE(sr.sig.empty());
00560   REQUIRE(sr.req.empty());
00561 }
00562 
00563 TEST_CASE("process with signatures")
00564 {
00565   NetworkState network;
00566   prepare_callers(network);
00567   TestUserFrontend frontend(*network.tables);
00568 
00569   SUBCASE("missing rpc")
00570   {
00571     constexpr auto rpc_name = "this_rpc_doesnt_exist";
00572     const auto invalid_call = create_simple_request(rpc_name);
00573     const auto serialized_call = invalid_call.build_request();
00574     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00575 
00576     const auto serialized_response = frontend.process(rpc_ctx).value();
00577     auto response = parse_response(serialized_response);
00578     REQUIRE(response.status == HTTP_STATUS_NOT_FOUND);
00579   }
00580 
00581   SUBCASE("endpoint does not require signature")
00582   {
00583     const auto simple_call = create_simple_request();
00584     const auto signed_call = create_signed_request(simple_call);
00585     const auto serialized_simple_call = simple_call.build_request();
00586     const auto serialized_signed_call = signed_call.build_request();
00587 
00588     auto simple_rpc_ctx =
00589       enclave::make_rpc_context(user_session, serialized_simple_call);
00590     auto signed_rpc_ctx =
00591       enclave::make_rpc_context(user_session, serialized_signed_call);
00592 
00593     INFO("Unsigned RPC");
00594     {
00595       const auto serialized_response = frontend.process(simple_rpc_ctx).value();
00596       auto response = parse_response(serialized_response);
00597       REQUIRE(response.status == HTTP_STATUS_OK);
00598     }
00599 
00600     INFO("Signed RPC");
00601     {
00602       const auto serialized_response = frontend.process(signed_rpc_ctx).value();
00603       auto response = parse_response(serialized_response);
00604       REQUIRE(response.status == HTTP_STATUS_OK);
00605     }
00606   }
00607 
00608   SUBCASE("endpoint requires signature")
00609   {
00610     const auto simple_call = create_simple_request("empty_function_signed");
00611     const auto signed_call = create_signed_request(simple_call);
00612     const auto serialized_simple_call = simple_call.build_request();
00613     const auto serialized_signed_call = signed_call.build_request();
00614 
00615     auto simple_rpc_ctx =
00616       enclave::make_rpc_context(user_session, serialized_simple_call);
00617     auto signed_rpc_ctx =
00618       enclave::make_rpc_context(user_session, serialized_signed_call);
00619 
00620     INFO("Unsigned RPC");
00621     {
00622       const auto serialized_response = frontend.process(simple_rpc_ctx).value();
00623       auto response = parse_response(serialized_response);
00624 
00625       CHECK(response.status == HTTP_STATUS_UNAUTHORIZED);
00626       const std::string error_msg(response.body.begin(), response.body.end());
00627       CHECK(error_msg.find("Missing signature") != std::string::npos);
00628     }
00629 
00630     INFO("Signed RPC");
00631     {
00632       const auto serialized_response = frontend.process(signed_rpc_ctx).value();
00633       auto response = parse_response(serialized_response);
00634       REQUIRE(response.status == HTTP_STATUS_OK);
00635     }
00636   }
00637 
00638   SUBCASE("request with signature but do not store")
00639   {
00640     TestReqNotStoredFrontend frontend_nostore(*network.tables);
00641     const auto simple_call = create_simple_request("empty_function");
00642     const auto signed_call = create_signed_request(simple_call);
00643     const auto serialized_signed_call = signed_call.build_request();
00644     auto signed_rpc_ctx =
00645       enclave::make_rpc_context(user_session, serialized_signed_call);
00646 
00647     const auto serialized_response =
00648       frontend_nostore.process(signed_rpc_ctx).value();
00649     const auto response = parse_response(serialized_response);
00650     REQUIRE(response.status == HTTP_STATUS_OK);
00651   }
00652 }
00653 
00654 TEST_CASE("process with caller")
00655 {
00656   NetworkState network;
00657   prepare_callers(network);
00658   TestUserFrontend frontend(*network.tables);
00659 
00660   SUBCASE("endpoint does not require valid caller")
00661   {
00662     const auto simple_call = create_simple_request("empty_function_no_auth");
00663     const auto serialized_simple_call = simple_call.build_request();
00664     auto authenticated_rpc_ctx =
00665       enclave::make_rpc_context(user_session, serialized_simple_call);
00666     auto invalid_rpc_ctx =
00667       enclave::make_rpc_context(invalid_session, serialized_simple_call);
00668     auto anonymous_rpc_ctx =
00669       enclave::make_rpc_context(anonymous_session, serialized_simple_call);
00670 
00671     INFO("Valid authentication");
00672     {
00673       const auto serialized_response =
00674         frontend.process(authenticated_rpc_ctx).value();
00675       auto response = parse_response(serialized_response);
00676 
00677       // Even though the RPC does not require authenticated caller, an
00678       // authenticated RPC succeeds
00679       REQUIRE(response.status == HTTP_STATUS_OK);
00680     }
00681 
00682     INFO("Invalid authentication");
00683     {
00684       const auto serialized_response =
00685         frontend.process(invalid_rpc_ctx).value();
00686       auto response = parse_response(serialized_response);
00687       REQUIRE(response.status == HTTP_STATUS_OK);
00688     }
00689 
00690     INFO("Anonymous caller");
00691     {
00692       const auto serialized_response =
00693         frontend.process(anonymous_rpc_ctx).value();
00694       auto response = parse_response(serialized_response);
00695       REQUIRE(response.status == HTTP_STATUS_OK);
00696     }
00697   }
00698 
00699   SUBCASE("endpoint requires valid caller")
00700   {
00701     const auto simple_call = create_simple_request("empty_function");
00702     const auto serialized_simple_call = simple_call.build_request();
00703     auto authenticated_rpc_ctx =
00704       enclave::make_rpc_context(user_session, serialized_simple_call);
00705     auto invalid_rpc_ctx =
00706       enclave::make_rpc_context(invalid_session, serialized_simple_call);
00707     auto anonymous_rpc_ctx =
00708       enclave::make_rpc_context(anonymous_session, serialized_simple_call);
00709 
00710     INFO("Valid authentication");
00711     {
00712       const auto serialized_response =
00713         frontend.process(authenticated_rpc_ctx).value();
00714       auto response = parse_response(serialized_response);
00715       REQUIRE(response.status == HTTP_STATUS_OK);
00716     }
00717 
00718     INFO("Invalid authentication");
00719     {
00720       const auto serialized_response =
00721         frontend.process(invalid_rpc_ctx).value();
00722       auto response = parse_response(serialized_response);
00723       REQUIRE(response.status == HTTP_STATUS_UNAUTHORIZED);
00724       const std::string error_msg(response.body.begin(), response.body.end());
00725       CHECK(
00726         error_msg.find("Could not find matching user certificate") !=
00727         std::string::npos);
00728     }
00729 
00730     INFO("Anonymous caller");
00731     {
00732       const auto serialized_response =
00733         frontend.process(anonymous_rpc_ctx).value();
00734       auto response = parse_response(serialized_response);
00735       REQUIRE(response.status == HTTP_STATUS_UNAUTHORIZED);
00736       const std::string error_msg(response.body.begin(), response.body.end());
00737       CHECK(
00738         error_msg.find("Could not find matching user certificate") !=
00739         std::string::npos);
00740     }
00741   }
00742 }
00743 
00744 TEST_CASE("No certs table")
00745 {
00746   NetworkState network;
00747   prepare_callers(network);
00748   TestNoCertsFrontend frontend(*network.tables);
00749   auto simple_call = create_simple_request();
00750   std::vector<uint8_t> serialized_call = simple_call.build_request();
00751 
00752   INFO("Authenticated caller");
00753   {
00754     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00755     std::vector<uint8_t> serialized_response =
00756       frontend.process(rpc_ctx).value();
00757     auto response = parse_response(serialized_response);
00758     CHECK(response.status == HTTP_STATUS_OK);
00759   }
00760 
00761   INFO("Anonymous caller");
00762   {
00763     auto rpc_ctx =
00764       enclave::make_rpc_context(anonymous_session, serialized_call);
00765     std::vector<uint8_t> serialized_response =
00766       frontend.process(rpc_ctx).value();
00767     auto response = parse_response(serialized_response);
00768     CHECK(response.status == HTTP_STATUS_OK);
00769   }
00770 }
00771 
00772 TEST_CASE("Member caller")
00773 {
00774   NetworkState network;
00775   prepare_callers(network);
00776 
00777   ShareManager share_manager(network);
00778   StubNodeState stub_node(share_manager);
00779 
00780   auto simple_call = create_simple_request();
00781   std::vector<uint8_t> serialized_call = simple_call.build_request();
00782   TestMemberFrontend frontend(network, stub_node, share_manager);
00783 
00784   SUBCASE("valid caller")
00785   {
00786     auto member_rpc_ctx =
00787       enclave::make_rpc_context(member_session, serialized_call);
00788     std::vector<uint8_t> serialized_response =
00789       frontend.process(member_rpc_ctx).value();
00790     auto response = parse_response(serialized_response);
00791     CHECK(response.status == HTTP_STATUS_OK);
00792   }
00793 
00794   SUBCASE("invalid caller")
00795   {
00796     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00797     std::vector<uint8_t> serialized_response =
00798       frontend.process(rpc_ctx).value();
00799     auto response = parse_response(serialized_response);
00800     CHECK(response.status == HTTP_STATUS_UNAUTHORIZED);
00801   }
00802 }
00803 
00804 TEST_CASE("MinimalEndpointFunction")
00805 {
00806   NetworkState network;
00807   prepare_callers(network);
00808   TestMinimalEndpointFunction frontend(*network.tables);
00809   for (const auto pack_type : {serdes::Pack::Text, serdes::Pack::MsgPack})
00810   {
00811     {
00812       INFO("Calling echo, with params in body");
00813       auto echo_call = create_simple_request("echo", pack_type);
00814       const nlohmann::json j_body = {{"data", {"nested", "Some string"}},
00815                                      {"other", "Another string"}};
00816       const auto serialized_body = serdes::pack(j_body, pack_type);
00817 
00818       auto signed_call = create_signed_request(echo_call, &serialized_body);
00819       const auto serialized_call = signed_call.build_request();
00820 
00821       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00822       auto response = parse_response(frontend.process(rpc_ctx).value());
00823       CHECK(response.status == HTTP_STATUS_OK);
00824 
00825       const auto response_body = parse_response_body(response.body, pack_type);
00826       CHECK(response_body == j_body);
00827     }
00828 
00829     {
00830       INFO("Calling echo, with params in query");
00831       auto echo_call = create_simple_request("echo", pack_type);
00832       const nlohmann::json j_params = {{"foo", "helloworld"},
00833                                        {"bar", 1},
00834                                        {"fooz", "2"},
00835                                        {"baz", "\"awkward\"\"escapes"}};
00836       echo_call.set_query_params(j_params);
00837       const auto serialized_call = echo_call.build_request();
00838 
00839       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00840       auto response = parse_response(frontend.process(rpc_ctx).value());
00841       CHECK(response.status == HTTP_STATUS_OK);
00842 
00843       const auto response_body = parse_response_body(response.body, pack_type);
00844       CHECK(response_body == j_params);
00845     }
00846 
00847     {
00848       INFO("Calling get_caller");
00849       auto get_caller = create_simple_request("get_caller", pack_type);
00850 
00851       const auto signed_call = create_signed_request(get_caller);
00852       const auto serialized_call = signed_call.build_request();
00853 
00854       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00855       auto response = parse_response(frontend.process(rpc_ctx).value());
00856       CHECK(response.status == HTTP_STATUS_OK);
00857 
00858       const auto response_body = parse_response_body(response.body, pack_type);
00859       CHECK(response_body == user_id);
00860     }
00861   }
00862 
00863   {
00864     INFO("Calling failable, without failing");
00865     auto dont_fail = create_simple_request("failable");
00866 
00867     const auto signed_call = create_signed_request(dont_fail);
00868     const auto serialized_call = signed_call.build_request();
00869 
00870     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00871     auto response = parse_response(frontend.process(rpc_ctx).value());
00872     CHECK(response.status == HTTP_STATUS_OK);
00873   }
00874 
00875   {
00876     for (const auto err : {
00877            HTTP_STATUS_INTERNAL_SERVER_ERROR,
00878            HTTP_STATUS_BAD_REQUEST,
00879            (http_status)418 // Teapot
00880          })
00881     {
00882       INFO("Calling failable, with error");
00883       const auto msg = fmt::format("An error message about {}", err);
00884       auto fail = create_simple_request("failable");
00885       const nlohmann::json j_body = {
00886         {"error", {{"code", err}, {"message", msg}}}};
00887       const auto serialized_body = serdes::pack(j_body, default_pack);
00888 
00889       const auto signed_call = create_signed_request(fail, &serialized_body);
00890       const auto serialized_call = signed_call.build_request();
00891 
00892       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_call);
00893       auto response = parse_response(frontend.process(rpc_ctx).value());
00894       CHECK(response.status == err);
00895       CHECK(
00896         response.headers[http::headers::CONTENT_TYPE] ==
00897         http::headervalues::contenttype::JSON);
00898       const std::string body_s(response.body.begin(), response.body.end());
00899       auto body_j = nlohmann::json::parse(body_s);
00900       CHECK(body_j["error"]["message"] == msg);
00901     }
00902   }
00903 }
00904 
00905 TEST_CASE("Restricted verbs")
00906 {
00907   NetworkState network;
00908   prepare_callers(network);
00909   TestRestrictedVerbsFrontend frontend(*network.tables);
00910 
00911   for (auto verb = HTTP_DELETE; verb <= HTTP_SOURCE;
00912        verb = (llhttp_method)(size_t(verb) + 1))
00913   {
00914     INFO(llhttp_method_name(verb));
00915 
00916     {
00917       http::Request get("get_only", verb);
00918       const auto serialized_get = get.build_request();
00919       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_get);
00920       const auto serialized_response = frontend.process(rpc_ctx).value();
00921       const auto response = parse_response(serialized_response);
00922       if (verb == HTTP_GET)
00923       {
00924         CHECK(response.status == HTTP_STATUS_OK);
00925       }
00926       else
00927       {
00928         CHECK(response.status == HTTP_STATUS_METHOD_NOT_ALLOWED);
00929         const auto it = response.headers.find(http::headers::ALLOW);
00930         REQUIRE(it != response.headers.end());
00931         const auto v = it->second;
00932         CHECK(v.find(llhttp_method_name(HTTP_GET)) != std::string::npos);
00933       }
00934     }
00935 
00936     {
00937       http::Request post("post_only", verb);
00938       const auto serialized_post = post.build_request();
00939       auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_post);
00940       const auto serialized_response = frontend.process(rpc_ctx).value();
00941       const auto response = parse_response(serialized_response);
00942       if (verb == HTTP_POST)
00943       {
00944         CHECK(response.status == HTTP_STATUS_OK);
00945       }
00946       else
00947       {
00948         CHECK(response.status == HTTP_STATUS_METHOD_NOT_ALLOWED);
00949         const auto it = response.headers.find(http::headers::ALLOW);
00950         REQUIRE(it != response.headers.end());
00951         const auto v = it->second;
00952         CHECK(v.find(llhttp_method_name(HTTP_POST)) != std::string::npos);
00953       }
00954     }
00955 
00956     {
00957       http::Request put_or_delete("put_or_delete", verb);
00958       const auto serialized_put_or_delete = put_or_delete.build_request();
00959       auto rpc_ctx =
00960         enclave::make_rpc_context(user_session, serialized_put_or_delete);
00961       const auto serialized_response = frontend.process(rpc_ctx).value();
00962       const auto response = parse_response(serialized_response);
00963       if (verb == HTTP_PUT || verb == HTTP_DELETE)
00964       {
00965         CHECK(response.status == HTTP_STATUS_OK);
00966       }
00967       else
00968       {
00969         CHECK(response.status == HTTP_STATUS_METHOD_NOT_ALLOWED);
00970         const auto it = response.headers.find(http::headers::ALLOW);
00971         REQUIRE(it != response.headers.end());
00972         const auto v = it->second;
00973         CHECK(v.find(llhttp_method_name(HTTP_PUT)) != std::string::npos);
00974         CHECK(v.find(llhttp_method_name(HTTP_DELETE)) != std::string::npos);
00975         CHECK(v.find(llhttp_method_name(verb)) == std::string::npos);
00976       }
00977     }
00978   }
00979 }
00980 
00981 TEST_CASE("Explicit commitability")
00982 {
00983   NetworkState network;
00984   prepare_callers(network);
00985   TestExplicitCommitability frontend(*network.tables);
00986 
00987 #define XX(num, name, string) 
00988   std::vector<http_status> all_statuses = {HTTP_STATUS_MAP(XX)};
00989 
00990 
00991   size_t next_value = 0;
00992 
00993   auto get_value = [&]() {
00994     auto tx = network.tables->create_tx();
00995     auto view = tx.get_view(frontend.values);
00996     auto actual_v = view->get(0).value();
00997     return actual_v;
00998   };
00999 
01000   // Set initial value
01001   {
01002     auto tx = network.tables->create_tx();
01003     tx.get_view(frontend.values)->put(0, next_value);
01004     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01005   }
01006 
01007   for (const auto status : all_statuses)
01008   {
01009     INFO(http_status_str(status));
01010 
01011     {
01012       INFO("Without override...");
01013       const auto new_value = ++next_value;
01014 
01015       http::Request request("maybe_commit", HTTP_POST);
01016 
01017       const nlohmann::json request_body = {{"value", new_value},
01018                                            {"status", status}};
01019       const auto serialized_body = serdes::pack(request_body, default_pack);
01020       request.set_body(&serialized_body);
01021 
01022       const auto serialized_request = request.build_request();
01023       auto rpc_ctx =
01024         enclave::make_rpc_context(user_session, serialized_request);
01025       const auto serialized_response = frontend.process(rpc_ctx).value();
01026       const auto response = parse_response(serialized_response);
01027 
01028       CHECK(response.status == status);
01029 
01030       const auto applied_value = get_value();
01031 
01032       if (status >= 200 && status < 300)
01033       {
01034         INFO("...2xx statuses are applied");
01035         CHECK(applied_value == new_value);
01036       }
01037       else
01038       {
01039         INFO("...error statuses are reverted");
01040         CHECK(applied_value != new_value);
01041       }
01042     }
01043 
01044     {
01045       INFO("With override...");
01046 
01047       for (bool apply : {false, true})
01048       {
01049         const auto new_value = ++next_value;
01050 
01051         http::Request request("maybe_commit", HTTP_POST);
01052 
01053         const nlohmann::json request_body = {
01054           {"value", new_value}, {"apply", apply}, {"status", status}};
01055         const auto serialized_body = serdes::pack(request_body, default_pack);
01056         request.set_body(&serialized_body);
01057 
01058         const auto serialized_request = request.build_request();
01059         auto rpc_ctx =
01060           enclave::make_rpc_context(user_session, serialized_request);
01061         const auto serialized_response = frontend.process(rpc_ctx).value();
01062         const auto response = parse_response(serialized_response);
01063 
01064         CHECK(response.status == status);
01065 
01066         const auto applied_value = get_value();
01067 
01068         if (apply)
01069         {
01070           INFO("...a request can be applied regardless of status");
01071           CHECK(applied_value == new_value);
01072         }
01073         else
01074         {
01075           INFO("...a request can be reverted regardless of status");
01076           CHECK(applied_value != new_value);
01077         }
01078       }
01079     }
01080   }
01081 }
01082 
01083 TEST_CASE("Alternative endpoints")
01084 {
01085   NetworkState network;
01086   prepare_callers(network);
01087   TestAlternativeHandlerTypes frontend(*network.tables);
01088 
01089   {
01090     auto command = create_simple_request("command");
01091     const auto serialized_command = command.build_request();
01092 
01093     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_command);
01094     auto response = parse_response(frontend.process(rpc_ctx).value());
01095     CHECK(response.status == HTTP_STATUS_OK);
01096   }
01097 
01098   for (auto verb : {HTTP_GET, HTTP_POST})
01099   {
01100     http::Request read_only("read_only", verb);
01101     const auto serialized_read_only = read_only.build_request();
01102 
01103     auto rpc_ctx =
01104       enclave::make_rpc_context(user_session, serialized_read_only);
01105     auto response = parse_response(frontend.process(rpc_ctx).value());
01106     CHECK(response.status == HTTP_STATUS_OK);
01107   }
01108 }
01109 
01110 TEST_CASE("Templated paths")
01111 {
01112   NetworkState network;
01113   prepare_callers(network);
01114   TestTemplatedPaths frontend(*network.tables);
01115 
01116   {
01117     auto request = create_simple_request("fin/fang/foom");
01118     const auto serialized_request = request.build_request();
01119 
01120     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_request);
01121     auto response = parse_response(frontend.process(rpc_ctx).value());
01122     CHECK(response.status == HTTP_STATUS_OK);
01123 
01124     std::map<std::string, std::string> expected_mapping;
01125     expected_mapping["foo"] = "fin";
01126     expected_mapping["bar"] = "fang";
01127     expected_mapping["baz"] = "foom";
01128 
01129     const auto response_json = nlohmann::json::parse(response.body);
01130     const auto actual_mapping = response_json.get<decltype(expected_mapping)>();
01131 
01132     CHECK(expected_mapping == actual_mapping);
01133   }
01134 
01135   {
01136     auto request = create_simple_request("users/1/address");
01137     const auto serialized_request = request.build_request();
01138 
01139     auto rpc_ctx = enclave::make_rpc_context(user_session, serialized_request);
01140     auto response = parse_response(frontend.process(rpc_ctx).value());
01141     CHECK(response.status == HTTP_STATUS_OK);
01142 
01143     std::map<std::string, std::string> expected_mapping;
01144     expected_mapping["foo"] = "users";
01145     expected_mapping["bar"] = "1";
01146     expected_mapping["baz"] = "address";
01147 
01148     const auto response_json = nlohmann::json::parse(response.body);
01149     const auto actual_mapping = response_json.get<decltype(expected_mapping)>();
01150 
01151     CHECK(expected_mapping == actual_mapping);
01152   }
01153 }
01154 
01155 TEST_CASE("Signed read requests can be executed on backup")
01156 {
01157   NetworkState network;
01158   prepare_callers(network);
01159   TestUserFrontend frontend(*network.tables);
01160 
01161   auto backup_consensus = std::make_shared<kv::BackupStubConsensus>();
01162   network.tables->set_consensus(backup_consensus);
01163 
01164   auto signed_call = create_signed_request();
01165   auto serialized_signed_call = signed_call.build_request();
01166   auto rpc_ctx =
01167     enclave::make_rpc_context(user_session, serialized_signed_call);
01168   auto response = parse_response(frontend.process(rpc_ctx).value());
01169   CHECK(response.status == HTTP_STATUS_OK);
01170 }
01171 
01172 
01173 {
01174   NetworkState network_primary;
01175 
01176   NetworkState network_backup;
01177   prepare_callers(network_backup);
01178 
01179   TestForwardingUserFrontEnd user_frontend_primary(*network_primary.tables);
01180   TestForwardingUserFrontEnd user_frontend_backup(*network_backup.tables);
01181 
01182   auto primary_consensus = std::make_shared<kv::PrimaryStubConsensus>();
01183   network_primary.tables->set_consensus(primary_consensus);
01184 
01185   auto channel_stub = std::make_shared<ChannelStubProxy>();
01186   auto backup_forwarder = std::make_shared<Forwarder<ChannelStubProxy>>(
01187     nullptr, channel_stub, nullptr, ConsensusType::CFT);
01188   auto backup_consensus = std::make_shared<kv::BackupStubConsensus>();
01189   network_backup.tables->set_consensus(backup_consensus);
01190 
01191   auto simple_call = create_simple_request();
01192   auto serialized_call = simple_call.build_request();
01193 
01194   auto backup_ctx =
01195     enclave::make_rpc_context(backup_user_session, serialized_call);
01196   auto ctx = enclave::make_rpc_context(user_session, serialized_call);
01197 
01198   {
01199     INFO("Backup frontend without forwarder does not forward");
01200     REQUIRE(channel_stub->is_empty());
01201 
01202     const auto r = user_frontend_backup.process(backup_ctx);
01203     REQUIRE(r.has_value());
01204     REQUIRE(channel_stub->is_empty());
01205 
01206     const auto response = parse_response(r.value());
01207     CHECK(response.status == HTTP_STATUS_TEMPORARY_REDIRECT);
01208   }
01209 
01210   user_frontend_backup.set_cmd_forwarder(backup_forwarder);
01211   backup_ctx->session->is_forwarding = false;
01212 
01213   {
01214     INFO("Read command is not forwarded to primary");
01215     TestUserFrontend user_frontend_backup_read(*network_backup.tables);
01216     REQUIRE(channel_stub->is_empty());
01217 
01218     const auto r = user_frontend_backup_read.process(backup_ctx);
01219     REQUIRE(r.has_value());
01220     REQUIRE(channel_stub->is_empty());
01221 
01222     const auto response = parse_response(r.value());
01223     CHECK(response.status == HTTP_STATUS_OK);
01224   }
01225 
01226   {
01227     INFO("Write command on backup is forwarded to primary");
01228     REQUIRE(channel_stub->is_empty());
01229 
01230     const auto r = user_frontend_backup.process(backup_ctx);
01231     REQUIRE(!r.has_value());
01232     REQUIRE(channel_stub->size() == 1);
01233 
01234     auto forwarded_msg = channel_stub->get_pop_back();
01235     auto [fwd_ctx, node_id] =
01236       backup_forwarder
01237         ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01238         .value();
01239 
01240     {
01241       INFO("Invalid caller");
01242       auto response =
01243         parse_response(user_frontend_primary.process_forwarded(fwd_ctx));
01244       CHECK(response.status == HTTP_STATUS_UNAUTHORIZED);
01245     };
01246 
01247     prepare_callers(network_primary);
01248 
01249     {
01250       INFO("Valid caller");
01251       auto response =
01252         parse_response(user_frontend_primary.process_forwarded(fwd_ctx));
01253       CHECK(response.status == HTTP_STATUS_OK);
01254     }
01255   }
01256 
01257   {
01258     INFO("Forwarding write command to a backup returns error");
01259     REQUIRE(channel_stub->is_empty());
01260 
01261     const auto r = user_frontend_backup.process(backup_ctx);
01262     REQUIRE(!r.has_value());
01263     REQUIRE(channel_stub->size() == 1);
01264 
01265     auto forwarded_msg = channel_stub->get_pop_back();
01266     auto [fwd_ctx, node_id] =
01267       backup_forwarder
01268         ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01269         .value();
01270 
01271     // Processing forwarded response by a backup frontend (here, the same
01272     // frontend that the command was originally issued to)
01273     auto response =
01274       parse_response(user_frontend_backup.process_forwarded(fwd_ctx));
01275 
01276     CHECK(response.status == HTTP_STATUS_TEMPORARY_REDIRECT);
01277   }
01278 
01279   {
01280     // A write was executed on this frontend (above), so reads must be
01281     // forwarded too for session consistency
01282     INFO("Read command is now forwarded to primary on this session");
01283     TestUserFrontend user_frontend_backup_read(*network_backup.tables);
01284     REQUIRE(channel_stub->is_empty());
01285 
01286     const auto r = user_frontend_backup_read.process(backup_ctx);
01287     REQUIRE(r.has_value());
01288     REQUIRE(channel_stub->is_empty());
01289 
01290     const auto response = parse_response(r.value());
01291     CHECK(response.status == HTTP_STATUS_TEMPORARY_REDIRECT);
01292   }
01293 
01294   {
01295     INFO("Client signature on forwarded RPC is recorded by primary");
01296 
01297     REQUIRE(channel_stub->is_empty());
01298     auto signed_call = create_signed_request();
01299     auto serialized_signed_call = signed_call.build_request();
01300     auto signed_ctx =
01301       enclave::make_rpc_context(user_session, serialized_signed_call);
01302     const auto r = user_frontend_backup.process(signed_ctx);
01303     REQUIRE(!r.has_value());
01304     REQUIRE(channel_stub->size() == 1);
01305 
01306     auto forwarded_msg = channel_stub->get_pop_back();
01307     auto [fwd_ctx, node_id] =
01308       backup_forwarder
01309         ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01310         .value();
01311 
01312     auto response =
01313       parse_response(user_frontend_primary.process_forwarded(fwd_ctx));
01314     CHECK(response.status == HTTP_STATUS_OK);
01315   }
01316 
01317   // On a session that was previously forwarded, and is now primary,
01318   // commands should still succeed
01319   ctx->session->is_forwarding = true;
01320   {
01321     INFO("Write command primary on a forwarded session succeeds");
01322     REQUIRE(channel_stub->is_empty());
01323 
01324     const auto r = user_frontend_primary.process(ctx);
01325     CHECK(r.has_value());
01326     auto response = parse_response(r.value());
01327     CHECK(response.status == HTTP_STATUS_OK);
01328   }
01329 }
01330 
01331 
01332 {
01333   NetworkState network_primary;
01334   prepare_callers(network_primary);
01335 
01336   NetworkState network_backup;
01337   prepare_callers(network_backup);
01338 
01339   ShareManager share_manager(network_primary);
01340   StubNodeState stub_node(share_manager);
01341 
01342   TestForwardingNodeFrontEnd node_frontend_primary(network_primary, stub_node);
01343   TestForwardingNodeFrontEnd node_frontend_backup(network_backup, stub_node);
01344 
01345   auto channel_stub = std::make_shared<ChannelStubProxy>();
01346 
01347   auto primary_consensus = std::make_shared<kv::PrimaryStubConsensus>();
01348   network_primary.tables->set_consensus(primary_consensus);
01349 
01350   auto backup_forwarder = std::make_shared<Forwarder<ChannelStubProxy>>(
01351     nullptr, channel_stub, nullptr, ConsensusType::CFT);
01352   node_frontend_backup.set_cmd_forwarder(backup_forwarder);
01353   auto backup_consensus = std::make_shared<kv::BackupStubConsensus>();
01354   network_backup.tables->set_consensus(backup_consensus);
01355 
01356   auto write_req = create_simple_request();
01357   auto serialized_call = write_req.build_request();
01358 
01359   auto node_session = std::make_shared<enclave::SessionContext>(
01360     enclave::InvalidSessionId, node_caller.raw());
01361   auto ctx = enclave::make_rpc_context(node_session, serialized_call);
01362   const auto r = node_frontend_backup.process(ctx);
01363   REQUIRE(!r.has_value());
01364   REQUIRE(channel_stub->size() == 1);
01365 
01366   auto forwarded_msg = channel_stub->get_pop_back();
01367   auto [fwd_ctx, node_id] =
01368     backup_forwarder
01369       ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01370       .value();
01371 
01372   auto response =
01373     parse_response(node_frontend_primary.process_forwarded(fwd_ctx));
01374   CHECK(response.status == HTTP_STATUS_OK);
01375 
01376   CHECK(node_frontend_primary.last_caller_cert == node_caller);
01377   CHECK(node_frontend_primary.last_caller_id == INVALID_ID);
01378 }
01379 
01380 
01381 {
01382   NetworkState network_primary;
01383   prepare_callers(network_primary);
01384 
01385   NetworkState network_backup;
01386   prepare_callers(network_backup);
01387 
01388   TestForwardingUserFrontEnd user_frontend_primary(*network_primary.tables);
01389   TestForwardingUserFrontEnd user_frontend_backup(*network_backup.tables);
01390 
01391   auto channel_stub = std::make_shared<ChannelStubProxy>();
01392 
01393   auto primary_consensus = std::make_shared<kv::PrimaryStubConsensus>();
01394   network_primary.tables->set_consensus(primary_consensus);
01395 
01396   auto backup_forwarder = std::make_shared<Forwarder<ChannelStubProxy>>(
01397     nullptr, channel_stub, nullptr, ConsensusType::CFT);
01398   user_frontend_backup.set_cmd_forwarder(backup_forwarder);
01399   auto backup_consensus = std::make_shared<kv::BackupStubConsensus>();
01400   network_backup.tables->set_consensus(backup_consensus);
01401 
01402   auto write_req = create_simple_request();
01403   auto serialized_call = write_req.build_request();
01404 
01405   auto ctx = enclave::make_rpc_context(user_session, serialized_call);
01406   const auto r = user_frontend_backup.process(ctx);
01407   REQUIRE(!r.has_value());
01408   REQUIRE(channel_stub->size() == 1);
01409 
01410   auto forwarded_msg = channel_stub->get_pop_back();
01411   auto [fwd_ctx, node_id] =
01412     backup_forwarder
01413       ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01414       .value();
01415 
01416   auto response =
01417     parse_response(user_frontend_primary.process_forwarded(fwd_ctx));
01418   CHECK(response.status == HTTP_STATUS_OK);
01419 
01420   CHECK(user_frontend_primary.last_caller_cert == user_caller);
01421   CHECK(user_frontend_primary.last_caller_id == 0);
01422 }
01423 
01424 
01425 {
01426   NetworkState network_primary;
01427   prepare_callers(network_primary);
01428 
01429   NetworkState network_backup;
01430   prepare_callers(network_backup);
01431 
01432   ShareManager share_manager(network_primary);
01433   StubNodeState stub_node(share_manager);
01434 
01435   TestForwardingMemberFrontEnd member_frontend_primary(
01436     *network_primary.tables, network_primary, stub_node, share_manager);
01437   TestForwardingMemberFrontEnd member_frontend_backup(
01438     *network_backup.tables, network_backup, stub_node, share_manager);
01439   auto channel_stub = std::make_shared<ChannelStubProxy>();
01440 
01441   auto primary_consensus = std::make_shared<kv::PrimaryStubConsensus>();
01442   network_primary.tables->set_consensus(primary_consensus);
01443 
01444   auto backup_forwarder = std::make_shared<Forwarder<ChannelStubProxy>>(
01445     nullptr, channel_stub, nullptr, ConsensusType::CFT);
01446   member_frontend_backup.set_cmd_forwarder(backup_forwarder);
01447   auto backup_consensus = std::make_shared<kv::BackupStubConsensus>();
01448   network_backup.tables->set_consensus(backup_consensus);
01449 
01450   auto write_req = create_simple_request();
01451   auto serialized_call = write_req.build_request();
01452 
01453   auto ctx = enclave::make_rpc_context(member_session, serialized_call);
01454   const auto r = member_frontend_backup.process(ctx);
01455   REQUIRE(!r.has_value());
01456   REQUIRE(channel_stub->size() == 1);
01457 
01458   auto forwarded_msg = channel_stub->get_pop_back();
01459   auto [fwd_ctx, node_id] =
01460     backup_forwarder
01461       ->recv_forwarded_command(forwarded_msg.data(), forwarded_msg.size())
01462       .value();
01463 
01464   auto response =
01465     parse_response(member_frontend_primary.process_forwarded(fwd_ctx));
01466   CHECK(response.status == HTTP_STATUS_OK);
01467 
01468   CHECK(member_frontend_primary.last_caller_cert == member_caller);
01469   CHECK(member_frontend_primary.last_caller_id == 0);
01470 }
01471 
01472 class TestConflictFrontend : public BaseTestFrontend
01473 {
01474 public:
01475   using Values = kv::Map<size_t, size_t>;
01476 
01477   TestConflictFrontend(kv::Store& tables) : BaseTestFrontend(tables)
01478   {
01479     open();
01480 
01481     auto conflict_once = [this](auto& args) {
01482       static bool conflict_next = true;
01483       if (conflict_next)
01484       {
01485         // Warning: Never do this in a real application!
01486         // Create another transaction that conflicts with the frontend one
01487         auto tx = this->tables.create_tx();
01488         auto view = tx.template get_view<Values>("test_values_conflict");
01489         view->put(0, 42);
01490         REQUIRE(tx.commit() == kv::CommitSuccess::OK);
01491         conflict_next = false;
01492       }
01493 
01494       auto view = args.tx.template get_view<Values>("test_values_conflict");
01495       view->get(0); // Record a read dependency
01496       view->put(0, 0);
01497 
01498       args.rpc_ctx->set_response_status(HTTP_STATUS_OK);
01499     };
01500     make_endpoint("conflict_once", HTTP_POST, conflict_once).install();
01501   }
01502 };
01503 
01504 int main(int argc, char** argv)
01505 {
01506   doctest::Context context;
01507   context.applyCommandLine(argc, argv);
01508   int res = context.run();
01509   if (context.shouldExit())
01510     return res;
01511   return res;
01512 }
01513 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT XX 
---------
Parsing file /data/git/CCF/src/node/rpc/test/frontend_test.cpp...
Preprocessing /data/git/CCF/src/node/rpc/test/member_voting_test.cpp...
#include ds/files.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/genesis_gen.h: not found! skipping...
#include node/rpc/member_frontend.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include node/rpc/user_frontend.h: not found! skipping...
#include node_stub.h: already included! skipping...
#include runtime_config/default_whitelists.h: not found! skipping...
#include tls/rsa_key_pair.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include iostream: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 68993 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT
00004 #define DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES
00005 #define DOCTEST_CONFIG_NO_EXCEPTIONS_BUT_WITH_ALL_ASSERTS
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 using namespace ccfapp;
00024 using namespace ccf;
00025 using namespace std;
00026 using namespace serdes;
00027 using namespace nlohmann;
00028 
00029 using TResponse = http::SimpleResponseProcessor::Response;
00030 
00031 // used throughout
00032 auto kp = tls::make_key_pair();
00033 auto member_cert = kp -> self_sign("CN=name_member");
00034 auto verifier_mem = tls::make_verifier(member_cert);
00035 auto member_caller = verifier_mem -> der_cert_data();
00036 auto user_cert = kp -> self_sign("CN=name_user");
00037 auto dummy_enc_pubk = tls::make_rsa_key_pair() -> public_key_pem();
00038 
00039 auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00040 
00041 constexpr auto default_pack = serdes::Pack::Text;
00042 
00043 string get_script_path(string name)
00044 {
00045   auto default_dir = "../src/runtime_config";
00046   auto dir = getenv("RUNTIME_CONFIG_DIR");
00047   stringstream ss;
00048   ss << (dir ? dir : default_dir) << "/" << name;
00049   return ss.str();
00050 }
00051 const auto gov_script_file = files::slurp_string(get_script_path("gov.lua"));
00052 const auto gov_veto_script_file =
00053   files::slurp_string(get_script_path("gov_veto.lua"));
00054 const auto operator_gov_script_file =
00055   files::slurp_string(get_script_path("operator_gov.lua"));
00056 
00057 template <typename T>
00058 T parse_response_body(const TResponse& r)
00059 {
00060   nlohmann::json body_j;
00061   try
00062   {
00063     body_j = serdes::unpack(r.body, serdes::Pack::Text);
00064   }
00065   catch (const nlohmann::json::parse_error& e)
00066   {
00067     LOG_FAIL_FMT("RPC error: {}", e.what());
00068     LOG_FAIL_FMT("RPC error: {}", std::string(r.body.begin(), r.body.end()));
00069   }
00070 
00071   return body_j.get<T>();
00072 }
00073 
00074 std::string parse_response_body(const TResponse& r)
00075 {
00076   return std::string(r.body.begin(), r.body.end());
00077 }
00078 
00079 void check_error(const TResponse& r, http_status expected)
00080 {
00081   DOCTEST_CHECK(r.status == expected);
00082 }
00083 
00084 void check_result_state(const TResponse& r, ProposalState expected)
00085 {
00086   DOCTEST_CHECK(r.status == HTTP_STATUS_OK);
00087   const auto result = parse_response_body<ProposalInfo>(r);
00088   DOCTEST_CHECK(result.state == expected);
00089 }
00090 
00091 void set_whitelists(GenesisGenerator& gen)
00092 {
00093   for (const auto& wl : default_whitelists)
00094     gen.set_whitelist(wl.first, wl.second);
00095 }
00096 
00097 std::vector<uint8_t> create_text_request(
00098   const std::string& text,
00099   const string& method_name,
00100   llhttp_method verb = HTTP_POST)
00101 {
00102   http::Request r(method_name, verb);
00103   const auto body = std::vector<uint8_t>(text.begin(), text.end());
00104   r.set_body(&body);
00105   return r.build_request();
00106 }
00107 
00108 std::vector<uint8_t> create_request(
00109   const json& params, const string& method_name, llhttp_method verb = HTTP_POST)
00110 {
00111   http::Request r(method_name, verb);
00112   const auto body = params.is_null() ? std::vector<uint8_t>() :
00113                                        serdes::pack(params, default_pack);
00114   r.set_body(&body);
00115   return r.build_request();
00116 }
00117 
00118 std::vector<uint8_t> create_signed_request(
00119   const json& params,
00120   const string& method_name,
00121   const tls::KeyPairPtr& kp_,
00122   llhttp_method verb = HTTP_POST)
00123 {
00124   http::Request r(method_name, verb);
00125 
00126   const auto body = params.is_null() ? std::vector<uint8_t>() :
00127                                        serdes::pack(params, default_pack);
00128 
00129   r.set_body(&body);
00130   http::sign_request(r, kp_);
00131 
00132   return r.build_request();
00133 }
00134 
00135 template <typename T>
00136 auto query_params(T script, bool compile)
00137 {
00138   json params;
00139   if (compile)
00140     params["bytecode"] = lua::compile(script);
00141   else
00142     params["text"] = script;
00143   return params;
00144 }
00145 
00146 template <typename T>
00147 auto read_params(const T& key, const string& table_name)
00148 {
00149   json params;
00150   params["key"] = key;
00151   params["table"] = table_name;
00152   return params;
00153 }
00154 
00155 auto frontend_process(
00156   MemberRpcFrontend& frontend,
00157   const std::vector<uint8_t>& serialized_request,
00158   const tls::Pem& caller)
00159 {
00160   auto session = std::make_shared<enclave::SessionContext>(
00161     enclave::InvalidSessionId, tls::make_verifier(caller)->der_cert_data());
00162   auto rpc_ctx = enclave::make_rpc_context(session, serialized_request);
00163   auto serialized_response = frontend.process(rpc_ctx);
00164 
00165   DOCTEST_CHECK(serialized_response.has_value());
00166 
00167   http::SimpleResponseProcessor processor;
00168   http::ResponseParser parser(processor);
00169 
00170   parser.execute(serialized_response->data(), serialized_response->size());
00171   DOCTEST_REQUIRE(processor.received.size() == 1);
00172 
00173   return processor.received.front();
00174 }
00175 
00176 auto get_proposal(
00177   MemberRpcFrontend& frontend, size_t proposal_id, const tls::Pem& caller)
00178 {
00179   const auto getter =
00180     create_request(nullptr, fmt::format("proposals/{}", proposal_id), HTTP_GET);
00181 
00182   return parse_response_body<Proposal>(
00183     frontend_process(frontend, getter, caller));
00184 }
00185 
00186 auto get_vote(
00187   MemberRpcFrontend& frontend,
00188   size_t proposal_id,
00189   MemberId voter,
00190   const tls::Pem& caller)
00191 {
00192   const auto getter = create_request(
00193     nullptr,
00194     fmt::format("proposals/{}/votes/{}", proposal_id, voter),
00195     HTTP_GET);
00196 
00197   return parse_response_body<Script>(
00198     frontend_process(frontend, getter, caller));
00199 }
00200 
00201 auto activate(
00202   MemberRpcFrontend& frontend,
00203   const tls::KeyPairPtr& kp,
00204   const tls::Pem& caller)
00205 {
00206   const auto state_digest_req =
00207     create_request(nullptr, "ack/update_state_digest");
00208   const auto ack = parse_response_body<StateDigest>(
00209     frontend_process(frontend, state_digest_req, caller));
00210 
00211   StateDigest params;
00212   params.state_digest = ack.state_digest;
00213   const auto ack_req = create_signed_request(params, "ack", kp);
00214   return frontend_process(frontend, ack_req, caller);
00215 }
00216 
00217 auto get_cert(uint64_t member_id, tls::KeyPairPtr& kp_mem)
00218 {
00219   return kp_mem->self_sign("CN=new member" + to_string(member_id));
00220 }
00221 
00222 auto init_frontend(
00223   NetworkTables& network,
00224   GenesisGenerator& gen,
00225   StubNodeState& node,
00226   ShareManager& share_manager,
00227   const int n_members,
00228   std::vector<tls::Pem>& member_certs)
00229 {
00230   // create members
00231   for (uint8_t i = 0; i < n_members; i++)
00232   {
00233     member_certs.push_back(get_cert(i, kp));
00234     gen.activate_member(gen.add_member(member_certs.back()));
00235   }
00236 
00237   set_whitelists(gen);
00238   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
00239   gen.finalize();
00240 
00241   return MemberRpcFrontend(network, node, share_manager);
00242 }
00243 
00244 DOCTEST_TEST_CASE("Member query/read")
00245 {
00246   // initialize the network state
00247   NetworkState network;
00248   auto gen_tx = network.tables->create_tx();
00249   GenesisGenerator gen(network, gen_tx);
00250   gen.init_values();
00251   gen.create_service({});
00252   ShareManager share_manager(network);
00253   StubNodeState node(share_manager);
00254   MemberRpcFrontend frontend(network, node, share_manager);
00255   frontend.open();
00256   const auto member_id = gen.add_member(member_cert);
00257   gen.finalize();
00258 
00259   const enclave::SessionContext member_session(
00260     enclave::InvalidSessionId, member_cert.raw());
00261 
00262   // put value to read
00263   constexpr auto key = 123;
00264   constexpr auto value = 456;
00265   auto tx = network.tables->create_tx();
00266   tx.get_view(network.values)->put(key, value);
00267   DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00268 
00269   static constexpr auto query = R"xxx(
00270   local tables = ...
00271   return tables["public:ccf.gov.values"]:get(123)
00272   )xxx";
00273 
00274   DOCTEST_SUBCASE("Query: bytecode/script allowed access")
00275   {
00276     // set member ACL so that the VALUES table is accessible
00277     auto tx = network.tables->create_tx();
00278     tx.get_view(network.whitelists)
00279       ->put(WlIds::MEMBER_CAN_READ, {Tables::VALUES});
00280     DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00281 
00282     bool compile = true;
00283     do
00284     {
00285       const auto req = create_request(query_params(query, compile), "query");
00286       const auto r = frontend_process(frontend, req, member_cert);
00287       const auto result = parse_response_body<int>(r);
00288       DOCTEST_CHECK(result == value);
00289       compile = !compile;
00290     } while (!compile);
00291   }
00292 
00293   DOCTEST_SUBCASE("Query: table not in ACL")
00294   {
00295     // set member ACL so that no table is accessible
00296     auto tx = network.tables->create_tx();
00297     tx.get_view(network.whitelists)->put(WlIds::MEMBER_CAN_READ, {});
00298     DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00299 
00300     auto req = create_request(query_params(query, true), "query");
00301     const auto response = frontend_process(frontend, req, member_cert);
00302 
00303     check_error(response, HTTP_STATUS_INTERNAL_SERVER_ERROR);
00304   }
00305 
00306   DOCTEST_SUBCASE("Read: allowed access, key exists")
00307   {
00308     auto tx = network.tables->create_tx();
00309     tx.get_view(network.whitelists)
00310       ->put(WlIds::MEMBER_CAN_READ, {Tables::VALUES});
00311     DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00312 
00313     auto read_call =
00314       create_request(read_params<int>(key, Tables::VALUES), "read");
00315     const auto r = frontend_process(frontend, read_call, member_cert);
00316     const auto result = parse_response_body<int>(r);
00317     DOCTEST_CHECK(result == value);
00318   }
00319 
00320   DOCTEST_SUBCASE("Read: allowed access, key doesn't exist")
00321   {
00322     constexpr auto wrong_key = 321;
00323     auto tx = network.tables->create_tx();
00324     tx.get_view(network.whitelists)
00325       ->put(WlIds::MEMBER_CAN_READ, {Tables::VALUES});
00326     DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00327 
00328     auto read_call =
00329       create_request(read_params<int>(wrong_key, Tables::VALUES), "read");
00330     const auto response = frontend_process(frontend, read_call, member_cert);
00331 
00332     check_error(response, HTTP_STATUS_BAD_REQUEST);
00333   }
00334 
00335   DOCTEST_SUBCASE("Read: access not allowed")
00336   {
00337     auto tx = network.tables->create_tx();
00338     tx.get_view(network.whitelists)->put(WlIds::MEMBER_CAN_READ, {});
00339     DOCTEST_CHECK(tx.commit() == kv::CommitSuccess::OK);
00340 
00341     auto read_call =
00342       create_request(read_params<int>(key, Tables::VALUES), "read");
00343     const auto response = frontend_process(frontend, read_call, member_cert);
00344 
00345     check_error(response, HTTP_STATUS_INTERNAL_SERVER_ERROR);
00346   }
00347 }
00348 
00349 DOCTEST_TEST_CASE("Proposer ballot")
00350 {
00351   NetworkState network;
00352   network.tables->set_encryptor(encryptor);
00353   auto gen_tx = network.tables->create_tx();
00354   GenesisGenerator gen(network, gen_tx);
00355   gen.init_values();
00356   gen.create_service({});
00357 
00358   const auto proposer_cert = get_cert(0, kp);
00359   const auto proposer_id = gen.add_member(proposer_cert);
00360   gen.activate_member(proposer_id);
00361   const auto voter_cert = get_cert(1, kp);
00362   const auto voter_id = gen.add_member(voter_cert);
00363   gen.activate_member(voter_id);
00364 
00365   set_whitelists(gen);
00366   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
00367   gen.finalize();
00368 
00369   ShareManager share_manager(network);
00370   StubNodeState node(share_manager);
00371   MemberRpcFrontend frontend(network, node, share_manager);
00372   frontend.open();
00373 
00374   size_t proposal_id;
00375 
00376   const ccf::Script vote_for("return true");
00377   const ccf::Script vote_against("return false");
00378   {
00379     DOCTEST_INFO("Propose, no votes");
00380 
00381     const auto proposed_member = get_cert(2, kp);
00382 
00383     Propose::In proposal;
00384     proposal.script = std::string(R"xxx(
00385       tables, member_info = ...
00386       return Calls:call("new_member", member_info)
00387     )xxx");
00388     proposal.parameter["cert"] = proposed_member;
00389     proposal.parameter["encryption_pub_key"] = dummy_enc_pubk;
00390     const auto propose = create_signed_request(proposal, "proposals", kp);
00391     const auto r = frontend_process(frontend, propose, proposer_cert);
00392 
00393     // the proposal should be accepted, but not succeed immediately
00394     const auto result = parse_response_body<Propose::Out>(r);
00395     DOCTEST_CHECK(result.state == ProposalState::OPEN);
00396 
00397     proposal_id = result.proposal_id;
00398   }
00399 
00400   {
00401     DOCTEST_INFO("Second member votes for proposal");
00402 
00403     const auto vote = create_signed_request(
00404       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
00405     const auto r = frontend_process(frontend, vote, voter_cert);
00406 
00407     // The vote should not yet succeed
00408     check_result_state(r, ProposalState::OPEN);
00409   }
00410 
00411   {
00412     DOCTEST_INFO("Read current votes");
00413 
00414     const auto proposal_result =
00415       get_proposal(frontend, proposal_id, proposer_cert);
00416 
00417     const auto& votes = proposal_result.votes;
00418     DOCTEST_CHECK(votes.size() == 1);
00419 
00420     const auto proposer_vote = votes.find(proposer_id);
00421     DOCTEST_CHECK(proposer_vote == votes.end());
00422 
00423     const auto voter_vote = votes.find(voter_id);
00424     DOCTEST_CHECK(voter_vote != votes.end());
00425     DOCTEST_CHECK(voter_vote->second == vote_for);
00426 
00427     {
00428       DOCTEST_INFO("Get votes directly");
00429       const auto voter_vote2 =
00430         get_vote(frontend, proposal_id, voter_id, proposer_cert);
00431       DOCTEST_CHECK(voter_vote2 == vote_for);
00432     }
00433   }
00434 
00435   {
00436     DOCTEST_INFO("Proposer votes for");
00437 
00438     const auto vote = create_signed_request(
00439       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
00440     const auto r = frontend_process(frontend, vote, proposer_cert);
00441 
00442     // The vote should now succeed
00443     check_result_state(r, ProposalState::ACCEPTED);
00444   }
00445 }
00446 
00447 DOCTEST_TEST_CASE("Reject duplicate vote")
00448 {
00449   NetworkState network;
00450   network.tables->set_encryptor(encryptor);
00451   auto gen_tx = network.tables->create_tx();
00452   GenesisGenerator gen(network, gen_tx);
00453   gen.init_values();
00454   gen.create_service({});
00455 
00456   const auto proposer_cert = get_cert(0, kp);
00457   const auto proposer_id = gen.add_member(proposer_cert);
00458   gen.activate_member(proposer_id);
00459 
00460   set_whitelists(gen);
00461   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
00462   gen.finalize();
00463 
00464   ShareManager share_manager(network);
00465   StubNodeState node(share_manager);
00466   MemberRpcFrontend frontend(network, node, share_manager);
00467   frontend.open();
00468 
00469   size_t proposal_id;
00470 
00471   const ccf::Script vote_for("return true");
00472   const ccf::Script vote_against("return false");
00473   {
00474     DOCTEST_INFO("Propose, no votes");
00475 
00476     const auto proposed_member = get_cert(2, kp);
00477 
00478     Propose::In proposal;
00479     proposal.script = std::string(R"xxx(
00480       tables, member_info = ...
00481       return Calls:call("new_member", member_info)
00482     )xxx");
00483     proposal.parameter["cert"] = proposed_member;
00484     proposal.parameter["encryption_pub_key"] = dummy_enc_pubk;
00485     const auto propose = create_signed_request(proposal, "proposals", kp);
00486     const auto r = frontend_process(frontend, propose, proposer_cert);
00487 
00488     // the proposal should be accepted, but not succeed immediately
00489     const auto result = parse_response_body<Propose::Out>(r);
00490     DOCTEST_CHECK(result.state == ProposalState::OPEN);
00491 
00492     proposal_id = result.proposal_id;
00493   }
00494 
00495   {
00496     DOCTEST_INFO("Proposer votes for");
00497 
00498     const auto vote = create_signed_request(
00499       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
00500     const auto r = frontend_process(frontend, vote, proposer_cert);
00501 
00502     // The vote should now succeed
00503     check_result_state(r, ProposalState::ACCEPTED);
00504   }
00505 
00506   {
00507     DOCTEST_INFO("Proposer cannot vote again");
00508 
00509     const auto vote = create_signed_request(
00510       Vote{vote_against}, fmt::format("proposals/{}/votes", proposal_id), kp);
00511     check_error(
00512       frontend_process(frontend, vote, proposer_cert), HTTP_STATUS_BAD_REQUEST);
00513   }
00514 }
00515 
00516 struct NewMember
00517 {
00518   MemberId id;
00519   tls::KeyPairPtr kp = tls::make_key_pair();
00520   tls::Pem cert;
00521 };
00522 
00523 DOCTEST_TEST_CASE("Add new members until there are 7 then reject")
00524 {
00525   logger::config::level() = logger::INFO;
00526 
00527   constexpr auto initial_members = 3;
00528   constexpr auto n_new_members = 7;
00529   constexpr auto max_members = 8;
00530   NetworkState network;
00531   network.ledger_secrets = std::make_shared<LedgerSecrets>();
00532   network.ledger_secrets->init();
00533   network.tables->set_encryptor(encryptor);
00534   auto gen_tx = network.tables->create_tx();
00535   GenesisGenerator gen(network, gen_tx);
00536   gen.init_values();
00537   gen.create_service({});
00538   ShareManager share_manager(network);
00539   StubNodeState node(share_manager);
00540   // add three initial active members
00541   // the proposer
00542   auto proposer_id = gen.add_member({member_cert, dummy_enc_pubk});
00543   gen.activate_member(proposer_id);
00544 
00545   // the voters
00546   const auto voter_a_cert = get_cert(1, kp);
00547   auto voter_a = gen.add_member({voter_a_cert, dummy_enc_pubk});
00548   gen.activate_member(voter_a);
00549   const auto voter_b_cert = get_cert(2, kp);
00550   auto voter_b = gen.add_member({voter_b_cert, dummy_enc_pubk});
00551   gen.activate_member(voter_b);
00552 
00553   set_whitelists(gen);
00554   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
00555   gen.set_recovery_threshold(1);
00556   gen.open_service();
00557   gen.finalize();
00558   MemberRpcFrontend frontend(network, node, share_manager);
00559   frontend.open();
00560 
00561   vector<NewMember> new_members(n_new_members);
00562 
00563   auto i = 0ul;
00564   for (auto& new_member : new_members)
00565   {
00566     const auto proposal_id = i;
00567     new_member.id = initial_members + i++;
00568 
00569     // new member certificate
00570     auto cert_pem =
00571       new_member.kp->self_sign(fmt::format("CN=new member{}", new_member.id));
00572     auto encryption_pub_key = dummy_enc_pubk;
00573     new_member.cert = cert_pem;
00574 
00575     // check new_member id does not work before member is added
00576     const auto read_next_req = create_request(
00577       read_params<int>(ValueIds::NEXT_MEMBER_ID, Tables::VALUES), "read");
00578     const auto r = frontend_process(frontend, read_next_req, new_member.cert);
00579     check_error(r, HTTP_STATUS_UNAUTHORIZED);
00580 
00581     // propose new member, as proposer
00582     Propose::In proposal;
00583     proposal.script = std::string(R"xxx(
00584       tables, member_info = ...
00585       return Calls:call("new_member", member_info)
00586     )xxx");
00587     proposal.parameter["cert"] = cert_pem;
00588     proposal.parameter["encryption_pub_key"] = dummy_enc_pubk;
00589 
00590     const auto propose = create_signed_request(proposal, "proposals", kp);
00591 
00592     {
00593       const auto r = frontend_process(frontend, propose, member_cert);
00594       const auto result = parse_response_body<Propose::Out>(r);
00595 
00596       // the proposal should be accepted, but not succeed immediately
00597       DOCTEST_CHECK(result.proposal_id == proposal_id);
00598       DOCTEST_CHECK(result.state == ProposalState::OPEN);
00599     }
00600 
00601     {
00602       // vote for own proposal
00603       Script vote_yes("return true");
00604       const auto vote = create_signed_request(
00605         Vote{vote_yes}, fmt::format("proposals/{}/votes", proposal_id), kp);
00606       const auto r = frontend_process(frontend, vote, member_cert);
00607       const auto result = parse_response_body<ProposalInfo>(r);
00608       DOCTEST_CHECK(result.state == ProposalState::OPEN);
00609     }
00610 
00611     // read initial proposal, as second member
00612     const Proposal initial_read =
00613       get_proposal(frontend, proposal_id, voter_a_cert);
00614     DOCTEST_CHECK(initial_read.proposer == proposer_id);
00615     DOCTEST_CHECK(initial_read.script == proposal.script);
00616     DOCTEST_CHECK(initial_read.parameter == proposal.parameter);
00617 
00618     // vote as second member
00619     Script vote_ballot(fmt::format(
00620       R"xxx(
00621         local tables, calls = ...
00622         local n = 0
00623         tables["public:ccf.gov.members"]:foreach( function(k, v) n = n + 1 end )
00624         if n < {} then
00625           return true
00626         else
00627           return false
00628         end
00629       )xxx",
00630       max_members));
00631 
00632     const auto vote = create_signed_request(
00633       Vote{vote_ballot}, fmt::format("proposals/{}/votes", proposal_id), kp);
00634 
00635     {
00636       const auto r = frontend_process(frontend, vote, voter_a_cert);
00637       const auto result = parse_response_body<ProposalInfo>(r);
00638 
00639       if (new_member.id < max_members)
00640       {
00641         // vote should succeed
00642         DOCTEST_CHECK(result.state == ProposalState::ACCEPTED);
00643         // check that member with the new new_member cert can make RPCs now
00644         DOCTEST_CHECK(
00645           parse_response_body<int>(frontend_process(
00646             frontend, read_next_req, new_member.cert)) == new_member.id + 1);
00647 
00648         // successful proposals are removed from the kv, so we can't confirm
00649         // their final state
00650       }
00651       else
00652       {
00653         // vote should not succeed
00654         DOCTEST_CHECK(result.state == ProposalState::OPEN);
00655         // check that member with the new new_member cert can make RPCs now
00656         check_error(
00657           frontend_process(frontend, read_next_req, new_member.cert),
00658           HTTP_STATUS_UNAUTHORIZED);
00659 
00660         // re-read proposal, as second member
00661         const Proposal final_read =
00662           get_proposal(frontend, proposal_id, voter_a_cert);
00663         DOCTEST_CHECK(final_read.proposer == proposer_id);
00664         DOCTEST_CHECK(final_read.script == proposal.script);
00665         DOCTEST_CHECK(final_read.parameter == proposal.parameter);
00666 
00667         const auto my_vote = final_read.votes.find(voter_a);
00668         DOCTEST_CHECK(my_vote != final_read.votes.end());
00669         DOCTEST_CHECK(my_vote->second == vote_ballot);
00670       }
00671     }
00672   }
00673 
00674   DOCTEST_SUBCASE("ACK from newly added members")
00675   {
00676     // iterate over all new_members, except for the last one
00677     for (auto new_member = new_members.cbegin(); new_member !=
00678          new_members.cend() - (initial_members + n_new_members - max_members);
00679          new_member++)
00680     {
00681       // (1) read ack entry
00682       const auto read_state_digest_req = create_request(
00683         read_params(new_member->id, Tables::MEMBER_ACKS), "read");
00684       const auto ack0 = parse_response_body<StateDigest>(
00685         frontend_process(frontend, read_state_digest_req, new_member->cert));
00686       DOCTEST_REQUIRE(std::all_of(
00687         ack0.state_digest.begin(), ack0.state_digest.end(), [](uint8_t i) {
00688           return i == 0;
00689         }));
00690 
00691       {
00692         // make sure that there is a signature in the signatures table since
00693         // ack's depend on that
00694         auto tx = network.tables->create_tx();
00695         auto sig_view = tx.get_view(network.signatures);
00696         PrimarySignature sig_value;
00697         sig_view->put(0, sig_value);
00698         DOCTEST_REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00699       }
00700 
00701       // (2) ask for a fresher digest of state
00702       const auto freshen_state_digest_req =
00703         create_request(nullptr, "ack/update_state_digest");
00704       const auto freshen_state_digest = parse_response_body<StateDigest>(
00705         frontend_process(frontend, freshen_state_digest_req, new_member->cert));
00706       DOCTEST_CHECK(freshen_state_digest.state_digest != ack0.state_digest);
00707 
00708       // (3) read ack entry again and check that the state digest has changed
00709       const auto ack1 = parse_response_body<StateDigest>(
00710         frontend_process(frontend, read_state_digest_req, new_member->cert));
00711       DOCTEST_CHECK(ack0.state_digest != ack1.state_digest);
00712       DOCTEST_CHECK(freshen_state_digest.state_digest == ack1.state_digest);
00713 
00714       // (4) sign stale state and send it
00715       StateDigest params;
00716       params.state_digest = ack0.state_digest;
00717       const auto send_stale_sig_req =
00718         create_signed_request(params, "ack", new_member->kp);
00719       check_error(
00720         frontend_process(frontend, send_stale_sig_req, new_member->cert),
00721         HTTP_STATUS_BAD_REQUEST);
00722 
00723       // (5) sign new state digest and send it
00724       params.state_digest = ack1.state_digest;
00725       const auto send_good_sig_req =
00726         create_signed_request(params, "ack", new_member->kp);
00727       const auto good_response =
00728         frontend_process(frontend, send_good_sig_req, new_member->cert);
00729       DOCTEST_CHECK(good_response.status == HTTP_STATUS_OK);
00730       DOCTEST_CHECK(parse_response_body<bool>(good_response));
00731 
00732       // (6) read own member status
00733       const auto read_status_req =
00734         create_request(read_params(new_member->id, Tables::MEMBERS), "read");
00735       const auto mi = parse_response_body<MemberInfo>(
00736         frontend_process(frontend, read_status_req, new_member->cert));
00737       DOCTEST_CHECK(mi.status == MemberStatus::ACTIVE);
00738       DOCTEST_CHECK(mi.cert == new_member->cert);
00739     }
00740   }
00741 }
00742 
00743 DOCTEST_TEST_CASE("Accept node")
00744 {
00745   NetworkState network;
00746   network.tables->set_encryptor(encryptor);
00747   auto gen_tx = network.tables->create_tx();
00748   GenesisGenerator gen(network, gen_tx);
00749   gen.init_values();
00750   gen.create_service({});
00751   ShareManager share_manager(network);
00752   StubNodeState node(share_manager);
00753   auto new_kp = tls::make_key_pair();
00754 
00755   const auto member_0_cert = get_cert(0, new_kp);
00756   const auto member_1_cert = get_cert(1, kp);
00757   const auto member_0 = gen.add_member(member_0_cert);
00758   const auto member_1 = gen.add_member(member_1_cert);
00759   gen.activate_member(member_0);
00760   gen.activate_member(member_1);
00761 
00762   // node to be tested
00763   // new node certificate
00764   auto new_ca = new_kp->self_sign("CN=new node");
00765   NodeInfo ni;
00766   ni.cert = new_ca;
00767   gen.add_node(ni);
00768   set_whitelists(gen);
00769   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
00770   gen.finalize();
00771   MemberRpcFrontend frontend(network, node, share_manager);
00772   frontend.open();
00773   auto node_id = 0;
00774 
00775   // check node exists with status pending
00776   {
00777     auto read_values =
00778       create_request(read_params<int>(node_id, Tables::NODES), "read");
00779     const auto r = parse_response_body<NodeInfo>(
00780       frontend_process(frontend, read_values, member_0_cert));
00781 
00782     DOCTEST_CHECK(r.status == NodeStatus::PENDING);
00783   }
00784 
00785   // m0 proposes adding new node
00786   ObjectId trust_node_proposal_id;
00787   {
00788     Script proposal(R"xxx(
00789       local tables, node_id = ...
00790       return Calls:call("trust_node", node_id)
00791     )xxx");
00792     const auto propose = create_signed_request(
00793       Propose::In{proposal, node_id}, "proposals", new_kp);
00794     const auto r = parse_response_body<Propose::Out>(
00795       frontend_process(frontend, propose, member_0_cert));
00796 
00797     DOCTEST_CHECK(r.state == ProposalState::OPEN);
00798     trust_node_proposal_id = r.proposal_id;
00799   }
00800 
00801   {
00802     // vote for own proposal
00803     Script vote_yes("return true");
00804     const auto vote = create_signed_request(
00805       Vote{vote_yes},
00806       fmt::format("proposals/{}/votes", trust_node_proposal_id),
00807       new_kp);
00808     const auto r = frontend_process(frontend, vote, member_0_cert);
00809     const auto result = parse_response_body<ProposalInfo>(r);
00810     DOCTEST_CHECK(result.state == ProposalState::OPEN);
00811   }
00812 
00813   // m1 votes for accepting a single new node
00814   {
00815     Script vote_ballot(R"xxx(
00816         local tables, calls = ...
00817         return #calls == 1 and calls[1].func == "trust_node"
00818        )xxx");
00819     const auto vote = create_signed_request(
00820       Vote{vote_ballot},
00821       fmt::format("proposals/{}/votes", trust_node_proposal_id),
00822       kp);
00823 
00824     check_result_state(
00825       frontend_process(frontend, vote, member_1_cert), ProposalState::ACCEPTED);
00826   }
00827 
00828   // check node exists with status pending
00829   {
00830     const auto read_values =
00831       create_request(read_params<int>(node_id, Tables::NODES), "read");
00832     const auto r = parse_response_body<NodeInfo>(
00833       frontend_process(frontend, read_values, member_0_cert));
00834     DOCTEST_CHECK(r.status == NodeStatus::TRUSTED);
00835   }
00836 
00837   // m0 proposes retire node
00838   ObjectId retire_node_proposal_id;
00839   {
00840     Script proposal(R"xxx(
00841       local tables, node_id = ...
00842       return Calls:call("retire_node", node_id)
00843     )xxx");
00844     const auto propose = create_signed_request(
00845       Propose::In{proposal, node_id}, "proposals", new_kp);
00846     const auto r = parse_response_body<Propose::Out>(
00847       frontend_process(frontend, propose, member_0_cert));
00848 
00849     DOCTEST_CHECK(r.state == ProposalState::OPEN);
00850     retire_node_proposal_id = r.proposal_id;
00851   }
00852 
00853   {
00854     // vote for own proposal
00855     Script vote_yes("return true");
00856     const auto vote = create_signed_request(
00857       Vote{vote_yes},
00858       fmt::format("proposals/{}/votes", retire_node_proposal_id),
00859       new_kp);
00860     const auto r = frontend_process(frontend, vote, member_0_cert);
00861     const auto result = parse_response_body<ProposalInfo>(r);
00862     DOCTEST_CHECK(result.state == ProposalState::OPEN);
00863   }
00864 
00865   // m1 votes for retiring node
00866   {
00867     const Script vote_ballot("return true");
00868     const auto vote = create_signed_request(
00869       Vote{vote_ballot},
00870       fmt::format("proposals/{}/votes", retire_node_proposal_id),
00871       kp);
00872     check_result_state(
00873       frontend_process(frontend, vote, member_1_cert), ProposalState::ACCEPTED);
00874   }
00875 
00876   // check that node exists with status retired
00877   {
00878     auto read_values =
00879       create_request(read_params<int>(node_id, Tables::NODES), "read");
00880     const auto r = parse_response_body<NodeInfo>(
00881       frontend_process(frontend, read_values, member_0_cert));
00882     DOCTEST_CHECK(r.status == NodeStatus::RETIRED);
00883   }
00884 
00885   // check that retired node cannot be trusted
00886   {
00887     Script proposal(R"xxx(
00888       local tables, node_id = ...
00889       return Calls:call("trust_node", node_id)
00890     )xxx");
00891     const auto propose = create_signed_request(
00892       Propose::In{proposal, node_id}, "proposals", new_kp);
00893     const auto r = parse_response_body<Propose::Out>(
00894       frontend_process(frontend, propose, member_0_cert));
00895 
00896     const Script vote_ballot("return true");
00897     auto vote = create_signed_request(
00898       Vote{vote_ballot},
00899       fmt::format("proposals/{}/votes", r.proposal_id),
00900       new_kp);
00901     frontend_process(frontend, vote, member_0_cert);
00902 
00903     vote = create_signed_request(
00904       Vote{vote_ballot}, fmt::format("proposals/{}/votes", r.proposal_id), kp);
00905     check_result_state(
00906       frontend_process(frontend, vote, member_1_cert), ProposalState::FAILED);
00907   }
00908 
00909   // check that retired node cannot be retired again
00910   {
00911     Script proposal(R"xxx(
00912       local tables, node_id = ...
00913       return Calls:call("retire_node", node_id)
00914     )xxx");
00915     const auto propose = create_signed_request(
00916       Propose::In{proposal, node_id}, "proposals", new_kp);
00917     const auto r = parse_response_body<Propose::Out>(
00918       frontend_process(frontend, propose, member_0_cert));
00919 
00920     const Script vote_ballot("return true");
00921     auto vote = create_signed_request(
00922       Vote{vote_ballot},
00923       fmt::format("proposals/{}/votes", r.proposal_id),
00924       new_kp);
00925     frontend_process(frontend, vote, member_0_cert);
00926 
00927     vote = create_signed_request(
00928       Vote{vote_ballot}, fmt::format("proposals/{}/votes", r.proposal_id), kp);
00929     check_result_state(
00930       frontend_process(frontend, vote, member_1_cert), ProposalState::FAILED);
00931   }
00932 }
00933 
00934 ProposalInfo test_raw_writes(
00935   NetworkTables& network,
00936   GenesisGenerator& gen,
00937   StubNodeState& node,
00938   ShareManager& share_manager,
00939   Propose::In proposal,
00940   const int n_members = 1,
00941   const int pro_votes = 1,
00942   bool explicit_proposer_vote = false)
00943 {
00944   std::vector<tls::Pem> member_certs;
00945   auto frontend =
00946     init_frontend(network, gen, node, share_manager, n_members, member_certs);
00947   frontend.open();
00948 
00949   // check values before
00950   {
00951     auto tx = network.tables->create_tx();
00952     auto next_member_id_r =
00953       tx.get_view(network.values)->get(ValueIds::NEXT_MEMBER_ID);
00954     DOCTEST_CHECK(next_member_id_r);
00955     DOCTEST_CHECK(*next_member_id_r == n_members);
00956   }
00957 
00958   // propose
00959   const auto proposal_id = 0ul;
00960   {
00961     const uint8_t proposer_id = 0;
00962     const auto propose = create_signed_request(proposal, "proposals", kp);
00963     const auto r = parse_response_body<Propose::Out>(
00964       frontend_process(frontend, propose, member_certs[0]));
00965 
00966     const auto expected_state =
00967       (n_members == 1) ? ProposalState::ACCEPTED : ProposalState::OPEN;
00968     DOCTEST_CHECK(r.state == expected_state);
00969     DOCTEST_CHECK(r.proposal_id == proposal_id);
00970     if (r.state == ProposalState::ACCEPTED)
00971       return r;
00972   }
00973 
00974   // con votes
00975   for (int i = n_members - 1; i >= pro_votes; i--)
00976   {
00977     const Script vote("return false");
00978     const auto vote_serialized = create_signed_request(
00979       Vote{vote}, fmt::format("proposals/{}/votes", proposal_id), kp);
00980 
00981     check_result_state(
00982       frontend_process(frontend, vote_serialized, member_certs[i]),
00983       ProposalState::OPEN);
00984   }
00985 
00986   // pro votes (proposer also votes)
00987   ProposalInfo info = {};
00988   for (uint8_t i = explicit_proposer_vote ? 0 : 1; i < pro_votes; i++)
00989   {
00990     const Script vote("return true");
00991     const auto vote_serialized = create_signed_request(
00992       Vote{vote}, fmt::format("proposals/{}/votes", proposal_id), kp);
00993     if (info.state == ProposalState::OPEN)
00994     {
00995       info = parse_response_body<ProposalInfo>(
00996         frontend_process(frontend, vote_serialized, member_certs[i]));
00997     }
00998     else
00999     {
01000       // proposal has been accepted - additional votes return an error
01001       check_error(
01002         frontend_process(frontend, vote_serialized, member_certs[i]),
01003         HTTP_STATUS_BAD_REQUEST);
01004     }
01005   }
01006   return info;
01007 }
01008 
01009 DOCTEST_TEST_CASE("Propose raw writes")
01010 {
01011   logger::config::level() = logger::INFO;
01012   DOCTEST_SUBCASE("insensitive tables")
01013   {
01014     const auto n_members = 3;
01015     for (int pro_votes = 0; pro_votes <= n_members; pro_votes++)
01016     {
01017       const bool should_succeed = pro_votes > n_members / 2;
01018       NetworkState network;
01019       network.tables->set_encryptor(encryptor);
01020       auto gen_tx = network.tables->create_tx();
01021       GenesisGenerator gen(network, gen_tx);
01022       gen.init_values();
01023       gen.create_service({});
01024       ShareManager share_manager(network);
01025       StubNodeState node(share_manager);
01026       nlohmann::json recovery_threshold = 4;
01027 
01028       auto tx_before = network.tables->create_tx();
01029       auto configuration = tx_before.get_view(network.config)->get(0);
01030       DOCTEST_REQUIRE_FALSE(configuration.has_value());
01031 
01032       const auto expected_state =
01033         should_succeed ? ProposalState::ACCEPTED : ProposalState::OPEN;
01034       const auto proposal_info = test_raw_writes(
01035         network,
01036         gen,
01037         node,
01038         share_manager,
01039         {R"xxx(
01040         local tables, recovery_threshold = ...
01041         local p = Puts:new()
01042         p:put("public:ccf.gov.config", 0, {recovery_threshold = recovery_threshold})
01043         return Calls:call("raw_puts", p)
01044       )xxx"s,
01045          4},
01046         n_members,
01047         pro_votes,
01048         true);
01049       DOCTEST_CHECK(proposal_info.state == expected_state);
01050       if (!should_succeed)
01051         continue;
01052 
01053       // check results
01054       auto tx_after = network.tables->create_tx();
01055       configuration = tx_after.get_view(network.config)->get(0);
01056       DOCTEST_CHECK(configuration.has_value());
01057       DOCTEST_CHECK(configuration->recovery_threshold == recovery_threshold);
01058     }
01059   }
01060 
01061   DOCTEST_SUBCASE("sensitive tables")
01062   {
01063     // propose changes to sensitive tables; changes must only be accepted
01064     // unanimously create new network for each case
01065     const auto sensitive_tables = {Tables::WHITELISTS, Tables::GOV_SCRIPTS};
01066     const auto n_members = 3;
01067     // let proposer vote/not vote
01068     for (const auto proposer_vote : {true})
01069     {
01070       for (int pro_votes = 0; pro_votes < n_members; pro_votes++)
01071       {
01072         for (const auto& sensitive_table : sensitive_tables)
01073         {
01074           NetworkState network;
01075           network.tables->set_encryptor(encryptor);
01076           auto gen_tx = network.tables->create_tx();
01077           GenesisGenerator gen(network, gen_tx);
01078           gen.init_values();
01079           gen.create_service({});
01080           ShareManager share_manager(network);
01081           StubNodeState node(share_manager);
01082 
01083           const auto sensitive_put =
01084             "return Calls:call('raw_puts', Puts:put('"s + sensitive_table +
01085             "', 9, {'aaa'}))"s;
01086           const auto expected_state = (n_members == pro_votes) ?
01087             ProposalState::ACCEPTED :
01088             ProposalState::OPEN;
01089           const auto proposal_info = test_raw_writes(
01090             network,
01091             gen,
01092             node,
01093             share_manager,
01094             {sensitive_put},
01095             n_members,
01096             pro_votes,
01097             proposer_vote);
01098           DOCTEST_CHECK(proposal_info.state == expected_state);
01099         }
01100       }
01101     }
01102   }
01103 }
01104 
01105 DOCTEST_TEST_CASE("Remove proposal")
01106 {
01107   NewMember caller;
01108   auto cert = caller.kp->self_sign("CN=new member");
01109   auto v = tls::make_verifier(cert);
01110   caller.cert = v->cert_pem();
01111 
01112   NetworkState network;
01113   network.tables->set_encryptor(encryptor);
01114   auto gen_tx = network.tables->create_tx();
01115   GenesisGenerator gen(network, gen_tx);
01116   gen.init_values();
01117   gen.create_service({});
01118 
01119   ShareManager share_manager(network);
01120   StubNodeState node(share_manager);
01121   gen.activate_member(gen.add_member(member_cert));
01122   gen.activate_member(gen.add_member(cert));
01123   set_whitelists(gen);
01124   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
01125   gen.finalize();
01126   MemberRpcFrontend frontend(network, node, share_manager);
01127   frontend.open();
01128   auto proposal_id = 0;
01129   auto wrong_proposal_id = 1;
01130   ccf::Script proposal_script(R"xxx(
01131       local tables, param = ...
01132       return {}
01133     )xxx");
01134 
01135   // check that the proposal doesn't exist
01136   {
01137     auto tx = network.tables->create_tx();
01138     auto proposal = tx.get_view(network.proposals)->get(proposal_id);
01139     DOCTEST_CHECK(!proposal);
01140   }
01141 
01142   {
01143     const auto propose =
01144       create_signed_request(Propose::In{proposal_script, 0}, "proposals", kp);
01145     const auto r = parse_response_body<Propose::Out>(
01146       frontend_process(frontend, propose, member_cert));
01147 
01148     DOCTEST_CHECK(r.proposal_id == proposal_id);
01149     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01150   }
01151 
01152   // check that the proposal is there
01153   {
01154     auto tx = network.tables->create_tx();
01155     auto proposal = tx.get_view(network.proposals)->get(proposal_id);
01156     DOCTEST_CHECK(proposal);
01157     DOCTEST_CHECK(proposal->state == ProposalState::OPEN);
01158     DOCTEST_CHECK(
01159       proposal->script.text.value() == proposal_script.text.value());
01160   }
01161 
01162   DOCTEST_SUBCASE("Attempt withdraw proposal with non existing id")
01163   {
01164     const auto withdraw = create_signed_request(
01165       nullptr, fmt::format("proposals/{}/withdraw", wrong_proposal_id), kp);
01166 
01167     check_error(
01168       frontend_process(frontend, withdraw, member_cert),
01169       HTTP_STATUS_BAD_REQUEST);
01170   }
01171 
01172   DOCTEST_SUBCASE("Attempt withdraw proposal that you didn't propose")
01173   {
01174     const auto withdraw = create_signed_request(
01175       nullptr, fmt::format("proposals/{}/withdraw", proposal_id), caller.kp);
01176 
01177     check_error(
01178       frontend_process(frontend, withdraw, cert), HTTP_STATUS_FORBIDDEN);
01179   }
01180 
01181   DOCTEST_SUBCASE("Successfully withdraw proposal")
01182   {
01183     const auto withdraw = create_signed_request(
01184       nullptr, fmt::format("proposals/{}/withdraw", proposal_id), kp);
01185 
01186     check_result_state(
01187       frontend_process(frontend, withdraw, member_cert),
01188       ProposalState::WITHDRAWN);
01189 
01190     // check that the proposal is now withdrawn
01191     {
01192       auto tx = network.tables->create_tx();
01193       auto proposal = tx.get_view(network.proposals)->get(proposal_id);
01194       DOCTEST_CHECK(proposal.has_value());
01195       DOCTEST_CHECK(proposal->state == ProposalState::WITHDRAWN);
01196     }
01197   }
01198 }
01199 
01200 DOCTEST_TEST_CASE("Vetoed proposal gets rejected")
01201 {
01202   NetworkState network;
01203   network.tables->set_encryptor(encryptor);
01204   auto gen_tx = network.tables->create_tx();
01205   GenesisGenerator gen(network, gen_tx);
01206   gen.init_values();
01207   gen.create_service({});
01208   ShareManager share_manager(network);
01209   StubNodeState node(share_manager);
01210   const auto voter_a_cert = get_cert(1, kp);
01211   auto voter_a = gen.add_member(voter_a_cert);
01212   const auto voter_b_cert = get_cert(2, kp);
01213   auto voter_b = gen.add_member(voter_b_cert);
01214   gen.activate_member(voter_a);
01215   gen.activate_member(voter_b);
01216   set_whitelists(gen);
01217   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_veto_script_file));
01218   gen.finalize();
01219   MemberRpcFrontend frontend(network, node, share_manager);
01220   frontend.open();
01221 
01222   Script proposal(R"xxx(
01223     tables, user_cert = ...
01224       return Calls:call("new_user", user_cert)
01225     )xxx");
01226 
01227   const auto propose =
01228     create_signed_request(Propose::In{proposal, user_cert}, "proposals", kp);
01229 
01230   const auto r = parse_response_body<Propose::Out>(
01231     frontend_process(frontend, propose, voter_a_cert));
01232   DOCTEST_CHECK(r.state == ProposalState::OPEN);
01233 
01234   const ccf::Script vote_against("return false");
01235   {
01236     DOCTEST_INFO("Member vetoes proposal");
01237 
01238     const auto vote = create_signed_request(
01239       Vote{vote_against}, fmt::format("proposals/{}/votes", r.proposal_id), kp);
01240     const auto r = frontend_process(frontend, vote, voter_b_cert);
01241 
01242     check_result_state(r, ProposalState::REJECTED);
01243   }
01244 
01245   {
01246     DOCTEST_INFO("Check proposal was rejected");
01247 
01248     const auto proposal = get_proposal(frontend, 0, voter_a_cert);
01249 
01250     DOCTEST_CHECK(proposal.state == ProposalState::REJECTED);
01251   }
01252 }
01253 
01254 DOCTEST_TEST_CASE("Add and remove user via proposed calls")
01255 {
01256   NetworkState network;
01257   network.tables->set_encryptor(encryptor);
01258   auto gen_tx = network.tables->create_tx();
01259   GenesisGenerator gen(network, gen_tx);
01260   gen.init_values();
01261   gen.create_service({});
01262   ShareManager share_manager(network);
01263   StubNodeState node(share_manager);
01264   const auto member_cert = get_cert(0, kp);
01265   gen.activate_member(gen.add_member(member_cert));
01266   set_whitelists(gen);
01267   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
01268   gen.finalize();
01269   MemberRpcFrontend frontend(network, node, share_manager);
01270   frontend.open();
01271 
01272   ccf::Cert user_der;
01273 
01274   {
01275     DOCTEST_INFO("Add user");
01276 
01277     Script proposal(R"xxx(
01278         tables, user_cert = ...
01279         return Calls:call("new_user", {cert = user_cert})
01280       )xxx");
01281 
01282     const auto user_cert = kp->self_sign("CN=new user");
01283     const auto propose =
01284       create_signed_request(Propose::In{proposal, user_cert}, "proposals", kp);
01285 
01286     auto r = parse_response_body<Propose::Out>(
01287       frontend_process(frontend, propose, member_cert));
01288 
01289     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01290     // vote for own proposal
01291     Script vote_yes("return true");
01292     const auto vote = create_signed_request(
01293       Vote{vote_yes}, fmt::format("proposals/{}/votes", r.proposal_id), kp);
01294     r = parse_response_body<ProposalInfo>(
01295       frontend_process(frontend, vote, member_cert));
01296 
01297     DOCTEST_CHECK(r.state == ProposalState::ACCEPTED);
01298     DOCTEST_CHECK(r.proposal_id == 0);
01299 
01300     auto tx1 = network.tables->create_tx();
01301     const auto uid = tx1.get_view(network.values)->get(ValueIds::NEXT_USER_ID);
01302     DOCTEST_CHECK(uid);
01303     DOCTEST_CHECK(*uid == 1);
01304     user_der = tls::make_verifier(user_cert)->der_cert_data();
01305     const auto uid1 = tx1.get_view(network.user_certs)->get(user_der);
01306     DOCTEST_CHECK(uid1);
01307     DOCTEST_CHECK(*uid1 == 0);
01308   }
01309 
01310   {
01311     DOCTEST_INFO("Remove user");
01312 
01313     Script proposal(R"xxx(
01314       tables, user_id = ...
01315         return Calls:call("remove_user", user_id)
01316       )xxx");
01317 
01318     const auto propose =
01319       create_signed_request(Propose::In{proposal, 0}, "proposals", kp);
01320 
01321     auto r = parse_response_body<Propose::Out>(
01322       frontend_process(frontend, propose, member_cert));
01323 
01324     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01325     // vote for own proposal
01326     Script vote_yes("return true");
01327     const auto vote = create_signed_request(
01328       Vote{vote_yes}, fmt::format("proposals/{}/votes", r.proposal_id), kp);
01329     r = parse_response_body<ProposalInfo>(
01330       frontend_process(frontend, vote, member_cert));
01331 
01332     DOCTEST_CHECK(r.state == ProposalState::ACCEPTED);
01333     DOCTEST_CHECK(r.proposal_id == 1);
01334 
01335     auto tx1 = network.tables->create_tx();
01336     auto user = tx1.get_view(network.users)->get(0);
01337     DOCTEST_CHECK(!user.has_value());
01338     auto user_cert = tx1.get_view(network.user_certs)->get(user_der);
01339     DOCTEST_CHECK(!user_cert.has_value());
01340   }
01341 }
01342 
01343 nlohmann::json operator_member_data()
01344 {
01345   auto md = nlohmann::json::object();
01346   md["is_operator"] = true;
01347   return md;
01348 }
01349 
01350 DOCTEST_TEST_CASE(
01351   "Passing members ballot with operator" * doctest::test_suite("operator"))
01352 {
01353   // Members pass a ballot with a constitution that includes an operator
01354   // Operator votes, but is _not_ taken into consideration
01355   NetworkState network;
01356   network.tables->set_encryptor(encryptor);
01357   auto gen_tx = network.tables->create_tx();
01358   GenesisGenerator gen(network, gen_tx);
01359   gen.init_values();
01360   gen.create_service({});
01361 
01362   // Operating member, as indicated by member data
01363   const auto operator_cert = get_cert(0, kp);
01364   const auto operator_id =
01365     gen.add_member({operator_cert, {}, operator_member_data()});
01366   gen.activate_member(operator_id);
01367 
01368   // Non-operating members
01369   std::map<size_t, tls::Pem> members;
01370   for (size_t i = 1; i < 4; i++)
01371   {
01372     auto cert = get_cert(i, kp);
01373     auto id = gen.add_member(cert);
01374     gen.activate_member(id);
01375     members[id] = cert;
01376   }
01377 
01378   set_whitelists(gen);
01379   gen.set_gov_scripts(
01380     lua::Interpreter().invoke<json>(operator_gov_script_file));
01381   gen.finalize();
01382 
01383   ShareManager share_manager(network);
01384   StubNodeState node(share_manager);
01385   MemberRpcFrontend frontend(network, node, share_manager);
01386   frontend.open();
01387 
01388   size_t proposal_id;
01389   size_t proposer_id = 1;
01390   size_t voter_id = 2;
01391 
01392   const ccf::Script vote_for("return true");
01393   const ccf::Script vote_against("return false");
01394   {
01395     DOCTEST_INFO("Propose and vote for");
01396 
01397     const auto proposed_member = get_cert(4, kp);
01398 
01399     Propose::In proposal;
01400     proposal.script = std::string(R"xxx(
01401       tables, member_info = ...
01402       return Calls:call("new_member", member_info)
01403     )xxx");
01404     proposal.parameter["cert"] = proposed_member;
01405     proposal.parameter["encryption_pub_key"] = dummy_enc_pubk;
01406 
01407     const auto propose = create_signed_request(proposal, "proposals", kp);
01408     const auto r = parse_response_body<Propose::Out>(frontend_process(
01409       frontend,
01410       propose,
01411       tls::make_verifier(members[proposer_id])->der_cert_data()));
01412 
01413     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01414 
01415     proposal_id = r.proposal_id;
01416   }
01417 
01418   {
01419     DOCTEST_INFO("First member votes");
01420 
01421     const auto vote = create_signed_request(
01422       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
01423     const auto r = frontend_process(frontend, vote, members[proposer_id]);
01424 
01425     check_result_state(r, ProposalState::OPEN);
01426   }
01427 
01428   {
01429     DOCTEST_INFO("Operator votes, but without effect");
01430 
01431     const auto vote = create_signed_request(
01432       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
01433     const auto r = frontend_process(frontend, vote, operator_cert);
01434 
01435     check_result_state(r, ProposalState::OPEN);
01436   }
01437 
01438   {
01439     DOCTEST_INFO("Second member votes for proposal, which passes");
01440 
01441     const auto vote = create_signed_request(
01442       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
01443     const auto r = frontend_process(frontend, vote, members[voter_id]);
01444 
01445     check_result_state(r, ProposalState::ACCEPTED);
01446   }
01447 
01448   {
01449     DOCTEST_INFO("Validate vote tally");
01450 
01451     const auto proposal =
01452       get_proposal(frontend, proposal_id, members[proposer_id]);
01453 
01454     const auto& votes = proposal.votes;
01455     DOCTEST_CHECK(votes.size() == 3);
01456 
01457     const auto operator_vote = votes.find(operator_id);
01458     DOCTEST_CHECK(operator_vote != votes.end());
01459     DOCTEST_CHECK(operator_vote->second == vote_for);
01460 
01461     const auto proposer_vote = votes.find(proposer_id);
01462     DOCTEST_CHECK(proposer_vote != votes.end());
01463     DOCTEST_CHECK(proposer_vote->second == vote_for);
01464 
01465     const auto voter_vote = votes.find(voter_id);
01466     DOCTEST_CHECK(voter_vote != votes.end());
01467     DOCTEST_CHECK(voter_vote->second == vote_for);
01468   }
01469 }
01470 
01471 
01472 {
01473   // Operator issues a proposal that is an operator change
01474   // and gets it through without member votes
01475   NetworkState network;
01476   network.tables->set_encryptor(encryptor);
01477   auto gen_tx = network.tables->create_tx();
01478   GenesisGenerator gen(network, gen_tx);
01479   gen.init_values();
01480   gen.create_service({});
01481   auto new_kp = tls::make_key_pair();
01482   auto new_ca = new_kp->self_sign("CN=new node");
01483   NodeInfo ni;
01484   ni.cert = new_ca;
01485   auto node_id = gen.add_node(ni);
01486 
01487   // Operating member, as indicated by member data
01488   const auto operator_cert = get_cert(0, kp);
01489   const auto operator_id =
01490     gen.add_member({operator_cert, std::nullopt, operator_member_data()});
01491   gen.activate_member(operator_id);
01492 
01493   // Non-operating members
01494   std::map<size_t, tls::Pem> members;
01495   for (size_t i = 1; i < 4; i++)
01496   {
01497     auto cert = get_cert(i, kp);
01498     auto id = gen.add_member({cert, dummy_enc_pubk});
01499     gen.activate_member(id);
01500     members[id] = cert;
01501   }
01502 
01503   set_whitelists(gen);
01504   gen.set_gov_scripts(
01505     lua::Interpreter().invoke<json>(operator_gov_script_file));
01506   gen.finalize();
01507 
01508   ShareManager share_manager(network);
01509   StubNodeState node(share_manager);
01510   MemberRpcFrontend frontend(network, node, share_manager);
01511   frontend.open();
01512 
01513   size_t proposal_id;
01514 
01515   const ccf::Script vote_for("return true");
01516   const ccf::Script vote_against("return false");
01517 
01518   {
01519     DOCTEST_INFO("Check node exists with status pending");
01520     auto read_values =
01521       create_request(read_params<int>(node_id, Tables::NODES), "read");
01522     const auto r = parse_response_body<NodeInfo>(
01523       frontend_process(frontend, read_values, operator_cert));
01524 
01525     DOCTEST_CHECK(r.status == NodeStatus::PENDING);
01526   }
01527 
01528   {
01529     DOCTEST_INFO("Operator proposes node");
01530     Script proposal(R"xxx(
01531       local tables, node_id = ...
01532       return Calls:call("trust_node", node_id)
01533     )xxx");
01534 
01535     const auto propose =
01536       create_signed_request(Propose::In{proposal, node_id}, "proposals", kp);
01537     const auto r = parse_response_body<Propose::Out>(
01538       frontend_process(frontend, propose, operator_cert));
01539 
01540     DOCTEST_CHECK(r.state == ProposalState::ACCEPTED);
01541     proposal_id = r.proposal_id;
01542   }
01543 
01544   {
01545     DOCTEST_INFO("Validate vote tally");
01546 
01547     const auto proposal = get_proposal(frontend, proposal_id, operator_cert);
01548 
01549     const auto& votes = proposal.votes;
01550     DOCTEST_CHECK(votes.size() == 0);
01551 
01552     const auto proposer_vote = votes.find(operator_id);
01553     DOCTEST_CHECK(proposer_vote == votes.end());
01554   }
01555 
01556   auto new_operator_kp = tls::make_key_pair();
01557   const auto new_operator_cert = get_cert(42, new_operator_kp);
01558 
01559   {
01560     DOCTEST_INFO("Operator adds another operator");
01561     Propose::In proposal;
01562     proposal.script = std::string(R"xxx(
01563       local tables, member_info = ...
01564       return Calls:call("new_member", member_info)
01565     )xxx");
01566 
01567     proposal.parameter["cert"] = new_operator_cert;
01568     proposal.parameter["member_data"] = operator_member_data();
01569 
01570     const auto propose = create_signed_request(proposal, "proposals", kp);
01571     const auto r = parse_response_body<Propose::Out>(
01572       frontend_process(frontend, propose, operator_cert));
01573 
01574     DOCTEST_CHECK(r.state == ProposalState::ACCEPTED);
01575 
01576     {
01577       DOCTEST_INFO("New operator acks to become active");
01578       const auto state_digest_req =
01579         create_request(nullptr, "ack/update_state_digest");
01580       const auto ack = parse_response_body<StateDigest>(
01581         frontend_process(frontend, state_digest_req, new_operator_cert));
01582 
01583       StateDigest params;
01584       params.state_digest = ack.state_digest;
01585       const auto ack_req =
01586         create_signed_request(params, "ack", new_operator_kp);
01587       const auto resp = frontend_process(frontend, ack_req, new_operator_cert);
01588     }
01589   }
01590 
01591   {
01592     DOCTEST_INFO("New operator retires original operator");
01593     Propose::In proposal;
01594     proposal.script = fmt::format(
01595       R"xxx(return Calls:call("retire_member", {}))xxx", operator_id);
01596 
01597     const auto propose =
01598       create_signed_request(proposal, "proposals", new_operator_kp);
01599     const auto r = parse_response_body<Propose::Out>(
01600       frontend_process(frontend, propose, new_operator_cert));
01601 
01602     DOCTEST_CHECK(r.state == ProposalState::ACCEPTED);
01603   }
01604 
01605   {
01606     DOCTEST_INFO("New operator cannot add non-operator member");
01607 
01608     auto new_member_kp = tls::make_key_pair();
01609     const auto new_member_cert = get_cert(100, new_member_kp);
01610 
01611     Propose::In proposal;
01612     proposal.script = std::string(R"xxx(
01613       local tables, member_info = ...
01614       return Calls:call("new_member", member_info)
01615     )xxx");
01616 
01617     proposal.parameter["cert"] = new_member_cert;
01618     proposal.parameter["encryption_pub_key"] = dummy_enc_pubk;
01619     proposal.parameter["member_data"] =
01620       nullptr; // blank member_data => not an operator
01621 
01622     const auto propose =
01623       create_signed_request(proposal, "proposals", new_operator_kp);
01624     const auto r = parse_response_body<Propose::Out>(
01625       frontend_process(frontend, propose, new_operator_cert));
01626 
01627     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01628   }
01629 
01630   {
01631     DOCTEST_INFO("New operator cannot retire non-operator member");
01632 
01633     const auto normal_member_id = members.begin()->first;
01634 
01635     Propose::In proposal;
01636     proposal.script = fmt::format(
01637       R"xxx(return Calls:call("retire_member", {}))xxx", normal_member_id);
01638 
01639     const auto propose =
01640       create_signed_request(proposal, "proposals", new_operator_kp);
01641     const auto r = parse_response_body<Propose::Out>(
01642       frontend_process(frontend, propose, new_operator_cert));
01643 
01644     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01645   }
01646 }
01647 
01648 DOCTEST_TEST_CASE(
01649   "Members passing an operator change" * doctest::test_suite("operator"))
01650 {
01651   // Member proposes an operator change
01652   // A majority of members pass the vote
01653   NetworkState network;
01654   network.tables->set_encryptor(encryptor);
01655   auto gen_tx = network.tables->create_tx();
01656   GenesisGenerator gen(network, gen_tx);
01657   gen.init_values();
01658   gen.create_service({});
01659   auto new_kp = tls::make_key_pair();
01660   auto new_ca = new_kp->self_sign("CN=new node");
01661   NodeInfo ni;
01662   ni.cert = new_ca;
01663   gen.add_node(ni);
01664 
01665   // Not operating member
01666   const auto proposer_cert = get_cert(0, kp);
01667   const auto proposer_id = gen.add_member(proposer_cert);
01668   gen.activate_member(proposer_id);
01669 
01670   // Non-operating members
01671   std::map<size_t, tls::Pem> members;
01672   for (size_t i = 1; i < 3; i++)
01673   {
01674     auto cert = get_cert(i, kp);
01675     auto id = gen.add_member(cert);
01676     gen.activate_member(id);
01677     members[id] = cert;
01678   }
01679 
01680   set_whitelists(gen);
01681   gen.set_gov_scripts(
01682     lua::Interpreter().invoke<json>(operator_gov_script_file));
01683   gen.finalize();
01684 
01685   ShareManager share_manager(network);
01686   StubNodeState node(share_manager);
01687   MemberRpcFrontend frontend(network, node, share_manager);
01688   frontend.open();
01689 
01690   size_t proposal_id;
01691 
01692   const ccf::Script vote_for("return true");
01693   const ccf::Script vote_against("return false");
01694 
01695   auto node_id = 0;
01696   {
01697     DOCTEST_INFO("Check node exists with status pending");
01698     const auto read_values =
01699       create_request(read_params<int>(node_id, Tables::NODES), "read");
01700     const auto r = parse_response_body<NodeInfo>(
01701       frontend_process(frontend, read_values, proposer_cert));
01702     DOCTEST_CHECK(r.status == NodeStatus::PENDING);
01703   }
01704 
01705   {
01706     DOCTEST_INFO("Member proposes");
01707     Script proposal(R"xxx(
01708       local tables, node_id = ...
01709       return Calls:call("trust_node", node_id)
01710     )xxx");
01711 
01712     const auto propose =
01713       create_signed_request(Propose::In{proposal, node_id}, "proposals", kp);
01714     const auto r = parse_response_body<Propose::Out>(
01715       frontend_process(frontend, propose, proposer_cert));
01716 
01717     DOCTEST_CHECK(r.state == ProposalState::OPEN);
01718     proposal_id = r.proposal_id;
01719   }
01720 
01721   {
01722     DOCTEST_INFO("Member votes against");
01723 
01724     const auto vote = create_signed_request(
01725       Vote{vote_against}, fmt::format("proposals/{}/votes", proposal_id), kp);
01726     const auto r = frontend_process(frontend, vote, proposer_cert);
01727 
01728     check_result_state(r, ProposalState::OPEN);
01729   }
01730 
01731   size_t first_voter_id = 1;
01732   size_t second_voter_id = 2;
01733 
01734   {
01735     DOCTEST_INFO("First member votes for proposal");
01736 
01737     const auto vote = create_signed_request(
01738       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
01739     const auto r = frontend_process(frontend, vote, members[first_voter_id]);
01740 
01741     check_result_state(r, ProposalState::OPEN);
01742   }
01743 
01744   {
01745     DOCTEST_INFO("Second member votes for proposal");
01746 
01747     const auto vote = create_signed_request(
01748       Vote{vote_for}, fmt::format("proposals/{}/votes", proposal_id), kp);
01749     const auto r = frontend_process(frontend, vote, members[second_voter_id]);
01750 
01751     check_result_state(r, ProposalState::ACCEPTED);
01752   }
01753 
01754   {
01755     DOCTEST_INFO("Validate vote tally");
01756 
01757     const auto proposal = get_proposal(frontend, proposal_id, proposer_cert);
01758 
01759     const auto& votes = proposal.votes;
01760     DOCTEST_CHECK(votes.size() == 3);
01761 
01762     const auto proposer_vote = votes.find(proposer_id);
01763     DOCTEST_CHECK(proposer_vote != votes.end());
01764     DOCTEST_CHECK(proposer_vote->second == vote_against);
01765 
01766     const auto first_vote = votes.find(first_voter_id);
01767     DOCTEST_CHECK(first_vote != votes.end());
01768     DOCTEST_CHECK(first_vote->second == vote_for);
01769 
01770     const auto second_vote = votes.find(second_voter_id);
01771     DOCTEST_CHECK(second_vote != votes.end());
01772     DOCTEST_CHECK(second_vote->second == vote_for);
01773   }
01774 }
01775 
01776 DOCTEST_TEST_CASE("User data")
01777 {
01778   NetworkState network;
01779   network.tables->set_encryptor(encryptor);
01780   auto gen_tx = network.tables->create_tx();
01781   GenesisGenerator gen(network, gen_tx);
01782   gen.init_values();
01783   gen.create_service({});
01784   const auto member_id = gen.add_member(member_cert);
01785   gen.activate_member(member_id);
01786   set_whitelists(gen);
01787   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
01788 
01789   ShareManager share_manager(network);
01790   StubNodeState node(share_manager);
01791   MemberRpcFrontend frontend(network, node, share_manager);
01792   frontend.open();
01793 
01794   ccf::UserId user_id;
01795   std::vector<uint8_t> read_user_info;
01796 
01797   DOCTEST_SUBCASE("No initial user data")
01798   {
01799     user_id = gen.add_user({user_cert});
01800     gen.finalize();
01801 
01802     read_user_info =
01803       create_request(read_params(user_id, Tables::USERS), "read");
01804 
01805     {
01806       DOCTEST_INFO("user data is initially empty");
01807       const auto read_response = parse_response_body<ccf::UserInfo>(
01808         frontend_process(frontend, read_user_info, member_cert));
01809       DOCTEST_CHECK(read_response.user_data.is_null());
01810     }
01811   }
01812 
01813   DOCTEST_SUBCASE("Initial user data")
01814   {
01815     const auto user_data_string = "BOB";
01816     user_id = gen.add_user({user_cert, user_data_string});
01817     gen.finalize();
01818 
01819     read_user_info =
01820       create_request(read_params(user_id, Tables::USERS), "read");
01821 
01822     {
01823       DOCTEST_INFO("initial user data object can be read");
01824       const auto read_response = parse_response_body<ccf::UserInfo>(
01825         frontend_process(frontend, read_user_info, member_cert));
01826       DOCTEST_CHECK(read_response.user_data == user_data_string);
01827     }
01828   }
01829 
01830   {
01831     auto user_data_object = nlohmann::json::object();
01832     user_data_object["name"] = "bob";
01833     user_data_object["permissions"] = {"read", "delete"};
01834 
01835     DOCTEST_INFO("user data can be set to an object");
01836     Propose::In proposal;
01837     proposal.script = fmt::format(
01838       R"xxx(
01839         proposed_user_data = {{
01840           name = "bob",
01841           permissions = {{"read", "delete"}}
01842         }}
01843         return Calls:call("set_user_data", {{user_id = {}, user_data =
01844         proposed_user_data}})
01845       )xxx",
01846       user_id);
01847     const auto proposal_serialized =
01848       create_signed_request(proposal, "proposals", kp);
01849     const auto propose_response = parse_response_body<Propose::Out>(
01850       frontend_process(frontend, proposal_serialized, member_cert));
01851 
01852     DOCTEST_CHECK(propose_response.state == ProposalState::OPEN);
01853 
01854     {
01855       // vote for own proposal
01856       Script vote_yes("return true");
01857       const auto vote = create_signed_request(
01858         Vote{vote_yes},
01859         fmt::format("proposals/{}/votes", propose_response.proposal_id),
01860         kp);
01861       const auto r = frontend_process(frontend, vote, member_cert);
01862       const auto result = parse_response_body<ProposalInfo>(r);
01863       DOCTEST_CHECK(result.state == ProposalState::ACCEPTED);
01864     }
01865 
01866     DOCTEST_INFO("user data object can be read");
01867     const auto read_response = parse_response_body<ccf::UserInfo>(
01868       frontend_process(frontend, read_user_info, member_cert));
01869     DOCTEST_CHECK(read_response.user_data == user_data_object);
01870   }
01871 
01872   {
01873     const auto user_data_string = "ADMINISTRATOR";
01874 
01875     DOCTEST_INFO("user data can be overwritten");
01876     Propose::In proposal;
01877     proposal.script = std::string(R"xxx(
01878       local tables, param = ...
01879       return Calls:call("set_user_data", {user_id = param.id, user_data =
01880       param.data})
01881     )xxx");
01882     proposal.parameter["id"] = user_id;
01883     proposal.parameter["data"] = user_data_string;
01884     const auto proposal_serialized =
01885       create_signed_request(proposal, "proposals", kp);
01886     const auto propose_response = parse_response_body<Propose::Out>(
01887       frontend_process(frontend, proposal_serialized, member_cert));
01888     DOCTEST_CHECK(propose_response.state == ProposalState::OPEN);
01889 
01890     {
01891       // vote for own proposal
01892       Script vote_yes("return true");
01893       const auto vote = create_signed_request(
01894         Vote{vote_yes},
01895         fmt::format("proposals/{}/votes", propose_response.proposal_id),
01896         kp);
01897       const auto r = frontend_process(frontend, vote, member_cert);
01898       const auto result = parse_response_body<ProposalInfo>(r);
01899       DOCTEST_CHECK(result.state == ProposalState::ACCEPTED);
01900     }
01901 
01902     DOCTEST_INFO("user data object can be read");
01903     const auto response = parse_response_body<ccf::UserInfo>(
01904       frontend_process(frontend, read_user_info, member_cert));
01905     DOCTEST_CHECK(response.user_data == user_data_string);
01906   }
01907 }
01908 
01909 DOCTEST_TEST_CASE("Submit recovery shares")
01910 {
01911   NetworkState network(ConsensusType::CFT);
01912   network.ledger_secrets = std::make_shared<LedgerSecrets>();
01913   network.ledger_secrets->init();
01914 
01915   ShareManager share_manager(network);
01916   auto node = StubNodeState(share_manager);
01917   MemberRpcFrontend frontend(network, node, share_manager);
01918   std::map<size_t, std::pair<tls::Pem, tls::RSAKeyPairPtr>> members;
01919 
01920   size_t members_count = 4;
01921   size_t recovery_threshold = 2;
01922   DOCTEST_REQUIRE(recovery_threshold <= members_count);
01923   std::map<size_t, std::vector<uint8_t>> retrieved_shares;
01924 
01925   DOCTEST_INFO("Setup state");
01926   {
01927     auto gen_tx = network.tables->create_tx();
01928     GenesisGenerator gen(network, gen_tx);
01929     gen.init_values();
01930     gen.create_service({});
01931 
01932     for (size_t i = 0; i < members_count; i++)
01933     {
01934       auto cert = get_cert(i, kp);
01935       auto enc_kp = tls::make_rsa_key_pair();
01936 
01937       auto id = gen.add_member({cert, enc_kp->public_key_pem()});
01938       gen.activate_member(id);
01939       members[id] = {cert, enc_kp};
01940     }
01941     gen.set_recovery_threshold(recovery_threshold);
01942     share_manager.issue_shares(gen_tx);
01943     gen.finalize();
01944     frontend.open();
01945   }
01946 
01947   DOCTEST_INFO("Retrieve and decrypt recovery shares");
01948   {
01949     const auto get_recovery_shares =
01950       create_request(nullptr, "recovery_share", HTTP_GET);
01951 
01952     for (auto const& m : members)
01953     {
01954       auto resp = parse_response_body<std::string>(
01955         frontend_process(frontend, get_recovery_shares, m.second.first));
01956 
01957       auto encrypted_share = tls::raw_from_b64(resp);
01958       retrieved_shares[m.first] = m.second.second->unwrap(encrypted_share);
01959     }
01960   }
01961 
01962   DOCTEST_INFO("Submit share before the service is in correct state");
01963   {
01964     MemberId member_id = 0;
01965     const auto submit_recovery_share = create_text_request(
01966       tls::b64_from_raw(retrieved_shares[member_id]), "recovery_share");
01967 
01968     check_error(
01969       frontend_process(
01970         frontend, submit_recovery_share, members[member_id].first),
01971       HTTP_STATUS_FORBIDDEN);
01972   }
01973 
01974   DOCTEST_INFO("Change service state to waiting for recovery shares");
01975   {
01976     auto tx = network.tables->create_tx();
01977     GenesisGenerator g(network, tx);
01978     DOCTEST_REQUIRE(g.service_wait_for_shares());
01979     g.finalize();
01980   }
01981 
01982   DOCTEST_INFO(
01983     "Threshold cannot be changed while service is waiting for shares");
01984   {
01985     auto tx = network.tables->create_tx();
01986     GenesisGenerator g(network, tx);
01987     DOCTEST_REQUIRE_FALSE(g.set_recovery_threshold(recovery_threshold));
01988   }
01989 
01990   DOCTEST_INFO("Submit bogus recovery shares");
01991   {
01992     size_t submitted_shares_count = 0;
01993     for (auto const& m : members)
01994     {
01995       auto bogus_recovery_share = retrieved_shares[m.first];
01996       bogus_recovery_share[0] = bogus_recovery_share[0] + 1;
01997       const auto submit_recovery_share = create_text_request(
01998         tls::b64_from_raw(bogus_recovery_share), "recovery_share");
01999 
02000       auto rep =
02001         frontend_process(frontend, submit_recovery_share, m.second.first);
02002 
02003       submitted_shares_count++;
02004 
02005       auto tx = network.tables->create_tx();
02006       auto submitted_shares = tx.get_view(network.submitted_shares);
02007       // Share submission should only complete when the recovery threshold
02008       // has been reached
02009       if (submitted_shares_count >= recovery_threshold)
02010       {
02011         check_error(rep, HTTP_STATUS_INTERNAL_SERVER_ERROR);
02012 
02013         // On error, all submitted shares should have been cleared
02014         size_t submitted_shares_count = 0;
02015         submitted_shares->foreach(
02016           [&submitted_shares_count](const auto& member_id, const auto& share) {
02017             submitted_shares_count++;
02018             return true;
02019           });
02020         DOCTEST_REQUIRE(submitted_shares_count == 0);
02021         break;
02022       }
02023       else
02024       {
02025         DOCTEST_REQUIRE(submitted_shares->has(m.first));
02026       }
02027     }
02028   }
02029 
02030   // It is still possible to re-submit recovery shares if a threshold of at
02031   // least one bogus share has been submitted.
02032 
02033   DOCTEST_INFO("Submit recovery shares");
02034   {
02035     size_t submitted_shares_count = 0;
02036     for (auto const& m : members)
02037     {
02038       const auto submit_recovery_share = create_text_request(
02039         tls::b64_from_raw(retrieved_shares[m.first]), "recovery_share");
02040 
02041       auto rep =
02042         frontend_process(frontend, submit_recovery_share, m.second.first);
02043 
02044       submitted_shares_count++;
02045 
02046       // Share submission should only complete when the recovery threshold
02047       // has been reached
02048       if (submitted_shares_count >= recovery_threshold)
02049       {
02050         DOCTEST_REQUIRE(
02051           parse_response_body(rep).find(
02052             "End of recovery procedure initiated.") != std::string::npos);
02053         break;
02054       }
02055     }
02056   }
02057 }
02058 
02059 DOCTEST_TEST_CASE("Number of active members with recovery shares limits")
02060 {
02061   auto level_before = logger::config::level();
02062   logger::config::level() = logger::INFO;
02063 
02064   NetworkState network;
02065   network.ledger_secrets = std::make_shared<LedgerSecrets>();
02066   network.ledger_secrets->init();
02067   network.tables->set_encryptor(encryptor);
02068   ShareManager share_manager(network);
02069   StubNodeState node(share_manager);
02070   MemberRpcFrontend frontend(network, node, share_manager);
02071   frontend.open();
02072 
02073   std::map<size_t, tls::Pem> members;
02074 
02075   auto gen_tx = network.tables->create_tx();
02076   GenesisGenerator gen(network, gen_tx);
02077   gen.init_values();
02078   gen.create_service({});
02079   gen.set_recovery_threshold(1);
02080   set_whitelists(gen);
02081   gen.set_gov_scripts(lua::Interpreter().invoke<json>(gov_script_file));
02082 
02083   DOCTEST_INFO("Add one too many members with recovery share");
02084   {
02085     // Members are not yet active
02086     for (size_t i = 0; i < max_active_recovery_members + 1; i++)
02087     {
02088       auto cert = get_cert(i, kp);
02089       members[gen.add_member({cert, dummy_enc_pubk})] = cert;
02090     }
02091     gen.finalize();
02092   }
02093 
02094   DOCTEST_INFO("Activate members until reaching limit");
02095   {
02096     for (auto const& m : members)
02097     {
02098       auto resp = activate(frontend, kp, m.second);
02099 
02100       if (m.first >= max_active_recovery_members)
02101       {
02102         DOCTEST_CHECK(resp.status == HTTP_STATUS_FORBIDDEN);
02103       }
02104       else
02105       {
02106         DOCTEST_CHECK(resp.status == HTTP_STATUS_OK);
02107         DOCTEST_CHECK(parse_response_body<bool>(resp));
02108       }
02109     }
02110   }
02111 
02112   DOCTEST_INFO("It is still OK to add and activate a non-recovery member");
02113   {
02114     auto gen_tx = network.tables->create_tx();
02115     GenesisGenerator gen(network, gen_tx);
02116     auto cert = get_cert(members.size(), kp);
02117     gen.add_member(cert); // No public encryption key added
02118     gen.finalize();
02119     auto resp = activate(frontend, kp, cert);
02120 
02121     DOCTEST_CHECK(resp.status == HTTP_STATUS_OK);
02122     DOCTEST_CHECK(parse_response_body<bool>(resp));
02123   }
02124 
02125   // Revert logging
02126   logger::config::level() = level_before;
02127 }
02128 
02129 DOCTEST_TEST_CASE("Open network sequence")
02130 {
02131   // Setup original state
02132   NetworkState network(ConsensusType::CFT);
02133   network.ledger_secrets = std::make_shared<LedgerSecrets>();
02134   network.ledger_secrets->init();
02135 
02136   ShareManager share_manager(network);
02137   auto node = StubNodeState(share_manager);
02138   MemberRpcFrontend frontend(network, node, share_manager);
02139   std::map<size_t, std::pair<tls::Pem, std::vector<uint8_t>>> members;
02140 
02141   size_t members_count = 4;
02142   size_t recovery_threshold = 100;
02143   DOCTEST_REQUIRE(members_count < recovery_threshold);
02144 
02145   DOCTEST_INFO("Setup state");
02146   {
02147     auto gen_tx = network.tables->create_tx();
02148     GenesisGenerator gen(network, gen_tx);
02149     gen.init_values();
02150     gen.create_service({});
02151 
02152     // Adding accepted members
02153     for (size_t i = 0; i < members_count; i++)
02154     {
02155       auto cert = get_cert(i, kp);
02156       auto id = gen.add_member({cert, dummy_enc_pubk});
02157       members[id] = {cert, {}};
02158     }
02159     gen.set_recovery_threshold(recovery_threshold);
02160     gen.finalize();
02161     frontend.open();
02162   }
02163 
02164   DOCTEST_INFO("Open fails as recovery threshold is too high");
02165   {
02166     auto gen_tx = network.tables->create_tx();
02167     GenesisGenerator gen(network, gen_tx);
02168 
02169     DOCTEST_REQUIRE_FALSE(gen.open_service());
02170   }
02171 
02172   DOCTEST_INFO("Activate all members - open still fails");
02173   {
02174     auto gen_tx = network.tables->create_tx();
02175     GenesisGenerator gen(network, gen_tx);
02176     for (auto const& m : members)
02177     {
02178       gen.activate_member(m.first);
02179     }
02180     DOCTEST_REQUIRE_FALSE(gen.open_service());
02181     gen.finalize();
02182   }
02183 
02184   DOCTEST_INFO("Reduce recovery threshold");
02185   {
02186     auto gen_tx = network.tables->create_tx();
02187     GenesisGenerator gen(network, gen_tx);
02188     gen.set_recovery_threshold(members_count);
02189 
02190     DOCTEST_REQUIRE(gen.open_service());
02191   }
02192 }
02193 
02194 int main(int argc, char** argv)
02195 {
02196   doctest::Context context;
02197   context.applyCommandLine(argc, argv);
02198   int res = context.run();
02199   if (context.shouldExit())
02200     return res;
02201   return res;
02202 }
02203 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT DOCTEST_CONFIG_NO_EXCEPTIONS_BUT_WITH_ALL_ASSERTS DOCTEST_CONFIG_NO_SHORT_MACRO_NAMES 
---------
Parsing file /data/git/CCF/src/node/rpc/test/member_voting_test.cpp...
Preprocessing /data/git/CCF/src/node/rpc/test/node_frontend_test.cpp...
#include ds/logger.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include node/genesis_gen.h: not found! skipping...
#include node/rpc/node_frontend.h: not found! skipping...
#include node/rpc/serdes.h: not found! skipping...
#include node_stub.h: already included! skipping...
#include tls/pem.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 9255 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 #define DOCTEST_CONFIG_IMPLEMENT
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 using namespace ccf;
00017 using namespace nlohmann;
00018 using namespace serdes;
00019 
00020 using TResponse = http::SimpleResponseProcessor::Response;
00021 
00022 auto kp = tls::make_key_pair();
00023 auto member_cert = kp -> self_sign("CN=name_member");
00024 
00025 void check_error(const TResponse& r, http_status expected)
00026 {
00027   CHECK(r.status == expected);
00028 }
00029 
00030 void check_error_message(const TResponse& r, const std::string& msg)
00031 {
00032   const std::string body_s(r.body.begin(), r.body.end());
00033   CHECK(body_s.find(msg) != std::string::npos);
00034 }
00035 
00036 TResponse frontend_process(
00037   NodeRpcFrontend& frontend,
00038   const json& json_params,
00039   const std::string& method,
00040   const tls::Pem& caller)
00041 {
00042   http::Request r(method);
00043   const auto body = json_params.is_null() ?
00044     std::vector<uint8_t>() :
00045     serdes::pack(json_params, Pack::Text);
00046   r.set_body(&body);
00047   auto serialise_request = r.build_request();
00048 
00049   auto session = std::make_shared<enclave::SessionContext>(
00050     enclave::InvalidSessionId, caller.raw());
00051   auto rpc_ctx = enclave::make_rpc_context(session, serialise_request);
00052   auto serialised_response = frontend.process(rpc_ctx);
00053 
00054   CHECK(serialised_response.has_value());
00055 
00056   http::SimpleResponseProcessor processor;
00057   http::ResponseParser parser(processor);
00058 
00059   parser.execute(serialised_response->data(), serialised_response->size());
00060   REQUIRE(processor.received.size() == 1);
00061 
00062   return processor.received.front();
00063 }
00064 
00065 template <typename T>
00066 T parse_response_body(const TResponse& r)
00067 {
00068   const auto body_j = serdes::unpack(r.body, serdes::Pack::Text);
00069   return body_j.get<T>();
00070 }
00071 
00072 TEST_CASE("Add a node to an opening service")
00073 {
00074   NetworkState network;
00075   auto gen_tx = network.tables->create_tx();
00076   GenesisGenerator gen(network, gen_tx);
00077   gen.init_values();
00078 
00079   ShareManager share_manager(network);
00080   StubNodeState node(share_manager);
00081   NodeRpcFrontend frontend(network, node);
00082   frontend.open();
00083 
00084   network.identity = std::make_unique<NetworkIdentity>();
00085   network.ledger_secrets = std::make_shared<LedgerSecrets>();
00086   network.ledger_secrets->init();
00087 
00088   // Node certificate
00089   tls::KeyPairPtr kp = tls::make_key_pair();
00090   const auto caller = kp->self_sign(fmt::format("CN=nodes"));
00091   const auto node_public_encryption_key =
00092     tls::make_key_pair()->public_key_pem();
00093 
00094   INFO("Try to join with a different consensus");
00095   {
00096     JoinNetworkNodeToNode::In join_input;
00097     join_input.public_encryption_key = node_public_encryption_key;
00098     join_input.consensus_type = ConsensusType::BFT;
00099     const auto response =
00100       frontend_process(frontend, join_input, "join", caller);
00101 
00102     check_error(response, HTTP_STATUS_BAD_REQUEST);
00103     check_error_message(
00104       response,
00105       fmt::format(
00106         "Node requested to join with consensus type {} but "
00107         "current consensus type is {}",
00108         ConsensusType::BFT,
00109         ConsensusType::CFT));
00110   }
00111 
00112   INFO("Add first node before a service exists");
00113   {
00114     JoinNetworkNodeToNode::In join_input;
00115     join_input.public_encryption_key = node_public_encryption_key;
00116     const auto response =
00117       frontend_process(frontend, join_input, "join", caller);
00118 
00119     check_error(response, HTTP_STATUS_INTERNAL_SERVER_ERROR);
00120     check_error_message(response, "No service is available to accept new node");
00121   }
00122 
00123   gen.create_service({});
00124   gen.finalize();
00125 
00126   INFO("Add first node which should be trusted straight away");
00127   {
00128     JoinNetworkNodeToNode::In join_input;
00129     join_input.public_encryption_key = node_public_encryption_key;
00130 
00131     auto http_response = frontend_process(frontend, join_input, "join", caller);
00132     CHECK(http_response.status == HTTP_STATUS_OK);
00133 
00134     const auto response =
00135       parse_response_body<JoinNetworkNodeToNode::Out>(http_response);
00136 
00137     CHECK(
00138       response.network_info.ledger_secrets == *network.ledger_secrets.get());
00139     CHECK(response.network_info.identity == *network.identity.get());
00140     CHECK(response.node_status == NodeStatus::TRUSTED);
00141     CHECK(response.network_info.public_only == false);
00142 
00143     auto tx = network.tables->create_tx();
00144     const NodeId node_id = response.node_id;
00145     auto nodes_view = tx.get_view(network.nodes);
00146     auto node_info = nodes_view->get(node_id);
00147 
00148     CHECK(node_info.has_value());
00149     CHECK(node_info->status == NodeStatus::TRUSTED);
00150     CHECK(caller == node_info->cert);
00151   }
00152 
00153   INFO("Adding the same node should return the same result");
00154   {
00155     JoinNetworkNodeToNode::In join_input;
00156     join_input.public_encryption_key = node_public_encryption_key;
00157 
00158     auto http_response = frontend_process(frontend, join_input, "join", caller);
00159     CHECK(http_response.status == HTTP_STATUS_OK);
00160 
00161     const auto response =
00162       parse_response_body<JoinNetworkNodeToNode::Out>(http_response);
00163 
00164     CHECK(
00165       response.network_info.ledger_secrets == *network.ledger_secrets.get());
00166     CHECK(response.network_info.identity == *network.identity.get());
00167     CHECK(response.node_status == NodeStatus::TRUSTED);
00168   }
00169 
00170   INFO(
00171     "Adding a different node with the same node network details should fail");
00172   {
00173     tls::KeyPairPtr kp = tls::make_key_pair();
00174     auto v = tls::make_verifier(kp->self_sign(fmt::format("CN=nodes")));
00175     const auto caller = v->der_cert_data();
00176 
00177     // Network node info is empty (same as before)
00178     JoinNetworkNodeToNode::In join_input;
00179     join_input.public_encryption_key = node_public_encryption_key;
00180 
00181     auto http_response = frontend_process(frontend, join_input, "join", caller);
00182 
00183     check_error(http_response, HTTP_STATUS_BAD_REQUEST);
00184     check_error_message(http_response, "A node with the same node host");
00185   }
00186 }
00187 
00188 TEST_CASE("Add a node to an open service")
00189 {
00190   NetworkState network;
00191   auto gen_tx = network.tables->create_tx();
00192   GenesisGenerator gen(network, gen_tx);
00193   gen.init_values();
00194 
00195   ShareManager share_manager(network);
00196   StubNodeState node(share_manager);
00197   node.set_is_public(true);
00198   NodeRpcFrontend frontend(network, node);
00199   frontend.open();
00200 
00201   network.identity = std::make_unique<NetworkIdentity>();
00202   network.ledger_secrets = std::make_shared<LedgerSecrets>();
00203   network.ledger_secrets->init();
00204   network.ledger_secrets->add_new_secret(4, LedgerSecret());
00205 
00206   gen.create_service({});
00207   gen.set_recovery_threshold(1);
00208   gen.activate_member(
00209     gen.add_member({member_cert, tls::make_rsa_key_pair()->public_key_pem()}));
00210   REQUIRE(gen.open_service());
00211   gen.finalize();
00212 
00213   // Node certificate
00214   tls::KeyPairPtr kp = tls::make_key_pair();
00215   const auto caller = kp->self_sign(fmt::format("CN=nodes"));
00216 
00217   std::optional<NodeInfo> node_info;
00218   auto tx = network.tables->create_tx();
00219 
00220   JoinNetworkNodeToNode::In join_input;
00221 
00222   INFO("Add node once service is open");
00223   {
00224     auto http_response = frontend_process(frontend, join_input, "join", caller);
00225     CHECK(http_response.status == HTTP_STATUS_OK);
00226 
00227     const auto response =
00228       parse_response_body<JoinNetworkNodeToNode::Out>(http_response);
00229 
00230     CHECK(response.network_info.identity.priv_key.empty());
00231 
00232     auto node_id = response.node_id;
00233 
00234     auto nodes_view = tx.get_view(network.nodes);
00235     node_info = nodes_view->get(node_id);
00236     CHECK(node_info.has_value());
00237     CHECK(node_info->status == NodeStatus::PENDING);
00238     CHECK(caller == node_info->cert);
00239   }
00240 
00241   INFO(
00242     "Adding a different node with the same node network details should fail");
00243   {
00244     tls::KeyPairPtr kp = tls::make_key_pair();
00245     auto v = tls::make_verifier(kp->self_sign(fmt::format("CN=nodes")));
00246     const auto caller = v->der_cert_data();
00247 
00248     // Network node info is empty (same as before)
00249     JoinNetworkNodeToNode::In join_input;
00250 
00251     auto http_response = frontend_process(frontend, join_input, "join", caller);
00252 
00253     check_error(http_response, HTTP_STATUS_BAD_REQUEST);
00254     check_error_message(http_response, "A node with the same node host");
00255   }
00256 
00257   INFO("Try to join again without being trusted");
00258   {
00259     auto http_response = frontend_process(frontend, join_input, "join", caller);
00260     CHECK(http_response.status == HTTP_STATUS_OK);
00261 
00262     const auto response =
00263       parse_response_body<JoinNetworkNodeToNode::Out>(http_response);
00264 
00265     // The network secrets are still not available to the joining node
00266     CHECK(response.network_info.identity.priv_key.empty());
00267   }
00268 
00269   INFO("Trust node and attempt to join");
00270   {
00271     // In a real scenario, nodes are trusted via member governance.
00272     node_info->status = NodeStatus::TRUSTED;
00273     auto nodes_view = tx.get_view(network.nodes);
00274     nodes_view->put(0, node_info.value());
00275     CHECK(tx.commit() == kv::CommitSuccess::OK);
00276 
00277     auto http_response = frontend_process(frontend, join_input, "join", caller);
00278     CHECK(http_response.status == HTTP_STATUS_OK);
00279 
00280     const auto response =
00281       parse_response_body<JoinNetworkNodeToNode::Out>(http_response);
00282 
00283     CHECK(
00284       response.network_info.ledger_secrets == *network.ledger_secrets.get());
00285     CHECK(response.network_info.identity == *network.identity.get());
00286     CHECK(response.node_status == NodeStatus::TRUSTED);
00287     CHECK(response.network_info.public_only == true);
00288   }
00289 }
00290 
00291 int main(int argc, char** argv)
00292 {
00293   doctest::Context context;
00294   context.applyCommandLine(argc, argv);
00295   int res = context.run();
00296   if (context.shouldExit())
00297     return res;
00298   return res;
00299 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT 
---------
Parsing file /data/git/CCF/src/node/rpc/test/node_frontend_test.cpp...
Preprocessing /data/git/CCF/src/node/rpc/test/node_stub.h...
#include node/rpc/node_interface.h: not found! skipping...
#include node/share_manager.h: not found! skipping...
Preprocessor output (size: 1651 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace ccf
00009 {
00010   class StubNodeState : public ccf::AbstractNodeState
00011   {
00012   private:
00013     bool is_public = false;
00014     ShareManager& share_manager;
00015 
00016   public:
00017     StubNodeState(ShareManager& share_manager) : share_manager(share_manager) {}
00018 
00019     bool accept_recovery(kv::Tx& tx) override
00020     {
00021       return true;
00022     }
00023 
00024     bool rekey_ledger(kv::Tx& tx) override
00025     {
00026       return true;
00027     }
00028 
00029     bool is_part_of_public_network() const override
00030     {
00031       return is_public;
00032     }
00033 
00034     bool is_primary() const override
00035     {
00036       return true;
00037     }
00038 
00039     bool is_reading_public_ledger() const override
00040     {
00041       return false;
00042     }
00043 
00044     bool is_reading_private_ledger() const override
00045     {
00046       return false;
00047     }
00048 
00049     bool is_verifying_snapshot() const override
00050     {
00051       return false;
00052     }
00053 
00054     bool is_part_of_network() const override
00055     {
00056       return true;
00057     }
00058 
00059     void node_quotes(
00060       kv::ReadOnlyTx& tx,
00061       GetQuotes::Out& result,
00062       const std::optional<std::set<NodeId>>& filter) override
00063     {}
00064 
00065     void initiate_private_recovery(kv::Tx& tx) override
00066     {
00067       share_manager.restore_recovery_shares_info(tx, {});
00068     }
00069 
00070     kv::Version get_last_recovered_signed_idx() override
00071     {
00072       return kv::NoVersion;
00073     }
00074 
00075     NodeId get_node_id() const override
00076     {
00077       return 0;
00078     }
00079 
00080     void set_is_public(bool is_public_)
00081     {
00082       is_public = is_public_;
00083     }
00084 
00085     ExtendedState state() override
00086     {
00087       return {State::partOfNetwork, {}, {}};
00088     }
00089 
00090     void open_user_frontend() override{};
00091   };
00092 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/test/node_stub.h...
Preprocessing /data/git/CCF/src/node/rpc/test/tx_status_test.cpp...
#include node/rpc/tx_status.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 4176 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 using namespace ccf;
00010 
00011 TEST_CASE("normal flow")
00012 {
00013   constexpr auto target_view = 3;
00014   constexpr auto target_seqno = 10;
00015 
00016   // A tx id is unknown locally
00017   CHECK(get_tx_status(3, 10, 0, 1, 0) == TxStatus::Unknown);
00018 
00019   // The tx id remains unknown while a node makes progress
00020   CHECK(get_tx_status(3, 10, 0, 1, 1) == TxStatus::Unknown);
00021   CHECK(get_tx_status(3, 10, 0, 1, 2) == TxStatus::Unknown);
00022   CHECK(get_tx_status(3, 10, 0, 2, 3) == TxStatus::Unknown);
00023   CHECK(get_tx_status(3, 10, 0, 2, 4) == TxStatus::Unknown);
00024   CHECK(get_tx_status(3, 10, 0, 3, 5) == TxStatus::Unknown);
00025   CHECK(get_tx_status(3, 10, 0, 3, 6) == TxStatus::Unknown);
00026 
00027   // Eventually the tx id becomes known locally
00028   CHECK(get_tx_status(3, 10, 3, 3, 6) == TxStatus::Pending);
00029 
00030   // The tx id remains known while a node makes progress
00031   CHECK(get_tx_status(3, 10, 3, 3, 7) == TxStatus::Pending);
00032   CHECK(get_tx_status(3, 10, 3, 3, 8) == TxStatus::Pending);
00033 
00034   // Until either...
00035   {
00036     // ...the tx is globally committed...
00037     CHECK(get_tx_status(3, 10, 3, 3, 9) == TxStatus::Pending);
00038     CHECK(get_tx_status(3, 10, 3, 3, 10) == TxStatus::Committed);
00039 
00040     // The tx id remains permanently committed
00041     CHECK(get_tx_status(3, 10, 3, 3, 11) == TxStatus::Committed);
00042     CHECK(get_tx_status(3, 10, 3, 3, 12) == TxStatus::Committed);
00043     CHECK(get_tx_status(3, 10, 3, 3, 13) == TxStatus::Committed);
00044     CHECK(get_tx_status(3, 10, 3, 4, 14) == TxStatus::Committed);
00045     CHECK(get_tx_status(3, 10, 3, 5, 15) == TxStatus::Committed);
00046   }
00047   // ...or...
00048   {
00049     // ...an election occurs, and the local tx is rolled back
00050     CHECK(get_tx_status(3, 10, 0, 4, 9) == TxStatus::Invalid);
00051 
00052     // The tx id can never be committed
00053     CHECK(get_tx_status(3, 10, 4, 4, 10) == TxStatus::Invalid);
00054     CHECK(get_tx_status(3, 10, 4, 4, 11) == TxStatus::Invalid);
00055     CHECK(get_tx_status(3, 10, 4, 4, 12) == TxStatus::Invalid);
00056     CHECK(get_tx_status(3, 10, 4, 4, 13) == TxStatus::Invalid);
00057     CHECK(get_tx_status(3, 10, 4, 4, 14) == TxStatus::Invalid);
00058     CHECK(get_tx_status(3, 10, 4, 5, 15) == TxStatus::Invalid);
00059   }
00060 }
00061 
00062 TEST_CASE("edge cases")
00063 {
00064   {
00065     INFO("Unknown views");
00066     // Impossible: view for all global txs must be known
00067     // get_tx_status(a, N, 0, b, >=N)
00068     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 1, 10));
00069     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 1, 11));
00070     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 3, 10));
00071     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 3, 11));
00072     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 4, 10));
00073     CHECK_THROWS(get_tx_status(3, 10, VIEW_UNKNOWN, 4, 11));
00074   }
00075   {
00076     INFO("seqno is known locally in an old view");
00077 
00078     // Node has heard about 2.10 locally, but has not committed to 10
00079     CHECK(get_tx_status(3, 10, 2, 2, 8) == TxStatus::Unknown);
00080     // Impossible: remembering a later commit from an earlier view - should have
00081     // been rolled back
00082     // CHECK(get_tx_status(3, 10, 2, 3, 8) == TxStatus::Unknown);
00083 
00084     // Node knows 2.10 (or later) has been committed - 3.10 is impossible
00085     CHECK(get_tx_status(3, 10, 2, 2, 10) == TxStatus::Invalid);
00086     CHECK(get_tx_status(3, 10, 2, 2, 11) == TxStatus::Invalid);
00087     CHECK(get_tx_status(3, 10, 2, 3, 11) == TxStatus::Invalid);
00088     // Impossible: local doesn't match global
00089     // CHECK(get_tx_status(3, 10, 2, 3, 10) == TxStatus::Invalid);
00090   }
00091 
00092   {
00093     INFO("Node is in a newer view");
00094 
00095     CHECK(get_tx_status(3, 10, 0, 4, 8) == TxStatus::Invalid);
00096     CHECK(get_tx_status(3, 10, 4, 4, 8) == TxStatus::Invalid);
00097     CHECK(get_tx_status(3, 10, 4, 4, 10) == TxStatus::Invalid);
00098     CHECK(get_tx_status(3, 10, 4, 4, 11) == TxStatus::Invalid);
00099     CHECK(get_tx_status(3, 10, 4, 5, 11) == TxStatus::Invalid);
00100     CHECK(get_tx_status(3, 10, 4, 5, 12) == TxStatus::Invalid);
00101   }
00102 
00103   {
00104     INFO("Asking about future views");
00105 
00106     CHECK(get_tx_status(100, 10, 0, 4, 8) == TxStatus::Unknown);
00107     CHECK(get_tx_status(100, 10, 4, 4, 10) == TxStatus::Invalid);
00108     CHECK(get_tx_status(100, 10, 4, 4, 12) == TxStatus::Invalid);
00109   }
00110 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/rpc/test/tx_status_test.cpp...
Preprocessing /data/git/CCF/src/node/rpc/tx_status.h...
#include ds/json.h: not found! skipping...
Preprocessor output (size: 2847 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace ccf
00008 {
00009   enum class TxStatus
00010   {
00011     Unknown,
00012     Pending,
00013     Committed,
00014     Invalid,
00015   };
00016 
00017   constexpr char const* tx_status_to_str(TxStatus status)
00018   {
00019     switch (status)
00020     {
00021       case TxStatus::Unknown:
00022       {
00023         return "UNKNOWN";
00024       }
00025       case TxStatus::Pending:
00026       {
00027         return "PENDING";
00028       }
00029       case TxStatus::Committed:
00030       {
00031         return "COMMITTED";
00032       }
00033       case TxStatus::Invalid:
00034       {
00035         return "INVALID";
00036       }
00037       default:
00038       {
00039         return "Unhandled value";
00040       }
00041     }
00042   }
00043 
00044   DECLARE_JSON_ENUM(
00045     TxStatus,
00046     {{TxStatus::Unknown, tx_status_to_str(TxStatus::Unknown)},
00047      {TxStatus::Pending, tx_status_to_str(TxStatus::Pending)},
00048      {TxStatus::Committed, tx_status_to_str(TxStatus::Committed)},
00049      {TxStatus::Invalid, tx_status_to_str(TxStatus::Invalid)}});
00050 
00051   constexpr int64_t VIEW_UNKNOWN = std::numeric_limits<int64_t>::min();
00052 
00053   static TxStatus get_tx_status(
00054     int64_t target_view,
00055     int64_t target_seqno,
00056     int64_t local_view,
00057     int64_t committed_view,
00058     int64_t committed_seqno)
00059   {
00060     const bool is_committed = committed_seqno >= target_seqno;
00061     const bool views_match = local_view == target_view;
00062     const bool view_known = local_view != VIEW_UNKNOWN;
00063 
00064     if (is_committed && !view_known)
00065     {
00066       throw std::logic_error(fmt::format(
00067         "Should know local view for seqnos up to {}, but have no view for {}",
00068         committed_seqno,
00069         target_seqno));
00070     }
00071 
00072     if (is_committed)
00073     {
00074       // The requested seqno has been committed, so we know for certain whether
00075       // the requested tx id is committed or not
00076       if (views_match)
00077       {
00078         return TxStatus::Committed;
00079       }
00080       else
00081       {
00082         return TxStatus::Invalid;
00083       }
00084     }
00085     else if (views_match)
00086     {
00087       // This node knows about the requested tx id, but it is not globally
00088       // committed
00089       return TxStatus::Pending;
00090     }
00091     else if (committed_view > target_view)
00092     {
00093       // This node has seen the seqno in a different view, and committed
00094       // further, so the requested tx id is impossible
00095       return TxStatus::Invalid;
00096     }
00097     else
00098     {
00099       // Otherwise, we cannot state anything about this tx id. The most common
00100       // reason is that the local_view is unknown (this transaction has never
00101       // existed, or has not reached this node yet). It is also possible that
00102       // this node believes locally that this tx id is impossible, but does not
00103       // have a global commit to back this up - it will eventually receive
00104       // either a global commit confirming this belief, or an election and
00105       // global commit making this tx id invalid
00106       return TxStatus::Unknown;
00107     }
00108   }
00109 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/rpc/tx_status.h...
Preprocessing /data/git/CCF/src/node/rpc/user_frontend.h...
#include frontend.h: already included! skipping...
#include node/client_signatures.h: not found! skipping...
#include node/network_tables.h: not found! skipping...
Preprocessor output (size: 1951 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   /** The CCF application must be an instance of UserRpcFrontend
00012    */
00013   class UserRpcFrontend : public RpcFrontend
00014   {
00015   public:
00016     UserRpcFrontend(kv::Store& tables, EndpointRegistry& h) :
00017       RpcFrontend(tables, h)
00018     {}
00019 
00020     void open(std::optional<tls::Pem*> identity = std::nullopt) override
00021     {
00022       RpcFrontend::open(identity);
00023       endpoints.openapi_info.title = "CCF Application API";
00024     }
00025 
00026     // Forward these methods so that apps can write foo(...); rather than
00027     // endpoints.foo(...);
00028     template <typename... Ts>
00029     ccf::EndpointRegistry::Endpoint make_endpoint(Ts&&... ts)
00030     {
00031       return endpoints.make_endpoint(std::forward<Ts>(ts)...);
00032     }
00033 
00034     template <typename... Ts>
00035     ccf::EndpointRegistry::Endpoint make_read_only_endpoint(Ts&&... ts)
00036     {
00037       return endpoints.make_read_only_endpoint(std::forward<Ts>(ts)...);
00038     }
00039 
00040     template <typename... Ts>
00041     ccf::EndpointRegistry::Endpoint make_command_endpoint(Ts&&... ts)
00042     {
00043       return endpoints.make_command_endpoint(std::forward<Ts>(ts)...);
00044     }
00045   };
00046 
00047   class UserEndpointRegistry : public CommonEndpointRegistry
00048   {
00049   public:
00050     UserEndpointRegistry(kv::Store& store) :
00051       CommonEndpointRegistry(
00052         get_actor_prefix(ActorsType::users),
00053         store,
00054         Tables::USER_CERT_DERS,
00055         Tables::USER_DIGESTS)
00056     {}
00057 
00058     UserEndpointRegistry(NetworkTables& network) :
00059       CommonEndpointRegistry(
00060         get_actor_prefix(ActorsType::users),
00061         *network.tables,
00062         Tables::USER_CERT_DERS,
00063         Tables::USER_DIGESTS)
00064     {}
00065   };
00066 
00067   class SimpleUserRpcFrontend : public UserRpcFrontend
00068   {
00069   protected:
00070     UserEndpointRegistry common_handlers;
00071 
00072   public:
00073     SimpleUserRpcFrontend(kv::Store& tables) :
00074       UserRpcFrontend(tables, common_handlers),
00075       common_handlers(tables)
00076     {}
00077   };
00078 }
00079 
---------
Macros accessible in this file:
---------
TX_RATE_BUCKETS_LEN FMT_HEADER_ONLY HIST_MIN HIST_MAX HIST_BUCKET_GRANULARITY 
---------
Parsing file /data/git/CCF/src/node/rpc/user_frontend.h...
Preprocessing /data/git/CCF/src/node/script.h...
#include msgpack/msgpack.hpp: not found! skipping...
#include optional: not found! skipping...
#include stdint.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1161 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   /** A script, e.g., a Lua script
00014    * The script may be in string or bytecode format.
00015    */
00016   struct Script
00017   {
00018     std::optional<std::vector<uint8_t>> bytecode;
00019     std::optional<std::string> text;
00020 
00021     Script() = default;
00022     Script(std::string script_)
00023     {
00024       text = std::move(script_);
00025     };
00026 
00027     Script(std::vector<uint8_t> script_)
00028     {
00029       bytecode = std::move(script_);
00030     };
00031 
00032     bool operator==(const Script& other) const
00033     {
00034       return bytecode == other.bytecode && text == other.text;
00035     }
00036 
00037     bool operator!=(const Script& other) const
00038     {
00039       return !operator==(other);
00040     }
00041 
00042     MSGPACK_DEFINE(bytecode, text);
00043   };
00044 
00045   DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(Script);
00046 
00047   // Current limitation of the JSON macros: It is necessary to defined
00048   // DECLARE_JSON_REQUIRED_FIELDS for Script even though there are no required
00049   // fields. This raises some compiler warnings that are disabled locally.
00050 
00051 
00052 
00053   DECLARE_JSON_REQUIRED_FIELDS(Script);
00054 
00055 
00056   DECLARE_JSON_OPTIONAL_FIELDS(Script, bytecode, text);
00057 }
00058 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/script.h...
Preprocessing /data/git/CCF/src/node/scripts.h...
#include script.h: already included! skipping...
Preprocessor output (size: 697 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace ccf
00008 {
00009   using Scripts = kv::Map<std::string, Script>;
00010 
00011   struct GovScriptIds
00012   {
00013     //! script that applies an accepted "raw puts" proposal
00014     static auto constexpr RAW_PUTS = "raw_puts";
00015     //! script that sets the environment for a proposal script
00016     static auto constexpr ENV_PROPOSAL = "environment_proposal";
00017     //! script that decides if a proposal has been accepted
00018     static auto constexpr PASS = "pass";
00019   };
00020 
00021   struct UserScriptIds
00022   {
00023     //! script that sets the environment for rpc handler scripts
00024     static auto constexpr ENV_HANDLER = "__environment";
00025   };
00026 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/scripts.h...
Preprocessing /data/git/CCF/src/node/secret_share.h...
#include tls/entropy.h: not found! skipping...
#include array: not found! skipping...
#include fmt/format.h: not found! skipping...
#include iostream: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
#include tls/random_bytes.h: not found! skipping...
#include sss/sss.h: not found! skipping...
Preprocessor output (size: 2250 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 #define FMT_HEADER_ONLY
00009 
00010 
00011 
00012 
00013 
00014 extern "C"
00015 {
00016 
00017 
00018 
00019 }
00020 
00021 namespace ccf
00022 {
00023   // The SecretSharing class provides static functions to split a secret into
00024   // shares and (re-)combine those shares into the original secret.
00025   // The size of the secret to share is fixed (SECRET_TO_SPLIT_LENGTH, 64
00026   // bytes). It is up to the caller to either shrink the secret if it is too
00027   // long. If the secret to split is shorter than SECRET_TO_SPLIT_LENGTH bytes,
00028   // the caller should ignore the extra bytes.
00029   class SecretSharing
00030   {
00031   public:
00032     static constexpr size_t SECRET_TO_SPLIT_LENGTH = sss_MLEN;
00033     static constexpr size_t SHARE_LENGTH = sss_SHARE_LEN;
00034     static constexpr size_t MAX_NUMBER_SHARES = 255; // As per sss documentation
00035 
00036     using Share = std::array<uint8_t, SHARE_LENGTH>;
00037     using SplitSecret = std::array<uint8_t, SECRET_TO_SPLIT_LENGTH>;
00038 
00039     static std::vector<Share> split(
00040       const SplitSecret& secret_to_split, size_t n, size_t k)
00041     {
00042       if (n == 0 || n > MAX_NUMBER_SHARES)
00043       {
00044         throw std::logic_error(fmt::format(
00045           "Share creation failed: n ({}) not in 1-{} range",
00046           n,
00047           MAX_NUMBER_SHARES));
00048       }
00049 
00050       if (k == 0 || k > n)
00051       {
00052         throw std::logic_error(fmt::format(
00053           "Share creation failed: k not in 1-n range (k: {}, n: {})", k, n));
00054       }
00055 
00056       std::vector<Share> shares(n);
00057 
00058       sss_create_shares(
00059         reinterpret_cast<sss_Share*>(shares.data()),
00060         secret_to_split.data(),
00061         n,
00062         k);
00063 
00064       return shares;
00065     }
00066 
00067     static SplitSecret combine(const std::vector<Share>& shares, size_t k)
00068     {
00069       if (k == 0 || k > shares.size())
00070       {
00071         throw std::logic_error(fmt::format(
00072           "Share combination failed: k not in 1-n range (k: {}, n: {})",
00073           k,
00074           shares.size()));
00075       }
00076 
00077       SplitSecret restored_secret;
00078 
00079       if (
00080         sss_combine_shares(
00081           restored_secret.data(), (sss_Share*)shares.data(), k) != 0)
00082       {
00083         throw std::logic_error(fmt::format(
00084           "Share combination failed: {} shares may be corrupted", k));
00085       }
00086 
00087       return restored_secret;
00088     }
00089   };
00090 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/node/secret_share.h...
Preprocessing /data/git/CCF/src/node/secrets.h...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 871 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   struct EncryptedLedgerSecret
00013   {
00014     NodeId node_id;
00015 
00016     // Encrypted secret for each backup
00017     std::vector<uint8_t> encrypted_secret = {};
00018 
00019     MSGPACK_DEFINE(node_id, encrypted_secret);
00020   };
00021 
00022 
00023 
00024 
00025   struct EncryptedLedgerSecrets
00026   {
00027     std::vector<uint8_t> primary_public_encryption_key = {};
00028     std::vector<EncryptedLedgerSecret> secrets = {};
00029 
00030     MSGPACK_DEFINE(primary_public_encryption_key, secrets);
00031   };
00032 
00033 
00034   DECLARE_JSON_REQUIRED_FIELDS(
00035     EncryptedLedgerSecrets, primary_public_encryption_key, secrets)
00036 
00037   // This map is used to communicate encrypted network secrets from the primary
00038   // to the backups during recovery (past secrets) and re-keying (new secrets)
00039   using Secrets = kv::Map<kv::Version, EncryptedLedgerSecrets>;
00040 }
00041 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/secrets.h...
Preprocessing /data/git/CCF/src/node/service.h...
#include ds/json.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 931 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   enum class ServiceStatus
00014   {
00015     OPENING = 1,
00016     OPEN = 2,
00017     WAITING_FOR_RECOVERY_SHARES = 3,
00018     CLOSED = 4 // For now, unused
00019   };
00020 
00021   DECLARE_JSON_ENUM(
00022     ServiceStatus,
00023     {{ServiceStatus::OPENING, "OPENING"},
00024      {ServiceStatus::OPEN, "OPEN"},
00025      {ServiceStatus::WAITING_FOR_RECOVERY_SHARES,
00026       "WAITING_FOR_RECOVERY_SHARES"},
00027      {ServiceStatus::CLOSED, "CLOSED"}});
00028 }
00029 
00030 MSGPACK_ADD_ENUM(ccf::ServiceStatus);
00031 
00032 namespace ccf
00033 {
00034   struct ServiceInfo
00035   {
00036     tls::Pem cert;
00037     ServiceStatus status;
00038 
00039     MSGPACK_DEFINE(cert, status);
00040   };
00041   DECLARE_JSON_TYPE(ServiceInfo);
00042   DECLARE_JSON_REQUIRED_FIELDS(ServiceInfo, cert, status);
00043 
00044   // As there is only one service active at a given time, the key for the
00045   // Service table is always 0.
00046   using Service = kv::Map<size_t, ServiceInfo>;
00047 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/service.h...
Preprocessing /data/git/CCF/src/node/share_manager.h...
#include crypto/symmetric_key.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include genesis_gen.h: already included! skipping...
#include ledger_secrets.h: already included! skipping...
#include network_state.h: already included! skipping...
#include secret_share.h: already included! skipping...
#include tls/entropy.h: not found! skipping...
#include tls/rsa_key_pair.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 13881 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace ccf
00017 {
00018   class LedgerSecretWrappingKey
00019   {
00020   private:
00021     static constexpr auto KZ_KEY_SIZE = crypto::GCM_SIZE_KEY;
00022     std::vector<uint8_t> data; // Referred to as "kz" in TR
00023     bool has_wrapped = false;
00024 
00025   public:
00026     LedgerSecretWrappingKey() : data(tls::create_entropy()->random(KZ_KEY_SIZE))
00027     {}
00028 
00029     template <typename T>
00030     LedgerSecretWrappingKey(T&& split_secret) :
00031       data(
00032         std::make_move_iterator(split_secret.begin()),
00033         std::make_move_iterator(split_secret.begin() + split_secret.size()))
00034     {}
00035 
00036     template <typename T>
00037     T get_raw_data() const
00038     {
00039       T ret;
00040       std::copy_n(data.begin(), data.size(), ret.begin());
00041       return ret;
00042     }
00043 
00044     std::vector<uint8_t> wrap(const LedgerSecret& ledger_secret)
00045     {
00046       if (has_wrapped)
00047       {
00048         throw std::logic_error(
00049           "Ledger Secret wrapping key has already wrapped once");
00050       }
00051 
00052       crypto::GcmCipher encrypted_ls(ledger_secret.master.size());
00053 
00054       crypto::KeyAesGcm(data).encrypt(
00055         encrypted_ls.hdr.get_iv(), // iv is always 0 here as the share wrapping
00056                                    // key is never re-used for encryption
00057         ledger_secret.master,
00058         nullb,
00059         encrypted_ls.cipher.data(),
00060         encrypted_ls.hdr.tag);
00061 
00062       has_wrapped = true;
00063 
00064       return encrypted_ls.serialise();
00065     }
00066 
00067     LedgerSecret unwrap(
00068       const std::vector<uint8_t>& wrapped_latest_ledger_secret)
00069     {
00070       crypto::GcmCipher encrypted_ls;
00071       encrypted_ls.deserialise(wrapped_latest_ledger_secret);
00072       std::vector<uint8_t> decrypted_ls(encrypted_ls.cipher.size());
00073 
00074       if (!crypto::KeyAesGcm(data).decrypt(
00075             encrypted_ls.hdr.get_iv(),
00076             encrypted_ls.hdr.tag,
00077             encrypted_ls.cipher,
00078             nullb,
00079             decrypted_ls.data()))
00080       {
00081         throw std::logic_error("Unwrapping latest ledger secret failed");
00082       }
00083 
00084       return LedgerSecret(decrypted_ls);
00085     }
00086   };
00087 
00088   // During recovery, a list of RecoveredLedgerSecret is constructed from a
00089   // local hook.
00090   struct RecoveredLedgerSecret
00091   {
00092     // Version at which the next ledger secret is applicable from
00093     kv::Version next_version;
00094 
00095     // Previous ledger secret, encrypted with the current ledger secret
00096     std::vector<uint8_t> encrypted_ledger_secret;
00097   };
00098 
00099   // The ShareManager class provides the interface between the ledger secrets,
00100   // the ccf.shares and ccf.submitted_shares KV tables and the rest of the
00101   // service. In particular, it is used to:
00102   //  - Issue new recovery shares whenever required (e.g. on startup, rekey and
00103   //  membership updates)
00104   //  - Re-assemble the ledger secrets on recovery, once a threshold of members
00105   //  have successfully submitted their shares
00106   class ShareManager
00107   {
00108   private:
00109     NetworkState& network;
00110 
00111     EncryptedSharesMap compute_encrypted_shares(
00112       kv::Tx& tx, const LedgerSecretWrappingKey& ls_wrapping_key)
00113     {
00114       EncryptedSharesMap encrypted_shares;
00115 
00116       auto secret_to_split =
00117         ls_wrapping_key.get_raw_data<SecretSharing::SplitSecret>();
00118 
00119       GenesisGenerator g(network, tx);
00120       auto active_recovery_members_info = g.get_active_recovery_members();
00121       size_t recovery_threshold = g.get_recovery_threshold();
00122 
00123       if (active_recovery_members_info.size() == 0)
00124       {
00125         throw std::logic_error(
00126           "There should be at least one active recovery member to issue "
00127           "recovery shares");
00128       }
00129 
00130       if (recovery_threshold == 0)
00131       {
00132         throw std::logic_error(
00133           "Recovery threshold should be set before recovery "
00134           "shares are computed");
00135       }
00136 
00137       auto shares = SecretSharing::split(
00138         secret_to_split,
00139         active_recovery_members_info.size(),
00140         recovery_threshold);
00141 
00142       size_t share_index = 0;
00143       for (auto const& [member_id, enc_pub_key] : active_recovery_members_info)
00144       {
00145         auto member_enc_pubk = tls::make_rsa_public_key(enc_pub_key);
00146         auto raw_share = std::vector<uint8_t>(
00147           shares[share_index].begin(), shares[share_index].end());
00148         encrypted_shares[member_id] = member_enc_pubk->wrap(raw_share);
00149         share_index++;
00150       }
00151 
00152       return encrypted_shares;
00153     }
00154 
00155     void set_recovery_shares_info(
00156       kv::Tx& tx,
00157       const LedgerSecret& latest_ledger_secret,
00158       const std::optional<LedgerSecret>& previous_ledger_secret = std::nullopt,
00159       kv::Version latest_ls_version = kv::NoVersion)
00160     {
00161       // First, generate a fresh ledger secrets wrapping key and wrap the
00162       // latest ledger secret with it. Then, encrypt the penultimate ledger
00163       // secret with the latest ledger secret and split the ledger secret
00164       // wrapping key, allocating a new share for each active member. Finally,
00165       // encrypt each share with the public key of each member and record it in
00166       // the shares table.
00167 
00168       auto ls_wrapping_key = LedgerSecretWrappingKey();
00169       auto wrapped_latest_ls = ls_wrapping_key.wrap(latest_ledger_secret);
00170 
00171       std::vector<uint8_t> encrypted_previous_secret = {};
00172       if (previous_ledger_secret.has_value())
00173       {
00174         crypto::GcmCipher encrypted_previous_ls(
00175           previous_ledger_secret->master.size());
00176         auto iv = tls::create_entropy()->random(crypto::GCM_SIZE_IV);
00177         encrypted_previous_ls.hdr.set_iv(iv.data(), iv.size());
00178 
00179         crypto::KeyAesGcm(latest_ledger_secret.master)
00180           .encrypt(
00181             encrypted_previous_ls.hdr.get_iv(),
00182             previous_ledger_secret->master,
00183             nullb,
00184             encrypted_previous_ls.cipher.data(),
00185             encrypted_previous_ls.hdr.tag);
00186 
00187         encrypted_previous_secret = encrypted_previous_ls.serialise();
00188       }
00189 
00190       GenesisGenerator g(network, tx);
00191       g.add_key_share_info({{latest_ls_version, wrapped_latest_ls},
00192                             encrypted_previous_secret,
00193                             compute_encrypted_shares(tx, ls_wrapping_key)});
00194     }
00195 
00196     std::vector<uint8_t> encrypt_submitted_share(
00197       const std::vector<uint8_t>& submitted_share)
00198     {
00199       // Submitted recovery shares are encrypted with the latest ledger secret.
00200       crypto::GcmCipher encrypted_submitted_share(submitted_share.size());
00201 
00202       auto iv = tls::create_entropy()->random(crypto::GCM_SIZE_IV);
00203       encrypted_submitted_share.hdr.set_iv(iv.data(), iv.size());
00204 
00205       crypto::KeyAesGcm(network.ledger_secrets->get_latest().master)
00206         .encrypt(
00207           encrypted_submitted_share.hdr.get_iv(),
00208           submitted_share,
00209           nullb,
00210           encrypted_submitted_share.cipher.data(),
00211           encrypted_submitted_share.hdr.tag);
00212 
00213       return encrypted_submitted_share.serialise();
00214     }
00215 
00216     std::vector<uint8_t> decrypt_submitted_share(
00217       const std::vector<uint8_t>& encrypted_submitted_share)
00218     {
00219       crypto::GcmCipher encrypted_share;
00220       encrypted_share.deserialise(encrypted_submitted_share);
00221       std::vector<uint8_t> decrypted_share(encrypted_share.cipher.size());
00222 
00223       crypto::KeyAesGcm(network.ledger_secrets->get_latest().master)
00224         .decrypt(
00225           encrypted_share.hdr.get_iv(),
00226           encrypted_share.hdr.tag,
00227           encrypted_share.cipher,
00228           nullb,
00229           decrypted_share.data());
00230 
00231       return decrypted_share;
00232     }
00233 
00234     LedgerSecretWrappingKey combine_from_submitted_shares(kv::Tx& tx)
00235     {
00236       auto [submitted_shares_view, config_view] =
00237         tx.get_view(network.submitted_shares, network.config);
00238 
00239       std::vector<SecretSharing::Share> shares;
00240       submitted_shares_view->foreach(
00241         [&shares,
00242          this](const MemberId, const std::vector<uint8_t>& encrypted_share) {
00243           SecretSharing::Share share;
00244           auto decrypted_share = decrypt_submitted_share(encrypted_share);
00245           std::copy_n(
00246             decrypted_share.begin(),
00247             SecretSharing::SHARE_LENGTH,
00248             share.begin());
00249           shares.emplace_back(share);
00250           return true;
00251         });
00252 
00253       auto recovery_threshold = config_view->get(0)->recovery_threshold;
00254       if (recovery_threshold > shares.size())
00255       {
00256         throw std::logic_error(fmt::format(
00257           "Error combining recovery shares: only {} recovery shares were "
00258           "submitted but recovery threshold is {}",
00259           shares.size(),
00260           recovery_threshold));
00261       }
00262 
00263       return LedgerSecretWrappingKey(
00264         SecretSharing::combine(shares, shares.size()));
00265     }
00266 
00267   public:
00268     ShareManager(NetworkState& network_) : network(network_) {}
00269 
00270     void issue_shares(kv::Tx& tx)
00271     {
00272       // Assumes that the ledger secrets have not been updated since the
00273       // last time shares have been issued (i.e. genesis or re-sharing only)
00274       set_recovery_shares_info(tx, network.ledger_secrets->get_latest());
00275     }
00276 
00277     void issue_shares_on_recovery(kv::Tx& tx, kv::Version latest_ls_version)
00278     {
00279       set_recovery_shares_info(
00280         tx,
00281         network.ledger_secrets->get_latest(),
00282         network.ledger_secrets->get_penultimate(),
00283         latest_ls_version);
00284     }
00285 
00286     void issue_shares_on_rekey(
00287       kv::Tx& tx, const LedgerSecret& new_ledger_secret)
00288     {
00289       set_recovery_shares_info(
00290         tx, new_ledger_secret, network.ledger_secrets->get_latest());
00291     }
00292 
00293     std::optional<EncryptedShare> get_encrypted_share(
00294       kv::Tx& tx, MemberId member_id)
00295     {
00296       std::optional<EncryptedShare> encrypted_share = std::nullopt;
00297       auto recovery_shares_info = tx.get_view(network.shares)->get(0);
00298       if (!recovery_shares_info.has_value())
00299       {
00300         throw std::logic_error(
00301           "Failed to retrieve current recovery shares info");
00302       }
00303 
00304       for (auto const& s : recovery_shares_info->encrypted_shares)
00305       {
00306         if (s.first == member_id)
00307         {
00308           encrypted_share = s.second;
00309         }
00310       }
00311       return encrypted_share;
00312     }
00313 
00314     std::vector<kv::Version> restore_recovery_shares_info(
00315       kv::Tx& tx,
00316       const std::list<RecoveredLedgerSecret>& encrypted_recovery_secrets)
00317     {
00318       // First, re-assemble the ledger secret wrapping key from the submitted
00319       // encrypted shares. Then, unwrap the latest ledger secret and use it to
00320       // decrypt the previous ledger secret and so on.
00321 
00322       auto ls_wrapping_key = combine_from_submitted_shares(tx);
00323 
00324       auto recovery_shares_info = tx.get_view(network.shares)->get(0);
00325       if (!recovery_shares_info.has_value())
00326       {
00327         throw std::logic_error(
00328           "Failed to retrieve current recovery shares info");
00329       }
00330 
00331       std::list<LedgerSecrets::VersionedLedgerSecret> restored_ledger_secrets;
00332 
00333       // We keep track of the restored versions so that the recovered ledger
00334       // secrets can be broadcast to backups
00335       std::vector<kv::Version> restored_versions;
00336       restored_versions.push_back(
00337         encrypted_recovery_secrets.back().next_version);
00338 
00339       auto restored_ls = ls_wrapping_key.unwrap(
00340         recovery_shares_info->wrapped_latest_ledger_secret.encrypted_data);
00341 
00342       restored_ledger_secrets.push_back(
00343         {encrypted_recovery_secrets.back().next_version, restored_ls});
00344 
00345       auto decryption_key = restored_ls.master;
00346       for (auto i = encrypted_recovery_secrets.rbegin();
00347            i != encrypted_recovery_secrets.rend();
00348            i++)
00349       {
00350         if (i->encrypted_ledger_secret.size() == 0)
00351         {
00352           // First entry does not encrypt any other ledger secret (i.e. genesis)
00353           break;
00354         }
00355 
00356         crypto::GcmCipher encrypted_ls;
00357         encrypted_ls.deserialise(i->encrypted_ledger_secret);
00358         std::vector<uint8_t> decrypted_ls(encrypted_ls.cipher.size());
00359 
00360         if (!crypto::KeyAesGcm(decryption_key)
00361                .decrypt(
00362                  encrypted_ls.hdr.get_iv(),
00363                  encrypted_ls.hdr.tag,
00364                  encrypted_ls.cipher,
00365                  nullb,
00366                  decrypted_ls.data()))
00367         {
00368           throw std::logic_error(fmt::format(
00369             "Decryption of ledger secret at {} failed",
00370             std::next(i)->next_version));
00371         }
00372 
00373         restored_ledger_secrets.push_back(
00374           {std::next(i)->next_version, LedgerSecret(decrypted_ls)});
00375 
00376         restored_versions.push_back(std::next(i)->next_version);
00377         decryption_key = decrypted_ls;
00378       }
00379 
00380       restored_ledger_secrets.reverse();
00381       network.ledger_secrets->restore(std::move(restored_ledger_secrets));
00382 
00383       return restored_versions;
00384     }
00385 
00386     size_t submit_recovery_share(
00387       kv::Tx& tx,
00388       MemberId member_id,
00389       const std::vector<uint8_t>& submitted_recovery_share)
00390     {
00391       auto [service_view, submitted_shares_view] =
00392         tx.get_view(network.service, network.submitted_shares);
00393       auto active_service = service_view->get(0);
00394       if (!active_service.has_value())
00395       {
00396         throw std::logic_error("Failed to get active service");
00397       }
00398 
00399       submitted_shares_view->put(
00400         member_id, encrypt_submitted_share(submitted_recovery_share));
00401 
00402       size_t submitted_shares_count = 0;
00403       submitted_shares_view->foreach(
00404         [&submitted_shares_count](const MemberId, const std::vector<uint8_t>&) {
00405           submitted_shares_count++;
00406           return true;
00407         });
00408 
00409       return submitted_shares_count;
00410     }
00411 
00412     void clear_submitted_recovery_shares(kv::Tx& tx)
00413     {
00414       auto submitted_shares_view = tx.get_view(network.submitted_shares);
00415 
00416       std::vector<uint8_t> submitted_share_ids = {};
00417 
00418       submitted_shares_view->foreach(
00419         [&submitted_share_ids](
00420           const MemberId member_id, const std::vector<uint8_t>&) {
00421           submitted_share_ids.push_back(member_id);
00422           return true;
00423         });
00424 
00425       for (auto const& id : submitted_share_ids)
00426       {
00427         submitted_shares_view->remove(id);
00428       }
00429     }
00430   };
00431 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/node/share_manager.h...
Preprocessing /data/git/CCF/src/node/shares.h...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include map: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2041 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   using EncryptedShare = std::vector<uint8_t>;
00015   using EncryptedSharesMap = std::map<MemberId, EncryptedShare>;
00016 
00017   struct LatestLedgerSecret
00018   {
00019     // In most cases (e.g. re-key, member retirement), this is unset
00020     // (kv::NoVersion), and the version at which the ledger secret is applicable
00021     // from is derived from the local hook on recovery.
00022     // In one case (i.e. after recovery of the public ledger), a new ledger
00023     // secret is created to protect the integrity on the public-only
00024     // transactions. However, the corresponding shares are only written at a
00025     // later version, once the previous ledger secrets have been restored.
00026     kv::Version version;
00027 
00028     std::vector<uint8_t> encrypted_data;
00029 
00030 
00031   };
00032 
00033 
00034 
00035 
00036   struct RecoverySharesInfo
00037   {
00038     // Keeping track of the latest and penultimate ledger secret allows the
00039     // value of this table to remain at a constant size through the lifetime of
00040     // the service. On recovery, a local hook on this table allows the service
00041     // to reconstruct the history of encrypted ledger secrets which are
00042     // decrypted in sequence once the ledger secret wrapping key is
00043     // re-assembled.
00044 
00045     // Latest ledger secret wrapped with the ledger secret wrapping key
00046     LatestLedgerSecret wrapped_latest_ledger_secret;
00047 
00048     // Previous ledger secret encrypted with the latest ledger secret
00049     std::vector<uint8_t> encrypted_previous_ledger_secret;
00050 
00051     EncryptedSharesMap encrypted_shares;
00052 
00053     MSGPACK_DEFINE(
00054       wrapped_latest_ledger_secret,
00055       encrypted_previous_ledger_secret,
00056       encrypted_shares);
00057   };
00058 
00059 
00060   DECLARE_JSON_REQUIRED_FIELDS(
00061     RecoverySharesInfo,
00062     wrapped_latest_ledger_secret,
00063     encrypted_previous_ledger_secret,
00064     encrypted_shares)
00065 
00066   // The key for this table will always be 0 since a live service never needs to
00067   // access historical recovery shares info.
00068   using Shares = kv::Map<size_t, RecoverySharesInfo>;
00069 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/shares.h...
Preprocessing /data/git/CCF/src/node/signatures.h...
#include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1467 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct PrimarySignature : public NodeSignature
00015   {
00016     kv::Consensus::SeqNo seqno = 0;
00017     kv::Consensus::View view = 0;
00018     ObjectId commit_seqno = 0;
00019     ObjectId commit_view = 0;
00020     crypto::Sha256Hash root;
00021     std::vector<uint8_t> tree = {0};
00022 
00023     MSGPACK_DEFINE(
00024       MSGPACK_BASE(NodeSignature),
00025       seqno,
00026       view,
00027       commit_seqno,
00028       commit_view,
00029       root,
00030       tree);
00031 
00032     PrimarySignature() {}
00033 
00034     PrimarySignature(ccf::NodeId node_, kv::Consensus::SeqNo seqno_) :
00035       NodeSignature(node_),
00036       seqno(seqno_)
00037     {}
00038 
00039     PrimarySignature(const crypto::Sha256Hash& root_) : root(root_) {}
00040 
00041     PrimarySignature(
00042       ccf::NodeId node_,
00043       kv::Consensus::SeqNo seqno_,
00044       kv::Consensus::View view_,
00045       kv::Consensus::SeqNo commit_seqno_,
00046       kv::Consensus::View commit_view_,
00047       const crypto::Sha256Hash root_,
00048       Nonce hashed_nonce_,
00049       const std::vector<uint8_t>& sig_,
00050       const std::vector<uint8_t>& tree_) :
00051       NodeSignature(sig_, node_, hashed_nonce_),
00052       seqno(seqno_),
00053       view(view_),
00054       commit_seqno(commit_seqno_),
00055       commit_view(commit_view_),
00056       root(root_),
00057       tree(tree_)
00058     {}
00059   };
00060 
00061   DECLARE_JSON_REQUIRED_FIELDS(
00062     PrimarySignature, seqno, view, commit_seqno, commit_view, root, tree)
00063   using Signatures = kv::Map<ObjectId, PrimarySignature>;
00064 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/signatures.h...
Preprocessing /data/git/CCF/src/node/snapshot_evidence.h...
#include crypto/hash.h: not found! skipping...
#include entities.h: already included! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 417 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct SnapshotHash
00015   {
00016     crypto::Sha256Hash hash;
00017     kv::Version version;
00018 
00019     MSGPACK_DEFINE(hash, version);
00020   };
00021 
00022   // As we only keep track of the latest snapshot, the key for the
00023   // SnapshotEvidence table is always 0.
00024   using SnapshotEvidence = kv::Map<size_t, SnapshotHash>;
00025 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/snapshot_evidence.h...
Preprocessing /data/git/CCF/src/node/snapshotter.h...
#include consensus/ledger_enclave_types.h: not found! skipping...
#include crypto/hash.h: not found! skipping...
#include ds/ccf_assert.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include ds/spin_lock.h: not found! skipping...
#include ds/thread_messaging.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/tx.h: not found! skipping...
#include node/network_state.h: not found! skipping...
#include node/snapshot_evidence.h: not found! skipping...
#include deque: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 7415 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
00019 namespace ccf
00020 {
00021   class Snapshotter : public std::enable_shared_from_this<Snapshotter>
00022   {
00023   public:
00024     static constexpr auto max_tx_interval = std::numeric_limits<size_t>::max();
00025 
00026   private:
00027     ringbuffer::WriterPtr to_host;
00028     SpinLock lock;
00029 
00030     NetworkState& network;
00031 
00032     // Snapshots are never generated by default (e.g. during public recovery)
00033     size_t snapshot_tx_interval = max_tx_interval;
00034 
00035     struct SnapshotInfo
00036     {
00037       consensus::Index idx;
00038       consensus::Index evidence_idx;
00039 
00040       // The evidence isn't committed when the snapshot is generated
00041       std::optional<consensus::Index> evidence_commit_idx;
00042 
00043       SnapshotInfo(consensus::Index idx, consensus::Index evidence_idx) :
00044         idx(idx),
00045         evidence_idx(evidence_idx)
00046       {}
00047     };
00048     std::deque<SnapshotInfo> snapshot_evidence_indices;
00049 
00050     // Index at which the lastest snapshot was generated
00051     consensus::Index last_snapshot_idx = 0;
00052 
00053     // Indices at which a snapshot will be next generated
00054     std::deque<consensus::Index> next_snapshot_indices;
00055 
00056     size_t get_execution_thread()
00057     {
00058       // Generate on main thread if there are no worker threads. Otherwise,
00059       // round robin on worker threads.
00060       if (threading::ThreadMessaging::thread_count > 1)
00061       {
00062         static size_t generation_count = 0;
00063         return (generation_count++ % threading::ThreadMessaging::thread_count) +
00064           1;
00065       }
00066       else
00067       {
00068         return threading::MAIN_THREAD_ID;
00069       }
00070     }
00071 
00072     void record_snapshot(
00073       consensus::Index idx,
00074       consensus::Index evidence_idx,
00075       const std::vector<uint8_t>& serialised_snapshot)
00076     {
00077       RINGBUFFER_WRITE_MESSAGE(
00078         consensus::snapshot, to_host, idx, evidence_idx, serialised_snapshot);
00079     }
00080 
00081     void commit_snapshot(
00082       consensus::Index snapshot_idx, consensus::Index evidence_commit_idx)
00083     {
00084       // The snapshot_idx is used to retrieve the correct snapshot file
00085       // previously generated. The evidence_commit_idx is recorded as metadata.
00086       RINGBUFFER_WRITE_MESSAGE(
00087         consensus::snapshot_commit, to_host, snapshot_idx, evidence_commit_idx);
00088     }
00089 
00090     struct SnapshotMsg
00091     {
00092       std::shared_ptr<Snapshotter> self;
00093       std::unique_ptr<kv::AbstractStore::AbstractSnapshot> snapshot;
00094     };
00095 
00096     static void snapshot_cb(std::unique_ptr<threading::Tmsg<SnapshotMsg>> msg)
00097     {
00098       msg->data.self->snapshot_(std::move(msg->data.snapshot));
00099     }
00100 
00101     void snapshot_(
00102       std::unique_ptr<kv::AbstractStore::AbstractSnapshot> snapshot)
00103     {
00104       auto snapshot_version = snapshot->get_version();
00105 
00106       auto serialised_snapshot =
00107         network.tables->serialise_snapshot(std::move(snapshot));
00108 
00109       auto tx = network.tables->create_tx();
00110       auto view = tx.get_view(network.snapshot_evidence);
00111       auto snapshot_hash = crypto::Sha256Hash(serialised_snapshot);
00112       view->put(0, {snapshot_hash, snapshot_version});
00113 
00114       auto rc = tx.commit();
00115       if (rc != kv::CommitSuccess::OK)
00116       {
00117         LOG_FAIL_FMT(
00118           "Could not commit snapshot evidence for seqno {}: {}",
00119           snapshot_version,
00120           rc);
00121         return;
00122       }
00123 
00124       auto evidence_version = tx.commit_version();
00125 
00126       record_snapshot(snapshot_version, evidence_version, serialised_snapshot);
00127       consensus::Index snapshot_idx =
00128         static_cast<consensus::Index>(snapshot_version);
00129       consensus::Index snapshot_evidence_idx =
00130         static_cast<consensus::Index>(evidence_version);
00131       snapshot_evidence_indices.emplace_back(
00132         snapshot_idx, snapshot_evidence_idx);
00133 
00134       LOG_DEBUG_FMT(
00135         "Snapshot successfully generated for seqno {}, with evidence seqno "
00136         "{}: "
00137         "{}",
00138         snapshot_idx,
00139         snapshot_evidence_idx,
00140         snapshot_hash);
00141     }
00142 
00143   public:
00144     Snapshotter(
00145       ringbuffer::AbstractWriterFactory& writer_factory,
00146       NetworkState& network_) :
00147       to_host(writer_factory.create_writer_to_outside()),
00148       network(network_)
00149     {
00150       next_snapshot_indices.push_back(last_snapshot_idx);
00151     }
00152 
00153     void set_tx_interval(size_t snapshot_tx_interval_)
00154     {
00155       std::lock_guard<SpinLock> guard(lock);
00156       snapshot_tx_interval = snapshot_tx_interval_;
00157     }
00158 
00159     void set_last_snapshot_idx(consensus::Index idx)
00160     {
00161       std::lock_guard<SpinLock> guard(lock);
00162 
00163       // Should only be called once, after a snapshot has been applied
00164       if (last_snapshot_idx != 0)
00165       {
00166         throw std::logic_error(
00167           "Last snapshot index can only be set if no snapshot has been "
00168           "generated");
00169       }
00170 
00171       last_snapshot_idx = idx;
00172 
00173       next_snapshot_indices.clear();
00174       next_snapshot_indices.push_back(last_snapshot_idx);
00175     }
00176 
00177     void snapshot(consensus::Index idx)
00178     {
00179       std::lock_guard<SpinLock> guard(lock);
00180 
00181       if (idx < last_snapshot_idx)
00182       {
00183         throw std::logic_error(fmt::format(
00184           "Cannot snapshot at seqno {} which is earlier than last snapshot "
00185           "seqno {}",
00186           idx,
00187           last_snapshot_idx));
00188       }
00189 
00190       if (idx - last_snapshot_idx >= snapshot_tx_interval)
00191       {
00192         auto msg = std::make_unique<threading::Tmsg<SnapshotMsg>>(&snapshot_cb);
00193         msg->data.self = shared_from_this();
00194         msg->data.snapshot = network.tables->snapshot(idx);
00195 
00196         last_snapshot_idx = idx;
00197         threading::ThreadMessaging::thread_messaging.add_task(
00198           get_execution_thread(), std::move(msg));
00199       }
00200     }
00201 
00202     void commit(consensus::Index idx)
00203     {
00204       std::lock_guard<SpinLock> guard(lock);
00205 
00206       while (!next_snapshot_indices.empty() &&
00207              (next_snapshot_indices.front() < idx))
00208       {
00209         next_snapshot_indices.pop_front();
00210       }
00211 
00212       if (next_snapshot_indices.empty())
00213       {
00214         next_snapshot_indices.push_back(last_snapshot_idx);
00215       }
00216 
00217       for (auto it = snapshot_evidence_indices.begin();
00218            it != snapshot_evidence_indices.end();)
00219       {
00220         if (it->evidence_commit_idx.has_value())
00221         {
00222           if (idx > it->evidence_commit_idx.value())
00223           {
00224             commit_snapshot(it->idx, idx);
00225             auto it_ = it;
00226             it++;
00227             snapshot_evidence_indices.erase(it_);
00228             continue;
00229           }
00230         }
00231         else if (idx >= it->evidence_idx)
00232         {
00233           it->evidence_commit_idx = idx;
00234         }
00235         it++;
00236       }
00237     }
00238 
00239     bool requires_snapshot(consensus::Index idx)
00240     {
00241       std::lock_guard<SpinLock> guard(lock);
00242 
00243       // Returns true if the idx will require the generation of a snapshot
00244       if ((idx - next_snapshot_indices.back()) >= snapshot_tx_interval)
00245       {
00246         next_snapshot_indices.push_back(idx);
00247         return true;
00248       }
00249       return false;
00250     }
00251 
00252     void rollback(consensus::Index idx)
00253     {
00254       std::lock_guard<SpinLock> guard(lock);
00255 
00256       while (!next_snapshot_indices.empty() &&
00257              (next_snapshot_indices.back() > idx))
00258       {
00259         next_snapshot_indices.pop_back();
00260       }
00261 
00262       if (next_snapshot_indices.empty())
00263       {
00264         next_snapshot_indices.push_back(last_snapshot_idx);
00265       }
00266 
00267       while (!snapshot_evidence_indices.empty() &&
00268              (snapshot_evidence_indices.back().evidence_idx > idx))
00269       {
00270         snapshot_evidence_indices.pop_back();
00271       }
00272     }
00273   };
00274 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/snapshotter.h...
Preprocessing /data/git/CCF/src/node/submitted_shares.h...
#include entities.h: already included! skipping...
#include kv/map.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 537 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   // This table keeps track of the submitted encrypted recovery share so that
00013   // the public-only service is resilient to elections while members submit
00014   // their recovery shares.
00015   // Because shares are submitted to the public-only network on recovery, this
00016   // table is public but the shares are encrypted with the latest ledger secret.
00017 
00018   using SubmittedShares = kv::Map<MemberId, std::vector<uint8_t>>;
00019 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/submitted_shares.h...
Preprocessing /data/git/CCF/src/node/tables/certs.h...
#include entities.h: not found! skipping...
Preprocessor output (size: 333 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 namespace ccf
00007 {
00008   using CertDERs = kv::Map<Cert, ObjectId>;
00009   using CACertDERs = kv::Map<std::string, Cert>;
00010   // Mapping from hex-encoded digest of PEM cert to entity id
00011   using CertDigests = kv::Map<std::string, ObjectId>;
00012 }
00013 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/tables/certs.h...
Preprocessing /data/git/CCF/src/node/tables/code_id.h...
#include ds/json.h: not found! skipping...
#include entities.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
Preprocessor output (size: 382 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   enum class CodeStatus
00014   {
00015     ALLOWED_TO_JOIN = 0
00016   };
00017   DECLARE_JSON_ENUM(
00018     CodeStatus, {{CodeStatus::ALLOWED_TO_JOIN, "ALLOWED_TO_JOIN"}});
00019 }
00020 
00021 MSGPACK_ADD_ENUM(ccf::CodeStatus);
00022 
00023 namespace ccf
00024 {
00025   using CodeIDs = kv::Map<CodeDigest, CodeStatus>;
00026 }
00027 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/tables/code_id.h...
Preprocessing /data/git/CCF/src/node/tables/node_info_network.h...
#include ds/json.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 777 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace ccf
00012 {
00013   /** @struct NodeInfoNetwork
00014    *  @brief Node network information
00015    */
00016   struct NodeInfoNetwork
00017   {
00018     std::string rpchost; /**< Node local RPC host */
00019     std::string pubhost; /**< Node RPC host */
00020     std::string nodehost; /**< Node-to-node local host */
00021     std::string nodeport; /**< Node-to-node local port */
00022     std::string rpcport; /**< Node local RPC port */
00023     std::string pubport; /**< Node RPC host */
00024 
00025     MSGPACK_DEFINE(rpchost, pubhost, nodehost, nodeport, rpcport, pubport);
00026   };
00027   DECLARE_JSON_TYPE(NodeInfoNetwork);
00028   DECLARE_JSON_REQUIRED_FIELDS(
00029     NodeInfoNetwork, rpchost, pubhost, nodehost, nodeport, rpcport, pubport);
00030 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/tables/node_info_network.h...
Preprocessing /data/git/CCF/src/node/tables/nodes.h...
#include entities.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2440 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 # 6 "/data/git/CCF/src/node/tables/nodes.h" 2
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   /** Nodes table name */
00015   static constexpr auto NODES_MAP_NAME = "public:ccf.gov.nodes";
00016 
00017   /** @enum NodeStatus
00018    * @brief Indicates whether has been trusted by the consortium to be part of
00019    * the service.
00020    */
00021   enum class NodeStatus
00022   {
00023     PENDING = 0, /**< The node is not yet trusted by the consortium */
00024     TRUSTED = 1, /**< The node has been trusted by the consortiun */
00025     RETIRED = 2 /**< The node has been retired by the consortium */
00026   };
00027   DECLARE_JSON_ENUM(
00028     NodeStatus,
00029     {{NodeStatus::PENDING, "PENDING"},
00030      {NodeStatus::TRUSTED, "TRUSTED"},
00031      {NodeStatus::RETIRED, "RETIRED"}});
00032 }
00033 
00034 MSGPACK_ADD_ENUM(ccf::NodeStatus);
00035 
00036 namespace ccf
00037 {
00038   /** @struct NodeInfo
00039    * @brief Node information...
00040    */
00041   struct NodeInfo : public NodeInfoNetwork
00042   {
00043     tls::Pem cert; /**< x509 PEM certificate */
00044     std::vector<uint8_t> quote; /**< Raw SGW Quote */
00045     tls::Pem
00046       encryption_pub_key; /**< Node encryption public key (internal use only) */
00047     NodeStatus status =
00048       NodeStatus::PENDING; /**< ccf::NodeStatus Status of node */
00049 
00050     MSGPACK_DEFINE(
00051       MSGPACK_BASE(NodeInfoNetwork), cert, quote, encryption_pub_key, status);
00052   };
00053   DECLARE_JSON_TYPE_WITH_BASE(NodeInfo, NodeInfoNetwork);
00054   DECLARE_JSON_REQUIRED_FIELDS(
00055     NodeInfo, cert, quote, encryption_pub_key, status);
00056 
00057   /** @typedef NodeId
00058    * @brief Unique node identifier
00059    * @tparam NodeId Unsigned 64-bit integer
00060    */
00061   using NodeId = uint64_t;
00062 
00063   /** @typedef Nodes
00064    * @brief Nodes table
00065    * @tparam Key: NodeId
00066    * @tparam Value: NodeInfo
00067    */
00068   using Nodes = kv::Map<NodeId, NodeInfo>;
00069 
00070 }
00071 
00072 FMT_BEGIN_NAMESPACE
00073 template <>
00074 struct formatter<ccf::NodeStatus>
00075 {
00076   template <typename ParseContext>
00077   auto parse(ParseContext& ctx)
00078   {
00079     return ctx.begin();
00080   }
00081 
00082   template <typename FormatContext>
00083   auto format(const ccf::NodeStatus& state, FormatContext& ctx)
00084     -> decltype(ctx.out())
00085   {
00086     switch (state)
00087     {
00088       case (ccf::NodeStatus::PENDING):
00089       {
00090         return format_to(ctx.out(), "PENDING");
00091       }
00092       case (ccf::NodeStatus::TRUSTED):
00093       {
00094         return format_to(ctx.out(), "TRUSTED");
00095       }
00096       case (ccf::NodeStatus::RETIRED):
00097       {
00098         return format_to(ctx.out(), "RETIRED");
00099       }
00100     }
00101   }
00102 };
00103 FMT_END_NAMESPACE
00104 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/tables/nodes.h...
Preprocessing /data/git/CCF/src/node/test/channel_stub.h...
#include node/entities.h: not found! skipping...
#include node/node_types.h: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1395 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   class ChannelStubProxy
00013   {
00014   public:
00015     std::vector<std::vector<uint8_t>> sent_encrypted_messages;
00016 
00017     ChannelStubProxy() {}
00018 
00019     template <class T>
00020     bool send_encrypted(
00021       const NodeMsgType& msg_type,
00022       NodeId to,
00023       const std::vector<uint8_t>& data,
00024       const T& msg)
00025     {
00026       sent_encrypted_messages.push_back(data);
00027       return true;
00028     }
00029 
00030     template <class T>
00031     bool send_authenticated(
00032       const ccf::NodeMsgType& msg_type, NodeId to, const T& data)
00033     {
00034       return true;
00035     }
00036 
00037     void send_request_hash_to_nodes(
00038       std::shared_ptr<enclave::RpcContext> rpc_ctx, std::set<ccf::NodeId> nodes)
00039     {}
00040 
00041     template <class T>
00042     std::pair<T, std::vector<uint8_t>> recv_encrypted(
00043       const uint8_t* data, size_t size)
00044     {
00045       T msg;
00046       return std::make_pair(msg, std::vector<uint8_t>(data, data + size));
00047     }
00048 
00049     std::vector<uint8_t> get_pop_back()
00050     {
00051       auto back = sent_encrypted_messages.back();
00052       sent_encrypted_messages.pop_back();
00053       return back;
00054     }
00055 
00056     void clear()
00057     {
00058       sent_encrypted_messages.clear();
00059     }
00060 
00061     size_t size() const
00062     {
00063       return sent_encrypted_messages.size();
00064     }
00065 
00066     bool is_empty() const
00067     {
00068       return sent_encrypted_messages.empty();
00069     }
00070   };
00071 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/test/channel_stub.h...
Preprocessing /data/git/CCF/src/node/test/channels.cpp...
#include ../channels.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include queue: not found! skipping...
Preprocessor output (size: 11762 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00011 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00012 
00013 constexpr auto buffer_size = 1024 * 16;
00014 
00015 auto in_buffer_1 = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00016 auto out_buffer_1 = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00017 ringbuffer::Circuit eio1(in_buffer_1->bd, out_buffer_1->bd);
00018 
00019 auto in_buffer_2 = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00020 auto out_buffer_2 = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00021 ringbuffer::Circuit eio2(in_buffer_1->bd, out_buffer_2->bd);
00022 
00023 auto wf1 = ringbuffer::WriterFactory(eio1);
00024 auto wf2 = ringbuffer::WriterFactory(eio2);
00025 
00026 using namespace ccf;
00027 
00028 // Use fixed-size messages as channels messages are not length-prefixed since
00029 // the type of the authenticated header is known in advance (e.g. AppendEntries)
00030 static constexpr auto msg_size = 64;
00031 using MsgType = std::array<uint8_t, msg_size>;
00032 
00033 template <typename T>
00034 struct NodeOutboundMsg
00035 {
00036   NodeMsgType type;
00037   T authenticated_hdr;
00038   std::vector<uint8_t> payload;
00039 };
00040 
00041 template <typename T>
00042 auto read_outbound_msgs(ringbuffer::Circuit& circuit)
00043 {
00044   std::vector<NodeOutboundMsg<T>> msgs;
00045 
00046   circuit.read_from_inside().read(
00047     -1, [&](ringbuffer::Message m, const uint8_t* data, size_t size) {
00048       switch (m)
00049       {
00050         case node_outbound:
00051         {
00052           serialized::read<NodeId>(data, size); // Ignore destination node id
00053           auto msg_type = serialized::read<NodeMsgType>(data, size);
00054           auto aad = serialized::read<T>(data, size);
00055           auto payload = serialized::read(data, size, size);
00056           msgs.push_back(NodeOutboundMsg<T>{msg_type, aad, payload});
00057           break;
00058         }
00059         case add_node:
00060         {
00061           LOG_DEBUG_FMT("Add node msg!");
00062           break;
00063         }
00064         default:
00065         {
00066           LOG_DEBUG_FMT("Outbound message is not expected: {}", m);
00067           REQUIRE(false);
00068         }
00069       }
00070     });
00071 
00072   return msgs;
00073 }
00074 
00075 auto read_node_msgs(ringbuffer::Circuit& circuit)
00076 {
00077   std::vector<std::tuple<NodeId, std::string, std::string>> add_node_msgs;
00078   std::vector<NodeId> remove_node_msgs;
00079 
00080   circuit.read_from_inside().read(
00081     -1, [&](ringbuffer::Message m, const uint8_t* data, size_t size) {
00082       switch (m)
00083       {
00084         case add_node:
00085         {
00086           auto [id, hostname, service] =
00087             ringbuffer::read_message<ccf::add_node>(data, size);
00088           add_node_msgs.push_back(std::make_tuple(id, hostname, service));
00089 
00090           break;
00091         }
00092         case remove_node:
00093         {
00094           auto [id] = ringbuffer::read_message<ccf::remove_node>(data, size);
00095           remove_node_msgs.push_back(id);
00096           break;
00097         }
00098         default:
00099         {
00100           LOG_DEBUG_FMT("Outbound message is not expected: {}", m);
00101           REQUIRE(false);
00102         }
00103       }
00104     });
00105 
00106   return std::make_pair(add_node_msgs, remove_node_msgs);
00107 }
00108 
00109 TEST_CASE("Client/Server key exchange")
00110 {
00111   auto network_kp = tls::make_key_pair();
00112   auto channel1 = Channel(wf1, network_kp, 1, 2);
00113   auto channel2 = Channel(wf2, network_kp, 2, 1);
00114 
00115   MsgType msg;
00116   msg.fill(0x42);
00117 
00118   INFO("Trying to tag/verify before channel establishment");
00119   {
00120     REQUIRE_FALSE(
00121       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00122     REQUIRE_FALSE(
00123       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00124 
00125     // Every send is replaced with a new channel establishment message
00126     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00127     REQUIRE(outbound_msgs.size() == 2);
00128     REQUIRE(outbound_msgs[0].type == channel_msg);
00129     REQUIRE(outbound_msgs[1].type == channel_msg);
00130   }
00131 
00132   INFO("Establish channels");
00133   {
00134     auto channel1_signed_public = channel1.get_signed_public();
00135     auto channel2_signed_public = channel2.get_signed_public();
00136 
00137     REQUIRE(channel1.load_peer_signed_public(
00138       true, channel2_signed_public.data(), channel2_signed_public.size()));
00139 
00140     // Messages sent before channel was established are flushed
00141     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00142     REQUIRE(outbound_msgs.size() == 1);
00143     REQUIRE(outbound_msgs[0].type == NodeMsgType::consensus_msg);
00144     REQUIRE(outbound_msgs[0].authenticated_hdr == msg);
00145 
00146     REQUIRE(channel2.load_peer_signed_public(
00147       true, channel1_signed_public.data(), channel1_signed_public.size()));
00148 
00149     // Second channel had no pending messages
00150     outbound_msgs = read_outbound_msgs<MsgType>(eio2);
00151     REQUIRE(outbound_msgs.size() == 0);
00152   }
00153 
00154   INFO("Protect integrity of message (peer1 -> peer2)");
00155   {
00156     REQUIRE(
00157       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00158     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00159     REQUIRE(outbound_msgs.size() == 1);
00160     auto msg_ = outbound_msgs[0];
00161     const auto* data_ = msg_.payload.data();
00162     auto size_ = msg_.payload.size();
00163     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00164 
00165     REQUIRE(channel2.recv_authenticated(
00166       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00167       data_,
00168       size_));
00169   }
00170 
00171   INFO("Protect integrity of message (peer2 -> peer1)");
00172   {
00173     REQUIRE(
00174       channel2.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00175     auto outbound_msgs = read_outbound_msgs<MsgType>(eio2);
00176     REQUIRE(outbound_msgs.size() == 1);
00177     auto msg_ = outbound_msgs[0];
00178     const auto* data_ = msg_.payload.data();
00179     auto size_ = msg_.payload.size();
00180     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00181 
00182     REQUIRE(channel1.recv_authenticated(
00183       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00184       data_,
00185       size_));
00186   }
00187 
00188   INFO("Tamper with message");
00189   {
00190     REQUIRE(
00191       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00192     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00193     REQUIRE(outbound_msgs.size() == 1);
00194     auto msg_ = outbound_msgs[0];
00195     msg_.payload[0] += 1; // Tamper with message
00196     const auto* data_ = msg_.payload.data();
00197     auto size_ = msg_.payload.size();
00198     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00199 
00200     REQUIRE_FALSE(channel2.recv_authenticated(
00201       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00202       data_,
00203       size_));
00204   }
00205 
00206   INFO("Encrypt message (peer1 -> peer2)");
00207   {
00208     std::vector<uint8_t> plain_text(128, 0x1);
00209     REQUIRE(channel1.send(
00210       NodeMsgType::consensus_msg, {msg.begin(), msg.size()}, plain_text));
00211 
00212     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00213     REQUIRE(outbound_msgs.size() == 1);
00214     auto msg_ = outbound_msgs[0];
00215     const auto* data_ = msg_.payload.data();
00216     auto size_ = msg_.payload.size();
00217     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00218 
00219     auto decrypted = channel2.recv_encrypted(
00220       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00221       data_,
00222       size_);
00223 
00224     REQUIRE(decrypted.has_value());
00225     REQUIRE(decrypted.value() == plain_text);
00226   }
00227 
00228   INFO("Encrypt message (peer2 -> peer1)");
00229   {
00230     std::vector<uint8_t> plain_text(128, 0x1);
00231     REQUIRE(channel2.send(
00232       NodeMsgType::consensus_msg, {msg.begin(), msg.size()}, plain_text));
00233 
00234     auto outbound_msgs = read_outbound_msgs<MsgType>(eio2);
00235     REQUIRE(outbound_msgs.size() == 1);
00236     auto msg_ = outbound_msgs[0];
00237     const auto* data_ = msg_.payload.data();
00238     auto size_ = msg_.payload.size();
00239     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00240 
00241     auto decrypted = channel1.recv_encrypted(
00242       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00243       data_,
00244       size_);
00245 
00246     REQUIRE(decrypted.has_value());
00247     REQUIRE(decrypted.value() == plain_text);
00248   }
00249 }
00250 
00251 TEST_CASE("Replay and out-of-order")
00252 {
00253   auto network_kp = tls::make_key_pair();
00254   auto channel1 = Channel(wf1, network_kp, 1, 2);
00255   auto channel2 = Channel(wf2, network_kp, 2, 1);
00256 
00257   MsgType msg;
00258   msg.fill(0x42);
00259 
00260   INFO("Establish channels");
00261   {
00262     auto channel1_signed_public = channel1.get_signed_public();
00263     auto channel2_signed_public = channel2.get_signed_public();
00264 
00265     REQUIRE(channel1.load_peer_signed_public(
00266       true, channel2_signed_public.data(), channel2_signed_public.size()));
00267     REQUIRE(channel2.load_peer_signed_public(
00268       true, channel1_signed_public.data(), channel1_signed_public.size()));
00269   }
00270 
00271   NodeOutboundMsg<MsgType> first_msg, first_msg_copy;
00272 
00273   INFO("Replay same message");
00274   {
00275     REQUIRE(
00276       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00277     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00278     REQUIRE(outbound_msgs.size() == 1);
00279     first_msg = outbound_msgs[0];
00280     auto msg_copy = first_msg;
00281     first_msg_copy = first_msg;
00282     const auto* data_ = first_msg.payload.data();
00283     auto size_ = first_msg.payload.size();
00284     REQUIRE(first_msg.type == NodeMsgType::consensus_msg);
00285 
00286     REQUIRE(channel2.recv_authenticated(
00287       {first_msg.authenticated_hdr.begin(), first_msg.authenticated_hdr.size()},
00288       data_,
00289       size_));
00290 
00291     // Replay
00292     data_ = msg_copy.payload.data();
00293     size_ = msg_copy.payload.size();
00294     REQUIRE_FALSE(channel2.recv_authenticated(
00295       {msg_copy.authenticated_hdr.begin(), msg_copy.authenticated_hdr.size()},
00296       data_,
00297       size_));
00298   }
00299 
00300   INFO("Issue more messages and replay old one");
00301   {
00302     REQUIRE(
00303       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00304     REQUIRE(read_outbound_msgs<MsgType>(eio1).size() == 1);
00305 
00306     REQUIRE(
00307       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00308     REQUIRE(read_outbound_msgs<MsgType>(eio1).size() == 1);
00309 
00310     REQUIRE(
00311       channel1.send(NodeMsgType::consensus_msg, {msg.begin(), msg.size()}));
00312     auto outbound_msgs = read_outbound_msgs<MsgType>(eio1);
00313     REQUIRE(outbound_msgs.size() == 1);
00314     auto msg_ = outbound_msgs[0];
00315     const auto* data_ = msg_.payload.data();
00316     auto size_ = msg_.payload.size();
00317     REQUIRE(msg_.type == NodeMsgType::consensus_msg);
00318 
00319     REQUIRE(channel2.recv_authenticated(
00320       {msg_.authenticated_hdr.begin(), msg_.authenticated_hdr.size()},
00321       data_,
00322       size_));
00323 
00324     const auto* first_msg_data_ = first_msg_copy.payload.data();
00325     auto first_msg_size_ = first_msg_copy.payload.size();
00326     REQUIRE_FALSE(channel2.recv_authenticated(
00327       {first_msg_copy.authenticated_hdr.begin(),
00328        first_msg_copy.authenticated_hdr.size()},
00329       first_msg_data_,
00330       first_msg_size_));
00331   }
00332 }
00333 
00334 TEST_CASE("Host connections")
00335 {
00336   NodeId self = 1;
00337   auto network_kp = tls::make_key_pair();
00338   auto channel_manager =
00339     ChannelManager(wf1, network_kp->private_key_pem(), self);
00340   NodeId peer_id = 2;
00341 
00342   INFO("New channel creates host connection");
00343   {
00344     channel_manager.create_channel(peer_id, "hostname", "port");
00345     auto [add_node_msgs, remove_node_msgs] = read_node_msgs(eio1);
00346     REQUIRE(add_node_msgs.size() == 1);
00347     REQUIRE(remove_node_msgs.size() == 0);
00348     REQUIRE(std::get<0>(add_node_msgs[0]) == peer_id);
00349     REQUIRE(std::get<1>(add_node_msgs[0]) == "hostname");
00350     REQUIRE(std::get<2>(add_node_msgs[0]) == "port");
00351   }
00352 
00353   INFO("Retrieving unknown channel does not create host connection");
00354   {
00355     NodeId unknown_peer_id = 3;
00356     channel_manager.get(unknown_peer_id);
00357     auto [add_node_msgs, remove_node_msgs] = read_node_msgs(eio1);
00358     REQUIRE(add_node_msgs.size() == 0);
00359     REQUIRE(remove_node_msgs.size() == 0);
00360   }
00361 
00362   INFO("Destroying channel closes host connection");
00363   {
00364     channel_manager.destroy_channel(peer_id);
00365     auto [add_node_msgs, remove_node_msgs] = read_node_msgs(eio1);
00366     REQUIRE(add_node_msgs.size() == 0);
00367     REQUIRE(remove_node_msgs.size() == 1);
00368   }
00369 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/channels.cpp...
Preprocessing /data/git/CCF/src/node/test/encryptor.cpp...
#include node/encryptor.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/ledger_secrets.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include random: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 8059 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 using namespace ccf;
00016 
00017 TEST_CASE("Simple encryption/decryption")
00018 {
00019   // Setting 1 ledger secret, valid for version 1+
00020   uint64_t node_id = 0;
00021   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00022   secrets->init();
00023   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00024   encryptor->set_iv_id(node_id);
00025 
00026   std::vector<uint8_t> plain(128, 0x42);
00027   std::vector<uint8_t> cipher;
00028   std::vector<uint8_t> serialised_header;
00029   std::vector<uint8_t> additional_data; // No additional data
00030   kv::Version version = 10;
00031 
00032   // Encrypting plain at version 10
00033   encryptor->encrypt(
00034     plain, additional_data, serialised_header, cipher, version);
00035 
00036   // Decrypting cipher at version 10
00037   std::vector<uint8_t> decrypted_cipher;
00038   REQUIRE(encryptor->decrypt(
00039     cipher, additional_data, serialised_header, decrypted_cipher, version));
00040   REQUIRE(plain == decrypted_cipher);
00041 }
00042 
00043 TEST_CASE(
00044   "Subsequent ciphers from same plaintext are different - CftTxEncryptor")
00045 {
00046   uint64_t node_id = 0;
00047   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00048   secrets->init();
00049   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00050   encryptor->set_iv_id(node_id);
00051 
00052   std::vector<uint8_t> plain(128, 0x42);
00053   std::vector<uint8_t> cipher;
00054   std::vector<uint8_t> cipher2;
00055   std::vector<uint8_t> serialised_header;
00056   std::vector<uint8_t> serialised_header2;
00057   std::vector<uint8_t> additional_data; // No additional data
00058   kv::Version version = 10;
00059 
00060   encryptor->encrypt(
00061     plain, additional_data, serialised_header, cipher, version);
00062   encryptor->encrypt(
00063     plain, additional_data, serialised_header2, cipher2, version);
00064 
00065   // Ciphers are different because IV is different
00066   REQUIRE(cipher != cipher2);
00067   REQUIRE(serialised_header != serialised_header2);
00068 }
00069 
00070 TEST_CASE(
00071   "Different node ciphers from same plaintext are different - CftTxEncryptor")
00072 {
00073   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00074   secrets->init();
00075   auto encryptor_0 = std::make_shared<ccf::CftTxEncryptor>(secrets);
00076   auto encryptor_1 = std::make_shared<ccf::CftTxEncryptor>(secrets);
00077   encryptor_0->set_iv_id(0);
00078   encryptor_1->set_iv_id(1);
00079 
00080   std::vector<uint8_t> plain(128, 0x42);
00081   std::vector<uint8_t> cipher;
00082   std::vector<uint8_t> cipher2;
00083   std::vector<uint8_t> serialised_header;
00084   std::vector<uint8_t> serialised_header2;
00085   std::vector<uint8_t> additional_data; // No additional data
00086   kv::Version version = 10;
00087 
00088   encryptor_0->encrypt(
00089     plain, additional_data, serialised_header, cipher, version);
00090   encryptor_1->encrypt(
00091     plain, additional_data, serialised_header2, cipher2, version);
00092 
00093   // Ciphers are different because IV is different
00094   REQUIRE(cipher != cipher2);
00095   REQUIRE(serialised_header != serialised_header2);
00096 }
00097 
00098 TEST_CASE("Two ciphers from same plaintext are different - BftTxEncryptor")
00099 {
00100   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00101   secrets->init();
00102   auto encryptor = std::make_shared<ccf::BftTxEncryptor>(secrets);
00103 
00104   std::vector<uint8_t> plain(128, 0x42);
00105   std::vector<uint8_t> cipher;
00106   std::vector<uint8_t> cipher2;
00107   std::vector<uint8_t> serialised_header;
00108   std::vector<uint8_t> serialised_header2;
00109   std::vector<uint8_t> additional_data; // No additional data
00110   kv::Version version = 10;
00111 
00112   encryptor->encrypt(
00113     plain, additional_data, serialised_header, cipher, version);
00114   encryptor->set_iv_id(1);
00115   encryptor->encrypt(
00116     plain, additional_data, serialised_header2, cipher2, version);
00117 
00118   // Ciphers are different because IV is different
00119   REQUIRE(cipher != cipher2);
00120   REQUIRE(serialised_header != serialised_header2);
00121 }
00122 
00123 TEST_CASE(
00124   "Different node ciphers from same plaintext with and without snapshots - "
00125   "BftTxEncryptor")
00126 {
00127   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00128   secrets->init();
00129   auto encryptor = std::make_shared<ccf::BftTxEncryptor>(secrets);
00130   encryptor->set_iv_id(0x7FFFFFFF);
00131 
00132   std::vector<uint8_t> plain(128, 0x42);
00133   std::vector<uint8_t> cipher;
00134   std::vector<uint8_t> cipher2;
00135   std::vector<uint8_t> serialised_header;
00136   std::vector<uint8_t> serialised_header2;
00137   std::vector<uint8_t> additional_data; // No additional data
00138   kv::Version version = 10;
00139 
00140   bool is_snapshot = false;
00141   encryptor->encrypt(
00142     plain, additional_data, serialised_header, cipher, version, is_snapshot);
00143 
00144   is_snapshot = true;
00145   encryptor->encrypt(
00146     plain, additional_data, serialised_header2, cipher2, version, is_snapshot);
00147 
00148   // Ciphers are different because IV is different
00149   REQUIRE(cipher != cipher2);
00150   REQUIRE(serialised_header != serialised_header2);
00151 }
00152 
00153 TEST_CASE("Additional data")
00154 {
00155   // Setting 1 ledger secret, valid for version 1+
00156   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00157   secrets->init();
00158   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00159 
00160   std::vector<uint8_t> plain(128, 0x42);
00161   std::vector<uint8_t> cipher;
00162   std::vector<uint8_t> serialised_header;
00163   std::vector<uint8_t> additional_data(256, 0x10);
00164   kv::Version version = 10;
00165 
00166   // Encrypting plain at version 10
00167   encryptor->encrypt(
00168     plain, additional_data, serialised_header, cipher, version);
00169 
00170   // Decrypting cipher at version 10
00171   std::vector<uint8_t> decrypted_cipher;
00172   REQUIRE(encryptor->decrypt(
00173     cipher, additional_data, serialised_header, decrypted_cipher, version));
00174   REQUIRE(plain == decrypted_cipher);
00175 
00176   // Tampering with additional data: decryption fails
00177   additional_data[100] = 0xAA;
00178   std::vector<uint8_t> decrypted_cipher2;
00179   REQUIRE_FALSE(encryptor->decrypt(
00180     cipher, additional_data, serialised_header, decrypted_cipher2, version));
00181 
00182   // mbedtls 2.16+ does not produce plain text if decryption fails
00183   REQUIRE(decrypted_cipher2.empty());
00184 }
00185 
00186 TEST_CASE("Encryption/decryption with multiple ledger secrets")
00187 {
00188   // Setting 2 ledger secrets, valid from version 1 and 4
00189   uint64_t node_id = 0;
00190   auto secrets = std::make_shared<ccf::LedgerSecrets>();
00191   secrets->init();
00192   secrets->add_new_secret(4, LedgerSecret());
00193   auto encryptor = std::make_shared<ccf::CftTxEncryptor>(secrets);
00194   encryptor->set_iv_id(node_id);
00195 
00196   INFO("Encryption with key at version 1");
00197   {
00198     std::vector<uint8_t> plain(128, 0x42);
00199     std::vector<uint8_t> cipher;
00200     std::vector<uint8_t> decrypted_cipher;
00201     std::vector<uint8_t> serialised_header;
00202     kv::Version version = 1;
00203     encryptor->encrypt(plain, {}, serialised_header, cipher, version);
00204 
00205     // Decrypting from the version which was used for encryption should succeed
00206     REQUIRE(encryptor->decrypt(
00207       cipher, {}, serialised_header, decrypted_cipher, version));
00208     REQUIRE(plain == decrypted_cipher);
00209 
00210     // Decrypting from a version in the same version interval should also
00211     // succeed
00212     REQUIRE(encryptor->decrypt(
00213       cipher, {}, serialised_header, decrypted_cipher, version + 1));
00214     REQUIRE(plain == decrypted_cipher);
00215 
00216     // Decrypting from a version encrypted with a different key should fail
00217     REQUIRE_FALSE(encryptor->decrypt(
00218       cipher, {}, serialised_header, decrypted_cipher, version + 4));
00219   }
00220 
00221   INFO("Encryption with key at version 4");
00222   {
00223     std::vector<uint8_t> plain(128, 0x42);
00224     std::vector<uint8_t> cipher;
00225     std::vector<uint8_t> decrypted_cipher;
00226     std::vector<uint8_t> serialised_header;
00227     kv::Version version = 4;
00228     encryptor->encrypt(plain, {}, serialised_header, cipher, version);
00229 
00230     // Decrypting from the version which was used for encryption should succeed
00231     REQUIRE(encryptor->decrypt(
00232       cipher, {}, serialised_header, decrypted_cipher, version));
00233     REQUIRE(plain == decrypted_cipher);
00234 
00235     // Decrypting from a version in the same version interval should also
00236     // succeed
00237     REQUIRE(encryptor->decrypt(
00238       cipher, {}, serialised_header, decrypted_cipher, version + 1));
00239     REQUIRE(plain == decrypted_cipher);
00240 
00241     // Decrypting from a version encrypted with a different key should fail
00242     REQUIRE_FALSE(
00243       encryptor->decrypt(cipher, {}, serialised_header, decrypted_cipher, 1));
00244   }
00245 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/encryptor.cpp...
Preprocessing /data/git/CCF/src/node/test/historical_queries.cpp...
#include node/historical_queries.h: not found! skipping...
#include ds/messaging.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include node/history.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 8819 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00012 
00013 
00014 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00015 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00016 
00017 struct StubWriter : public ringbuffer::AbstractWriter
00018 {
00019 public:
00020   struct Write
00021   {
00022     ringbuffer::Message m;
00023     bool finished;
00024     std::vector<uint8_t> contents;
00025   };
00026   std::vector<Write> writes;
00027 
00028   Write& get_write(const WriteMarker& marker)
00029   {
00030     REQUIRE(marker.has_value());
00031     REQUIRE(marker.value() < writes.size());
00032     return writes[marker.value()];
00033   }
00034 
00035   Write& get_last_message()
00036   {
00037     REQUIRE(writes.size() > 0);
00038     auto& write = writes.back();
00039     REQUIRE(write.finished);
00040     return write;
00041   }
00042 
00043   WriteMarker prepare(
00044     ringbuffer::Message m,
00045     size_t size,
00046     bool wait = true,
00047     size_t* identifier = nullptr) override
00048   {
00049     const auto index = writes.size();
00050     writes.push_back(Write{m, false, {}});
00051     return index;
00052   }
00053 
00054   void finish(const WriteMarker& marker) override
00055   {
00056     get_write(marker).finished = true;
00057   }
00058 
00059   WriteMarker write_bytes(
00060     const WriteMarker& marker, const uint8_t* bytes, size_t size) override
00061   {
00062     auto& write = get_write(marker);
00063     write.contents.insert(write.contents.end(), bytes, bytes + size);
00064     return marker;
00065   }
00066 };
00067 
00068 TEST_CASE("StateCache")
00069 {
00070   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00071   auto consensus = std::make_shared<kv::StubConsensus>();
00072 
00073   kv::Store store(consensus);
00074   store.set_encryptor(encryptor);
00075 
00076   // Make history to produce signatures
00077   const auto node_id = 0;
00078   auto kp = tls::make_key_pair();
00079   auto history = std::make_shared<ccf::MerkleTxHistory>(store, node_id, *kp);
00080 
00081   store.set_history(history);
00082 
00083   using NumToString = kv::Map<size_t, std::string>;
00084 
00085   constexpr size_t low_signature_transaction = 3;
00086   constexpr size_t high_signature_transaction = 100;
00087 
00088   constexpr size_t low_index = low_signature_transaction + 2;
00089   constexpr size_t high_index = high_signature_transaction - 3;
00090   constexpr size_t unsigned_index = high_signature_transaction + 5;
00091 
00092   {
00093     INFO("Build some interesting state in the store");
00094 
00095     {
00096       INFO("Store the signing node's key");
00097       auto tx = store.create_tx();
00098       auto view = tx.get_view<ccf::Nodes>(ccf::Tables::NODES);
00099       ccf::NodeInfo ni;
00100       ni.cert = kp->self_sign("CN=Test node");
00101       ni.status = ccf::NodeStatus::TRUSTED;
00102       view->put(node_id, ni);
00103       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00104     }
00105 
00106     {
00107       for (size_t i = 1; i < high_signature_transaction; ++i)
00108       {
00109         if (
00110           i == low_signature_transaction - 1 ||
00111           i == high_signature_transaction - 1)
00112         {
00113           history->emit_signature();
00114           store.compact(store.current_version());
00115         }
00116         else
00117         {
00118           auto tx = store.create_tx();
00119           auto [public_view, private_view] =
00120             tx.get_view<NumToString, NumToString>("public:data", "data");
00121           const auto s = std::to_string(i);
00122           public_view->put(i, s);
00123           private_view->put(i, s);
00124 
00125           REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00126         }
00127       }
00128     }
00129 
00130     REQUIRE(store.current_version() == high_signature_transaction);
00131   }
00132 
00133   std::map<consensus::Index, std::vector<uint8_t>> ledger;
00134   {
00135     INFO("Rebuild ledger as seen by host");
00136     auto next_ledger_entry = consensus->pop_oldest_entry();
00137     while (next_ledger_entry.has_value())
00138     {
00139       const auto ib = ledger.insert(std::make_pair(
00140         std::get<0>(next_ledger_entry.value()),
00141         *std::get<1>(next_ledger_entry.value())));
00142       REQUIRE(ib.second);
00143       next_ledger_entry = consensus->pop_oldest_entry();
00144     }
00145 
00146     REQUIRE(ledger.size() == high_signature_transaction);
00147   }
00148 
00149   // Now we actually get to the historical queries
00150   std::vector<consensus::Index> requested_ledger_entries = {};
00151   messaging::BufferProcessor bp("historical_queries");
00152   DISPATCHER_SET_MESSAGE_HANDLER(
00153     bp,
00154     consensus::ledger_get,
00155     [&requested_ledger_entries](const uint8_t* data, size_t size) {
00156       auto [idx, purpose] =
00157         ringbuffer::read_message<consensus::ledger_get>(data, size);
00158       REQUIRE(purpose == consensus::LedgerRequestPurpose::HistoricalQuery);
00159       requested_ledger_entries.push_back(idx);
00160     });
00161 
00162   constexpr size_t buffer_size = 1 << 12;
00163   auto buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00164   ringbuffer::Reader rr(buffer->bd);
00165 
00166   auto rw = std::make_shared<ringbuffer::Writer>(rr);
00167   ccf::historical::StateCache cache(store, rw);
00168 
00169   {
00170     INFO(
00171       "Initially, no stores are available, even if they're requested multiple "
00172       "times");
00173     REQUIRE(cache.get_store_at(low_index) == nullptr);
00174     REQUIRE(cache.get_store_at(low_index) == nullptr);
00175     REQUIRE(cache.get_store_at(high_index) == nullptr);
00176     REQUIRE(cache.get_store_at(low_index) == nullptr);
00177     REQUIRE(cache.get_store_at(unsigned_index) == nullptr);
00178     REQUIRE(cache.get_store_at(high_index) == nullptr);
00179     REQUIRE(cache.get_store_at(low_index) == nullptr);
00180   }
00181 
00182   {
00183     INFO("The host sees one request for each index");
00184     const auto read = bp.read_n(100, rr);
00185     REQUIRE(read == 3);
00186     REQUIRE(requested_ledger_entries.size() == 3);
00187     REQUIRE(
00188       requested_ledger_entries ==
00189       std::vector<consensus::Index>{low_index, high_index, unsigned_index});
00190   }
00191 
00192   auto provide_ledger_entry = [&](size_t i) {
00193     bool accepted = cache.handle_ledger_entry(i, ledger.at(i));
00194     // Pump outbound ringbuffer to clear messages
00195     bp.read_n(100, rr);
00196     return accepted;
00197   };
00198 
00199   {
00200     INFO("Cache doesn't accept arbitrary entries");
00201     REQUIRE(!provide_ledger_entry(high_index - 1));
00202     REQUIRE(!provide_ledger_entry(high_index + 1));
00203   }
00204 
00205   {
00206     INFO(
00207       "Cache accepts requested entries, and then range of supporting entries");
00208     REQUIRE(provide_ledger_entry(high_index));
00209 
00210     // Count up to next signature
00211     for (size_t i = high_index + 1; i < high_signature_transaction; ++i)
00212     {
00213       REQUIRE(provide_ledger_entry(i));
00214       REQUIRE(cache.get_store_at(high_index) == nullptr);
00215     }
00216 
00217     REQUIRE(provide_ledger_entry(high_signature_transaction));
00218     REQUIRE(cache.get_store_at(high_index) != nullptr);
00219   }
00220 
00221   {
00222     INFO(
00223       "Cache accepts _wrong_ requested entry, and the range of supporting "
00224       "entries");
00225     // NB: This is _a_ valid entry, but not at this index. In fact this stage
00226     // will accept anything that looks quite like a valid entry, even if it
00227     // never came from a legitimate node - they should all fail at the signature
00228     // check
00229     REQUIRE(cache.get_store_at(low_index) == nullptr);
00230     REQUIRE(cache.handle_ledger_entry(low_index, ledger.at(low_index + 1)));
00231 
00232     // Count up to next signature
00233     for (size_t i = low_index + 1; i < high_signature_transaction; ++i)
00234     {
00235       REQUIRE(provide_ledger_entry(i));
00236       REQUIRE(cache.get_store_at(low_index) == nullptr);
00237     }
00238 
00239     // Signature is good
00240     REQUIRE(provide_ledger_entry(high_signature_transaction));
00241     // Junk entry is still not available
00242     REQUIRE(cache.get_store_at(low_index) == nullptr);
00243   }
00244 
00245   {
00246     INFO("Historical state can be retrieved from provided entries");
00247     auto store_at_index = cache.get_store_at(high_index);
00248     REQUIRE(store_at_index != nullptr);
00249 
00250     {
00251       auto tx = store_at_index->create_tx();
00252       auto [public_view, private_view] =
00253         tx.get_view<NumToString, NumToString>("public:data", "data");
00254 
00255       const auto k = high_index - 1;
00256       const auto v = std::to_string(k);
00257 
00258       auto public_v = public_view->get(k);
00259       REQUIRE(public_v.has_value());
00260       REQUIRE(*public_v == v);
00261 
00262       auto private_v = private_view->get(k);
00263       REQUIRE(private_v.has_value());
00264       REQUIRE(*private_v == v);
00265 
00266       size_t public_count = 0;
00267       public_view->foreach([&public_count](const auto& k, const auto& v) {
00268         REQUIRE(public_count++ == 0);
00269         return true;
00270       });
00271 
00272       size_t private_count = 0;
00273       private_view->foreach([&private_count](const auto& k, const auto& v) {
00274         REQUIRE(private_count++ == 0);
00275         return true;
00276       });
00277     }
00278   }
00279 
00280   {
00281     INFO("Cache doesn't throw when given junk");
00282     REQUIRE(cache.get_store_at(unsigned_index) == nullptr);
00283     bool result;
00284     REQUIRE_NOTHROW(result = cache.handle_ledger_entry(unsigned_index, {}));
00285     REQUIRE(!result);
00286     REQUIRE_NOTHROW(
00287       result = cache.handle_ledger_entry(unsigned_index, {0x1, 0x2, 0x3}));
00288     REQUIRE(!result);
00289     REQUIRE_NOTHROW(
00290       result = cache.handle_ledger_entry(unsigned_index, ledger[low_index]));
00291     REQUIRE(!result);
00292     REQUIRE_NOTHROW(
00293       result = cache.handle_ledger_entry(
00294         unsigned_index, ledger[high_signature_transaction]));
00295     REQUIRE(!result);
00296   }
00297 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/historical_queries.cpp...
Preprocessing /data/git/CCF/src/node/test/history.cpp...
#include node/history.h: not found! skipping...
#include enclave/app_interface.h: not found! skipping...
#include kv/kv_types.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include kv/test/stub_consensus.h: not found! skipping...
#include node/entities.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/signatures.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 9868 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 #define DOCTEST_CONFIG_IMPLEMENT
00015 
00016 
00017 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00018 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00019 using MapT = kv::Map<size_t, size_t>;
00020 
00021 class DummyConsensus : public kv::StubConsensus
00022 {
00023 public:
00024   kv::Store* store;
00025 
00026   DummyConsensus(kv::Store* store_) : store(store_) {}
00027 
00028   bool replicate(const kv::BatchVector& entries, View view) override
00029   {
00030     if (store)
00031     {
00032       REQUIRE(entries.size() == 1);
00033       return store->deserialise(*std::get<1>(entries[0]));
00034     }
00035     return true;
00036   }
00037 
00038   std::pair<View, SeqNo> get_committed_txid() override
00039   {
00040     return {2, 0};
00041   }
00042 
00043   SeqNo get_committed_seqno() override
00044   {
00045     return 0;
00046   }
00047 
00048   kv::NodeId primary() override
00049   {
00050     return 1;
00051   }
00052 
00053   kv::NodeId id() override
00054   {
00055     return 0;
00056   }
00057 };
00058 
00059 TEST_CASE("Check signature verification")
00060 {
00061   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00062 
00063   kv::Store primary_store;
00064   primary_store.set_encryptor(encryptor);
00065 
00066   kv::Store backup_store;
00067   backup_store.set_encryptor(encryptor);
00068 
00069   ccf::Nodes nodes(ccf::Tables::NODES);
00070   ccf::Signatures signatures(ccf::Tables::SIGNATURES);
00071 
00072   auto kp = tls::make_key_pair();
00073 
00074   std::shared_ptr<kv::Consensus> consensus =
00075     std::make_shared<DummyConsensus>(&backup_store);
00076   primary_store.set_consensus(consensus);
00077   std::shared_ptr<kv::Consensus> null_consensus =
00078     std::make_shared<DummyConsensus>(nullptr);
00079   backup_store.set_consensus(null_consensus);
00080 
00081   std::shared_ptr<kv::TxHistory> primary_history =
00082     std::make_shared<ccf::MerkleTxHistory>(primary_store, 0, *kp);
00083   primary_store.set_history(primary_history);
00084 
00085   std::shared_ptr<kv::TxHistory> backup_history =
00086     std::make_shared<ccf::MerkleTxHistory>(backup_store, 1, *kp);
00087   backup_store.set_history(backup_history);
00088 
00089   INFO("Write certificate");
00090   {
00091     auto txs = primary_store.create_tx();
00092     auto tx = txs.get_view(nodes);
00093     ccf::NodeInfo ni;
00094     ni.cert = kp->self_sign("CN=name");
00095     tx->put(0, ni);
00096     REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00097   }
00098 
00099   INFO("Issue signature, and verify successfully on backup");
00100   {
00101     primary_history->emit_signature();
00102     REQUIRE(backup_store.current_version() == 2);
00103   }
00104 
00105   INFO("Issue a bogus signature, rejected by verification on the backup");
00106   {
00107     auto txs = primary_store.create_tx();
00108     auto tx = txs.get_view(signatures);
00109     ccf::PrimarySignature bogus(0, 0);
00110     bogus.sig = std::vector<uint8_t>(MBEDTLS_ECDSA_MAX_LEN, 1);
00111     tx->put(0, bogus);
00112     REQUIRE(txs.commit() == kv::CommitSuccess::NO_REPLICATE);
00113   }
00114 }
00115 
00116 TEST_CASE("Check signing works across rollback")
00117 {
00118   auto encryptor = std::make_shared<kv::NullTxEncryptor>();
00119   kv::Store primary_store;
00120   primary_store.set_encryptor(encryptor);
00121 
00122   kv::Store backup_store;
00123   backup_store.set_encryptor(encryptor);
00124 
00125   ccf::Nodes nodes(ccf::Tables::NODES);
00126 
00127   auto kp = tls::make_key_pair();
00128 
00129   std::shared_ptr<kv::Consensus> consensus =
00130     std::make_shared<DummyConsensus>(&backup_store);
00131   primary_store.set_consensus(consensus);
00132   std::shared_ptr<kv::Consensus> null_consensus =
00133     std::make_shared<DummyConsensus>(nullptr);
00134   backup_store.set_consensus(null_consensus);
00135 
00136   std::shared_ptr<kv::TxHistory> primary_history =
00137     std::make_shared<ccf::MerkleTxHistory>(primary_store, 0, *kp);
00138   primary_store.set_history(primary_history);
00139 
00140   std::shared_ptr<kv::TxHistory> backup_history =
00141     std::make_shared<ccf::MerkleTxHistory>(backup_store, 1, *kp);
00142   backup_store.set_history(backup_history);
00143 
00144   INFO("Write certificate");
00145   {
00146     auto txs = primary_store.create_tx();
00147     auto tx = txs.get_view(nodes);
00148     ccf::NodeInfo ni;
00149     ni.cert = kp->self_sign("CN=name");
00150     tx->put(0, ni);
00151     REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00152   }
00153 
00154   INFO("Transaction that we will roll back");
00155   {
00156     auto txs = primary_store.create_tx();
00157     auto tx = txs.get_view(nodes);
00158     ccf::NodeInfo ni;
00159     tx->put(1, ni);
00160     REQUIRE(txs.commit() == kv::CommitSuccess::OK);
00161   }
00162 
00163   primary_store.rollback(1);
00164   if (consensus->type() == ConsensusType::BFT)
00165   {
00166     backup_store.rollback(1);
00167   }
00168 
00169   INFO("Issue signature, and verify successfully on backup");
00170   {
00171     primary_history->emit_signature();
00172     if (consensus->type() == ConsensusType::BFT)
00173     {
00174       REQUIRE(backup_store.current_version() == 1);
00175     }
00176     else
00177     {
00178       REQUIRE(backup_store.current_version() == 2);
00179     }
00180   }
00181 
00182   INFO("Check merkle roots are updating");
00183   {
00184     auto primary_root = primary_history->get_replicated_state_root();
00185     auto pr_str = fmt::format("{}", primary_root);
00186     auto backup_root = backup_history->get_replicated_state_root();
00187     auto bk_str = fmt::format("{}", backup_root);
00188 
00189     REQUIRE(pr_str == bk_str);
00190   }
00191 }
00192 
00193 class CompactingConsensus : public kv::StubConsensus
00194 {
00195 public:
00196   kv::Store* store;
00197   size_t count = 0;
00198 
00199   CompactingConsensus(kv::Store* store_) : store(store_) {}
00200 
00201   bool replicate(const kv::BatchVector& entries, View view) override
00202   {
00203     for (auto& [version, data, committable] : entries)
00204     {
00205       count++;
00206       if (committable)
00207         store->compact(version);
00208     }
00209     return true;
00210   }
00211 
00212   std::pair<View, SeqNo> get_committed_txid() override
00213   {
00214     return {2, 0};
00215   }
00216 
00217   SeqNo get_committed_seqno() override
00218   {
00219     return 0;
00220   }
00221 
00222   kv::NodeId primary() override
00223   {
00224     return 1;
00225   }
00226 
00227   kv::NodeId id() override
00228   {
00229     return 0;
00230   }
00231 
00232   View get_view(kv::Version version) override
00233   {
00234     return 2;
00235   }
00236 };
00237 
00238 TEST_CASE(
00239   "Batches containing but not ending on a committable transaction should not "
00240   "halt replication")
00241 {
00242   kv::Store store;
00243   std::shared_ptr<CompactingConsensus> consensus =
00244     std::make_shared<CompactingConsensus>(&store);
00245   store.set_consensus(consensus);
00246 
00247   MapT table("public:table");
00248   MapT other_table("public:other_table");
00249 
00250   INFO("Write first tx");
00251   {
00252     auto tx = store.create_tx();
00253     auto txv = tx.get_view(table);
00254     txv->put(0, 1);
00255     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00256     REQUIRE(consensus->count == 1);
00257   }
00258 
00259   INFO("Batch of two, starting with a commitable");
00260   {
00261     auto rv = store.next_txid();
00262 
00263     auto tx = store.create_tx();
00264     auto txv = tx.get_view(table);
00265     txv->put(0, 2);
00266     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00267     REQUIRE(consensus->count == 1);
00268 
00269     store.commit(
00270       rv,
00271       [&store, rv, &other_table]() {
00272         auto txr = store.create_reserved_tx(rv.version);
00273         auto txrv = txr.get_view(other_table);
00274         txrv->put(0, 1);
00275         return txr.commit_reserved();
00276       },
00277       true);
00278     REQUIRE(consensus->count == 3);
00279   }
00280 
00281   INFO("Single tx");
00282   {
00283     auto tx = store.create_tx();
00284     auto txv = tx.get_view(table);
00285     txv->put(0, 3);
00286     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00287     REQUIRE(consensus->count == 4);
00288   }
00289 }
00290 
00291 class RollbackConsensus : public kv::StubConsensus
00292 {
00293 public:
00294   kv::Store* store;
00295   size_t count = 0;
00296   kv::Version rollback_at;
00297   kv::Version rollback_to;
00298 
00299   RollbackConsensus(
00300     kv::Store* store_, kv::Version rollback_at_, kv::Version rollback_to_) :
00301     store(store_),
00302     rollback_at(rollback_at_),
00303     rollback_to(rollback_to_)
00304   {}
00305 
00306   bool replicate(const kv::BatchVector& entries, View view) override
00307   {
00308     for (auto& [version, data, committable] : entries)
00309     {
00310       count++;
00311       if (version == rollback_at)
00312         store->rollback(rollback_to);
00313     }
00314     return true;
00315   }
00316 
00317   std::pair<View, SeqNo> get_committed_txid() override
00318   {
00319     return {2, 0};
00320   }
00321 
00322   SeqNo get_committed_seqno() override
00323   {
00324     return 0;
00325   }
00326 
00327   kv::NodeId primary() override
00328   {
00329     return 1;
00330   }
00331 
00332   kv::NodeId id() override
00333   {
00334     return 0;
00335   }
00336 
00337   View get_view(SeqNo seqno) override
00338   {
00339     return 2;
00340   }
00341 
00342   View get_view() override
00343   {
00344     return 2;
00345   }
00346 };
00347 
00348 TEST_CASE(
00349   "Check that empty rollback during replicate does not cause replication halts")
00350 {
00351   kv::Store store;
00352   std::shared_ptr<RollbackConsensus> consensus =
00353     std::make_shared<RollbackConsensus>(&store, 2, 2);
00354   store.set_consensus(consensus);
00355 
00356   MapT table("public:table");
00357 
00358   INFO("Write first tx");
00359   {
00360     auto tx = store.create_tx();
00361     auto txv = tx.get_view(table);
00362     txv->put(0, 1);
00363     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00364     REQUIRE(consensus->count == 1);
00365   }
00366 
00367   INFO("Write second tx, causing a rollback");
00368   {
00369     auto tx = store.create_tx();
00370     auto txv = tx.get_view(table);
00371     txv->put(0, 2);
00372     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00373     REQUIRE(consensus->count == 2);
00374   }
00375 
00376   INFO("Single tx");
00377   {
00378     auto tx = store.create_tx();
00379     auto txv = tx.get_view(table);
00380     txv->put(0, 3);
00381     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00382     REQUIRE(consensus->count == 3);
00383   }
00384 }
00385 
00386 TEST_CASE(
00387   "Check that rollback during replicate does not cause replication halts")
00388 {
00389   kv::Store store;
00390   std::shared_ptr<RollbackConsensus> consensus =
00391     std::make_shared<RollbackConsensus>(&store, 2, 1);
00392   store.set_consensus(consensus);
00393 
00394   MapT table("public:table");
00395 
00396   INFO("Write first tx");
00397   {
00398     auto tx = store.create_tx();
00399     auto txv = tx.get_view(table);
00400     txv->put(0, 1);
00401     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00402     REQUIRE(consensus->count == 1);
00403   }
00404 
00405   INFO("Write second tx, causing a rollback");
00406   {
00407     auto tx = store.create_tx();
00408     auto txv = tx.get_view(table);
00409     txv->put(0, 2);
00410     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00411     REQUIRE(consensus->count == 2);
00412   }
00413 
00414   INFO("Single tx");
00415   {
00416     auto tx = store.create_tx();
00417     auto txv = tx.get_view(table);
00418     txv->put(0, 3);
00419     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00420     REQUIRE(consensus->count == 3);
00421   }
00422 }
00423 
00424 int main(int argc, char** argv)
00425 {
00426   doctest::Context context;
00427   context.applyCommandLine(argc, argv);
00428   int res = context.run();
00429   if (context.shouldExit())
00430     return res;
00431   return res;
00432 }
00433 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT 
---------
Parsing file /data/git/CCF/src/node/test/history.cpp...
Preprocessing /data/git/CCF/src/node/test/history_bench.cpp...
#include kv/test/stub_consensus.h: not found! skipping...
#include node/history.h: not found! skipping...
#include cstdlib: not found! skipping...
#include ctime: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 3665 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 #define PICOBENCH_IMPLEMENT
00009 
00010 
00011 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00012 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00013 
00014 namespace threading
00015 {
00016   std::map<std::thread::id, uint16_t> thread_ids;
00017 }
00018 
00019 using namespace ccf;
00020 
00021 class DummyConsensus : public kv::StubConsensus
00022 {
00023 public:
00024   DummyConsensus() {}
00025 };
00026 
00027 template <class A>
00028 inline void do_not_optimize(A const& value)
00029 {
00030   asm volatile("" : : "r,m"(value) : "memory");
00031 }
00032 
00033 inline void clobber_memory()
00034 {
00035   asm volatile("" : : : "memory");
00036 }
00037 
00038 template <size_t S>
00039 static void hash_only(picobench::state& s)
00040 {
00041   ::srand(42);
00042 
00043   std::vector<std::vector<uint8_t>> txs;
00044   for (size_t i = 0; i < s.iterations(); i++)
00045   {
00046     std::vector<uint8_t> tx;
00047     for (size_t j = 0; j < S; j++)
00048     {
00049       tx.push_back(::rand() % 256);
00050     }
00051     txs.push_back(tx);
00052   }
00053 
00054   size_t idx = 0;
00055   s.start_timer();
00056   for (auto _ : s)
00057   {
00058     (void)_;
00059     auto data = txs[idx++];
00060     crypto::Sha256Hash h;
00061     crypto::Sha256Hash::mbedtls_sha256({data}, h.h.data());
00062     do_not_optimize(h);
00063     clobber_memory();
00064   }
00065   s.stop_timer();
00066 }
00067 
00068 template <size_t S>
00069 static void append(picobench::state& s)
00070 {
00071   ::srand(42);
00072 
00073   kv::Store store;
00074   auto kp = tls::make_key_pair();
00075 
00076   std::shared_ptr<kv::Consensus> consensus = std::make_shared<DummyConsensus>();
00077   store.set_consensus(consensus);
00078 
00079   std::shared_ptr<kv::TxHistory> history =
00080     std::make_shared<ccf::MerkleTxHistory>(store, 0, *kp);
00081   store.set_history(history);
00082 
00083   std::vector<std::vector<uint8_t>> txs;
00084   for (size_t i = 0; i < s.iterations(); i++)
00085   {
00086     std::vector<uint8_t> tx;
00087     for (size_t j = 0; j < S; j++)
00088     {
00089       tx.push_back(::rand() % 256);
00090     }
00091     txs.push_back(tx);
00092   }
00093 
00094   size_t idx = 0;
00095   s.start_timer();
00096   for (auto _ : s)
00097   {
00098     (void)_;
00099     history->append(txs[idx++]);
00100     clobber_memory();
00101   }
00102   s.stop_timer();
00103 }
00104 
00105 template <size_t S>
00106 static void append_compact(picobench::state& s)
00107 {
00108   ::srand(42);
00109 
00110   kv::Store store;
00111   auto kp = tls::make_key_pair();
00112 
00113   std::shared_ptr<kv::Consensus> consensus = std::make_shared<DummyConsensus>();
00114   store.set_consensus(consensus);
00115 
00116   std::shared_ptr<kv::TxHistory> history =
00117     std::make_shared<ccf::MerkleTxHistory>(store, 0, *kp);
00118   store.set_history(history);
00119 
00120   std::vector<std::vector<uint8_t>> txs;
00121   for (size_t i = 0; i < s.iterations(); i++)
00122   {
00123     std::vector<uint8_t> tx;
00124     for (size_t j = 0; j < S; j++)
00125     {
00126       tx.push_back(::rand() % 256);
00127     }
00128     txs.push_back(tx);
00129   }
00130 
00131   size_t idx = 0;
00132   s.start_timer();
00133   for (auto _ : s)
00134   {
00135     (void)_;
00136     history->append(txs[idx++]);
00137     if (idx % 1000)
00138       history->compact(idx);
00139     clobber_memory();
00140   }
00141   s.stop_timer();
00142 }
00143 
00144 const std::vector<int> sizes = {1000, 10000};
00145 
00146 PICOBENCH_SUITE("hash_only");
00147 PICOBENCH(hash_only<10>).iterations(sizes).samples(10).baseline();
00148 PICOBENCH(hash_only<100>).iterations(sizes).samples(10);
00149 PICOBENCH(hash_only<1000>).iterations(sizes).samples(10);
00150 
00151 PICOBENCH_SUITE("append");
00152 PICOBENCH(append<10>).iterations(sizes).samples(10).baseline();
00153 PICOBENCH(append<100>).iterations(sizes).samples(10);
00154 PICOBENCH(append<1000>).iterations(sizes).samples(10);
00155 
00156 PICOBENCH_SUITE("append_compact");
00157 PICOBENCH(append_compact<10>).iterations(sizes).samples(10).baseline();
00158 PICOBENCH(append_compact<100>).iterations(sizes).samples(10);
00159 PICOBENCH(append_compact<1000>).iterations(sizes).samples(10);
00160 
00161 int main(int argc, char* argv[])
00162 {
00163   logger::config::level() = logger::FATAL;
00164 
00165   picobench::runner runner;
00166   runner.parse_cmd_line(argc, argv);
00167   return runner.run();
00168 }
---------
Macros accessible in this file:
---------
PICOBENCH_IMPLEMENT 
---------
Parsing file /data/git/CCF/src/node/test/history_bench.cpp...
Preprocessing /data/git/CCF/src/node/test/merkle_bench.cpp...
#include ../history.h: already included! skipping...
#include algorithm: not found! skipping...
#include fmt/format.h: not found! skipping...
#include picobench/picobench.hpp: not found! skipping...
#include random: not found! skipping...
Preprocessor output (size: 4922 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT
00004 
00005 
00006 #define FMT_HEADER_ONLY
00007 
00008 
00009 
00010 
00011 
00012 using namespace std;
00013 
00014 template <class A>
00015 inline void do_not_optimize(A const& value)
00016 {
00017   asm volatile("" : : "r,m"(value) : "memory");
00018 }
00019 
00020 inline void clobber_memory()
00021 {
00022   asm volatile("" : : : "memory");
00023 }
00024 
00025 static void append_retract(picobench::state& s)
00026 {
00027   ccf::MerkleTreeHistory t;
00028   vector<crypto::Sha256Hash> hashes;
00029   std::random_device r;
00030 
00031   for (size_t i = 0; i < s.iterations(); ++i)
00032   {
00033     crypto::Sha256Hash h;
00034     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00035       h.h[j] = r();
00036 
00037     hashes.emplace_back(h);
00038   }
00039 
00040   size_t index = 0;
00041   s.start_timer();
00042   for (auto _ : s)
00043   {
00044     (void)_;
00045     t.append(hashes[index++]);
00046 
00047     if (index > 0 && index % 1000 == 0)
00048     {
00049       t.retract(index - 1000);
00050     }
00051 
00052     // do_not_optimize();
00053     clobber_memory();
00054   }
00055   s.stop_timer();
00056 }
00057 
00058 static void append_flush(picobench::state& s)
00059 {
00060   ccf::MerkleTreeHistory t;
00061   vector<crypto::Sha256Hash> hashes;
00062   std::random_device r;
00063 
00064   for (size_t i = 0; i < s.iterations(); ++i)
00065   {
00066     crypto::Sha256Hash h;
00067     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00068       h.h[j] = r();
00069 
00070     hashes.emplace_back(h);
00071   }
00072 
00073   size_t index = 0;
00074   s.start_timer();
00075   for (auto _ : s)
00076   {
00077     (void)_;
00078     t.append(hashes[index++]);
00079     if (index > 0 && index % 1000 == 0)
00080       t.flush(index - 1000);
00081 
00082     // do_not_optimize();
00083     clobber_memory();
00084   }
00085   s.stop_timer();
00086 }
00087 
00088 static void append_get_receipt_verify(picobench::state& s)
00089 {
00090   ccf::MerkleTreeHistory t;
00091   vector<crypto::Sha256Hash> hashes;
00092   std::random_device r;
00093 
00094   for (size_t i = 0; i < s.iterations(); ++i)
00095   {
00096     crypto::Sha256Hash h;
00097     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00098       h.h[j] = r();
00099 
00100     hashes.emplace_back(h);
00101   }
00102 
00103   size_t index = 0;
00104   s.start_timer();
00105   for (auto _ : s)
00106   {
00107     (void)_;
00108     t.append(hashes[index++]);
00109 
00110     auto p = t.get_receipt(index);
00111     if (!t.verify(p))
00112       throw std::runtime_error("Bad path");
00113 
00114     // do_not_optimize();
00115     clobber_memory();
00116   }
00117   s.stop_timer();
00118 }
00119 
00120 static void append_get_receipt_verify_v(picobench::state& s)
00121 {
00122   ccf::MerkleTreeHistory t;
00123   vector<crypto::Sha256Hash> hashes;
00124   std::random_device r;
00125 
00126   for (size_t i = 0; i < s.iterations(); ++i)
00127   {
00128     crypto::Sha256Hash h;
00129     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00130       h.h[j] = r();
00131 
00132     hashes.emplace_back(h);
00133   }
00134 
00135   size_t index = 0;
00136   s.start_timer();
00137   for (auto _ : s)
00138   {
00139     (void)_;
00140     t.append(hashes[index++]);
00141 
00142     auto v = t.get_receipt(index).to_v();
00143     ccf::Receipt r(v);
00144     if (!t.verify(r))
00145       throw std::runtime_error("Bad path");
00146 
00147     // do_not_optimize();
00148     clobber_memory();
00149   }
00150   s.stop_timer();
00151 }
00152 
00153 static void serialise_deserialise(picobench::state& s)
00154 {
00155   ccf::MerkleTreeHistory t;
00156   std::random_device r;
00157 
00158   for (size_t i = 0; i < s.iterations(); ++i)
00159   {
00160     crypto::Sha256Hash h;
00161     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00162       h.h[j] = r();
00163     t.append(h);
00164   }
00165 
00166   s.start_timer();
00167   auto buf = t.serialise();
00168   auto ds = ccf::MerkleTreeHistory(buf);
00169   s.stop_timer();
00170 }
00171 
00172 static void serialised_size(picobench::state& s)
00173 {
00174   ccf::MerkleTreeHistory t;
00175   std::random_device r;
00176 
00177   for (size_t i = 0; i < s.iterations(); ++i)
00178   {
00179     crypto::Sha256Hash h;
00180     for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00181       h.h[j] = r();
00182     t.append(h);
00183   }
00184 
00185   s.start_timer();
00186   auto buf = t.serialise();
00187   s.stop_timer();
00188   auto bph = ((float)buf.size()) / s.iterations();
00189   std::cout << fmt::format(
00190                  "mt_serialize n={} : {} bytes, {} bytes/hash, {}% overhead",
00191                  s.iterations(),
00192                  buf.size(),
00193                  bph,
00194                  (bph - crypto::Sha256Hash::SIZE) * 100 /
00195                    crypto::Sha256Hash::SIZE)
00196             << std::endl;
00197 }
00198 
00199 const std::vector<int> sizes = {1000, 10000};
00200 
00201 PICOBENCH_SUITE("append_retract");
00202 PICOBENCH(append_retract).iterations(sizes).samples(10).baseline();
00203 PICOBENCH_SUITE("append_flush");
00204 PICOBENCH(append_flush).iterations(sizes).samples(10).baseline();
00205 PICOBENCH_SUITE("append_get_receipt_verify");
00206 PICOBENCH(append_get_receipt_verify).iterations(sizes).samples(10).baseline();
00207 PICOBENCH_SUITE("append_get_receipt_verify_v");
00208 PICOBENCH(append_get_receipt_verify_v).iterations(sizes).samples(10).baseline();
00209 PICOBENCH_SUITE("serialise_deserialise");
00210 PICOBENCH(serialise_deserialise).iterations(sizes).samples(10).baseline();
00211 // Checks the size of serialised tree, timing results are irrelevant here
00212 // and since we run a single sample probably not that accurate anyway
00213 PICOBENCH_SUITE("serialised_size");
00214 
00215   .iterations({1, 2, 10, 100, 1000, 10000})
00216   .samples(1)
00217   .baseline();
00218 
00219 int main(int argc, char* argv[])
00220 {
00221   picobench::runner runner;
00222   runner.parse_cmd_line(argc, argv);
00223   return runner.run();
00224 }
---------
Macros accessible in this file:
---------
HAVE_OPENSSL HAVE_MBEDTLS FMT_HEADER_ONLY PICOBENCH_IMPLEMENT 
---------
Parsing file /data/git/CCF/src/node/test/merkle_bench.cpp...
Preprocessing /data/git/CCF/src/node/test/merkle_mem.cpp...
#include ../../ds/logger.h: already included! skipping...
#include ../history.h: already included! skipping...
#include algorithm: not found! skipping...
#include random: not found! skipping...
#include sys/resource.h: not found! skipping...
#include sys/time.h: not found! skipping...
Preprocessor output (size: 1811 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 using namespace std;
00012 
00013 static constexpr size_t appends = 1'000'000;
00014 static constexpr size_t max_tree_size = 1000;
00015 static constexpr size_t flushes_without_retract = 10;
00016 
00017 static constexpr size_t max_expected_rss = 4096;
00018 
00019 static size_t get_maxrss()
00020 {
00021   rusage r;
00022   auto rc = getrusage(RUSAGE_SELF, &r);
00023   if (rc != 0)
00024     throw std::logic_error("getrusage failed");
00025   return r.ru_maxrss;
00026 }
00027 
00028 static crypto::Sha256Hash random_hash(std::random_device& rdev)
00029 {
00030   crypto::Sha256Hash h;
00031   for (size_t j = 0; j < crypto::Sha256Hash::SIZE; j++)
00032     h.h[j] = rdev();
00033   return h;
00034 }
00035 
00036 static int append_flush_and_retract()
00037 {
00038   ccf::MerkleTreeHistory t;
00039   std::random_device r;
00040 
00041   for (size_t index = 0; index < appends; ++index)
00042   {
00043     auto h = random_hash(r);
00044     t.append(h);
00045 
00046     if (index > 0 && index % max_tree_size == 0)
00047     {
00048       if (index % (flushes_without_retract * max_tree_size) == 0)
00049       {
00050         t.retract(index - max_tree_size);
00051         LOG_DEBUG_FMT("retract() {}", index - max_tree_size);
00052       }
00053       else
00054       {
00055         t.flush(index - max_tree_size);
00056         LOG_DEBUG_FMT("flush() {}", index - max_tree_size);
00057       }
00058     }
00059     if (index % (appends / 10) == 0)
00060     {
00061       LOG_INFO_FMT("At {}", index);
00062       LOG_INFO_FMT("  MAX RSS: {}Kb", get_maxrss());
00063       const auto serialised = t.serialise();
00064       LOG_INFO_FMT("  SERIALISED: {}Kb", serialised.size() / 1024);
00065       const auto receipt = t.get_receipt(t.end_index());
00066       LOG_INFO_FMT("  SERIALISED RECEIPT: {}bytes", receipt.to_v().size());
00067     }
00068   }
00069   LOG_INFO_FMT("MAX RSS: {}Kb", get_maxrss());
00070 
00071   return get_maxrss() < max_expected_rss ? 0 : 1;
00072 }
00073 
00074 int main(int argc, char* argv[])
00075 {
00076   return append_flush_and_retract();
00077 }
---------
Macros accessible in this file:
---------
LOG_DEBUG LOG_TRACE LOG_FATAL RINGBUFFER_TRY_WRITE_MESSAGE LOG_TRACE_FMT LOG_FAIL LOG_FAIL_FMT LOG_INFO DEFINE_RINGBUFFER_MSG_TYPE LOG_FATAL_FMT RINGBUFFER_WRITE_MESSAGE HAVE_OPENSSL LOG_DEBUG_FMT DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD HAVE_MBEDTLS FMT_HEADER_ONLY DECLARE_RINGBUFFER_MESSAGE_PAYLOAD LOG_INFO_FMT CCF_PAUSE LOG_FAIL_EXC 
---------
Parsing file /data/git/CCF/src/node/test/merkle_mem.cpp...
Preprocessing /data/git/CCF/src/node/test/merkle_test.cpp...
#include node/history.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 4341 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00007 
00008 
00009 crypto::Sha256Hash rand_hash()
00010 {
00011   crypto::Sha256Hash hash;
00012   uint8_t* data = hash.h.data();
00013   for (size_t i = 0; i < hash.h.size(); ++i)
00014   {
00015     data[i] = rand();
00016   }
00017   return hash;
00018 }
00019 
00020 TEST_CASE("Building a tree")
00021 {
00022   ccf::MerkleTreeHistory history;
00023   REQUIRE(history.begin_index() == 0);
00024   REQUIRE(history.end_index() == 0);
00025 
00026   constexpr size_t hash_count = 10'000;
00027   for (size_t i = 1; i < hash_count; ++i)
00028   {
00029     auto h = rand_hash();
00030     history.append(h);
00031     REQUIRE(history.begin_index() == 0);
00032     REQUIRE(history.end_index() == i);
00033   }
00034 
00035   constexpr size_t retract_point = hash_count / 3;
00036   history.retract(retract_point);
00037   REQUIRE(history.end_index() == retract_point);
00038 
00039   for (size_t i = retract_point + 1; i < hash_count; ++i)
00040   {
00041     auto h = rand_hash();
00042     history.append(h);
00043     REQUIRE(history.end_index() == i);
00044   }
00045 
00046   constexpr size_t flush_point = retract_point;
00047   const auto prev_first = history.begin_index();
00048   history.flush(flush_point);
00049   const auto new_first = history.begin_index();
00050   REQUIRE(new_first >= prev_first);
00051   REQUIRE(new_first <= flush_point);
00052 
00053   REQUIRE_THROWS(history.flush(new_first - 1));
00054   REQUIRE(history.begin_index() == new_first);
00055 }
00056 
00057 TEST_CASE("Tree equality")
00058 {
00059   ccf::MerkleTreeHistory tree1;
00060   ccf::MerkleTreeHistory tree2;
00061   REQUIRE(tree1.get_root() == tree2.get_root());
00062 
00063   for (size_t i = 0; i < 100; ++i)
00064   {
00065     const auto h = rand_hash();
00066     {
00067       auto h1 = h;
00068       tree1.append(h1);
00069     }
00070     {
00071       auto h2 = h;
00072       tree2.append(h2);
00073     }
00074     REQUIRE(tree1.get_root() == tree2.get_root());
00075   }
00076 
00077   {
00078     INFO("Flushing doesn't affect root");
00079     const auto final_root = tree1.get_root();
00080     for (size_t i = 0; i < tree1.end_index(); ++i)
00081     {
00082       tree1.flush(i + 1);
00083       REQUIRE(tree1.get_root() == final_root);
00084     }
00085   }
00086 }
00087 
00088 TEST_CASE("Retrieving leaves")
00089 {
00090   constexpr size_t hash_count = 1'000;
00091 
00092   std::map<uint64_t, crypto::Sha256Hash> hashes;
00093   hashes[0] = crypto::Sha256Hash(); // Default index 0 always contains all-0s
00094 
00095   ccf::MerkleTreeHistory history;
00096 
00097   size_t index = 1;
00098   while (hashes.size() < hash_count)
00099   {
00100     auto h = rand_hash();
00101     hashes[index++] = h;
00102     history.append(h);
00103   }
00104 
00105   for (const auto& [i, hash] : hashes)
00106   {
00107     const auto h = history.get_leaf(i);
00108     REQUIRE(h == hash);
00109   }
00110 
00111   for (const auto& [i, hash] : hashes)
00112   {
00113     history.flush(i);
00114     const auto h = history.get_leaf(i);
00115     REQUIRE(h == hash);
00116   }
00117 }
00118 
00119 TEST_CASE("Deserialised")
00120 {
00121   constexpr size_t hash_count = 1'000;
00122   constexpr auto third = hash_count / 3;
00123   constexpr auto two_thirds = 2 * hash_count / 3;
00124   std::vector<std::pair<size_t, size_t>> flush_retract = {
00125     {0, hash_count},
00126     {third, two_thirds},
00127     {third + 1, two_thirds},
00128     {third, two_thirds + 1}};
00129   for (auto [flush_index, retract_index] : flush_retract)
00130   {
00131     ccf::MerkleTreeHistory original_tree;
00132     for (size_t i = 0; i < hash_count; ++i)
00133     {
00134       auto h = rand_hash();
00135       original_tree.append(h);
00136     }
00137     original_tree.flush(flush_index);
00138     original_tree.retract(retract_index);
00139 
00140     const auto serialised = original_tree.serialise();
00141 
00142     ccf::MerkleTreeHistory deser_tree(serialised);
00143 
00144     REQUIRE(deser_tree.begin_index() == original_tree.begin_index());
00145     REQUIRE(deser_tree.end_index() == original_tree.end_index());
00146     REQUIRE(deser_tree.get_root() == original_tree.get_root());
00147 
00148     for (size_t i = deser_tree.begin_index(); i <= deser_tree.end_index(); ++i)
00149     {
00150       REQUIRE(deser_tree.get_leaf(i) == original_tree.get_leaf(i));
00151     }
00152 
00153     auto h = rand_hash();
00154     auto h1 = h; // tree.append(h) modifies h so we take a copy
00155     original_tree.append(h);
00156     deser_tree.append(h1);
00157     REQUIRE(original_tree.get_root() == deser_tree.get_root());
00158   }
00159 }
00160 
00161 TEST_CASE("First root")
00162 {
00163   {
00164     INFO("Empty root");
00165     ccf::MerkleTreeHistory tree;
00166     const auto empty_root = tree.get_root();
00167     REQUIRE(empty_root == crypto::Sha256Hash());
00168     REQUIRE(tree.get_leaf(0) == empty_root);
00169   }
00170 
00171   {
00172     INFO("Single root");
00173     const auto h = rand_hash();
00174     ccf::MerkleTreeHistory tree(h);
00175     const auto single_root = tree.get_root();
00176     REQUIRE(single_root == h);
00177     REQUIRE(tree.get_leaf(0) == single_root);
00178   }
00179 }
00180 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/merkle_test.cpp...
Preprocessing /data/git/CCF/src/node/test/msgpack_serialization.cpp...
#include ../members.h: already included! skipping...
#include ../proposals.h: already included! skipping...
#include ../signatures.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 4310 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00008 
00009 
00010 template <typename T>
00011 T msgpack_roundtrip(const T& t)
00012 {
00013   // Serialize
00014   msgpack::sbuffer sb;
00015   msgpack::pack(sb, t);
00016 
00017   // Deserialize
00018   msgpack::object_handle obj;
00019   msgpack::unpack(obj, sb.data(), sb.size(), 0);
00020 
00021   return obj->as<T>();
00022 }
00023 
00024 TEST_CASE("nlohmann::json")
00025 {
00026   using namespace nlohmann;
00027 
00028   json j_null = nullptr;
00029   {
00030     const auto converted = msgpack_roundtrip(j_null);
00031     CHECK(j_null == converted);
00032   }
00033 
00034   json j_int = 42;
00035   {
00036     const auto converted = msgpack_roundtrip(j_int);
00037     CHECK(j_int == converted);
00038   }
00039 
00040   json j_float = 3.14f;
00041   {
00042     const auto converted = msgpack_roundtrip(j_float);
00043     CHECK(j_float == converted);
00044   }
00045 
00046   json j_string = "hello world";
00047   {
00048     const auto converted = msgpack_roundtrip(j_string);
00049     CHECK(j_string == converted);
00050   }
00051 
00052   json j_array = json::array();
00053   j_array.push_back(j_null);
00054   j_array.push_back(j_int);
00055   j_array.push_back(j_float);
00056   j_array.push_back(j_string);
00057   {
00058     const auto converted = msgpack_roundtrip(j_array);
00059     CHECK(j_array == converted);
00060   }
00061 
00062   json j_object = json::object();
00063   j_object["A"] = j_array;
00064   j_object["saluton mondo"] = j_string;
00065   {
00066     const auto converted = msgpack_roundtrip(j_object);
00067     CHECK(j_object == converted);
00068   }
00069 }
00070 
00071 TEST_CASE("Proposal")
00072 {
00073   using namespace ccf;
00074 
00075   {
00076     INFO("Empty proposal");
00077     Proposal proposal;
00078     const auto converted = msgpack_roundtrip(proposal);
00079     CHECK(proposal == converted);
00080   }
00081 
00082   {
00083     INFO("Initial proposal");
00084     Script s("return true");
00085     nlohmann::json p("hello world");
00086     MemberId m(0);
00087     Proposal proposal(s, p, m);
00088     const auto converted = msgpack_roundtrip(proposal);
00089     CHECK(proposal == converted);
00090   }
00091 
00092   {
00093     INFO("Voted proposal");
00094     Script s("return true");
00095     nlohmann::json p("hello world");
00096     MemberId m(0);
00097     Proposal proposal(s, p, m);
00098     proposal.votes[1] = Script("return true");
00099     proposal.votes[2] = Script("return false");
00100     proposal.votes[3] = Script("return RoN");
00101     proposal.votes[4] = Script("Robert'); DROP TABLE Students;--");
00102     const auto converted = msgpack_roundtrip(proposal);
00103     CHECK(proposal == converted);
00104   }
00105 }
00106 
00107 void fill_rand(std::vector<uint8_t>& v, size_t n)
00108 {
00109   v.resize(n);
00110   for (size_t i = 0; i < n; ++i)
00111   {
00112     v[i] = rand();
00113   }
00114 }
00115 
00116 TEST_CASE("NodeSignature")
00117 {
00118   using namespace ccf;
00119 
00120   {
00121     INFO("Empty signature");
00122     NodeSignature rs;
00123     const auto converted = msgpack_roundtrip(rs);
00124     CHECK(rs == converted);
00125   }
00126 
00127   {
00128     INFO("Byte signature");
00129     NodeSignature rs;
00130     rs.sig.push_back(42);
00131     const auto converted = msgpack_roundtrip(rs);
00132     CHECK(rs == converted);
00133   }
00134 
00135   {
00136     INFO("Large signature");
00137     NodeSignature rs;
00138     fill_rand(rs.sig, 256);
00139     const auto converted = msgpack_roundtrip(rs);
00140     CHECK(rs == converted);
00141   }
00142 }
00143 
00144 TEST_CASE("MemberAck")
00145 {
00146   using namespace ccf;
00147 
00148   {
00149     INFO("Empty ack");
00150     MemberAck ma;
00151     const auto converted = msgpack_roundtrip(ma);
00152     CHECK(ma.state_digest == converted.state_digest);
00153   }
00154 
00155   {
00156     INFO("Implausible ack");
00157     MemberAck ma;
00158     ma.state_digest = "string";
00159     const auto converted = msgpack_roundtrip(ma);
00160     CHECK(ma.state_digest == converted.state_digest);
00161   }
00162 
00163   {
00164     INFO("Plausible ack");
00165     MemberAck ma;
00166     std::vector<uint8_t> data;
00167     fill_rand(data, 1024);
00168     ma.state_digest = crypto::Sha256Hash(data).hex_str();
00169     const auto converted = msgpack_roundtrip(ma);
00170     CHECK(ma.state_digest == converted.state_digest);
00171   }
00172 }
00173 
00174 TEST_CASE("Signature")
00175 {
00176   using namespace ccf;
00177 
00178   {
00179     INFO("Empty sig");
00180     PrimarySignature sig;
00181     const auto converted = msgpack_roundtrip(sig);
00182     CHECK(sig == converted);
00183   }
00184 
00185   {
00186     INFO("Simple sig");
00187     PrimarySignature sig;
00188     sig.sig.push_back(0);
00189     sig.node = 0;
00190     sig.seqno = 1;
00191     sig.view = 2;
00192     sig.commit_seqno = 3;
00193     const auto converted = msgpack_roundtrip(sig);
00194     CHECK(sig == converted);
00195   }
00196 
00197   {
00198     INFO("Rand sig");
00199     PrimarySignature sig;
00200     fill_rand(sig.sig, 256);
00201     sig.node = rand();
00202     sig.seqno = rand();
00203     sig.view = rand();
00204     sig.commit_seqno = rand();
00205     const auto converted = msgpack_roundtrip(sig);
00206     CHECK(sig == converted);
00207   }
00208 }
00209 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/msgpack_serialization.cpp...
Preprocessing /data/git/CCF/src/node/test/progress_tracker.cpp...
#include node/progress_tracker.h: not found! skipping...
#include consensus/aft/impl/view_change_tracker.h: not found! skipping...
#include kv/store.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/request_tracker.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
#include trompeloeil/include/trompeloeil.hpp: not found! skipping...
Preprocessor output (size: 17900 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00012 
00013 
00014 
00015 
00016 class StoreMock : public ccf::ProgressTrackerStore
00017 {
00018 public:
00019   MAKE_MOCK1(write_backup_signatures, void(ccf::BackupSignatures&), override);
00020   MAKE_MOCK0(
00021     get_backup_signatures, std::optional<ccf::BackupSignatures>(), override);
00022   MAKE_MOCK0(
00023     get_new_view, std::optional<ccf::ViewChangeConfirmation>(), override);
00024   MAKE_MOCK1(write_nonces, void(aft::RevealedNonces&), override);
00025   MAKE_MOCK0(get_nonces, std::optional<aft::RevealedNonces>(), override);
00026   MAKE_MOCK4(
00027     verify_signature,
00028     bool(kv::NodeId, crypto::Sha256Hash&, uint32_t, uint8_t*),
00029     override);
00030   MAKE_MOCK3(
00031     sign_view_change_request,
00032     void(
00033       ccf::ViewChangeRequest& view_change,
00034       kv::Consensus::View view,
00035       kv::Consensus::SeqNo seqno),
00036     override);
00037   MAKE_MOCK4(
00038     verify_view_change_request,
00039     bool(
00040       ccf::ViewChangeRequest& view_change,
00041       kv::NodeId from,
00042       kv::Consensus::View view,
00043       kv::Consensus::SeqNo seqno),
00044     override);
00045   MAKE_MOCK2(
00046     verify_view_change_request_confirmation,
00047     bool(ccf::ViewChangeConfirmation& new_view, kv::NodeId from),
00048     override);
00049   MAKE_MOCK1(
00050     write_view_change_confirmation,
00051     kv::Consensus::SeqNo(ccf::ViewChangeConfirmation& new_view),
00052     override);
00053 };
00054 
00055 void ordered_execution(
00056   uint32_t my_node_id, std::unique_ptr<ccf::ProgressTracker>& pt)
00057 {
00058   kv::Consensus::View view = 0;
00059   kv::Consensus::SeqNo seqno = 42;
00060   uint32_t node_count = 4;
00061   uint32_t node_count_quorum =
00062     2; // Takes into account that counting starts at 0
00063   bool am_i_primary = (my_node_id == 0);
00064 
00065   crypto::Sha256Hash root;
00066   std::array<uint8_t, MBEDTLS_ECDSA_MAX_LEN> sig;
00067   ccf::Nonce nonce;
00068   auto h = pt->hash_data(nonce);
00069   ccf::Nonce hashed_nonce;
00070   std::copy(h.h.begin(), h.h.end(), hashed_nonce.h.begin());
00071   std::vector<uint8_t> primary_sig;
00072 
00073   INFO("Adding signatures");
00074   {
00075     auto result = pt->record_primary(
00076       {view, seqno}, 0, root, primary_sig, hashed_nonce, node_count);
00077     REQUIRE(result == kv::TxHistory::Result::OK);
00078     primary_sig = {1};
00079     result = pt->record_primary_signature({view, seqno}, primary_sig);
00080     REQUIRE(result == kv::TxHistory::Result::OK);
00081 
00082     for (uint32_t i = 1; i < node_count; ++i)
00083     {
00084       if (i == my_node_id)
00085       {
00086         auto h = pt->get_my_hashed_nonce({view, seqno});
00087         std::copy(h.h.begin(), h.h.end(), hashed_nonce.h.begin());
00088       }
00089       else
00090       {
00091         std::copy(h.h.begin(), h.h.end(), hashed_nonce.h.begin());
00092       }
00093 
00094       auto result = pt->add_signature(
00095         {view, seqno},
00096         i,
00097         MBEDTLS_ECDSA_MAX_LEN,
00098         sig,
00099         hashed_nonce,
00100         node_count,
00101         am_i_primary);
00102       REQUIRE(
00103         ((result == kv::TxHistory::Result::OK && i != node_count_quorum) ||
00104          (result == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK &&
00105           i == node_count_quorum)));
00106     }
00107   }
00108 
00109   INFO("Add signature acks");
00110   {
00111     for (uint32_t i = 0; i < node_count; ++i)
00112     {
00113       auto result = pt->add_signature_ack({view, seqno}, i, node_count);
00114       REQUIRE(
00115         ((result == kv::TxHistory::Result::OK && i != node_count_quorum) ||
00116          (result == kv::TxHistory::Result::SEND_REPLY_AND_NONCE &&
00117           i == node_count_quorum)));
00118     }
00119   }
00120 
00121   INFO("Add nonces here");
00122   {
00123     for (uint32_t i = 0; i < node_count; ++i)
00124     {
00125       if (my_node_id == i)
00126       {
00127         pt->add_nonce_reveal(
00128           {view, seqno},
00129           pt->get_my_nonce({view, seqno}),
00130           i,
00131           node_count,
00132           am_i_primary);
00133       }
00134       else
00135       {
00136         pt->add_nonce_reveal({view, seqno}, nonce, i, node_count, am_i_primary);
00137       }
00138 
00139       if (i < 2)
00140       {
00141         REQUIRE(pt->get_highest_committed_nonce() == 0);
00142       }
00143       else
00144       {
00145         REQUIRE(pt->get_highest_committed_nonce() == seqno);
00146       }
00147     }
00148   }
00149 }
00150 
00151 void ordered_execution_primary(
00152   uint32_t my_node_id,
00153   std::unique_ptr<ccf::ProgressTracker> pt,
00154   StoreMock& store_mock)
00155 {
00156   using trompeloeil::_;
00157 
00158   REQUIRE_CALL(store_mock, write_backup_signatures(_));
00159   REQUIRE_CALL(store_mock, write_nonces(_));
00160 
00161   ordered_execution(my_node_id, pt);
00162 }
00163 
00164 void run_ordered_execution(uint32_t my_node_id)
00165 {
00166   using trompeloeil::_;
00167 
00168   auto store = std::make_unique<StoreMock>();
00169   StoreMock& store_mock = *store.get();
00170   auto pt =
00171     std::make_unique<ccf::ProgressTracker>(std::move(store), my_node_id);
00172 
00173 
00174     .RETURN(true)
00175     .TIMES(AT_LEAST(2));
00176 
00177   if (my_node_id == 0)
00178   {
00179     ordered_execution_primary(my_node_id, std::move(pt), store_mock);
00180   }
00181   else
00182   {
00183     ordered_execution(my_node_id, pt);
00184   }
00185 }
00186 
00187 TEST_CASE("Ordered Execution")
00188 {
00189   for (uint32_t i = 0; i < 4; ++i)
00190   {
00191     run_ordered_execution(i);
00192   }
00193 }
00194 
00195 TEST_CASE("Request tracker")
00196 {
00197   INFO("Can add and remove from progress tracker");
00198   {
00199     aft::RequestTracker t;
00200     crypto::Sha256Hash h;
00201     h.h.fill(0);
00202     for (uint32_t i = 0; i < 10; ++i)
00203     {
00204       h.h[0] = i;
00205       t.insert(h, std::chrono::milliseconds(i));
00206       REQUIRE(t.oldest_entry() == std::chrono::milliseconds(0));
00207     }
00208 
00209     h.h[0] = 2;
00210     REQUIRE(t.remove(h));
00211     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(0));
00212 
00213     h.h[0] = 0;
00214     REQUIRE(t.remove(h));
00215     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(1));
00216 
00217     h.h[0] = 99;
00218     REQUIRE(t.remove(h) == false);
00219     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(1));
00220   }
00221 
00222   INFO("Entry that was deleted is not tracked after it is added");
00223   {
00224     aft::RequestTracker t;
00225     crypto::Sha256Hash h;
00226     h.h.fill(0);
00227     REQUIRE(t.oldest_entry().has_value() == false);
00228 
00229     h.h[0] = 0;
00230     REQUIRE(t.remove(h) == false);
00231     t.insert_deleted(h, std::chrono::milliseconds(100));
00232     t.insert(h, std::chrono::milliseconds(0));
00233     REQUIRE(t.oldest_entry().has_value() == false);
00234 
00235     h.h[1] = 1;
00236     REQUIRE(t.remove(h) == false);
00237     t.insert_deleted(h, std::chrono::milliseconds(100));
00238     t.tick(std::chrono::milliseconds(120));
00239     t.insert(h, std::chrono::milliseconds(0));
00240     REQUIRE(t.oldest_entry().has_value() == false);
00241 
00242     h.h[2] = 2;
00243     REQUIRE(t.remove(h) == false);
00244     t.insert_deleted(h, std::chrono::milliseconds(100));
00245     t.tick(std::chrono::minutes(3));
00246     REQUIRE(t.is_empty());
00247     t.insert(h, std::chrono::milliseconds(0));
00248     REQUIRE(t.oldest_entry().has_value());
00249   }
00250 
00251   INFO("Can enter multiple items");
00252   {
00253     aft::RequestTracker t;
00254     crypto::Sha256Hash h;
00255     h.h.fill(0);
00256 
00257     t.insert(h, std::chrono::milliseconds(0));
00258 
00259     for (uint32_t i = 1; i < 4; ++i)
00260     {
00261       h.h[0] = 1;
00262       t.insert(h, std::chrono::milliseconds(i));
00263     }
00264 
00265     h.h[0] = 2;
00266     t.insert(h, std::chrono::milliseconds(4));
00267     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(0));
00268 
00269     h.h[0] = 1;
00270     REQUIRE(t.remove(h));
00271     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(0));
00272 
00273     h.h[0] = 0;
00274     t.remove(h);
00275     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(2));
00276 
00277     h.h[0] = 1;
00278     t.remove(h);
00279     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(3));
00280     t.remove(h);
00281     REQUIRE(t.oldest_entry() == std::chrono::milliseconds(4));
00282     t.remove(h);
00283     REQUIRE(!t.is_empty());
00284 
00285     h.h[0] = 2;
00286     t.remove(h);
00287     REQUIRE(t.is_empty());
00288   }
00289 
00290   INFO("Verify seqno and time of last sig stored correctly");
00291   {
00292     aft::RequestTracker t;
00293 
00294     auto r = t.get_seqno_time_last_request();
00295     REQUIRE(std::get<0>(r) == -1);
00296     REQUIRE(std::get<1>(r) == std::chrono::milliseconds(0));
00297 
00298     t.insert_signed_request(2, std::chrono::milliseconds(2));
00299     r = t.get_seqno_time_last_request();
00300     REQUIRE(std::get<0>(r) == 2);
00301     REQUIRE(std::get<1>(r) == std::chrono::milliseconds(2));
00302 
00303     t.insert_signed_request(1, std::chrono::milliseconds(1));
00304     r = t.get_seqno_time_last_request();
00305     REQUIRE(std::get<0>(r) == 2);
00306     REQUIRE(std::get<1>(r) == std::chrono::milliseconds(2));
00307   }
00308 }
00309 
00310 TEST_CASE("Record primary signature")
00311 {
00312   uint32_t my_node_id = 0;
00313   kv::Consensus::View view = 0;
00314   kv::Consensus::SeqNo seqno = 42;
00315   crypto::Sha256Hash root;
00316   ccf::Nonce nonce;
00317   std::vector<uint8_t> primary_sig;
00318 
00319   ccf::ProgressTracker pt(nullptr, my_node_id);
00320 
00321   auto result = pt.record_primary({view, seqno}, 0, root, primary_sig, nonce);
00322   REQUIRE(result == kv::TxHistory::Result::OK);
00323 
00324   primary_sig = {1};
00325   result = pt.record_primary_signature({view, seqno}, primary_sig);
00326   REQUIRE(result == kv::TxHistory::Result::OK);
00327   result = pt.record_primary_signature({view, seqno + 1}, primary_sig);
00328   REQUIRE(result != kv::TxHistory::Result::OK);
00329 }
00330 
00331 TEST_CASE("View Changes")
00332 {
00333   using trompeloeil::_;
00334 
00335   uint32_t my_node_id = 0;
00336   auto store = std::make_unique<StoreMock>();
00337   StoreMock& store_mock = *store.get();
00338   ccf::ProgressTracker pt(std::move(store), my_node_id);
00339 
00340   kv::Consensus::View view = 0;
00341   kv::Consensus::SeqNo seqno = 42;
00342   uint32_t node_count = 4;
00343   uint32_t node_count_quorum =
00344     2; // Takes into account that counting starts at 0
00345   crypto::Sha256Hash root;
00346   root.h.fill(1);
00347   ccf::Nonce nonce;
00348   auto h = pt.hash_data(nonce);
00349   ccf::Nonce hashed_nonce;
00350   std::copy(h.h.begin(), h.h.end(), hashed_nonce.h.begin());
00351   std::array<uint8_t, MBEDTLS_ECDSA_MAX_LEN> sig;
00352   std::vector<uint8_t> primary_sig;
00353 
00354   INFO("find first view-change message");
00355   {
00356 
00357       .RETURN(true)
00358       .TIMES(AT_LEAST(2));
00359 
00360       .TIMES(AT_LEAST(2));
00361     auto result = pt.record_primary(
00362       {view, seqno}, 0, root, primary_sig, hashed_nonce, node_count);
00363     REQUIRE(result == kv::TxHistory::Result::OK);
00364 
00365     for (uint32_t i = 1; i < node_count; ++i)
00366     {
00367       auto result = pt.add_signature(
00368         {view, seqno},
00369         i,
00370         MBEDTLS_ECDSA_MAX_LEN,
00371         sig,
00372         hashed_nonce,
00373         node_count,
00374         false);
00375       REQUIRE(
00376         ((result == kv::TxHistory::Result::OK && i != node_count_quorum) ||
00377          (result == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK &&
00378           i == node_count_quorum)));
00379 
00380       if (i < 2)
00381       {
00382         CHECK_THROWS(pt.get_view_change_message(view));
00383       }
00384       else
00385       {
00386         auto vc = pt.get_view_change_message(view);
00387         REQUIRE(std::get<0>(vc) != nullptr);
00388       }
00389     }
00390   }
00391 
00392   INFO("Update latest prepared");
00393   {
00394     kv::Consensus::SeqNo new_seqno = 84;
00395 
00396 
00397       .RETURN(true)
00398       .TIMES(AT_LEAST(2));
00399 
00400       .TIMES(AT_LEAST(2));
00401     auto result = pt.record_primary(
00402       {view, new_seqno}, 0, root, primary_sig, hashed_nonce, node_count);
00403     REQUIRE(result == kv::TxHistory::Result::OK);
00404 
00405     for (uint32_t i = 1; i < node_count; ++i)
00406     {
00407       auto result = pt.add_signature(
00408         {view, new_seqno},
00409         i,
00410         MBEDTLS_ECDSA_MAX_LEN,
00411         sig,
00412         hashed_nonce,
00413         node_count,
00414         false);
00415       REQUIRE(
00416         ((result == kv::TxHistory::Result::OK && i != node_count_quorum) ||
00417          (result == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK &&
00418           i == node_count_quorum)));
00419 
00420       if (i < 2)
00421       {
00422         auto vc = pt.get_view_change_message(view);
00423         REQUIRE(std::get<0>(vc) != nullptr);
00424       }
00425       else
00426       {
00427         auto vc = pt.get_view_change_message(view);
00428         REQUIRE(std::get<0>(vc) != nullptr);
00429       }
00430     }
00431     seqno = new_seqno;
00432   }
00433 
00434   INFO("Update older prepared");
00435   {
00436     kv::Consensus::SeqNo new_seqno = 21;
00437 
00438 
00439       .RETURN(true)
00440       .TIMES(AT_LEAST(2));
00441 
00442       .TIMES(AT_LEAST(2));
00443     auto result = pt.record_primary(
00444       {view, new_seqno}, 0, root, primary_sig, hashed_nonce, node_count);
00445     REQUIRE(result == kv::TxHistory::Result::OK);
00446 
00447     for (uint32_t i = 1; i < node_count; ++i)
00448     {
00449       auto result = pt.add_signature(
00450         {view, new_seqno},
00451         i,
00452         MBEDTLS_ECDSA_MAX_LEN,
00453         sig,
00454         hashed_nonce,
00455         node_count,
00456         false);
00457       REQUIRE(
00458         ((result == kv::TxHistory::Result::OK && i != node_count_quorum) ||
00459          (result == kv::TxHistory::Result::SEND_SIG_RECEIPT_ACK &&
00460           i == node_count_quorum)));
00461 
00462       auto vc = pt.get_view_change_message(view);
00463       REQUIRE(std::get<0>(vc) != nullptr);
00464     }
00465   }
00466 }
00467 
00468 TEST_CASE("Serialization")
00469 {
00470   std::vector<uint8_t> serialized;
00471   INFO("view-change serialization");
00472   {
00473     ccf::ViewChangeRequest v;
00474 
00475     for (uint32_t i = 10; i < 110; i += 10)
00476     {
00477       ccf::Nonce n;
00478       n.h.fill(i + 2);
00479       v.signatures.push_back({{static_cast<uint8_t>(i)}, i + 1, n});
00480     }
00481 
00482     v.signature = {5};
00483     serialized.resize(v.get_serialized_size());
00484 
00485     uint8_t* data = serialized.data();
00486     size_t size = serialized.size();
00487 
00488     v.serialize(data, size);
00489     REQUIRE(size == 0);
00490   }
00491 
00492   INFO("view-change deserialization");
00493   {
00494     const uint8_t* data = serialized.data();
00495     size_t size = serialized.size();
00496     ccf::ViewChangeRequest v = ccf::ViewChangeRequest::deserialize(data, size);
00497 
00498     REQUIRE(v.signatures.size() == 10);
00499     for (uint32_t i = 1; i < 11; ++i)
00500     {
00501       ccf::Nonce n;
00502       n.h.fill(i * 10 + 2);
00503       ccf::NodeSignature& ns = v.signatures[i - 1];
00504       REQUIRE(ns.sig.size() == 1);
00505       REQUIRE(ns.sig[0] == i * 10);
00506       REQUIRE(ns.node == i * 10 + 1);
00507       REQUIRE(ns.hashed_nonce.h == n.h);
00508     }
00509 
00510     REQUIRE(v.signature.size() == 1);
00511     REQUIRE(v.signature[0] == 5);
00512   }
00513 }
00514 
00515 TEST_CASE("view-change-tracker timeout tests")
00516 {
00517   INFO("Check timeout works correctly");
00518   {
00519     aft::ViewChangeTracker vct(nullptr, std::chrono::seconds(10));
00520     REQUIRE(vct.should_send_view_change(std::chrono::seconds(1)) == false);
00521     REQUIRE(vct.get_target_view() == 0);
00522     REQUIRE(vct.should_send_view_change(std::chrono::seconds(11)));
00523     REQUIRE(vct.get_target_view() == 1);
00524     REQUIRE(vct.should_send_view_change(std::chrono::seconds(12)) == false);
00525     REQUIRE(vct.get_target_view() == 1);
00526     REQUIRE(vct.should_send_view_change(std::chrono::seconds(100)));
00527     REQUIRE(vct.get_target_view() == 2);
00528   }
00529 }
00530 
00531 TEST_CASE("view-change-tracker statemachine tests")
00532 {
00533   ccf::ViewChangeRequest v;
00534   kv::Consensus::View view = 3;
00535   kv::Consensus::SeqNo seqno = 1;
00536   uint32_t node_count = 4;
00537 
00538   INFO("Can trigger view change");
00539   {
00540     aft::ViewChangeTracker vct(nullptr, std::chrono::seconds(10));
00541     for (uint32_t i = 0; i < node_count; ++i)
00542     {
00543       auto r = vct.add_request_view_change(v, i, view, seqno, node_count);
00544       if (i == 2)
00545       {
00546         REQUIRE(
00547           r == aft::ViewChangeTracker::ResultAddView::APPEND_NEW_VIEW_MESSAGE);
00548       }
00549       else
00550       {
00551         REQUIRE(r == aft::ViewChangeTracker::ResultAddView::OK);
00552       }
00553       REQUIRE((vct.check_evidence(view) == i >= 2));
00554       REQUIRE(!vct.check_evidence(view + 1));
00555     }
00556     vct.clear(true, view);
00557     REQUIRE(vct.check_evidence(view));
00558     REQUIRE(!vct.check_evidence(view + 1));
00559   }
00560 
00561   INFO("Can differentiate view change for different view");
00562   {
00563     aft::ViewChangeTracker vct(nullptr, std::chrono::seconds(10));
00564     for (uint32_t i = 0; i < node_count; ++i)
00565     {
00566       auto r = vct.add_request_view_change(v, i, i, seqno, node_count);
00567       REQUIRE(r == aft::ViewChangeTracker::ResultAddView::OK);
00568     }
00569   }
00570 }
00571 
00572 TEST_CASE("test progress_tracker apply_view_change")
00573 {
00574   using trompeloeil::_;
00575 
00576   uint32_t node_id = 1;
00577   auto store = std::make_unique<StoreMock>();
00578   StoreMock& store_mock = *store.get();
00579   auto pt = std::make_unique<ccf::ProgressTracker>(std::move(store), node_id);
00580 
00581   {
00582 
00583       .RETURN(true)
00584       .TIMES(AT_LEAST(2));
00585 
00586     ordered_execution(node_id, pt);
00587   }
00588 
00589   INFO("View-change signature does not verify");
00590   {
00591 
00592       .RETURN(false);
00593     ccf::ViewChangeRequest v;
00594     bool result = pt->apply_view_change_message(v, 1, 1, 1);
00595     REQUIRE(result == false);
00596   }
00597 
00598   INFO("Unknown seqno");
00599   {
00600 
00601       .RETURN(true);
00602     ccf::ViewChangeRequest v;
00603     bool result = pt->apply_view_change_message(v, 1, 1, 999);
00604     REQUIRE(result == false);
00605   }
00606 
00607   INFO("View-change matches - known node");
00608   {
00609 
00610       .RETURN(true);
00611     REQUIRE_CALL(store_mock, verify_signature(_, _, _, _)).RETURN(true);
00612     ccf::ViewChangeRequest v;
00613     v.signatures.push_back(ccf::NodeSignature(0));
00614 
00615     bool result = pt->apply_view_change_message(v, 1, 1, 42);
00616     REQUIRE(result);
00617   }
00618 
00619   INFO("View-change matches - unknown node");
00620   {
00621 
00622       .RETURN(true);
00623     REQUIRE_CALL(store_mock, verify_signature(_, _, _, _)).RETURN(false);
00624 
00625     ccf::ViewChangeRequest v;
00626     v.signatures.push_back(ccf::NodeSignature(5));
00627 
00628     bool result = pt->apply_view_change_message(v, 1, 1, 42);
00629     REQUIRE(result == false);
00630   }
00631 }
00632 
00633 TEST_CASE("Sending evidence out of band")
00634 {
00635   using trompeloeil::_;
00636 
00637   ccf::ViewChangeRequest v;
00638   kv::Consensus::View view = 3;
00639   kv::Consensus::SeqNo seqno = 1;
00640   constexpr uint32_t node_count = 4;
00641 
00642   INFO("Can trigger view change");
00643   {
00644     aft::ViewChangeTracker vct(nullptr, std::chrono::seconds(10));
00645     for (uint32_t i = 0; i < node_count; ++i)
00646     {
00647       auto r = vct.add_request_view_change(v, i, view, seqno, node_count);
00648       if (i == 2)
00649       {
00650         REQUIRE(
00651           r == aft::ViewChangeTracker::ResultAddView::APPEND_NEW_VIEW_MESSAGE);
00652       }
00653       else
00654       {
00655         REQUIRE(r == aft::ViewChangeTracker::ResultAddView::OK);
00656       }
00657 
00658       auto data = vct.get_serialized_view_change_confirmation(view);
00659       std::shared_ptr<ccf::ProgressTrackerStore> store =
00660         std::make_unique<StoreMock>();
00661 
00662       aft::ViewChangeTracker vct_2(store, std::chrono::seconds(10));
00663       if (i >= 2)
00664       {
00665         REQUIRE_CALL(
00666           *reinterpret_cast<StoreMock*>(store.get()),
00667           verify_view_change_request(_, _, _, _))
00668           .RETURN(true)
00669           .TIMES(AT_LEAST(1));
00670 
00671         REQUIRE(vct_2.add_unknown_primary_evidence(
00672           {data.data(), data.size()}, view, node_count));
00673         REQUIRE(vct_2.check_evidence(view));
00674       }
00675       else
00676       {
00677         REQUIRE(!vct_2.add_unknown_primary_evidence(
00678           {data.data(), data.size()}, view, node_count));
00679         REQUIRE(!vct_2.check_evidence(view));
00680       }
00681       REQUIRE(!vct_2.check_evidence(view + 1));
00682     }
00683   }
00684 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/progress_tracker.cpp...
Preprocessing /data/git/CCF/src/node/test/secret_share.cpp...
#include ../secret_share.h: already included! skipping...
#include doctest/doctest.h: not found! skipping...
#include iomanip: not found! skipping...
Preprocessor output (size: 1420 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 TEST_CASE("Simple test")
00011 {
00012   size_t n = 5;
00013   size_t k = 3;
00014   ccf::SecretSharing::SplitSecret data_to_split;
00015 
00016   INFO("Data to split must be have fixed length");
00017   {
00018     auto random =
00019       tls::create_entropy()->random(ccf::SecretSharing::SECRET_TO_SPLIT_LENGTH);
00020     std::copy_n(
00021       random.begin(),
00022       ccf::SecretSharing::SECRET_TO_SPLIT_LENGTH,
00023       data_to_split.begin());
00024   }
00025 
00026   INFO("Split and combine shares");
00027   {
00028     auto shares = ccf::SecretSharing::split(data_to_split, n, k);
00029     REQUIRE(shares.size() == n);
00030     auto restored = ccf::SecretSharing::combine(shares, k);
00031     REQUIRE(data_to_split == restored);
00032   }
00033 }
00034 
00035 TEST_CASE("Edge cases")
00036 {
00037   size_t n = 3;
00038   size_t k = 2;
00039   ccf::SecretSharing::SplitSecret data_to_split;
00040 
00041   INFO("n = 0 and n too large");
00042   {
00043     REQUIRE_THROWS_AS(
00044       ccf::SecretSharing::split(data_to_split, 0, 2), std::logic_error);
00045     REQUIRE_THROWS_AS(
00046       ccf::SecretSharing::split(
00047         data_to_split, ccf::SecretSharing::MAX_NUMBER_SHARES + 1, k),
00048       std::logic_error);
00049   }
00050 
00051   INFO("k = 0 and k too large");
00052   {
00053     REQUIRE_THROWS_AS(
00054       ccf::SecretSharing::split(data_to_split, n, 0), std::logic_error);
00055     REQUIRE_THROWS_AS(
00056       ccf::SecretSharing::split(data_to_split, n, n + 1), std::logic_error);
00057   }
00058 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/node/test/secret_share.cpp...
Preprocessing /data/git/CCF/src/node/test/snapshot.cpp...
#include kv/test/stub_consensus.h: not found! skipping...
#include node/history.h: not found! skipping...
#include node/nodes.h: not found! skipping...
#include node/signatures.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 4263 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00011 
00012 
00013 
00014 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00015 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 0;
00016 
00017 
00018 {
00019   auto source_consensus = std::make_shared<kv::StubConsensus>();
00020   kv::Store source_store(source_consensus);
00021 
00022   ccf::NodeId source_node_id = 0;
00023   auto source_node_kp = tls::make_key_pair();
00024 
00025   auto source_history =
00026     std::make_shared<ccf::MerkleTxHistory>(source_store, 0, *source_node_kp);
00027 
00028   source_store.set_history(source_history);
00029 
00030   kv::Map<std::string, std::string> string_map("public:string_map");
00031 
00032   size_t transactions_count = 3;
00033   kv::Version snapshot_version = kv::NoVersion;
00034 
00035   INFO("Apply transactions to original store");
00036   {
00037     for (size_t i = 0; i < transactions_count; i++)
00038     {
00039       auto tx = source_store.create_tx();
00040       auto view = tx.get_view(string_map);
00041       view->put(fmt::format("key#{}", i), "value");
00042       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00043     }
00044   }
00045 
00046   auto source_root_before_signature =
00047     source_history->get_replicated_state_root();
00048 
00049   INFO("Emit signature");
00050   {
00051     source_history->emit_signature();
00052     // Snapshot version is the version of the signature
00053     snapshot_version = transactions_count + 1;
00054   }
00055 
00056   INFO("Check tree start from mini-tree and sig hash");
00057   {
00058     // No snapshot here, only verify that a fresh tree can be started from the
00059     // mini-tree in a signature and the hash of the signature
00060     auto tx = source_store.create_read_only_tx();
00061     auto view = tx.get_read_only_view<ccf::Signatures>(ccf::Tables::SIGNATURES);
00062     REQUIRE(view->has(0));
00063     auto sig = view->get(0).value();
00064 
00065     auto serialised_signature = source_consensus->get_latest_data().value();
00066     auto serialised_signature_hash = crypto::Sha256Hash(serialised_signature);
00067 
00068     ccf::MerkleTreeHistory target_tree(sig.tree);
00069 
00070     REQUIRE(source_root_before_signature == target_tree.get_root());
00071 
00072     target_tree.append(serialised_signature_hash);
00073     REQUIRE(
00074       target_tree.get_root() == source_history->get_replicated_state_root());
00075   }
00076 
00077   INFO("Snapshot at signature");
00078   {
00079     kv::Store target_store;
00080     INFO("Setup target store");
00081     {
00082       auto target_node_kp = tls::make_key_pair();
00083 
00084       auto target_history = std::make_shared<ccf::MerkleTxHistory>(
00085         target_store, 0, *target_node_kp);
00086       target_store.set_history(target_history);
00087     }
00088 
00089     auto target_history = target_store.get_history();
00090 
00091     INFO("Apply snapshot taken before any signature was emitted");
00092     {
00093       auto snapshot = source_store.snapshot(snapshot_version - 1);
00094       auto serialised_snapshot =
00095         source_store.serialise_snapshot(std::move(snapshot));
00096 
00097       // There is no signature to read to seed the target history
00098       std::vector<kv::Version> view_history;
00099       REQUIRE(
00100         target_store.deserialise_snapshot(serialised_snapshot, &view_history) ==
00101         kv::DeserialiseSuccess::FAILED);
00102     }
00103 
00104     INFO("Apply snapshot taken at signature");
00105     {
00106       auto snapshot = source_store.snapshot(snapshot_version);
00107       auto serialised_snapshot =
00108         source_store.serialise_snapshot(std::move(snapshot));
00109 
00110       std::vector<kv::Version> view_history;
00111       REQUIRE(
00112         target_store.deserialise_snapshot(serialised_snapshot, &view_history) ==
00113         kv::DeserialiseSuccess::PASS);
00114 
00115       // Merkle history and view history thus far are restored when applying
00116       // snapshot
00117       REQUIRE(
00118         source_history->get_replicated_state_root() ==
00119         target_history->get_replicated_state_root());
00120       REQUIRE(
00121         source_consensus->view_history.get_history_until() == view_history);
00122     }
00123 
00124     INFO("Deserialise additional transaction after restart");
00125     {
00126       auto tx = source_store.create_tx();
00127       auto view = tx.get_view(string_map);
00128       view->put("key", "value");
00129       REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00130 
00131       auto serialised_tx = source_consensus->get_latest_data().value();
00132 
00133       target_store.deserialise(serialised_tx);
00134 
00135       REQUIRE(
00136         target_history->get_replicated_state_root() ==
00137         source_history->get_replicated_state_root());
00138     }
00139   }
00140 }
00141 
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/snapshot.cpp...
Preprocessing /data/git/CCF/src/node/test/snapshotter.cpp...
#include node/snapshotter.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include kv/test/null_encryptor.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 6486 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00010 
00011 
00012 
00013 // Because snapshot serialisation is costly, the snapshotter serialises
00014 // snapshots asynchronously.
00015 std::atomic<uint16_t> threading::ThreadMessaging::thread_count = 1;
00016 threading::ThreadMessaging threading::ThreadMessaging::thread_messaging;
00017 constexpr auto buffer_size = 1024 * 16;
00018 
00019 using StringString = kv::Map<std::string, std::string>;
00020 using rb_msg = std::pair<ringbuffer::Message, size_t>;
00021 
00022 auto read_ringbuffer_out(ringbuffer::Circuit& circuit)
00023 {
00024   std::optional<rb_msg> idx = std::nullopt;
00025   circuit.read_from_inside().read(
00026     -1, [&idx](ringbuffer::Message m, const uint8_t* data, size_t size) {
00027       switch (m)
00028       {
00029         case consensus::snapshot:
00030         case consensus::snapshot_commit:
00031         {
00032           auto idx_ = serialized::read<consensus::Index>(data, size);
00033           idx = {m, idx_};
00034           break;
00035         }
00036         default:
00037         {
00038           REQUIRE(false);
00039         }
00040       }
00041     });
00042 
00043   return idx;
00044 }
00045 
00046 void issue_transactions(ccf::NetworkState& network, size_t tx_count)
00047 {
00048   for (size_t i = 0; i < tx_count; i++)
00049   {
00050     auto tx = network.tables->create_tx();
00051     auto view = tx.get_view<StringString>("public:map");
00052     view->put("foo", "bar");
00053     REQUIRE(tx.commit() == kv::CommitSuccess::OK);
00054   }
00055 }
00056 
00057 TEST_CASE("Regular snapshotting")
00058 {
00059   ccf::NetworkState network;
00060 
00061   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00062   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00063   ringbuffer::Circuit eio(in_buffer->bd, out_buffer->bd);
00064 
00065   std::unique_ptr<ringbuffer::WriterFactory> writer_factory =
00066     std::make_unique<ringbuffer::WriterFactory>(eio);
00067 
00068   size_t snapshot_tx_interval = 10;
00069   size_t interval_count = 3;
00070 
00071   issue_transactions(network, snapshot_tx_interval * interval_count);
00072 
00073   auto snapshotter =
00074     std::make_shared<ccf::Snapshotter>(*writer_factory, network);
00075   snapshotter->set_tx_interval(snapshot_tx_interval);
00076 
00077   REQUIRE_FALSE(snapshotter->requires_snapshot(snapshot_tx_interval - 1));
00078   REQUIRE(snapshotter->requires_snapshot(snapshot_tx_interval));
00079 
00080   INFO("Generate snapshots at regular intervals");
00081   {
00082     for (size_t i = 1; i <= interval_count; i++)
00083     {
00084       // No snapshot generated if < interval
00085       snapshotter->snapshot(i * (snapshot_tx_interval - 1));
00086       threading::ThreadMessaging::thread_messaging.run_one();
00087       REQUIRE(read_ringbuffer_out(eio) == std::nullopt);
00088 
00089       snapshotter->snapshot(i * snapshot_tx_interval);
00090       threading::ThreadMessaging::thread_messaging.run_one();
00091       REQUIRE(
00092         read_ringbuffer_out(eio) ==
00093         rb_msg({consensus::snapshot, (i * snapshot_tx_interval)}));
00094     }
00095   }
00096 
00097   INFO("Cannot snapshot before latest snapshot");
00098   {
00099     REQUIRE_THROWS_AS(
00100       snapshotter->snapshot(snapshot_tx_interval - 1), std::logic_error);
00101   }
00102 }
00103 
00104 TEST_CASE("Commit snapshot evidence")
00105 {
00106   ccf::NetworkState network;
00107 
00108   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00109   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00110   ringbuffer::Circuit eio(in_buffer->bd, out_buffer->bd);
00111 
00112   std::unique_ptr<ringbuffer::WriterFactory> writer_factory =
00113     std::make_unique<ringbuffer::WriterFactory>(eio);
00114 
00115   size_t snapshot_tx_interval = 10;
00116   issue_transactions(network, snapshot_tx_interval);
00117 
00118   auto snapshotter =
00119     std::make_shared<ccf::Snapshotter>(*writer_factory, network);
00120   snapshotter->set_tx_interval(snapshot_tx_interval);
00121 
00122   INFO("Generate snapshot");
00123   {
00124     snapshotter->snapshot(snapshot_tx_interval);
00125     threading::ThreadMessaging::thread_messaging.run_one();
00126     REQUIRE(
00127       read_ringbuffer_out(eio) ==
00128       rb_msg({consensus::snapshot, snapshot_tx_interval}));
00129   }
00130 
00131   INFO("Commit evidence");
00132   {
00133     // This assumes that the evidence was committed just after the snasphot, at
00134     // idx = (snapshot_tx_interval + 1)
00135 
00136     // First commit marks evidence as committed but no commit message is emitted
00137     // yet
00138     snapshotter->commit(snapshot_tx_interval + 1);
00139     threading::ThreadMessaging::thread_messaging.run_one();
00140     REQUIRE(read_ringbuffer_out(eio) == std::nullopt);
00141 
00142     // Second commit passed evidence commit, snapshot is committed
00143     snapshotter->commit(snapshot_tx_interval + 2);
00144     threading::ThreadMessaging::thread_messaging.run_one();
00145     REQUIRE(
00146       read_ringbuffer_out(eio) ==
00147       rb_msg({consensus::snapshot_commit, snapshot_tx_interval}));
00148   }
00149 }
00150 
00151 TEST_CASE("Rollback before evidence is committed")
00152 {
00153   ccf::NetworkState network;
00154 
00155   auto in_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00156   auto out_buffer = std::make_unique<ringbuffer::TestBuffer>(buffer_size);
00157   ringbuffer::Circuit eio(in_buffer->bd, out_buffer->bd);
00158 
00159   std::unique_ptr<ringbuffer::WriterFactory> writer_factory =
00160     std::make_unique<ringbuffer::WriterFactory>(eio);
00161 
00162   size_t snapshot_tx_interval = 10;
00163   issue_transactions(network, snapshot_tx_interval);
00164 
00165   auto snapshotter =
00166     std::make_shared<ccf::Snapshotter>(*writer_factory, network);
00167   snapshotter->set_tx_interval(snapshot_tx_interval);
00168 
00169   INFO("Generate snapshot");
00170   {
00171     snapshotter->snapshot(snapshot_tx_interval);
00172     threading::ThreadMessaging::thread_messaging.run_one();
00173     REQUIRE(
00174       read_ringbuffer_out(eio) ==
00175       rb_msg({consensus::snapshot, snapshot_tx_interval}));
00176   }
00177 
00178   INFO("Rollback evidence and commit past it");
00179   {
00180     snapshotter->rollback(snapshot_tx_interval);
00181 
00182     // ... More transactions are committed, passing the idx at which the
00183     // evidence was originally committed
00184 
00185     snapshotter->commit(snapshot_tx_interval + 1);
00186 
00187     // Snapshot previously generated is not committed
00188     REQUIRE(read_ringbuffer_out(eio) == std::nullopt);
00189   }
00190 
00191   INFO("Snapshot again and commit evidence");
00192   {
00193     issue_transactions(network, snapshot_tx_interval);
00194 
00195     size_t snapshot_idx = network.tables->current_version();
00196     snapshotter->snapshot(snapshot_idx);
00197     threading::ThreadMessaging::thread_messaging.run_one();
00198     REQUIRE(
00199       read_ringbuffer_out(eio) == rb_msg({consensus::snapshot, snapshot_idx}));
00200 
00201     // Commit evidence
00202     snapshotter->commit(snapshot_idx + 1);
00203     REQUIRE(read_ringbuffer_out(eio) == std::nullopt);
00204 
00205     // Evidence proof is committed
00206     snapshotter->commit(snapshot_idx + 2);
00207     REQUIRE(
00208       read_ringbuffer_out(eio) ==
00209       rb_msg({consensus::snapshot_commit, snapshot_idx}));
00210   }
00211 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/node/test/snapshotter.cpp...
Preprocessing /data/git/CCF/src/node/users.h...
#include kv/map.h: not found! skipping...
#include tls/pem.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
Preprocessor output (size: 448 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   struct UserInfo
00013   {
00014     tls::Pem cert;
00015     nlohmann::json user_data = nullptr;
00016 
00017     MSGPACK_DEFINE(cert, user_data);
00018   };
00019   DECLARE_JSON_TYPE_WITH_OPTIONAL_FIELDS(UserInfo);
00020   DECLARE_JSON_REQUIRED_FIELDS(UserInfo, cert);
00021   DECLARE_JSON_OPTIONAL_FIELDS(UserInfo, user_data);
00022 
00023   using Users = kv::Map<UserId, UserInfo>;
00024 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/users.h...
Preprocessing /data/git/CCF/src/node/values.h...
#include kv/map.h: not found! skipping...
#include exception: not found! skipping...
Preprocessor output (size: 936 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 namespace ccf
00010 {
00011   using ValueId = uint8_t;
00012   using Value = uint64_t;
00013   using Values = kv::Map<ValueId, Value>;
00014 
00015   enum ValueIds : ValueId
00016   {
00017     NEXT_MEMBER_ID = 0,
00018     NEXT_USER_ID = 1,
00019     NEXT_NODE_ID = 2,
00020     NEXT_PROPOSAL_ID = 3,
00021     NEXT_CODE_ID = 4,
00022     // not to be used
00023     END_ID
00024   };
00025 
00026   /* returns the given value and increments it in the table.
00027   This is for example useful for getting a new member ID.
00028   */
00029   inline auto get_next_id(Values::TxView* view, ValueId id)
00030   {
00031     auto search = view->get(id);
00032     if (!search.has_value())
00033       throw std::logic_error("Failed to get next ID.");
00034 
00035     auto& v = search.value();
00036     auto nextId = v + 1;
00037 
00038     // overflow? (unlikely, but not impossible.)
00039     if (nextId < v)
00040       throw std::overflow_error("Overflow in ID");
00041 
00042     view->put(id, nextId);
00043     return v;
00044   }
00045 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/values.h...
Preprocessing /data/git/CCF/src/node/view_change.h...
#include crypto/hash.h: not found! skipping...
#include kv/map.h: not found! skipping...
#include node_signature.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2320 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace ccf
00013 {
00014   struct ViewChangeRequest
00015   {
00016     std::vector<NodeSignature> signatures;
00017     std::vector<uint8_t> signature;
00018 
00019     ViewChangeRequest() = default;
00020 
00021     size_t get_serialized_size() const
00022     {
00023       size_t size = sizeof(size_t) + sizeof(size_t) + signature.size();
00024 
00025       for (const auto& s : signatures)
00026       {
00027         size += s.get_serialized_size();
00028       }
00029       return size;
00030     }
00031 
00032     void serialize(uint8_t*& data, size_t& size)
00033     {
00034       size_t num_sigs = signatures.size();
00035       serialized::write(
00036         data, size, reinterpret_cast<uint8_t*>(&num_sigs), sizeof(num_sigs));
00037 
00038       for (const auto& s : signatures)
00039       {
00040         s.serialize(data, size);
00041       }
00042 
00043       size_t sig_size = signature.size();
00044       serialized::write(
00045         data, size, reinterpret_cast<uint8_t*>(&sig_size), sizeof(sig_size));
00046       serialized::write(data, size, signature.data(), sig_size);
00047     }
00048 
00049     static ViewChangeRequest deserialize(const uint8_t*& data, size_t& size)
00050     {
00051       ViewChangeRequest v;
00052       size_t num_sigs = serialized::read<size_t>(data, size);
00053       for (size_t i = 0; i < num_sigs; ++i)
00054       {
00055         v.signatures.push_back(ccf::NodeSignature::deserialize(data, size));
00056       }
00057 
00058       size_t sig_size = serialized::read<size_t>(data, size);
00059       v.signature = serialized::read(data, size, sig_size);
00060 
00061       return v;
00062     }
00063     MSGPACK_DEFINE(signatures, signature);
00064   };
00065   DECLARE_JSON_TYPE(ViewChangeRequest);
00066   DECLARE_JSON_REQUIRED_FIELDS(ViewChangeRequest, signatures, signature);
00067 
00068   struct ViewChangeConfirmation
00069   {
00070     kv::Consensus::View view = 0;
00071     kv::Consensus::SeqNo seqno = 0;
00072     std::vector<uint8_t> signature;
00073 
00074     std::map<kv::NodeId, ViewChangeRequest> view_change_messages;
00075 
00076     ViewChangeConfirmation() = default;
00077     ViewChangeConfirmation(
00078       kv::Consensus::View view_, kv::Consensus::SeqNo seqno_) :
00079       view(view_),
00080       seqno(seqno_)
00081     {}
00082 
00083     MSGPACK_DEFINE(view, seqno, signature, view_change_messages);
00084   };
00085   DECLARE_JSON_TYPE(ViewChangeConfirmation);
00086   DECLARE_JSON_REQUIRED_FIELDS(
00087     ViewChangeConfirmation, view, seqno, signature, view_change_messages);
00088 
00089   using NewViewsMap = kv::Map<ObjectId, ViewChangeConfirmation>;
00090 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/view_change.h...
Preprocessing /data/git/CCF/src/node/whitelists.h...
#include kv/map.h: not found! skipping...
#include set: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 576 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 namespace ccf
00011 {
00012   using WlId = uint8_t;
00013   using Whitelist = std::set<std::string>;
00014   // whitelists are sets of table names
00015   using Whitelists = kv::Map<WlId, Whitelist>;
00016 
00017   enum WlIds : WlId
00018   {
00019     // tables members can read
00020     MEMBER_CAN_READ = 0,
00021     // tables members can propose changes to
00022     MEMBER_CAN_PROPOSE,
00023     // tables the user app can read (but not write)
00024     USER_APP_CAN_READ_ONLY,
00025     // tables the user app can write
00026     USER_APP_CAN_WRITE
00027   };
00028 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/node/whitelists.h...
Preprocessing /data/git/CCF/src/perf_client/perf_client.h...
#include clients/rpc_tls_client.h: not found! skipping...
#include chrono: not found! skipping...
#include fstream: not found! skipping...
#include iomanip: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mbedtls/asn1.h: not found! skipping...
#include clients/rpc_tls_client.h: not found! skipping...
#include ds/cli_helper.h: not found! skipping...
#include ds/files.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
#include chrono: not found! skipping...
#include fstream: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include random: not found! skipping...
#include thread: not found! skipping...
#include unistd.h: not found! skipping...
Preprocessor output (size: 26160 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 // Local
00006 # 6 "/data/git/CCF/src/perf_client/perf_client.h" 2
00007 
00008 // CCF
00009 
00010 
00011 
00012 
00013 
00014 // STL/3rdparty
00015 
00016 
00017 
00018 
00019 
00020 
00021 
00022 
00023 namespace client
00024 {
00025   constexpr auto perf_summary = "perf_summary.csv";
00026 
00027   bool pin_to_core(int core_id)
00028   {
00029     int threads = std::thread::hardware_concurrency();
00030     if (core_id > threads || core_id < 0)
00031     {
00032       LOG_FATAL_FMT("Invalid core id: {}", core_id);
00033       return false;
00034     }
00035 
00036     cpu_set_t set;
00037     LOG_INFO_FMT("Pinning to core: {}", core_id);
00038     CPU_ZERO(&set);
00039     CPU_SET(core_id, &set);
00040 
00041     if (sched_setaffinity(0, sizeof(cpu_set_t), &set) < 0)
00042     {
00043       LOG_FATAL_FMT("Unable to set affinity");
00044       return false;
00045     }
00046 
00047     return true;
00048   }
00049 
00050   struct PerfOptions
00051   {
00052     /// Options set from command line
00053     ///@{
00054     std::string label; //< Default set in constructor
00055     std::string pid_file; //< Default set in constructor
00056 
00057     cli::ParsedAddress server_address;
00058     std::string cert_file, key_file, ca_file, verification_file;
00059 
00060     size_t num_transactions = 10000;
00061     size_t thread_count = 1;
00062     size_t session_count = 1;
00063     size_t max_writes_ahead = 0;
00064     size_t latency_rounds = 1;
00065     size_t generator_seed = 42u;
00066     size_t transactions_per_s = 0;
00067 
00068     bool sign = false;
00069     bool no_create = false;
00070     bool no_wait = false;
00071     bool write_tx_times = false;
00072     bool randomise = false;
00073     bool check_responses = false;
00074     bool relax_commit_target = false;
00075     bool websockets = false;
00076     ///@}
00077 
00078     PerfOptions(
00079       const std::string& default_label,
00080       const std::string& default_pid_file,
00081       CLI::App& app) :
00082       label(default_label),
00083       pid_file(fmt::format("{}.pid", default_pid_file))
00084     {
00085       // Enable config from file
00086       app.set_config("--config");
00087 
00088       app
00089         .add_option(
00090           "--label",
00091           label,
00092           fmt::format(
00093             "Identifier for this client, written to {}", perf_summary))
00094         ->capture_default_str();
00095 
00096       app
00097         .add_option(
00098           "--pid-file",
00099           pid_file,
00100           "Path to which the client PID will be written")
00101         ->capture_default_str();
00102 
00103       // Connection details
00104       cli::add_address_option(
00105         app,
00106         server_address,
00107         "--rpc-address",
00108         "Remote node JSON RPC address to which requests should be sent")
00109         ->required(true);
00110 
00111       app.add_option("--cert", cert_file)
00112         ->required(true)
00113         ->check(CLI::ExistingFile);
00114       app.add_option("--pk", key_file)
00115         ->required(true)
00116         ->check(CLI::ExistingFile);
00117       app.add_option("--ca", ca_file)->required(true)->check(CLI::ExistingFile);
00118 
00119       app
00120         .add_option(
00121           "--verify",
00122           verification_file,
00123           "Verify results against expectation, specified in file")
00124         ->required(false)
00125         ->check(CLI::ExistingFile);
00126       app.add_option("--generator-seed", generator_seed);
00127 
00128       app.add_option(
00129         "--transaction-rate",
00130         transactions_per_s,
00131         "The number of transactions per second to send");
00132 
00133       // Transaction counts and batching details
00134       app
00135         .add_option(
00136           "--transactions",
00137           num_transactions,
00138           "The basic number of transactions to send (will actually send this "
00139           "many for each thread, in each session)")
00140         ->capture_default_str();
00141       app.add_option("-t,--threads", thread_count)->capture_default_str();
00142       app.add_option("-s,--sessions", session_count)->capture_default_str();
00143       app
00144         .add_option(
00145           "--max-writes-ahead",
00146           max_writes_ahead,
00147           "How many transactions the client should send without waiting for "
00148           "responses. 0 will send all transactions before blocking for any "
00149           "responses, 1 will minimise latency by serially waiting for each "
00150           "transaction's response, other values may provide a balance between "
00151           "throughput and latency")
00152         ->capture_default_str();
00153 
00154       app.add_option("--latency-rounds", latency_rounds)->capture_default_str();
00155 
00156       // Boolean flags
00157       app.add_flag("--sign", sign, "Send client-signed transactions")
00158         ->capture_default_str();
00159       app
00160         .add_flag("--no-create", no_create, "Skip creation/setup transactions")
00161         ->capture_default_str();
00162       app
00163         .add_flag(
00164           "--no-wait",
00165           no_wait,
00166           "Don't wait for transactions to be globally committed")
00167         ->capture_default_str();
00168       app
00169         .add_flag(
00170           "--write-tx-times",
00171           write_tx_times,
00172           "Write tx sent and received times to csv")
00173         ->capture_default_str();
00174       app
00175         .add_flag(
00176           "--randomise",
00177           randomise,
00178           "Use non-deterministically random transaction contents each run")
00179         ->capture_default_str();
00180       app
00181         .add_flag(
00182           "--check-responses",
00183           check_responses,
00184           "Check every JSON response for errors. Potentially slow")
00185         ->capture_default_str();
00186       app
00187         .add_flag(
00188           "--use-websockets", websockets, "Use websockets to send transactions")
00189         ->capture_default_str();
00190     }
00191   };
00192 
00193   /** Base class for perf-testing clients. Provides hooks to set initial state,
00194    * prepare a batch of transactions, and then measure the latency and
00195    * throughput of processing those batched transactions */
00196   template <typename TOptions>
00197   class PerfBase
00198   {
00199   protected:
00200     struct PreparedTx
00201     {
00202       RpcTlsClient::PreparedRpc rpc;
00203       std::string method;
00204       bool expects_commit;
00205     };
00206 
00207   private:
00208     tls::Pem key = {};
00209     std::shared_ptr<tls::Cert> tls_cert;
00210 
00211     // Create tls_cert if it doesn't exist, and return it
00212     bool get_cert()
00213     {
00214       if (tls_cert == nullptr)
00215       {
00216         const auto raw_cert = files::slurp(options.cert_file);
00217         const auto raw_key = files::slurp(options.key_file);
00218         const auto ca = files::slurp(options.ca_file);
00219 
00220         key = tls::Pem(raw_key);
00221 
00222         tls_cert = std::make_shared<tls::Cert>(
00223           std::make_shared<tls::CA>(ca), raw_cert, key);
00224 
00225         return true;
00226       }
00227 
00228       return false;
00229     }
00230 
00231     // Process reply to an RPC. Records time reply was received. Calls
00232     // check_response for derived-overridable validation
00233     void process_reply(const RpcTlsClient::Response& reply)
00234     {
00235       if (options.check_responses)
00236       {
00237         if (!check_response(reply))
00238         {
00239           throw std::logic_error("Response failed check");
00240         }
00241       }
00242 
00243       if (response_times.is_timing_active() && reply.status == HTTP_STATUS_OK)
00244       {
00245         const auto commits = timing::parse_commit_ids(reply);
00246 
00247         // Record time of received responses
00248         response_times.record_receive(reply.id, commits);
00249 
00250         if (commits->view < last_response_commit.view)
00251         {
00252           throw std::logic_error(fmt::format(
00253             "View went backwards (expected {}, saw {})!",
00254             last_response_commit.view,
00255             commits->view));
00256         }
00257         else if (
00258           commits->view > last_response_commit.view &&
00259           commits->seqno <= last_response_commit.seqno)
00260         {
00261           throw std::logic_error(fmt::format(
00262             "There has been an election and transactions have "
00263             "been lost! (saw {}.{}, currently at {}.{})",
00264             last_response_commit.view,
00265             last_response_commit.seqno,
00266             commits->view,
00267             commits->seqno));
00268         }
00269 
00270         last_response_commit = {commits->view, commits->seqno};
00271       }
00272     }
00273 
00274     void append_prepared_tx(
00275       const PreparedTx& tx, const std::optional<size_t>& index)
00276     {
00277       if (index.has_value())
00278       {
00279         assert(index.value() < prepared_txs.size());
00280         prepared_txs[index.value()] = tx;
00281       }
00282       else
00283       {
00284         prepared_txs.push_back(tx);
00285       }
00286     }
00287 
00288   protected:
00289     TOptions options;
00290 
00291     std::mt19937 rand_generator;
00292 
00293     nlohmann::json verification_target;
00294 
00295     using PreparedTxs = std::vector<PreparedTx>;
00296 
00297     std::shared_ptr<RpcTlsClient> rpc_connection;
00298     PreparedTxs prepared_txs;
00299 
00300     timing::ResponseTimes response_times;
00301     timing::CommitPoint last_response_commit = {0, 0};
00302 
00303     std::chrono::high_resolution_clock::time_point last_write_time;
00304     std::chrono::nanoseconds write_delay_ns = std::chrono::nanoseconds::zero();
00305 
00306     std::shared_ptr<RpcTlsClient> create_connection(
00307       bool force_unsigned = false, bool upgrade = false)
00308     {
00309       // Create a cert if this is our first rpc_connection
00310       const bool is_first = get_cert();
00311 
00312       auto conn = std::make_shared<RpcTlsClient>(
00313         options.server_address.hostname,
00314         options.server_address.port,
00315         nullptr,
00316         tls_cert);
00317 
00318       if (options.sign && !force_unsigned)
00319       {
00320         conn->create_key_pair(key);
00321       }
00322 
00323       conn->set_prefix("app");
00324 
00325       // Report ciphersuite of first client (assume it is the same for each)
00326       if (is_first)
00327       {
00328         LOG_DEBUG_FMT(
00329           "Connected to server via TLS ({})", conn->get_ciphersuite_name());
00330       }
00331 
00332       if (upgrade)
00333         conn->upgrade_to_ws();
00334 
00335       return conn;
00336     }
00337 
00338     void add_prepared_tx(
00339       const std::string& method,
00340       const CBuffer params,
00341       bool expects_commit,
00342       const std::optional<size_t>& index)
00343     {
00344       const PreparedTx tx{
00345         rpc_connection->gen_request(
00346           method, params, http::headervalues::contenttype::JSON),
00347         method,
00348         expects_commit};
00349 
00350       append_prepared_tx(tx, index);
00351     }
00352 
00353     void add_prepared_tx(
00354       const std::string& method,
00355       const nlohmann::json& params,
00356       bool expects_commit,
00357       const std::optional<size_t>& index,
00358       const serdes::Pack& serdes)
00359     {
00360       auto body = serdes::pack(params, serdes);
00361 
00362       const PreparedTx tx{rpc_connection->gen_request(
00363                             method,
00364                             body,
00365                             serdes == serdes::Pack::Text ?
00366                               http::headervalues::contenttype::JSON :
00367                               http::headervalues::contenttype::MSGPACK),
00368                           method,
00369                           expects_commit};
00370 
00371       append_prepared_tx(tx, index);
00372     }
00373 
00374     void add_prepared_tx(
00375       const std::string& method,
00376       const nlohmann::json& params,
00377       bool expects_commit,
00378       const std::optional<size_t>& index)
00379     {
00380       const PreparedTx tx{
00381         rpc_connection->gen_request(method, params), method, expects_commit};
00382       append_prepared_tx(tx, index);
00383     }
00384 
00385     static size_t total_byte_size(const PreparedTxs& txs)
00386     {
00387       return std::accumulate(
00388         txs.begin(), txs.end(), 0, [](size_t n, const PreparedTx& tx) {
00389           return n + tx.rpc.encoded.size();
00390         });
00391     }
00392 
00393     // Everything else has empty stubs and can optionally be overridden. This
00394     // must be provided by derived class
00395     virtual void prepare_transactions() = 0;
00396 
00397     virtual std::optional<RpcTlsClient::Response> send_creation_transactions()
00398     {
00399       return std::nullopt;
00400     }
00401 
00402     virtual bool check_response(const RpcTlsClient::Response& r)
00403     {
00404       // Default behaviour is to accept anything that doesn't contain an error
00405       return r.status == HTTP_STATUS_OK;
00406     }
00407 
00408     virtual void pre_creation_hook(){};
00409     virtual void post_creation_hook(){};
00410 
00411     virtual void pre_timing_body_hook(){};
00412     virtual void post_timing_body_hook(){};
00413 
00414     virtual timing::Results call_raw_batch(
00415       std::shared_ptr<RpcTlsClient>& connection, const PreparedTxs& txs)
00416     {
00417       size_t read;
00418       size_t written;
00419 
00420       if (options.transactions_per_s > 0)
00421       {
00422         write_delay_ns =
00423           std::chrono::nanoseconds{1000000000 / options.transactions_per_s};
00424         connection->set_tcp_nodelay(true);
00425       }
00426 
00427       last_write_time = std::chrono::high_resolution_clock::now();
00428       kick_off_timing();
00429 
00430       // Repeat for each session
00431       for (size_t session = 1; session <= options.session_count; ++session)
00432       {
00433         read = 0;
00434         written = 0;
00435 
00436         // Write everything
00437         while (written < txs.size())
00438           write(txs[written], read, written, connection);
00439 
00440         blocking_read(read, written, connection);
00441 
00442         // Reconnect for each session (except the last)
00443         if (session != options.session_count)
00444         {
00445           reconnect(connection);
00446         }
00447       }
00448 
00449       if (!options.no_wait)
00450       {
00451         // Create a new connection, because we need to do some GETs
00452         // and when all you have is a WebSocket, everything looks like a POST!
00453         auto c = create_connection(true, false);
00454         wait_for_global_commit(last_response_commit);
00455       }
00456       const auto last_commit = last_response_commit.seqno;
00457       auto timing_results = end_timing(last_commit);
00458       LOG_INFO_FMT("Timing ended");
00459       return timing_results;
00460     }
00461 
00462     void kick_off_timing()
00463     {
00464       LOG_INFO_FMT("About to begin timing");
00465       begin_timing();
00466       LOG_INFO_FMT("Began timing");
00467     }
00468 
00469     inline void write(
00470       const PreparedTx& tx,
00471       size_t& read,
00472       size_t& written,
00473       const std::shared_ptr<RpcTlsClient>& connection)
00474     {
00475       while (std::chrono::high_resolution_clock::now() - last_write_time <
00476              write_delay_ns)
00477       {
00478         continue;
00479       }
00480 
00481       // Record time of sent requests
00482       if (response_times.is_timing_active())
00483       {
00484         response_times.record_send(tx.method, tx.rpc.id, tx.expects_commit);
00485       }
00486 
00487       connection->write(tx.rpc.encoded);
00488       last_write_time = std::chrono::high_resolution_clock::now();
00489 
00490       ++written;
00491 
00492       // Optimistically read (non-blocking) any current responses
00493       while (read < written)
00494       {
00495         const auto r = connection->read_response_non_blocking();
00496         if (!r.has_value())
00497         {
00498           // If we have no responses waiting, move on to the next thing
00499           break;
00500         }
00501 
00502         process_reply(r.value());
00503         ++read;
00504       }
00505 
00506       // Do blocking reads if we're beyond our write-ahead limit
00507       if (options.max_writes_ahead > 0) // 0 is a special value allowing
00508                                         // unlimited write-ahead
00509       {
00510         while (written - read >= options.max_writes_ahead)
00511         {
00512           process_reply(connection->read_response());
00513           ++read;
00514         }
00515       }
00516     }
00517 
00518     void blocking_read(
00519       size_t& read,
00520       size_t written,
00521       const std::shared_ptr<RpcTlsClient>& connection)
00522     {
00523       // Read response (blocking) for all pending txs
00524       while (read < written)
00525       {
00526         process_reply(connection->read_response());
00527         ++read;
00528       }
00529     }
00530 
00531     void reconnect(std::shared_ptr<RpcTlsClient>& connection)
00532     {
00533       connection.reset(new RpcTlsClient(*connection.get()));
00534     }
00535 
00536     RpcTlsClient::Response get_tx_status(
00537       const std::shared_ptr<RpcTlsClient>& connection,
00538       size_t view,
00539       size_t seqno)
00540     {
00541       nlohmann::json p;
00542       p["seqno"] = seqno;
00543       p["view"] = view;
00544       return connection->get("tx", p);
00545     }
00546 
00547     virtual void verify_params(const nlohmann::json& expected)
00548     {
00549       // It's only reasonable to compare against expected state if the initial
00550       // parameters match, so check a few obvious ones
00551 
00552       {
00553         const auto it = expected.find("seed");
00554         if (it != expected.end())
00555         {
00556           const auto expected_seed =
00557             it->get<decltype(options.generator_seed)>();
00558           if (expected_seed != options.generator_seed)
00559           {
00560             throw std::runtime_error(fmt::format(
00561               "Verification file expects seed {}, but currently using {}",
00562               expected_seed,
00563               options.generator_seed));
00564           }
00565         }
00566       }
00567 
00568       {
00569         const auto it = expected.find("transactions");
00570         if (it != expected.end())
00571         {
00572           const auto expected_txs =
00573             it->get<decltype(options.num_transactions)>();
00574           if (expected_txs != options.num_transactions)
00575           {
00576             throw std::runtime_error(fmt::format(
00577               "Verification file is only applicable for {} transactions, but "
00578               "currently running {}",
00579               expected_txs,
00580               options.num_transactions));
00581           }
00582         }
00583       }
00584 
00585       {
00586         const auto it = expected.find("sessions");
00587         if (it != expected.end())
00588         {
00589           const auto expected_sessions =
00590             it->get<decltype(options.session_count)>();
00591           if (expected_sessions != options.session_count)
00592           {
00593             throw std::runtime_error(fmt::format(
00594               "Verification file is only applicable for {} sessions, but "
00595               "currently running {}",
00596               expected_sessions,
00597               options.session_count));
00598           }
00599         }
00600       }
00601 
00602       {
00603         bool expected_randomise = false;
00604         const auto it = expected.find("randomise");
00605         if (it != expected.end())
00606         {
00607           expected_randomise = it->get<bool>();
00608         }
00609 
00610         if (expected_randomise != options.randomise)
00611         {
00612           throw std::runtime_error(fmt::format(
00613             "Verification file is only applicable when randomisation is {}, "
00614             "but this option is currently {}",
00615             expected_randomise ? "ON" : "OFF",
00616             options.randomise ? "ON" : "OFF"));
00617         }
00618       }
00619     }
00620     virtual void verify_initial_state(const nlohmann::json& expected) {}
00621     virtual void verify_final_state(const nlohmann::json& expected) {}
00622 
00623   public:
00624     PerfBase(const TOptions& o) :
00625       options(o),
00626       rand_generator(),
00627       // timing gets its own new connection for any requests it wants to send -
00628       // these are never signed
00629       response_times(create_connection(true, false))
00630     {}
00631 
00632     void init_connection()
00633     {
00634       // Make sure the connection we're about to use has been initialised
00635       if (!rpc_connection)
00636       {
00637         rpc_connection = create_connection(false, options.websockets);
00638       }
00639     }
00640 
00641     std::shared_ptr<RpcTlsClient> get_connection()
00642     {
00643       init_connection();
00644       return rpc_connection;
00645     }
00646 
00647     void send_all_creation_transactions()
00648     {
00649       if (!options.no_create)
00650       {
00651         try
00652         {
00653           const auto last_response = send_creation_transactions();
00654 
00655           if (
00656             last_response.has_value() &&
00657             http::status_success(last_response->status))
00658           {
00659             // Ensure creation transactions are globally committed before
00660             // proceeding
00661             wait_for_global_commit(last_response.value());
00662           }
00663         }
00664         catch (std::exception& e)
00665         {
00666           LOG_FAIL_FMT("Exception during creation steps: {}", e.what());
00667           throw e;
00668         }
00669       }
00670     }
00671 
00672     void prepare_all_transactions()
00673     {
00674       init_connection();
00675       try
00676       {
00677         prepare_transactions();
00678       }
00679       catch (std::exception& e)
00680       {
00681         LOG_FAIL_FMT("Preparation exception: {}", e.what());
00682         throw e;
00683       }
00684     }
00685 
00686     timing::Results send_all_prepared_transactions()
00687     {
00688       init_connection();
00689       try
00690       {
00691         // ...send any transactions which were previously prepared
00692         return call_raw_batch(rpc_connection, prepared_txs);
00693       }
00694       catch (std::exception& e)
00695       {
00696         LOG_FAIL_FMT("Transaction exception: {}", e.what());
00697         throw e;
00698       }
00699     }
00700 
00701     void wait_for_global_commit(const timing::CommitPoint& target)
00702     {
00703       response_times.wait_for_global_commit(target);
00704     }
00705 
00706     void wait_for_global_commit(const RpcTlsClient::Response& response)
00707     {
00708       check_response(response);
00709 
00710       const auto response_commit_ids = timing::parse_commit_ids(response);
00711       if (!response_commit_ids.has_value())
00712       {
00713         throw std::logic_error(
00714           "Cannot wait for response to commit - it does not have a TxID");
00715       }
00716 
00717       const timing::CommitPoint cp{response_commit_ids->view,
00718                                    response_commit_ids->seqno};
00719       wait_for_global_commit(cp);
00720     }
00721 
00722     void begin_timing()
00723     {
00724       if (response_times.is_timing_active())
00725       {
00726         throw std::logic_error(
00727           "timing is already set - has begin_timing been called multiple "
00728           "times?");
00729       }
00730 
00731       response_times.start_timing();
00732     }
00733 
00734     timing::Results end_timing(size_t end_highest_local_commit)
00735     {
00736       if (!response_times.is_timing_active())
00737       {
00738         throw std::logic_error(
00739           "timing is not set - has begin_timing not been called?");
00740       }
00741 
00742       timing::Results results;
00743       try
00744       {
00745         results = response_times.produce_results(
00746           options.no_wait, end_highest_local_commit, options.latency_rounds);
00747       }
00748       catch (const std::runtime_error& e)
00749       {
00750         response_times.write_to_file(options.label);
00751         throw;
00752       }
00753 
00754       if (options.write_tx_times)
00755       {
00756         response_times.write_to_file(options.label);
00757       }
00758 
00759       response_times.stop_timing();
00760 
00761       return results;
00762     }
00763 
00764     void summarize_results(const timing::Results& timing_results)
00765     {
00766       using namespace std;
00767       using namespace chrono;
00768 
00769       // Write tx/s to std out
00770       const auto total_txs = timing_results.total_sends;
00771       const auto dur_ms =
00772         duration_cast<milliseconds>(timing_results.duration).count();
00773       const auto duration = dur_ms / 1000.0;
00774       const auto tx_per_sec = total_txs / duration;
00775 
00776       LOG_INFO_FMT(
00777         "{} transactions took {}ms.\n"
00778         "=> {}tx/s\n", //< This is grepped for by _get_perf in Python
00779         total_txs,
00780         dur_ms,
00781         tx_per_sec);
00782 
00783       LOG_DEBUG_FMT(
00784         "  Sends: {}\n"
00785         "  Receives: {}\n"
00786         "  All txs (local_commit): {}\n"
00787         "  Global commit: {}\n",
00788         timing_results.total_sends,
00789         timing_results.total_receives,
00790         timing_results.total_local_commit,
00791         timing_results.total_global_commit);
00792 
00793       for (size_t round = 0; round < timing_results.per_round.size(); ++round)
00794       {
00795         const auto& round_info = timing_results.per_round[round];
00796 
00797         LOG_TRACE_FMT(
00798           "  Round {} (req ids #{} to #{})\n"
00799           "    Local: {}\n"
00800           "    Global: {}\n",
00801           round,
00802           round_info.begin_rpc_id,
00803           round_info.end_rpc_id,
00804           round_info.local_commit,
00805           round_info.global_commit);
00806       }
00807 
00808       // Write perf summary to csv
00809       std::ofstream perf_summary_csv(
00810         perf_summary, std::ofstream::out | std::ofstream::app);
00811       if (perf_summary_csv.is_open())
00812       {
00813         // Total number of bytes sent is:
00814         // sessions * sum-per-tx of tx-bytes)
00815         const auto total_bytes =
00816           options.session_count * total_byte_size(prepared_txs);
00817 
00818         perf_summary_csv << duration_cast<milliseconds>(
00819                               timing_results.start_time.time_since_epoch())
00820                               .count(); // timeStamp
00821         perf_summary_csv << "," << dur_ms; // elapsed
00822         perf_summary_csv << ","
00823                          << (options.server_address.hostname.find("127.") == 0 ?
00824                                options.label :
00825                                options.label + string("_distributed")); // label
00826         perf_summary_csv << "," << total_bytes; // bytes
00827         perf_summary_csv << "," << options.thread_count; // allThreads
00828         perf_summary_csv << "," << (double)dur_ms / total_txs; // latency
00829         perf_summary_csv << "," << total_txs; // SampleCount
00830 
00831         const auto& lc = timing_results.total_local_commit;
00832         perf_summary_csv << "," << lc.average; // local_commit_latency
00833         perf_summary_csv << "," << lc.sample_count; // local_commit_samples
00834 
00835         const auto& gc = timing_results.total_global_commit;
00836         perf_summary_csv << "," << gc.average; // global_commit_latency
00837         perf_summary_csv << "," << gc.sample_count; // global_commit_samples
00838 
00839         perf_summary_csv << endl;
00840       }
00841     }
00842 
00843     virtual void run()
00844     {
00845       // Write PID to disk
00846       files::dump(fmt::format("{}", ::getpid()), options.pid_file);
00847 
00848       if (options.randomise)
00849       {
00850         options.generator_seed = std::random_device()();
00851       }
00852 
00853       LOG_INFO_FMT(
00854         "Random choices determined by seed: {}", options.generator_seed);
00855       rand_generator.seed(options.generator_seed);
00856 
00857       /*
00858       const auto target_core = 0;
00859       if (!pin_to_core(target_core))
00860       {
00861         LOG_FAIL_FMT("Failed to pin to core: {}", target_core);
00862       }
00863       */
00864 
00865       const bool verifying = !options.verification_file.empty();
00866 
00867       if (verifying)
00868       {
00869         verification_target = files::slurp_json(options.verification_file);
00870         verify_params(verification_target["params"]);
00871       }
00872 
00873       // Pre- and post- hooks allow derived classes to gather/log initial state
00874       pre_creation_hook();
00875       send_all_creation_transactions();
00876       post_creation_hook();
00877 
00878       if (verifying)
00879       {
00880         verify_initial_state(verification_target["initial"]);
00881       }
00882 
00883       prepare_all_transactions();
00884 
00885       pre_timing_body_hook();
00886 
00887       LOG_TRACE_FMT(
00888         "Sending {} transactions from {} clients {} times...",
00889         options.num_transactions,
00890         options.thread_count,
00891         options.session_count);
00892 
00893       auto timing_results = send_all_prepared_transactions();
00894 
00895       LOG_INFO_FMT("Done");
00896 
00897       post_timing_body_hook();
00898 
00899       if (verifying)
00900       {
00901         verify_final_state(verification_target["final"]);
00902       }
00903 
00904       summarize_results(timing_results);
00905     }
00906 
00907     template <typename T>
00908     T rand_range()
00909     {
00910       std::uniform_int_distribution<T> dist;
00911       return dist(rand_generator);
00912     }
00913 
00914     template <typename T>
00915     T rand_range(T exclusive_upper_bound)
00916     {
00917       std::uniform_int_distribution<T> dist(0, exclusive_upper_bound - 1);
00918       return dist(rand_generator);
00919     }
00920 
00921     template <typename T>
00922     T rand_range(T inclusive_lower_bound, T exclusive_upper_bound)
00923     {
00924       std::uniform_int_distribution<T> dist(
00925         inclusive_lower_bound, exclusive_upper_bound - 1);
00926       return dist(rand_generator);
00927     }
00928   };
00929 }
00930 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/perf_client/perf_client.h...
Preprocessing /data/git/CCF/src/perf_client/scenario_perf_client.cpp...
#include ds/files.h: not found! skipping...
#include timing.h: already included! skipping...
#include clients/rpc_tls_client.h: not found! skipping...
#include ds/cli_helper.h: not found! skipping...
#include ds/files.h: not found! skipping...
#include ds/logger.h: not found! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
#include chrono: not found! skipping...
#include fstream: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include random: not found! skipping...
#include thread: not found! skipping...
#include unistd.h: not found! skipping...
#include nlohmann/json.hpp: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 3882 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 # 4 "/data/git/CCF/src/perf_client/scenario_perf_client.cpp" 2
00005 
00006 
00007 
00008 
00009 struct ScenarioPerfClientOptions : public client::PerfOptions
00010 {
00011   size_t repetitions = 1;
00012   std::string scenario_file;
00013   std::vector<std::pair<std::string, serdes::Pack>> serdes_map{
00014     {"text", serdes::Pack::Text}, {"msgpack", serdes::Pack::MsgPack}};
00015   serdes::Pack serdes;
00016 
00017   ScenarioPerfClientOptions(
00018     CLI::App& app, const std::string& default_pid_file) :
00019     client::PerfOptions("scenario_perf", default_pid_file, app)
00020   {
00021     app.add_option("--repetitions", repetitions)->capture_default_str();
00022     app.add_option("--scenario-file", scenario_file)
00023       ->required(true)
00024       ->check(CLI::ExistingFile);
00025     app.add_option("--msg-ser-fmt", serdes, "Message serialisation format")
00026       ->required()
00027       ->transform(CLI::CheckedTransformer(serdes_map, CLI::ignore_case));
00028   }
00029 };
00030 
00031 using Base = client::PerfBase<ScenarioPerfClientOptions>;
00032 
00033 class ScenarioPerfClient : public Base
00034 {
00035 private:
00036   nlohmann::json scenario_json;
00037 
00038   std::optional<RpcTlsClient::Response> send_verbose_transactions(
00039     const std::shared_ptr<RpcTlsClient>& connection, char const* element_name)
00040   {
00041     const auto it = scenario_json.find(element_name);
00042 
00043     RpcTlsClient::Response response;
00044     bool sent = false;
00045 
00046     if (it != scenario_json.end())
00047     {
00048       const auto transactions = *it;
00049       if (!transactions.is_array())
00050       {
00051         throw std::runtime_error(fmt::format(
00052           "Expected scenario to contain '{}' field containing an array of "
00053           "transaction objects",
00054           element_name));
00055       }
00056 
00057       LOG_INFO_FMT(
00058         "Sending {} {} transactions", transactions.size(), element_name);
00059       for (const auto& transaction : transactions)
00060       {
00061         const auto method = transaction["method"];
00062         const auto params = transaction["params"];
00063 
00064         LOG_INFO_FMT("Sending {}: {}", method, params.dump(2));
00065         response = connection->call(method, params);
00066         sent = true;
00067         const auto response_body = connection->unpack_body(response);
00068         LOG_INFO_FMT("Response: {} {}", response.status, response_body.dump(2));
00069       }
00070     }
00071 
00072     if (sent)
00073       return response;
00074     else
00075       return std::nullopt;
00076   }
00077 
00078   void pre_creation_hook() override
00079   {
00080     scenario_json = files::slurp_json(options.scenario_file);
00081   }
00082 
00083   std::optional<RpcTlsClient::Response> send_creation_transactions() override
00084   {
00085     return send_verbose_transactions(get_connection(), "setup");
00086   }
00087 
00088   void post_timing_body_hook() override
00089   {
00090     send_verbose_transactions(get_connection(), "cleanup");
00091   }
00092 
00093   void prepare_transactions() override
00094   {
00095     constexpr auto transactions_element_name = "transactions";
00096 
00097     const auto transactions = scenario_json[transactions_element_name];
00098     if (!transactions.is_array())
00099     {
00100       throw std::runtime_error(fmt::format(
00101         "Expected scenario to contain '{}' field containing an array of "
00102         "transaction objects",
00103         transactions_element_name));
00104     }
00105 
00106     // Reserve space for transactions
00107     prepared_txs.reserve(transactions.size() * options.repetitions);
00108 
00109     for (size_t r = 0; r < options.repetitions; ++r)
00110     {
00111       for (size_t i = 0; i < transactions.size(); ++i)
00112       {
00113         const auto& transaction = transactions[i];
00114 
00115         add_prepared_tx(
00116           transaction["method"],
00117           transaction["params"],
00118           true,
00119           std::nullopt,
00120           options.serdes);
00121       }
00122     }
00123   }
00124 
00125 public:
00126   ScenarioPerfClient(const ScenarioPerfClientOptions& o) : Base(o) {}
00127 };
00128 
00129 int main(int argc, char** argv)
00130 {
00131   CLI::App cli_app{"Scenario Perf Client"};
00132   ScenarioPerfClientOptions options(cli_app, argv[0]);
00133   CLI11_PARSE(cli_app, argc, argv);
00134 
00135   ScenarioPerfClient client(options);
00136   client.run();
00137 
00138   return 0;
00139 }
00140 
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/perf_client/scenario_perf_client.cpp...
Preprocessing /data/git/CCF/src/perf_client/timing.h...
#include clients/rpc_tls_client.h: not found! skipping...
#include chrono: not found! skipping...
#include fstream: not found! skipping...
#include iomanip: not found! skipping...
#include thread: not found! skipping...
#include vector: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mbedtls/asn1.h: not found! skipping...
Preprocessor output (size: 16993 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 // CCF
00006 
00007 
00008 // STL/3rdparty
00009 
00010 
00011 
00012 
00013 
00014 
00015 #define FMT_HEADER_ONLY
00016 
00017 
00018 
00019 namespace timing
00020 {
00021   struct Measure
00022   {
00023     size_t sample_count;
00024     double average;
00025     double variance;
00026   };
00027 }
00028 
00029 namespace fmt
00030 {
00031   template <>
00032   struct formatter<timing::Measure>
00033   {
00034     template <typename ParseContext>
00035     constexpr auto parse(ParseContext& ctx)
00036     {
00037       return ctx.begin();
00038     }
00039 
00040     template <typename FormatContext>
00041     auto format(const timing::Measure& e, FormatContext& ctx)
00042     {
00043       return format_to(
00044         ctx.out(),
00045         "sample_count: {}, average: {}, variance: {}",
00046         e.sample_count,
00047         e.average,
00048         e.variance);
00049     }
00050   };
00051 }
00052 
00053 namespace timing
00054 {
00055   using namespace std;
00056   using namespace chrono;
00057 
00058   using Clock = high_resolution_clock;
00059   using TimeDelta = duration<double>;
00060 
00061   struct SentRequest
00062   {
00063     const TimeDelta send_time;
00064     const std::string method;
00065     const size_t rpc_id;
00066     const bool expects_commit;
00067   };
00068 
00069   struct CommitIDs
00070   {
00071     size_t seqno;
00072     size_t global;
00073     size_t view;
00074   };
00075 
00076   struct ReceivedReply
00077   {
00078     const TimeDelta receive_time;
00079     const size_t rpc_id;
00080     const optional<CommitIDs> commit;
00081   };
00082 
00083   struct CommitPoint
00084   {
00085     size_t view;
00086     size_t seqno;
00087   };
00088 
00089   std::string timestamp()
00090   {
00091     std::stringstream ss;
00092 
00093     const auto now = Clock::now();
00094     auto now_tt = Clock::to_time_t(now);
00095     tm now_tm;
00096     ::localtime_r(&now_tt, &now_tm);
00097 
00098     ss << "[" << std::put_time(&now_tm, "%T.");
00099 
00100     const auto remainder =
00101       duration_cast<microseconds>(now.time_since_epoch()) % seconds(1);
00102     ss << std::setfill('0') << std::setw(6) << remainder.count() << "] ";
00103 
00104     return ss.str();
00105   }
00106 
00107   // NaNs are ignored (treated as though they are not present)
00108   Measure measure(const vector<double>& samples)
00109   {
00110     vector<double> non_nans;
00111     non_nans.reserve(samples.size());
00112     for (double d : samples)
00113     {
00114       if (!isnan(d))
00115         non_nans.push_back(d);
00116     }
00117 
00118     const double average =
00119       accumulate(non_nans.begin(), non_nans.end(), 0.0) / non_nans.size();
00120 
00121     vector<double> sq_diffs(non_nans.size());
00122     transform(
00123       non_nans.begin(), non_nans.end(), sq_diffs.begin(), [average](double d) {
00124         return (d - average) * (d - average);
00125       });
00126 
00127     const double variance =
00128       accumulate(sq_diffs.begin(), sq_diffs.end(), 0.0) / sq_diffs.size();
00129 
00130     return {non_nans.size(), average, variance};
00131   }
00132 
00133   ostream& operator<<(ostream& stream, const Measure& m)
00134   {
00135     stream << m.sample_count << " samples with average latency " << m.average
00136            << "s";
00137     const auto prev_precision = stream.precision(3);
00138     stream << " (variance " << std::scientific << m.variance
00139            << std::defaultfloat << ")";
00140     stream.precision(prev_precision);
00141     return stream;
00142   }
00143 
00144   struct Results
00145   {
00146     size_t total_sends;
00147     size_t total_receives;
00148     Clock::time_point start_time;
00149     TimeDelta duration;
00150 
00151     Measure total_local_commit;
00152     Measure total_global_commit;
00153 
00154     struct PerRound
00155     {
00156       size_t begin_rpc_id;
00157       size_t end_rpc_id;
00158 
00159       Measure local_commit;
00160       Measure global_commit;
00161     };
00162 
00163     vector<PerRound> per_round;
00164   };
00165 
00166   static std::optional<CommitIDs> parse_commit_ids(
00167     const RpcTlsClient::Response& response)
00168   {
00169     const auto& h = response.headers;
00170     const auto local_commit_it = h.find(http::headers::CCF_TX_SEQNO);
00171     if (local_commit_it == h.end())
00172     {
00173       return std::nullopt;
00174     }
00175 
00176     const auto global_commit_it = h.find(http::headers::CCF_GLOBAL_COMMIT);
00177     if (global_commit_it == h.end())
00178     {
00179       return std::nullopt;
00180     }
00181 
00182     const auto view_it = h.find(http::headers::CCF_TX_VIEW);
00183     if (view_it == h.end())
00184     {
00185       return std::nullopt;
00186     }
00187 
00188     const auto seqno =
00189       std::strtoul(local_commit_it->second.c_str(), nullptr, 0);
00190     const auto global =
00191       std::strtoul(global_commit_it->second.c_str(), nullptr, 0);
00192     const auto view = std::strtoul(view_it->second.c_str(), nullptr, 0);
00193 
00194     return {{seqno, global, view}};
00195   }
00196 
00197   class ResponseTimes
00198   {
00199     const shared_ptr<RpcTlsClient> net_client;
00200     time_point<Clock> start_time;
00201 
00202     vector<SentRequest> sends;
00203     vector<ReceivedReply> receives;
00204 
00205     bool active = false;
00206 
00207   public:
00208     ResponseTimes(const shared_ptr<RpcTlsClient>& client) :
00209       net_client(client),
00210       start_time(Clock::now())
00211     {}
00212 
00213     ResponseTimes(const ResponseTimes& other) = default;
00214 
00215     void start_timing()
00216     {
00217       active = true;
00218       start_time = Clock::now();
00219     }
00220 
00221     bool is_timing_active()
00222     {
00223       return active;
00224     }
00225 
00226     void stop_timing()
00227     {
00228       active = false;
00229     }
00230 
00231     auto get_start_time() const
00232     {
00233       return start_time;
00234     }
00235 
00236     void record_send(
00237       const std::string& method, size_t rpc_id, bool expects_commit)
00238     {
00239       sends.push_back(
00240         {Clock::now() - start_time, method, rpc_id, expects_commit});
00241     }
00242 
00243     void record_receive(size_t rpc_id, const optional<CommitIDs>& commit)
00244     {
00245       receives.push_back({Clock::now() - start_time, rpc_id, commit});
00246     }
00247 
00248     // Repeatedly calls GET /tx RPC until the target seqno has been
00249     // committed (or will never be committed), returns first confirming
00250     // response. Calls record_[send/response], if record is true.
00251     // Throws on errors, or if target is rolled back
00252     void wait_for_global_commit(const CommitPoint& target, bool record = true)
00253     {
00254       auto params = nlohmann::json::object();
00255       params["view"] = target.view;
00256       params["seqno"] = target.seqno;
00257 
00258       constexpr auto get_tx_status = "tx";
00259 
00260       LOG_INFO_FMT(
00261         "Waiting for transaction ID {}.{}", target.view, target.seqno);
00262 
00263       while (true)
00264       {
00265         const auto response = net_client->get(get_tx_status, params);
00266 
00267         if (record)
00268         {
00269           record_send(get_tx_status, response.id, false);
00270         }
00271 
00272         const auto body = net_client->unpack_body(response);
00273         if (response.status != HTTP_STATUS_OK)
00274         {
00275           throw runtime_error(fmt::format(
00276             "{} failed with status {}: {}",
00277             get_tx_status,
00278             http_status_str(response.status),
00279             body.dump()));
00280         }
00281 
00282         const auto commit_ids = parse_commit_ids(response);
00283 
00284         // NB: Eventual header re-org should be exposing API types so
00285         // they can be consumed cleanly from C++ clients
00286         const auto tx_status = body["status"];
00287         if (tx_status == "PENDING" || tx_status == "UNKNOWN")
00288         {
00289           if (record)
00290           {
00291             record_receive(response.id, commit_ids);
00292           }
00293 
00294           // Commit is pending, poll again
00295           this_thread::sleep_for(10us);
00296           continue;
00297         }
00298         else if (tx_status == "COMMITTED")
00299         {
00300           LOG_INFO_FMT("Found global commit {}.{}", target.view, target.seqno);
00301           if (commit_ids.has_value())
00302           {
00303             LOG_INFO_FMT(
00304               " (headers view: {}, seqno: {}, global: {})",
00305               commit_ids->view,
00306               commit_ids->seqno,
00307               commit_ids->global);
00308           }
00309 
00310           if (record)
00311           {
00312             if (commit_ids.has_value())
00313             {
00314               record_receive(response.id, commit_ids);
00315             }
00316             else
00317             {
00318               // If this response didn't contain commit IDs in headers, we can
00319               // still construct them from the body
00320               record_receive(
00321                 response.id, {{target.seqno, target.seqno, target.view}});
00322             }
00323           }
00324           return;
00325         }
00326         else if (tx_status == "INVALID")
00327         {
00328           throw std::logic_error(fmt::format(
00329             "Transaction {}.{} is now marked as invalid",
00330             target.view,
00331             target.seqno));
00332         }
00333         else
00334         {
00335           throw std::logic_error(
00336             fmt::format("Unhandled tx status: {}", tx_status));
00337         }
00338       }
00339     }
00340 
00341     Results produce_results(
00342       bool allow_pending,
00343       size_t highest_local_commit,
00344       size_t desired_rounds = 1)
00345     {
00346       TimeDelta end_time_delta = Clock::now() - start_time;
00347 
00348       const auto rounds = min(max(sends.size(), 1ul), desired_rounds);
00349       const auto round_size = sends.size() / rounds;
00350 
00351       // Assume we receive responses in the same order requests were sent, then
00352       // duplicate IDs shouldn't cause a problem
00353       size_t next_recv = 0u;
00354 
00355       using Latencies = vector<double>;
00356 
00357       Results res;
00358       Latencies all_local_commits;
00359       Latencies all_global_commits;
00360 
00361       // get test duration for last sent message's global commit
00362       for (auto i = next_recv; i < receives.size(); ++i)
00363       {
00364         auto receive = receives[i];
00365 
00366         if (receive.commit.has_value())
00367         {
00368           if (receive.commit->global >= highest_local_commit)
00369           {
00370             LOG_INFO_FMT(
00371               "Global commit match {} for highest local commit {}",
00372               receive.commit->global,
00373               highest_local_commit);
00374             auto was =
00375               duration_cast<milliseconds>(end_time_delta).count() / 1000.0;
00376             auto is =
00377               duration_cast<milliseconds>(receive.receive_time).count() /
00378               1000.0;
00379             LOG_INFO_FMT("Duration changing from {}s to {}s", was, is);
00380             end_time_delta = receive.receive_time;
00381             break;
00382           }
00383         }
00384       }
00385 
00386       for (auto round = 1; round <= rounds; ++round)
00387       {
00388         const auto round_begin = sends.begin() + (round_size * (round - 1));
00389         const auto round_end =
00390           round == rounds ? sends.end() : round_begin + round_size;
00391 
00392         Latencies round_local_commit;
00393         Latencies round_global_commit;
00394 
00395         struct PendingGlobalCommit
00396         {
00397           TimeDelta send_time;
00398           size_t target_commit;
00399         };
00400         vector<PendingGlobalCommit> pending_global_commits;
00401 
00402         auto complete_pending = [&](const ReceivedReply& receive) {
00403           if (receive.commit.has_value())
00404           {
00405             auto pending_it = pending_global_commits.begin();
00406             while (pending_it != pending_global_commits.end())
00407             {
00408               if (receive.commit->global >= pending_it->target_commit)
00409               {
00410                 round_global_commit.push_back(
00411                   (receive.receive_time - pending_it->send_time).count());
00412                 pending_it = pending_global_commits.erase(pending_it);
00413               }
00414               else
00415               {
00416                 // Assuming the target_commits within pending_global_commits are
00417                 // monotonic, we can break here. If this receive didn't satisfy
00418                 // the first pending commit, it can't satisfy any later
00419                 break;
00420               }
00421             }
00422           }
00423         };
00424 
00425         for (auto send_it = round_begin; send_it != round_end; ++send_it)
00426         {
00427           const auto& send = *send_it;
00428 
00429           double tx_latency;
00430           optional<CommitIDs> response_commit;
00431           for (auto i = next_recv; i < receives.size(); ++i)
00432           {
00433             const auto& receive = receives[i];
00434 
00435             complete_pending(receive);
00436 
00437             if (receive.rpc_id == send.rpc_id)
00438             {
00439               tx_latency = (receive.receive_time - send.send_time).count();
00440 
00441               if (tx_latency < 0)
00442               {
00443                 LOG_FAIL_FMT(
00444                   "Calculated a negative latency ({}) for RPC {} - duplicate "
00445                   "ID causing mismatch?",
00446                   tx_latency,
00447                   receive.rpc_id);
00448                 continue;
00449               }
00450 
00451               response_commit = receive.commit;
00452               next_recv = i + 1;
00453               break;
00454             }
00455           }
00456 
00457           if (send.expects_commit)
00458           {
00459             if (response_commit.has_value())
00460             {
00461               // Successful write - measure local tx time AND try to find global
00462               // commit time
00463               round_local_commit.push_back(tx_latency);
00464 
00465               if (response_commit->global >= response_commit->seqno)
00466               {
00467                 // Global commit already already
00468                 round_global_commit.push_back(tx_latency);
00469               }
00470               else
00471               {
00472                 if (response_commit->seqno <= highest_local_commit)
00473                 {
00474                   // Store expected global commit to find later
00475                   pending_global_commits.push_back(
00476                     {send.send_time, response_commit->seqno});
00477                 }
00478                 else
00479                 {
00480                   LOG_DEBUG_FMT(
00481                     "Ignoring request with ID {} because it committed too late "
00482                     "({} > {})",
00483                     send.rpc_id,
00484                     response_commit->seqno,
00485                     highest_local_commit);
00486                 }
00487               }
00488             }
00489             else
00490             {
00491               // Write failed - measure local tx time
00492               round_local_commit.push_back(tx_latency);
00493             }
00494           }
00495           else
00496           {
00497             // Read-only - measure local tx time
00498             round_local_commit.push_back(tx_latency);
00499           }
00500         }
00501 
00502         // After every tracked send has been processed, consider every remaining
00503         // receive to satisfy outstanding pending global commits
00504         for (auto i = next_recv; i < receives.size(); ++i)
00505         {
00506           if (pending_global_commits.empty())
00507           {
00508             break;
00509           }
00510 
00511           complete_pending(receives[i]);
00512         }
00513 
00514         all_local_commits.insert(
00515           all_local_commits.end(),
00516           round_local_commit.begin(),
00517           round_local_commit.end());
00518         all_global_commits.insert(
00519           all_global_commits.end(),
00520           round_global_commit.begin(),
00521           round_global_commit.end());
00522 
00523         if (rounds > 1)
00524         {
00525           res.per_round.push_back({round_begin->rpc_id,
00526                                    (round_end - 1)->rpc_id,
00527                                    measure(round_local_commit),
00528                                    measure(round_global_commit)});
00529         }
00530 
00531         if (!allow_pending)
00532         {
00533           if (!pending_global_commits.empty())
00534           {
00535             const auto& first = pending_global_commits[0];
00536             throw runtime_error(fmt::format(
00537               "Still waiting for {} global commits. First expected is {} for "
00538               "a transaction sent at {} (NB: Highest local commit is {})",
00539               pending_global_commits.size(),
00540               first.target_commit,
00541               first.send_time.count(),
00542               highest_local_commit));
00543           }
00544         }
00545 
00546         const auto expected_local_samples = distance(round_begin, round_end);
00547         const auto actual_local_samples = round_local_commit.size();
00548         if (actual_local_samples != expected_local_samples)
00549         {
00550           throw runtime_error(fmt::format(
00551             "Measured {} response times, yet sent {} requests",
00552             actual_local_samples,
00553             expected_local_samples));
00554         }
00555       }
00556 
00557       res.total_sends = sends.size();
00558       res.total_receives = receives.size();
00559       res.start_time = start_time;
00560       res.duration = end_time_delta;
00561 
00562       res.total_local_commit = measure(all_local_commits);
00563       res.total_global_commit = measure(all_global_commits);
00564       return res;
00565     }
00566 
00567     void write_to_file(const string& filename)
00568     {
00569       LOG_INFO_FMT("Writing timing data to files");
00570 
00571       const auto sent_path = filename + "_sent.csv";
00572       ofstream sent_csv(sent_path, ofstream::out);
00573       if (sent_csv.is_open())
00574       {
00575         sent_csv << "sent_sec,idx,method,expects_commit" << endl;
00576         for (const auto& sent : sends)
00577         {
00578           sent_csv << sent.send_time.count() << "," << sent.rpc_id << ","
00579                    << sent.method << "," << sent.expects_commit << endl;
00580         }
00581         LOG_INFO_FMT("Wrote {} entries to {}", sends.size(), sent_path);
00582       }
00583 
00584       const auto recv_path = filename + "_recv.csv";
00585       ofstream recv_csv(recv_path, ofstream::out);
00586       if (recv_csv.is_open())
00587       {
00588         recv_csv << "recv_sec,idx,has_commits,commit,view,global_commit"
00589                  << endl;
00590         for (const auto& reply : receives)
00591         {
00592           recv_csv << reply.receive_time.count();
00593           recv_csv << "," << reply.rpc_id;
00594           recv_csv << "," << reply.commit.has_value();
00595 
00596           if (reply.commit.has_value())
00597           {
00598             recv_csv << "," << reply.commit->seqno;
00599             recv_csv << "," << reply.commit->view;
00600             recv_csv << "," << reply.commit->global;
00601           }
00602           else
00603           {
00604             recv_csv << "," << 0;
00605             recv_csv << "," << 0;
00606             recv_csv << "," << 0;
00607           }
00608           recv_csv << endl;
00609         }
00610         LOG_INFO_FMT("Wrote {} entries to {}", receives.size(), recv_path);
00611       }
00612     }
00613   };
00614 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/perf_client/timing.h...
Preprocessing /data/git/CCF/src/runtime_config/default_whitelists.h...
#include node/whitelists.h: not found! skipping...
#include map: not found! skipping...
Preprocessor output (size: 1541 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace ccf
00009 {
00010   static const std::map<WlIds, Whitelist> default_whitelists = {
00011     {MEMBER_CAN_READ,
00012      {Tables::MEMBERS,
00013       Tables::MEMBER_CERT_DERS,
00014       Tables::MEMBER_ACKS,
00015       Tables::USERS,
00016       Tables::USER_CERT_DERS,
00017       Tables::NODES,
00018       Tables::VALUES,
00019       Tables::SIGNATURES,
00020       Tables::NODE_CODE_IDS,
00021       Tables::WHITELISTS,
00022       Tables::PROPOSALS,
00023       Tables::GOV_SCRIPTS,
00024       Tables::APP_SCRIPTS,
00025       Tables::MODULES,
00026       Tables::SERVICE,
00027       Tables::CONFIGURATION,
00028       Tables::CA_CERT_DERS,
00029       Tables::JWT_ISSUERS,
00030       Tables::JWT_PUBLIC_SIGNING_KEYS,
00031       Tables::JWT_PUBLIC_SIGNING_KEY_ISSUER}},
00032 
00033     {MEMBER_CAN_PROPOSE,
00034      {Tables::USERS,
00035       Tables::USER_CERT_DERS,
00036       Tables::VALUES,
00037       Tables::WHITELISTS,
00038       Tables::GOV_SCRIPTS,
00039       Tables::APP_SCRIPTS,
00040       Tables::MODULES,
00041       Tables::CONFIGURATION,
00042       Tables::CA_CERT_DERS,
00043       Tables::JWT_ISSUERS,
00044       Tables::JWT_PUBLIC_SIGNING_KEYS,
00045       Tables::JWT_PUBLIC_SIGNING_KEY_ISSUER}},
00046 
00047     {USER_APP_CAN_READ_ONLY,
00048      {Tables::MEMBERS,
00049       Tables::MEMBER_CERT_DERS,
00050       Tables::MEMBER_ACKS,
00051       Tables::USERS,
00052       Tables::WHITELISTS,
00053       Tables::GOV_SCRIPTS,
00054       Tables::APP_SCRIPTS,
00055       Tables::MODULES,
00056       Tables::GOV_HISTORY,
00057       Tables::CA_CERT_DERS,
00058       Tables::JWT_ISSUERS,
00059       Tables::JWT_PUBLIC_SIGNING_KEYS,
00060       Tables::JWT_PUBLIC_SIGNING_KEY_ISSUER}}};
00061 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/runtime_config/default_whitelists.h...
Preprocessing /data/git/CCF/src/tls/asn1_san.h...
#include ds/net.h: not found! skipping...
#include tls/san.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mbedtls/asn1write.h: not found! skipping...
#include mbedtls/oid.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 6267 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 #define FMT_HEADER_ONLY
00009 
00010 
00011 
00012 
00013 
00014 
00015 namespace tls
00016 {
00017   // Unfortunately, mbedtls does not provide a convenient API to write x509v3
00018   // extensions for all supported Subject Alternative Name (SAN). Until they do,
00019   // we have to write raw ASN1 ourselves.
00020 
00021   // rfc5280 does not specify a maximum length for SAN,
00022   // but rfc1035 specified that 255 bytes is enough for a DNS name
00023   static constexpr auto max_san_length = 256;
00024   static constexpr auto max_san_entries = 8;
00025 
00026   // As per https://tools.ietf.org/html/rfc5280#section-4.2.1.6
00027   enum san_type
00028   {
00029     other_name = 0,
00030     rfc822_name = 1,
00031     dns_name = 2,
00032     x400_address = 3,
00033     directory_name = 4,
00034     edi_party_name = 5,
00035     uniform_resource_identifier = 6,
00036     ip_address = 7,
00037     registeredID = 8
00038   };
00039 
00040   inline int x509write_crt_set_subject_alt_name(
00041     mbedtls_x509write_cert* ctx,
00042     const char* name,
00043     san_type san = san_type::dns_name)
00044   {
00045     uint8_t san_buf[max_san_length];
00046     int ret = 0;
00047     size_t len = 0;
00048 
00049     // mbedtls asn1 write API writes backward in san_buf
00050     uint8_t* pc = san_buf + max_san_length;
00051 
00052     auto name_len = strlen(name);
00053     if (name_len > max_san_length)
00054     {
00055       throw std::logic_error(fmt::format(
00056         "Subject Alternative Name {} is too long ({}>{})",
00057         name,
00058         name_len,
00059         max_san_length));
00060     }
00061 
00062     switch (san)
00063     {
00064       case san_type::dns_name:
00065       {
00066         MBEDTLS_ASN1_CHK_ADD(
00067           len,
00068           mbedtls_asn1_write_raw_buffer(
00069             &pc, san_buf, (const unsigned char*)name, name_len));
00070         MBEDTLS_ASN1_CHK_ADD(
00071           len, mbedtls_asn1_write_len(&pc, san_buf, name_len));
00072         break;
00073       }
00074 
00075       // mbedtls (2.16.2) only supports parsing of subject alternative name that
00076       // is DNS= (so no IPAddress=). When connecting to a node that has
00077       // IPAddress set, mbedtls_ssl_set_hostname() should not be called.
00078       // However, it should work fine with a majority of other clients (e.g.
00079       // curl).
00080       case san_type::ip_address:
00081       {
00082         auto addr = ds::ip_to_binary(name);
00083         if (!addr.has_value())
00084         {
00085           throw std ::logic_error(fmt::format(
00086             "Subject Alternative Name {} is not a valid IPv4 or "
00087             "IPv6 address",
00088             name));
00089         }
00090 
00091         MBEDTLS_ASN1_CHK_ADD(
00092           len,
00093           mbedtls_asn1_write_raw_buffer(
00094             &pc, san_buf, (const unsigned char*)&addr->buf, addr->size));
00095         MBEDTLS_ASN1_CHK_ADD(
00096           len, mbedtls_asn1_write_len(&pc, san_buf, addr->size));
00097 
00098         break;
00099       }
00100 
00101       default:
00102       {
00103         throw std::logic_error(
00104           fmt::format("Subject Alternative Name {} is not supported", san));
00105       }
00106     }
00107 
00108     MBEDTLS_ASN1_CHK_ADD(
00109       len,
00110       mbedtls_asn1_write_tag(
00111         &pc, san_buf, MBEDTLS_ASN1_CONTEXT_SPECIFIC | san));
00112     MBEDTLS_ASN1_CHK_ADD(len, mbedtls_asn1_write_len(&pc, san_buf, len));
00113     MBEDTLS_ASN1_CHK_ADD(
00114       len,
00115       mbedtls_asn1_write_tag(
00116         &pc, san_buf, MBEDTLS_ASN1_CONSTRUCTED | MBEDTLS_ASN1_SEQUENCE));
00117 
00118     return mbedtls_x509write_crt_set_extension(
00119       ctx,
00120       MBEDTLS_OID_SUBJECT_ALT_NAME,
00121       MBEDTLS_OID_SIZE(MBEDTLS_OID_SUBJECT_ALT_NAME),
00122       0, // Mark SAN as non-critical
00123       san_buf + max_san_length - len,
00124       len);
00125   }
00126 
00127   inline int x509write_crt_set_subject_alt_names(
00128     mbedtls_x509write_cert* ctx, const std::vector<SubjectAltName>& sans)
00129   {
00130     if (sans.size() == 0)
00131       return 0;
00132 
00133     if (sans.size() > max_san_entries)
00134     {
00135       throw std::logic_error(fmt::format(
00136         "Cannot set more than {} subject alternative names", max_san_entries));
00137     }
00138     // The factor of two is an extremely conservative provision for ASN.1
00139     // metadata
00140     size_t buf_len = sans.size() * max_san_length * 2;
00141 
00142     std::vector<uint8_t> buf(buf_len);
00143     uint8_t* san_buf = buf.data();
00144 
00145     int ret = 0;
00146     size_t len = 0;
00147 
00148     // mbedtls asn1 write API writes backward in san_buf
00149     uint8_t* pc = san_buf + buf_len;
00150 
00151     for (auto& san : sans)
00152     {
00153       if (san.san.size() > max_san_length)
00154       {
00155         throw std::logic_error(fmt::format(
00156           "Subject Alternative Name {} is too long ({}>{})",
00157           san.san,
00158           san.san.size(),
00159           max_san_length));
00160       }
00161 
00162       if (san.is_ip)
00163       {
00164         // mbedtls (2.16.2) only supports parsing of subject alternative name
00165         // that is DNS= (so no IPAddress=). When connecting to a node that has
00166         // IPAddress set, mbedtls_ssl_set_hostname() should not be called.
00167         // However, it should work fine with a majority of other clients (e.g.
00168         // curl).
00169 
00170         auto addr = ds::ip_to_binary(san.san.c_str());
00171         if (!addr.has_value())
00172         {
00173           throw std ::logic_error(fmt::format(
00174             "Subject Alternative Name {} is not a valid IPv4 or "
00175             "IPv6 address",
00176             san.san));
00177         }
00178 
00179         MBEDTLS_ASN1_CHK_ADD(
00180           len,
00181           mbedtls_asn1_write_raw_buffer(
00182             &pc, san_buf, (const unsigned char*)&addr->buf, addr->size));
00183         MBEDTLS_ASN1_CHK_ADD(
00184           len, mbedtls_asn1_write_len(&pc, san_buf, addr->size));
00185       }
00186       else
00187       {
00188         MBEDTLS_ASN1_CHK_ADD(
00189           len,
00190           mbedtls_asn1_write_raw_buffer(
00191             &pc,
00192             san_buf,
00193             (const unsigned char*)san.san.data(),
00194             san.san.size()));
00195         MBEDTLS_ASN1_CHK_ADD(
00196           len, mbedtls_asn1_write_len(&pc, san_buf, san.san.size()));
00197       }
00198 
00199       MBEDTLS_ASN1_CHK_ADD(
00200         len,
00201         mbedtls_asn1_write_tag(
00202           &pc,
00203           san_buf,
00204           MBEDTLS_ASN1_CONTEXT_SPECIFIC |
00205             (san.is_ip ? san_type::ip_address : san_type::dns_name)));
00206     }
00207 
00208     MBEDTLS_ASN1_CHK_ADD(len, mbedtls_asn1_write_len(&pc, san_buf, len));
00209     MBEDTLS_ASN1_CHK_ADD(
00210       len,
00211       mbedtls_asn1_write_tag(
00212         &pc, san_buf, MBEDTLS_ASN1_CONSTRUCTED | MBEDTLS_ASN1_SEQUENCE));
00213 
00214     return mbedtls_x509write_crt_set_extension(
00215       ctx,
00216       MBEDTLS_OID_SUBJECT_ALT_NAME,
00217       MBEDTLS_OID_SIZE(MBEDTLS_OID_SUBJECT_ALT_NAME),
00218       0, // Mark SAN as non-critical
00219       san_buf + buf_len - len,
00220       len);
00221   }
00222 }
---------
Macros accessible in this file:
---------
FMT_HEADER_ONLY 
---------
Parsing file /data/git/CCF/src/tls/asn1_san.h...
Preprocessing /data/git/CCF/src/tls/base64.h...
#include ds/logger.h: not found! skipping...
#include error_string.h: already included! skipping...
#include mbedtls/base64.h: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2669 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace tls
00013 {
00014   inline std::vector<uint8_t> raw_from_b64(const std::string_view& b64_string)
00015   {
00016     size_t len_written = 0;
00017     const auto data = reinterpret_cast<const uint8_t*>(b64_string.data());
00018     const auto size = b64_string.size();
00019 
00020     // Obtain the size of the output buffer
00021     auto rc = mbedtls_base64_decode(nullptr, 0, &len_written, data, size);
00022     if (rc < 0 && rc != MBEDTLS_ERR_BASE64_BUFFER_TOO_SMALL)
00023     {
00024       throw std::logic_error(fmt::format(
00025         "Could not obtain length of decoded base64 buffer: {}",
00026         error_string(rc)));
00027     }
00028 
00029     std::vector<uint8_t> decoded(len_written);
00030 
00031     rc = mbedtls_base64_decode(
00032       decoded.data(), decoded.size(), &len_written, data, size);
00033     if (rc != 0)
00034     {
00035       throw std::invalid_argument(
00036         fmt::format("Could not decode base64 string: {}", error_string(rc)));
00037     }
00038 
00039     return decoded;
00040   }
00041 
00042   inline std::vector<uint8_t> raw_from_b64url(
00043     const std::string_view& b64url_string)
00044   {
00045     std::string b64_string = std::string(b64url_string);
00046     for (size_t i = 0; i < b64_string.size(); i++)
00047     {
00048       switch (b64_string[i])
00049       {
00050         case '-':
00051           b64_string[i] = '+';
00052           break;
00053         case '_':
00054           b64_string[i] = '/';
00055           break;
00056       }
00057     }
00058     auto padding =
00059       b64_string.size() % 4 == 2 ? 2 : b64_string.size() % 4 == 3 ? 1 : 0;
00060     b64_string += std::string(padding, '=');
00061     return raw_from_b64(b64_string);
00062   }
00063 
00064   inline std::string b64_from_raw(const uint8_t* data, size_t size)
00065   {
00066     size_t len_written = 0;
00067 
00068     // Obtain required size for output buffer
00069     auto rc = mbedtls_base64_encode(nullptr, 0, &len_written, data, size);
00070     if (rc < 0 && rc != MBEDTLS_ERR_BASE64_BUFFER_TOO_SMALL)
00071     {
00072       throw std::logic_error(fmt::format(
00073         "Could not obtain length required for encoded base64 buffer: {}",
00074         error_string(rc)));
00075     }
00076 
00077     std::string b64_string(len_written, '\0');
00078     auto dest = reinterpret_cast<uint8_t*>(b64_string.data());
00079 
00080     rc =
00081       mbedtls_base64_encode(dest, b64_string.size(), &len_written, data, size);
00082     if (rc != 0)
00083     {
00084       throw std::logic_error(
00085         fmt::format("Could not encode base64 string: {}", error_string(rc)));
00086     }
00087 
00088     if (b64_string.size() > 0)
00089     {
00090       // mbedtls includes the terminating null, but std-string provides this
00091       // already
00092       b64_string.pop_back();
00093     }
00094 
00095     return b64_string;
00096   }
00097 
00098   inline std::string b64_from_raw(const std::vector<uint8_t>& data)
00099   {
00100     return b64_from_raw(data.data(), data.size());
00101   }
00102 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/base64.h...
Preprocessing /data/git/CCF/src/tls/ca.h...
#include ../ds/buffer.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include pem.h: already included! skipping...
#include exception: not found! skipping...
Preprocessor output (size: 1076 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 namespace tls
00012 {
00013   class CA
00014   {
00015   private:
00016     mbedtls::X509Crt ca = nullptr;
00017     mbedtls::X509Crl crl = nullptr;
00018 
00019   public:
00020     CA(CBuffer ca_ = nullb, CBuffer crl_ = nullb)
00021     {
00022       auto tmp_ca = mbedtls::make_unique<mbedtls::X509Crt>();
00023       auto tmp_crl = mbedtls::make_unique<mbedtls::X509Crl>();
00024 
00025       if (ca_.n > 0)
00026       {
00027         Pem pem_ca(ca_);
00028         if (
00029           mbedtls_x509_crt_parse(tmp_ca.get(), pem_ca.data(), pem_ca.size()) !=
00030           0)
00031           throw std::logic_error("Could not parse CA");
00032       }
00033 
00034       if (crl_.n > 0)
00035       {
00036         Pem pem_crl(crl_);
00037         if (
00038           mbedtls_x509_crl_parse(
00039             tmp_crl.get(), pem_crl.data(), pem_crl.size()) != 0)
00040           throw std::logic_error("Could not parse CRL");
00041       }
00042 
00043       ca = std::move(tmp_ca);
00044       crl = std::move(tmp_crl);
00045     }
00046 
00047     ~CA() {}
00048 
00049     void use(mbedtls_ssl_config* cfg)
00050     {
00051       mbedtls_ssl_conf_ca_chain(cfg, ca.get(), crl.get());
00052     }
00053   };
00054 }
00055 
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER 
---------
Parsing file /data/git/CCF/src/tls/ca.h...
Preprocessing /data/git/CCF/src/tls/cert.h...
#include ca.h: already included! skipping...
#include error_string.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include cstring: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
Preprocessor output (size: 3547 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace tls
00014 {
00015   enum Auth
00016   {
00017     auth_default,
00018     auth_none,
00019     auth_optional,
00020     auth_required
00021   };
00022 
00023   // This class represents the authentication/authorization context for a TLS
00024   // session. At least, it contains the peer's CA. At most, it also contains our
00025   // own private key/certificate which will be presented in the TLS handshake.
00026   // The peer's certificate verification can be overridden with the auth
00027   // parameter.
00028   class Cert
00029   {
00030   private:
00031     std::shared_ptr<CA> peer_ca;
00032     std::optional<std::string> peer_hostname;
00033 
00034     mbedtls::X509Crt own_cert = nullptr;
00035     mbedtls::PKContext own_pkey = nullptr;
00036     bool has_own_cert;
00037 
00038     Auth auth;
00039 
00040   public:
00041     Cert(
00042       std::shared_ptr<CA> peer_ca_,
00043       const std::optional<tls::Pem>& own_cert_ = std::nullopt,
00044       const std::optional<tls::Pem>& own_pkey_ = std::nullopt,
00045       CBuffer pw = nullb,
00046       Auth auth_ = auth_default,
00047       const std::optional<std::string>& peer_hostname_ = std::nullopt) :
00048       peer_ca(peer_ca_),
00049       peer_hostname(peer_hostname_),
00050       has_own_cert(false),
00051       auth(auth_)
00052     {
00053       auto tmp_cert = mbedtls::make_unique<mbedtls::X509Crt>();
00054       auto tmp_pkey = mbedtls::make_unique<mbedtls::PKContext>();
00055 
00056       if (own_cert_.has_value() && own_pkey_.has_value())
00057       {
00058         int rc = mbedtls_x509_crt_parse(
00059           tmp_cert.get(), own_cert_->data(), own_cert_->size());
00060 
00061         if (rc != 0)
00062         {
00063           throw std::logic_error(
00064             "Could not parse certificate: " + error_string(rc));
00065         }
00066 
00067         rc = mbedtls_pk_parse_key(
00068           tmp_pkey.get(), own_pkey_->data(), own_pkey_->size(), pw.p, pw.n);
00069         if (rc != 0)
00070         {
00071           throw std::logic_error("Could not parse key: " + error_string(rc));
00072         }
00073 
00074         has_own_cert = true;
00075       }
00076 
00077       own_cert = std::move(tmp_cert);
00078       own_pkey = std::move(tmp_pkey);
00079     }
00080 
00081     ~Cert() {}
00082 
00083     void use(mbedtls_ssl_context* ssl, mbedtls_ssl_config* cfg)
00084     {
00085       if (peer_hostname.has_value())
00086       {
00087         // Peer hostname is only checked against peer certificate (SAN
00088         // extension) if it is set. This lets us connect to peers that present
00089         // certificates with IPAddress in SAN field (mbedtls does not parse
00090         // IPAddress in SAN field). This is OK since we check for peer CA
00091         // endorsement.
00092         mbedtls_ssl_set_hostname(ssl, peer_hostname->c_str());
00093       }
00094 
00095       if (peer_ca)
00096       {
00097         peer_ca->use(cfg);
00098       }
00099 
00100       if (auth != auth_default)
00101       {
00102         mbedtls_ssl_conf_authmode(cfg, authmode(auth));
00103       }
00104 
00105       if (has_own_cert)
00106       {
00107         mbedtls_ssl_conf_own_cert(cfg, own_cert.get(), own_pkey.get());
00108       }
00109     }
00110 
00111     const mbedtls_x509_crt* raw()
00112     {
00113       return own_cert.get();
00114     }
00115 
00116   private:
00117     int authmode(Auth auth)
00118     {
00119       switch (auth)
00120       {
00121         case auth_none:
00122         {
00123           // Peer certificate is not checked
00124           return MBEDTLS_SSL_VERIFY_NONE;
00125         }
00126 
00127         case auth_optional:
00128         {
00129           // Peer certificate is checked but handshake continues even if
00130           // verification fails
00131           return MBEDTLS_SSL_VERIFY_OPTIONAL;
00132         }
00133 
00134         case auth_required:
00135         {
00136           // Peer must present a valid certificate
00137           return MBEDTLS_SSL_VERIFY_REQUIRED;
00138         }
00139 
00140         default:
00141         {
00142         }
00143       }
00144 
00145       return MBEDTLS_SSL_VERIFY_REQUIRED;
00146     }
00147   };
00148 }
00149 
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER 
---------
Parsing file /data/git/CCF/src/tls/cert.h...
Preprocessing /data/git/CCF/src/tls/client.h...
#include cert.h: already included! skipping...
      #include tls.h: already included! skipping...
#include cassert: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include tls.h: already included! skipping...
#include functional: not found! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
#include error_string.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 415 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/tls/client.h" 2
00006 
00007 namespace tls
00008 {
00009   class Client : public Context
00010   {
00011   private:
00012     std::shared_ptr<Cert> cert;
00013 
00014   public:
00015     Client(std::shared_ptr<Cert> cert_, bool dtls = false) :
00016       Context(true, dtls),
00017       cert(cert_)
00018     {
00019       cert->use(ssl.get(), cfg.get());
00020     }
00021   };
00022 }
00023 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/client.h...
Preprocessing /data/git/CCF/src/tls/context.h...
#include cert.h: already included! skipping...
#include entropy.h: already included! skipping...
#include error_string.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 2843 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace tls
00013 {
00014   class Context
00015   {
00016   protected:
00017     mbedtls::SSLContext ssl = nullptr;
00018     mbedtls::SSLConfig cfg = nullptr;
00019     EntropyPtr entropy;
00020 
00021 
00022     const int ciphersuites[2] = {
00023       MBEDTLS_TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, 0};
00024 
00025 
00026   public:
00027     Context(bool client, bool dgram) : entropy(tls::create_entropy())
00028     {
00029       int rc = 0;
00030 
00031       auto tmp_ssl = mbedtls::make_unique<mbedtls::SSLContext>();
00032       auto tmp_cfg = mbedtls::make_unique<mbedtls::SSLConfig>();
00033 
00034       mbedtls_ssl_conf_rng(
00035         tmp_cfg.get(), entropy->get_rng(), entropy->get_data());
00036 
00037       rc = mbedtls_ssl_config_defaults(
00038         tmp_cfg.get(),
00039         client ? MBEDTLS_SSL_IS_CLIENT : MBEDTLS_SSL_IS_SERVER,
00040         dgram ? MBEDTLS_SSL_TRANSPORT_DATAGRAM : MBEDTLS_SSL_TRANSPORT_STREAM,
00041         MBEDTLS_SSL_PRESET_DEFAULT);
00042       if (rc != 0)
00043       {
00044         throw std::logic_error(fmt::format(
00045           "mbedtls_ssl_config_defaults failed: {}", error_string(rc)));
00046       }
00047 
00048       if (!client)
00049         mbedtls_ssl_conf_ciphersuites(tmp_cfg.get(), ciphersuites);
00050 
00051 
00052       // Require TLS 1.2
00053       mbedtls_ssl_conf_min_version(
00054         tmp_cfg.get(),
00055         MBEDTLS_SSL_MAJOR_VERSION_3,
00056         MBEDTLS_SSL_MINOR_VERSION_3);
00057 
00058       rc = mbedtls_ssl_setup(tmp_ssl.get(), tmp_cfg.get());
00059       if (rc != 0)
00060       {
00061         throw std::logic_error(
00062           fmt::format("mbedtls_ssl_setup failed: {}", error_string(rc)));
00063       }
00064 
00065       ssl = std::move(tmp_ssl);
00066       cfg = std::move(tmp_cfg);
00067     }
00068 
00069     virtual ~Context() {}
00070 
00071     void set_bio(
00072       void* enclave,
00073       mbedtls_ssl_send_t send,
00074       mbedtls_ssl_recv_t recv,
00075       void (*dbg)(void*, int, const char*, int, const char*))
00076     {
00077       mbedtls_ssl_conf_dbg(cfg.get(), dbg, enclave);
00078       mbedtls_ssl_set_bio(ssl.get(), enclave, send, recv, nullptr);
00079     }
00080 
00081     int handshake()
00082     {
00083       return mbedtls_ssl_handshake(ssl.get());
00084     }
00085 
00086     size_t available_bytes()
00087     {
00088       return mbedtls_ssl_get_bytes_avail(ssl.get());
00089     }
00090 
00091     int read(uint8_t* buf, size_t len)
00092     {
00093       return mbedtls_ssl_read(ssl.get(), buf, len);
00094     }
00095 
00096     int write(const uint8_t* buf, size_t len)
00097     {
00098       return mbedtls_ssl_write(ssl.get(), buf, len);
00099     }
00100 
00101     int close()
00102     {
00103       return mbedtls_ssl_close_notify(ssl.get());
00104     }
00105 
00106     int verify_result()
00107     {
00108       return mbedtls_ssl_get_verify_result(ssl.get());
00109     }
00110 
00111     virtual std::string host()
00112     {
00113       return {};
00114     }
00115 
00116     const mbedtls_x509_crt* peer_cert()
00117     {
00118       return mbedtls_ssl_get_peer_cert(ssl.get());
00119     }
00120 
00121     void set_require_auth(bool state)
00122     {
00123       mbedtls_ssl_conf_authmode(
00124         cfg.get(),
00125         state ? MBEDTLS_SSL_VERIFY_REQUIRED : MBEDTLS_SSL_VERIFY_OPTIONAL);
00126     }
00127   };
00128 }
00129 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/context.h...
Preprocessing /data/git/CCF/src/tls/curve.h...
#include ds/logger.h: not found! skipping...
#include tls.h: already included! skipping...
#include secp256k1/include/secp256k1.h: not found! skipping...
#include secp256k1/include/secp256k1_recovery.h: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 3793 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace tls
00014 {
00015   // SNIPPET_START: supported_curves
00016   enum class CurveImpl
00017   {
00018     secp384r1 = 1,
00019     secp256k1_mbedtls = 2,
00020     secp256k1_bitcoin = 3,
00021 
00022     service_identity_curve_choice = secp384r1,
00023   };
00024   // SNIPPET_END: supported_curves
00025 
00026   // 2 implementations of secp256k1 are available - mbedtls and bitcoin. Either
00027   // can be asked for explicitly via the CurveImpl enum. For cases where we
00028   // receive a raw 256k1 key/signature/cert only, this flag determines which
00029   // implementation is used
00030   static constexpr bool prefer_bitcoin_secp256k1 = true;
00031 
00032   // Helper to access elliptic curve id from context
00033   inline mbedtls_ecp_group_id get_ec_from_context(const mbedtls_pk_context& ctx)
00034   {
00035     return mbedtls_pk_ec(ctx)->grp.id;
00036   }
00037 
00038   // Get mbedtls elliptic curve for given CCF curve implementation
00039   inline mbedtls_ecp_group_id get_ec_for_curve_impl(CurveImpl curve)
00040   {
00041     switch (curve)
00042     {
00043       case CurveImpl::secp384r1:
00044       {
00045         return MBEDTLS_ECP_DP_SECP384R1;
00046       }
00047       case CurveImpl::secp256k1_mbedtls:
00048       case CurveImpl::secp256k1_bitcoin:
00049       {
00050         return MBEDTLS_ECP_DP_SECP256K1;
00051       }
00052       default:
00053       {
00054         throw std::logic_error(
00055           "Unhandled curve type: " +
00056           std::to_string(static_cast<size_t>(curve)));
00057       }
00058     }
00059   }
00060 
00061   // Get message digest algorithm to use for given elliptic curve
00062   inline mbedtls_md_type_t get_md_for_ec(
00063     mbedtls_ecp_group_id ec, bool allow_none = false)
00064   {
00065     switch (ec)
00066     {
00067       case MBEDTLS_ECP_DP_SECP384R1:
00068       {
00069         return MBEDTLS_MD_SHA384;
00070       }
00071       case MBEDTLS_ECP_DP_SECP256K1:
00072       {
00073         return MBEDTLS_MD_SHA256;
00074       }
00075       default:
00076       {
00077         if (allow_none)
00078         {
00079           return MBEDTLS_MD_NONE;
00080         }
00081         else
00082         {
00083           const auto curve_info = mbedtls_ecp_curve_info_from_grp_id(ec);
00084           const auto error = fmt::format(
00085             "Unhandled ecp group id: {}",
00086             curve_info ? curve_info->name :
00087                          fmt::format("UNKNOWN ({})", (size_t)ec));
00088           throw std::logic_error(error);
00089         }
00090       }
00091     }
00092   }
00093 
00094   inline bool verify_secp256k_bc(
00095     secp256k1_context* ctx,
00096     const uint8_t* signature,
00097     size_t signature_size,
00098     const uint8_t* hash,
00099     size_t hash_size,
00100     const secp256k1_pubkey* public_key)
00101   {
00102     if (hash_size != 32)
00103       return false;
00104 
00105     secp256k1_ecdsa_signature sig;
00106     if (
00107       secp256k1_ecdsa_signature_parse_der(
00108         ctx, &sig, signature, signature_size) != 1)
00109       return false;
00110 
00111     secp256k1_ecdsa_signature norm_sig;
00112     if (secp256k1_ecdsa_signature_normalize(ctx, &norm_sig, &sig) == 1)
00113     {
00114       LOG_TRACE_FMT("secp256k1 normalized a signature to lower-S form");
00115     }
00116 
00117     return secp256k1_ecdsa_verify(ctx, &norm_sig, hash, public_key) == 1;
00118   }
00119 
00120   static void secp256k1_illegal_callback(const char* str, void*)
00121   {
00122     throw std::logic_error(
00123       fmt::format("[libsecp256k1] illegal argument: {}", str));
00124   }
00125 
00126   // Wrap calls to secp256k1_context_create, setting illegal callback to throw
00127   // catchable errors rather than aborting, and ensuring destroy is called when
00128   // this goes out of scope
00129   class BCk1Context
00130   {
00131   public:
00132     secp256k1_context* p = nullptr;
00133 
00134     BCk1Context(unsigned int flags)
00135     {
00136       p = secp256k1_context_create(flags);
00137 
00138       secp256k1_context_set_illegal_callback(
00139         p, secp256k1_illegal_callback, nullptr);
00140     }
00141 
00142     ~BCk1Context()
00143     {
00144       secp256k1_context_destroy(p);
00145     }
00146   };
00147 
00148   using BCk1ContextPtr = std::unique_ptr<BCk1Context>;
00149 
00150   inline BCk1ContextPtr make_bc_context(unsigned int flags)
00151   {
00152     return std::make_unique<BCk1Context>(flags);
00153   }
00154 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/curve.h...
Preprocessing /data/git/CCF/src/tls/entropy.h...
#include intel_drng.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include tls.h: already included! skipping...
#include functional: not found! skipping...
#include memory: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 1973 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 namespace tls
00014 {
00015   static bool use_drng = IntelDRNG::is_drng_supported();
00016   using EntropyPtr = std::shared_ptr<Entropy>;
00017   static EntropyPtr intel_drng_ptr;
00018   EntropyPtr create_entropy();
00019 
00020   class MbedtlsEntropy : public Entropy
00021   {
00022   private:
00023     mbedtls::Entropy entropy = mbedtls::make_unique<mbedtls::Entropy>();
00024     mbedtls::CtrDrbg drbg = mbedtls::make_unique<mbedtls::CtrDrbg>();
00025 
00026     static bool gen(uint64_t& v);
00027 
00028   public:
00029     MbedtlsEntropy()
00030     {
00031       mbedtls_ctr_drbg_seed(
00032         drbg.get(), mbedtls_entropy_func, entropy.get(), nullptr, 0);
00033     }
00034 
00035     std::vector<uint8_t> random(size_t len) override
00036     {
00037       std::vector<uint8_t> data(len);
00038 
00039       if (mbedtls_ctr_drbg_random(drbg.get(), data.data(), data.size()) != 0)
00040         throw std::logic_error("Couldn't create random data");
00041 
00042       return data;
00043     }
00044 
00045     uint64_t random64() override
00046     {
00047       uint64_t rnd;
00048       uint64_t len = sizeof(uint64_t);
00049 
00050       if (
00051         mbedtls_ctr_drbg_random(
00052           drbg.get(), reinterpret_cast<unsigned char*>(&rnd), len) != 0)
00053       {
00054         throw std::logic_error("Couldn't create random data");
00055       }
00056 
00057       return rnd;
00058     }
00059 
00060     void random(unsigned char* data, size_t len) override
00061     {
00062       if (mbedtls_ctr_drbg_random(drbg.get(), data, len) != 0)
00063         throw std::logic_error("Couldn't create random data");
00064     }
00065 
00066     static int rng(void* ctx, unsigned char* output, size_t len)
00067     {
00068       return mbedtls_ctr_drbg_random(ctx, output, len);
00069     }
00070 
00071     rng_func_t get_rng() override
00072     {
00073       return &rng;
00074     }
00075 
00076     void* get_data() override
00077     {
00078       return drbg.get();
00079     }
00080   };
00081 
00082   inline EntropyPtr create_entropy()
00083   {
00084     if (use_drng)
00085     {
00086       if (!intel_drng_ptr)
00087         intel_drng_ptr = std::make_shared<IntelDRNG>();
00088       return intel_drng_ptr;
00089     }
00090 
00091     return std::make_shared<MbedtlsEntropy>();
00092   }
00093 
00094 }
00095 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/entropy.h...
Preprocessing /data/git/CCF/src/tls/error_string.h...
#include mbedtls/error.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 367 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace tls
00009 {
00010   inline std::string error_string(int err)
00011   {
00012     constexpr size_t len = 256;
00013     char buf[len];
00014     mbedtls_strerror(err, buf, len);
00015 
00016     if (strlen(buf) == 0)
00017     {
00018       return std::to_string(err);
00019     }
00020 
00021     return std::string(buf);
00022   }
00023 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/error_string.h...
Preprocessing /data/git/CCF/src/tls/hash.h...
#include ds/logger.h: not found! skipping...
#include tls.h: already included! skipping...
#include secp256k1/include/secp256k1.h: not found! skipping...
#include secp256k1/include/secp256k1_recovery.h: not found! skipping...
#include stdexcept: not found! skipping...
#include string: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2066 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/tls/hash.h" 2
00006 
00007 
00008 
00009 namespace tls
00010 {
00011   using HashBytes = std::vector<uint8_t>;
00012 
00013   template <size_t T>
00014   using HashFixedSize = std::array<uint8_t, T>;
00015 
00016   /**
00017    * Hash the given data, with the specified digest algorithm
00018    *
00019    * @return 0 on success
00020    */
00021   inline int do_hash(
00022     const uint8_t* data_ptr,
00023     size_t data_size,
00024     HashBytes& o_hash,
00025     mbedtls_md_type_t md_type)
00026   {
00027     const auto md_info = mbedtls_md_info_from_type(md_type);
00028     const auto hash_size = mbedtls_md_get_size(md_info);
00029 
00030     if (o_hash.size() < hash_size)
00031     {
00032       o_hash.resize(hash_size);
00033     }
00034 
00035     return mbedtls_md(md_info, data_ptr, data_size, o_hash.data());
00036   }
00037 
00038   /**
00039    * Hash the given data, with the specified digest algorithm
00040    *
00041    * @return 0 on success
00042    */
00043   template <size_t T>
00044   inline int do_hash(
00045     const uint8_t* data_ptr,
00046     size_t data_size,
00047     HashFixedSize<T>& o_hash,
00048     mbedtls_md_type_t md_type)
00049   {
00050     const auto md_info = mbedtls_md_info_from_type(md_type);
00051     const auto hash_size = mbedtls_md_get_size(md_info);
00052 
00053     if (o_hash.size() != hash_size)
00054     {
00055       return -1;
00056     }
00057 
00058     return mbedtls_md(md_info, data_ptr, data_size, o_hash.data());
00059   }
00060 
00061   /**
00062    * Hash the given data, with an algorithm chosen by key type
00063    *
00064    * @return 0 on success
00065    */
00066   inline int do_hash(
00067     const mbedtls_pk_context& ctx,
00068     const uint8_t* data_ptr,
00069     size_t data_size,
00070     HashBytes& o_hash,
00071     mbedtls_md_type_t md_type_ = MBEDTLS_MD_NONE)
00072   {
00073     const auto ec = get_ec_from_context(ctx);
00074     mbedtls_md_type_t md_type;
00075     if (md_type_ != MBEDTLS_MD_NONE)
00076     {
00077       md_type = md_type_;
00078     }
00079     else
00080     {
00081       md_type = get_md_for_ec(ec);
00082     }
00083     const auto md_info = mbedtls_md_info_from_type(md_type);
00084     const auto hash_size = mbedtls_md_get_size(md_info);
00085 
00086     if (o_hash.size() < hash_size)
00087       o_hash.resize(hash_size);
00088 
00089     return mbedtls_md(md_info, data_ptr, data_size, o_hash.data());
00090   }
00091 
00092 }
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/hash.h...
Preprocessing /data/git/CCF/src/tls/intel_drng.h...
#include tls.h: already included! skipping...
#include cassert: not found! skipping...
#include utility: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 7734 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 // Adapted from:
00012 // https://software.intel.com/en-us/articles/intel-digital-random-number-generator-drng-software-implementation-guide
00013 
00014 #define DRNG_NO_SUPPORT
00015 #define DRNG_HAS_RDRAND
00016 #define DRNG_HAS_RDSEED
00017 
00018 // `It is recommended that applications attempt 10 retries in a tight loop in
00019 // the unlikely event that the RDRAND instruction does not return a random
00020 // number. This number is based on a binomial probability argument: given
00021 // the design margins of the DRNG, the odds of ten failures in a row are
00022 // astronomically small and would in fact be an indication of a larger CPU
00023 // issue.`
00024 #define RDRAND_RETRIES
00025 
00026 namespace tls
00027 {
00028   using rng_func_t = int (*)(void* ctx, unsigned char* output, size_t len);
00029 
00030   class Entropy
00031   {
00032   public:
00033     virtual void* get_data() = 0;
00034     virtual rng_func_t get_rng() = 0;
00035     virtual std::vector<uint8_t> random(size_t len) = 0;
00036     virtual void random(unsigned char* data, size_t len) = 0;
00037     virtual uint64_t random64() = 0;
00038     virtual ~Entropy() {}
00039   };
00040 
00041   class IntelDRNG : public Entropy
00042   {
00043   private:
00044     typedef struct cpuid_struct
00045     {
00046       unsigned int eax;
00047       unsigned int ebx;
00048       unsigned int ecx;
00049       unsigned int edx;
00050     } cpuid_t;
00051 
00052     static void cpuid(cpuid_t* info, unsigned int leaf, unsigned int subleaf)
00053     {
00054       asm volatile(
00055         "cpuid"
00056         : "=a"(info->eax), "=b"(info->ebx), "=c"(info->ecx), "=d"(info->edx)
00057         : "a"(leaf), "c"(subleaf));
00058     }
00059 
00060     static int _is_intel_cpu()
00061     {
00062       static int intel_cpu = -1;
00063       cpuid_t info;
00064 
00065       if (intel_cpu == -1)
00066       {
00067         cpuid(&info, 0, 0);
00068 
00069         if (
00070           memcmp((char*)&info.ebx, "Genu", 4) ||
00071           memcmp((char*)&info.edx, "ineI", 4) ||
00072           memcmp((char*)&info.ecx, "ntel", 4))
00073           intel_cpu = 0;
00074         else
00075           intel_cpu = 1;
00076       }
00077 
00078       return intel_cpu;
00079     }
00080 
00081     static int get_drng_support()
00082     {
00083       static int drng_features = -1;
00084 
00085       /* So we don't call cpuid multiple times for the same information */
00086 
00087       if (drng_features == -1)
00088       {
00089         drng_features = DRNG_NO_SUPPORT;
00090 
00091         if (_is_intel_cpu())
00092         {
00093           cpuid_t info;
00094 
00095           cpuid(&info, 1, 0);
00096 
00097           if ((info.ecx & 0x40000000) == 0x40000000)
00098             drng_features |= DRNG_HAS_RDRAND;
00099 
00100           cpuid(&info, 7, 0);
00101 
00102           if ((info.ebx & 0x40000) == 0x40000)
00103             drng_features |= DRNG_HAS_RDSEED;
00104         }
00105       }
00106 
00107       return drng_features;
00108     }
00109 
00110     static int rdrand16_step(uint16_t* rand)
00111     {
00112       unsigned char ok;
00113       asm volatile("rdrand %0; setc %1" : "=r"(*rand), "=qm"(ok));
00114       return (int)ok;
00115     }
00116 
00117     static int rdrand32_step(uint32_t* rand)
00118     {
00119       unsigned char ok;
00120       asm volatile("rdrand %0; setc %1" : "=r"(*rand), "=qm"(ok));
00121       return (int)ok;
00122     }
00123 
00124     static int rdrand64_step(uint64_t* rand)
00125     {
00126       unsigned char ok;
00127       asm volatile("rdrand %0; setc %1" : "=r"(*rand), "=qm"(ok));
00128       return (int)ok;
00129     }
00130 
00131     static int rdrand16_retry(unsigned int retries, uint16_t* rand)
00132     {
00133       unsigned int count = 0;
00134 
00135       while (count <= retries)
00136       {
00137         if (rdrand16_step(rand))
00138           return 1;
00139         ++count;
00140       }
00141 
00142       return 0;
00143     }
00144 
00145     static int rdrand32_retry(unsigned int retries, uint32_t* rand)
00146     {
00147       unsigned int count = 0;
00148 
00149       while (count <= retries)
00150       {
00151         if (rdrand32_step(rand))
00152           return 1;
00153 
00154         ++count;
00155       }
00156 
00157       return 0;
00158     }
00159 
00160     static int rdrand64_retry(unsigned int retries, uint64_t* rand)
00161     {
00162       unsigned int count = 0;
00163 
00164       while (count <= retries)
00165       {
00166         if (rdrand64_step(rand))
00167           return 1;
00168 
00169         ++count;
00170       }
00171 
00172       return 0;
00173     }
00174 
00175     static unsigned int rdrand_get_bytes(unsigned int n, unsigned char* dest)
00176     {
00177       unsigned char *headstart, *tailstart = nullptr;
00178       uint64_t* blockstart;
00179       unsigned int count, ltail, lhead, lblock;
00180       uint64_t i, temprand;
00181 
00182       /* Get the address of the first 64-bit aligned block in the
00183        * destination buffer. */
00184       headstart = dest;
00185       if (((uint64_t)headstart % (uint64_t)8) == 0)
00186       {
00187         blockstart = (uint64_t*)headstart;
00188         lblock = n;
00189         lhead = 0;
00190       }
00191       else
00192       {
00193         blockstart =
00194           (uint64_t*)(((uint64_t)headstart & ~(uint64_t)7) + (uint64_t)8);
00195         lhead = (unsigned int)((uint64_t)blockstart - (uint64_t)headstart);
00196         lblock =
00197           ((n - lhead) & ~(unsigned int)7); // cwinter: this bit is/as buggy in
00198                                             // the Intel examples.
00199       }
00200 
00201       /* Compute the number of 64-bit blocks and the remaining number
00202        * of bytes (the tail) */
00203       ltail = n - lblock - lhead;
00204       count = lblock / 8; /* The number 64-bit rands needed */
00205 
00206       assert(lhead < 8);
00207       assert(lblock <= n);
00208       assert(ltail < 8);
00209 
00210       if (ltail)
00211         tailstart = (unsigned char*)((uint64_t)blockstart + (uint64_t)lblock);
00212 
00213       /* Populate the starting, mis-aligned section (the head) */
00214       if (lhead)
00215       {
00216         if (!rdrand64_retry(RDRAND_RETRIES, &temprand))
00217           return 0;
00218         memcpy(headstart, &temprand, lhead);
00219       }
00220 
00221       /* Populate the central, aligned block */
00222       for (i = 0; i < count; ++i, ++blockstart)
00223       {
00224         if (!rdrand64_retry(RDRAND_RETRIES, blockstart))
00225           return i * 8 + lhead;
00226       }
00227 
00228       /* Populate the tail */
00229       if (ltail)
00230       {
00231         if (!rdrand64_retry(RDRAND_RETRIES, &temprand))
00232           return count * 8 + lhead;
00233         memcpy(tailstart, &temprand, ltail);
00234       }
00235 
00236       return n;
00237     }
00238 
00239     // The following three functions should be used to generate
00240     // randomness that will be used as seed for another RNG
00241     static int rdseed16_step(uint16_t* seed)
00242     {
00243       unsigned char ok;
00244       asm volatile("rdseed %0; setc %1" : "=r"(*seed), "=qm"(ok));
00245       return (int)ok;
00246     }
00247 
00248     static int rdseed32_step(uint32_t* seed)
00249     {
00250       unsigned char ok;
00251       asm volatile("rdseed %0; setc %1" : "=r"(*seed), "=qm"(ok));
00252       return (int)ok;
00253     }
00254 
00255     static int rdseed64_step(uint64_t* seed)
00256     {
00257       unsigned char ok;
00258       asm volatile("rdseed %0; setc %1" : "=r"(*seed), "=qm"(ok));
00259       return (int)ok;
00260     }
00261 
00262   public:
00263     IntelDRNG()
00264     {
00265       if (!is_drng_supported())
00266         throw std::logic_error("No support for RDRAND / RDSEED on this CPU.");
00267     }
00268 
00269     std::vector<uint8_t> random(size_t len) override
00270     {
00271       std::vector<uint8_t> buf(len);
00272 
00273       if (rdrand_get_bytes(buf.size(), buf.data()) < buf.size())
00274         throw std::logic_error("Couldn't create random data");
00275 
00276       return buf;
00277     }
00278 
00279     uint64_t random64() override
00280     {
00281       uint64_t rnd;
00282       uint64_t len = sizeof(uint64_t);
00283 
00284       if (rdrand_get_bytes(len, reinterpret_cast<unsigned char*>(&rnd)) < len)
00285       {
00286         throw std::logic_error("Couldn't create random data");
00287       }
00288 
00289       return rnd;
00290     }
00291 
00292     void random(unsigned char* data, size_t len) override
00293     {
00294       if (rdrand_get_bytes(len, data) < len)
00295         throw std::logic_error("Couldn't create random data");
00296     }
00297 
00298     static int rng(void*, unsigned char* output, size_t len)
00299     {
00300       if (rdrand_get_bytes(len, output) < len)
00301         throw std::logic_error("Couldn't create random data");
00302       return 0;
00303     }
00304 
00305     rng_func_t get_rng() override
00306     {
00307       return &rng;
00308     }
00309 
00310     void* get_data() override
00311     {
00312       return this;
00313     }
00314 
00315     static bool is_drng_supported()
00316     {
00317       return (get_drng_support() & (DRNG_HAS_RDRAND | DRNG_HAS_RDSEED)) ==
00318         (DRNG_HAS_RDRAND | DRNG_HAS_RDSEED);
00319     }
00320   };
00321 }
00322 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/intel_drng.h...
Preprocessing /data/git/CCF/src/tls/key_exchange.h...
#include ds/logger.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include tls/error_string.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include mbedtls/ecdh.h: not found! skipping...
Preprocessor output (size: 3006 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 namespace tls
00015 {
00016   class KeyExchangeContext
00017   {
00018   private:
00019     mbedtls::ECDHContext ctx = nullptr;
00020     std::vector<uint8_t> own_public;
00021     tls::EntropyPtr entropy;
00022 
00023   public:
00024     static constexpr mbedtls_ecp_group_id domain_parameter =
00025       MBEDTLS_ECP_DP_SECP384R1;
00026 
00027     static constexpr size_t len_public = 1024 + 1;
00028     static constexpr size_t len_shared_secret = 1024;
00029 
00030     KeyExchangeContext() : own_public(len_public), entropy(create_entropy())
00031     {
00032       auto tmp_ctx = mbedtls::make_unique<mbedtls::ECDHContext>();
00033       size_t len;
00034 
00035       int rc = mbedtls_ecp_group_load(&tmp_ctx->grp, domain_parameter);
00036 
00037       if (rc != 0)
00038       {
00039         throw std::logic_error(error_string(rc));
00040       }
00041 
00042       rc = mbedtls_ecdh_make_public(
00043         tmp_ctx.get(),
00044         &len,
00045         own_public.data(),
00046         own_public.size(),
00047         entropy->get_rng(),
00048         entropy->get_data());
00049 
00050       if (rc != 0)
00051       {
00052         throw std::logic_error(error_string(rc));
00053       }
00054 
00055       own_public.resize(len);
00056 
00057       ctx = std::move(tmp_ctx);
00058     }
00059 
00060     KeyExchangeContext(KeyPairPtr own_kp, PublicKeyPtr peer_pubk) :
00061       entropy(create_entropy())
00062     {
00063       auto tmp_ctx = mbedtls::make_unique<mbedtls::ECDHContext>();
00064 
00065       int rc = mbedtls_ecdh_get_params(
00066         tmp_ctx.get(),
00067         mbedtls_pk_ec(*own_kp->get_raw_context()),
00068         MBEDTLS_ECDH_OURS);
00069       if (rc != 0)
00070       {
00071         throw std::logic_error(error_string(rc));
00072       }
00073 
00074       rc = mbedtls_ecdh_get_params(
00075         tmp_ctx.get(),
00076         mbedtls_pk_ec(*peer_pubk->get_raw_context()),
00077         MBEDTLS_ECDH_THEIRS);
00078       if (rc != 0)
00079       {
00080         throw std::logic_error(error_string(rc));
00081       }
00082 
00083       ctx = std::move(tmp_ctx);
00084     }
00085 
00086     void free_ctx()
00087     {
00088       // Should only be called when shared secret has been computed.
00089       ctx.reset();
00090     }
00091 
00092     ~KeyExchangeContext()
00093     {
00094       free_ctx();
00095     }
00096 
00097     std::vector<uint8_t> get_own_public()
00098     {
00099       // Note that this function returns a vector of bytes
00100       // where the first byte represents the
00101       // size of the public key
00102       return own_public;
00103     }
00104 
00105     void load_peer_public(const uint8_t* bytes, size_t size)
00106     {
00107       int rc = mbedtls_ecdh_read_public(ctx.get(), bytes, size);
00108       if (rc != 0)
00109       {
00110         throw std::logic_error(error_string(rc));
00111       }
00112     }
00113 
00114     std::vector<uint8_t> compute_shared_secret()
00115     {
00116       // Should only be called once, when peer public has been loaded.
00117       std::vector<uint8_t> shared_secret(len_shared_secret);
00118       size_t len;
00119       int rc = mbedtls_ecdh_calc_secret(
00120         ctx.get(),
00121         &len,
00122         shared_secret.data(),
00123         shared_secret.size(),
00124         entropy->get_rng(),
00125         entropy->get_data());
00126       if (rc != 0)
00127       {
00128         throw std::logic_error(error_string(rc));
00129       }
00130 
00131       shared_secret.resize(len);
00132 
00133       return shared_secret;
00134     }
00135   };
00136 }
00137 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/key_exchange.h...
Preprocessing /data/git/CCF/src/tls/key_pair.h...
#include ds/net.h: not found! skipping...
#include tls/san.h: not found! skipping...
#include fmt/format.h: not found! skipping...
#include mbedtls/asn1write.h: not found! skipping...
#include mbedtls/oid.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include string: not found! skipping...
#include curve.h: already included! skipping...
#include entropy.h: already included! skipping...
#include error_string.h: already included! skipping...
#include curve.h: already included! skipping...
#include vector: not found! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include pem.h: already included! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
#include cstring: not found! skipping...
#include iomanip: not found! skipping...
#include limits: not found! skipping...
#include mbedtls/bignum.h: not found! skipping...
#include mbedtls/pem.h: not found! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 23208 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/tls/key_pair.h" 2
00006 
00007 
00008 
00009 # 9 "/data/git/CCF/src/tls/key_pair.h" 2
00010 
00011 
00012 # 12 "/data/git/CCF/src/tls/key_pair.h" 2
00013 
00014 
00015 
00016 
00017 
00018 
00019 
00020 
00021 namespace tls
00022 {
00023   static constexpr size_t ecp_num_size = 100;
00024   static constexpr size_t max_pem_key_size = 2048;
00025 
00026   inline void parse_secp256k_bc(
00027     const mbedtls_pk_context& ctx,
00028     secp256k1_context* bc_ctx,
00029     secp256k1_pubkey* bc_pub)
00030   {
00031     auto k = mbedtls_pk_ec(ctx);
00032     size_t pub_len;
00033     uint8_t pub_buf[ecp_num_size];
00034 
00035     int rc = mbedtls_ecp_point_write_binary(
00036       &k->grp,
00037       &k->Q,
00038       MBEDTLS_ECP_PF_COMPRESSED,
00039       &pub_len,
00040       pub_buf,
00041       ecp_num_size);
00042     if (rc != 0)
00043     {
00044       throw std::logic_error(
00045         "mbedtls_ecp_point_write_binary failed: " + error_string(rc));
00046     }
00047 
00048     rc = secp256k1_ec_pubkey_parse(bc_ctx, bc_pub, pub_buf, pub_len);
00049     if (rc != 1)
00050     {
00051       throw std::logic_error("secp256k1_ec_pubkey_parse failed");
00052     }
00053   }
00054 
00055   struct RecoverableSignature
00056   {
00057     // Signature consists of 32 byte R, 32 byte S, and recovery id. Some formats
00058     // concatenate all 3 into 65 bytes. We stick with libsecp256k1 and separate
00059     // 64 bytes of (R, S) from recovery_id.
00060     static constexpr size_t RS_Size = 64;
00061     std::array<uint8_t, RS_Size> raw;
00062     int recovery_id;
00063   };
00064 
00065   class PublicKey
00066   {
00067   protected:
00068     mbedtls::PKContext ctx = mbedtls::make_unique<mbedtls::PKContext>();
00069 
00070     PublicKey() {}
00071 
00072   public:
00073     /**
00074      * Construct from a pre-initialised pk context
00075      */
00076     PublicKey(mbedtls::PKContext&& c) : ctx(std::move(c)) {}
00077 
00078     virtual ~PublicKey() = default;
00079 
00080     /**
00081      * Verify that a signature was produced on contents with the private key
00082      * associated with the public key held by the object.
00083      *
00084      * @param contents Sequence of bytes that was signed
00085      * @param signature Signature as a sequence of bytes
00086      *
00087      * @return Whether the signature matches the contents and the key
00088      */
00089     bool verify(
00090       const std::vector<uint8_t>& contents,
00091       const std::vector<uint8_t>& signature)
00092     {
00093       return verify(
00094         contents.data(), contents.size(), signature.data(), signature.size());
00095     }
00096 
00097     /**
00098      * Verify that a signature was produced on contents with the private key
00099      * associated with the public key held by the object.
00100      *
00101      * @param contents address of contents
00102      * @param contents_size size of contents
00103      * @param sig address of signature
00104      * @param sig_size size of signature
00105      * @param md_type Digest algorithm to use. Derived from the
00106      * public key if MBEDTLS_MD_NONE.
00107      *
00108      * @return Whether the signature matches the contents and the key
00109      */
00110     bool verify(
00111       const uint8_t* contents,
00112       size_t contents_size,
00113       const uint8_t* sig,
00114       size_t sig_size,
00115       mbedtls_md_type_t md_type = MBEDTLS_MD_NONE)
00116     {
00117       HashBytes hash;
00118       do_hash(*ctx, contents, contents_size, hash, md_type);
00119 
00120       return verify_hash(hash.data(), hash.size(), sig, sig_size);
00121     }
00122 
00123     /**
00124      * Verify that a signature was produced on a hash with the private key
00125      * associated with the public key held by the object.
00126      *
00127      * @param hash Hash produced from contents as a sequence of bytes
00128      * @param signature Signature as a sequence of bytes
00129      *
00130      * @return Whether the signature matches the hash and the key
00131      */
00132     bool verify_hash(
00133       const std::vector<uint8_t>& hash, const std::vector<uint8_t>& signature)
00134     {
00135       return verify_hash(
00136         hash.data(), hash.size(), signature.data(), signature.size());
00137     }
00138 
00139     virtual bool verify_hash(
00140       const uint8_t* hash,
00141       size_t hash_size,
00142       const uint8_t* sig,
00143       size_t sig_size)
00144     {
00145       const auto md_type = get_md_for_ec(get_ec_from_context(*ctx));
00146 
00147       int rc =
00148         mbedtls_pk_verify(ctx.get(), md_type, hash, hash_size, sig, sig_size);
00149 
00150       if (rc)
00151         LOG_DEBUG_FMT("Failed to verify signature: {}", error_string(rc));
00152 
00153       return rc == 0;
00154     }
00155 
00156     /**
00157      * Get the public key in PEM format
00158      */
00159     Pem public_key_pem()
00160     {
00161       uint8_t data[max_pem_key_size];
00162 
00163       int rc = mbedtls_pk_write_pubkey_pem(ctx.get(), data, max_pem_key_size);
00164       if (rc != 0)
00165       {
00166         throw std::logic_error(
00167           "mbedtls_pk_write_pubkey_pem: " + error_string(rc));
00168       }
00169 
00170       const size_t len = strlen((char const*)data);
00171       return Pem(data, len);
00172     }
00173 
00174     mbedtls_pk_context* get_raw_context() const
00175     {
00176       return ctx.get();
00177     }
00178   };
00179 
00180   class PublicKey_k1Bitcoin : public PublicKey
00181   {
00182   protected:
00183     BCk1ContextPtr bc_ctx = make_bc_context(SECP256K1_CONTEXT_VERIFY);
00184 
00185     secp256k1_pubkey bc_pub;
00186 
00187   public:
00188     template <typename... Ts>
00189     PublicKey_k1Bitcoin(Ts... ts) : PublicKey(std::forward<Ts>(ts)...)
00190     {
00191       parse_secp256k_bc(*ctx, bc_ctx->p, &bc_pub);
00192     }
00193 
00194     bool verify_hash(
00195       const uint8_t* hash,
00196       size_t hash_size,
00197       const uint8_t* sig,
00198       size_t sig_size) override
00199     {
00200       return verify_secp256k_bc(
00201         bc_ctx->p, sig, sig_size, hash, hash_size, &bc_pub);
00202     }
00203 
00204     static PublicKey_k1Bitcoin recover_key(
00205       const RecoverableSignature& rs, CBuffer hashed)
00206     {
00207       int rc;
00208 
00209       size_t buf_len = 65;
00210       std::array<uint8_t, 65> buf;
00211 
00212       if (hashed.n != 32)
00213       {
00214         throw std::logic_error(
00215           fmt::format("Expected {} bytes in hash, got {}", 32, hashed.n));
00216       }
00217 
00218       // Recover with libsecp256k1
00219       {
00220         auto ctx = make_bc_context(SECP256K1_CONTEXT_VERIFY);
00221 
00222         secp256k1_ecdsa_recoverable_signature sig;
00223         rc = secp256k1_ecdsa_recoverable_signature_parse_compact(
00224           ctx->p, &sig, rs.raw.data(), rs.recovery_id);
00225         if (rc != 1)
00226         {
00227           throw std::logic_error(
00228             "secp256k1_ecdsa_recoverable_signature_parse_compact failed");
00229         }
00230 
00231         secp256k1_pubkey pubk;
00232         rc = secp256k1_ecdsa_recover(ctx->p, &pubk, &sig, hashed.p);
00233         if (rc != 1)
00234         {
00235           throw std::logic_error("secp256k1_ecdsa_recover failed");
00236         }
00237 
00238         rc = secp256k1_ec_pubkey_serialize(
00239           ctx->p, buf.data(), &buf_len, &pubk, SECP256K1_EC_UNCOMPRESSED);
00240         if (rc != 1)
00241         {
00242           throw std::logic_error("secp256k1_ec_pubkey_serialize failed");
00243         }
00244       }
00245 
00246       // Read recovered key into mbedtls context
00247       {
00248         auto pk_info = mbedtls_pk_info_from_type(MBEDTLS_PK_ECKEY);
00249         if (pk_info == nullptr)
00250         {
00251           throw std::logic_error("mbedtls_pk_info_t not found");
00252         }
00253 
00254         auto ctx = mbedtls::make_unique<mbedtls::PKContext>();
00255 
00256         rc = mbedtls_pk_setup(ctx.get(), pk_info);
00257         if (rc != 0)
00258         {
00259           throw std::logic_error(
00260             "mbedtls_pk_setup failed with: " + error_string(rc));
00261         }
00262 
00263         auto kp = mbedtls_pk_ec(*ctx);
00264 
00265         rc = mbedtls_ecp_group_load(&kp->grp, MBEDTLS_ECP_DP_SECP256K1);
00266         if (rc != 0)
00267         {
00268           throw std::logic_error(
00269             "mbedtls_ecp_group_load failed with: " + error_string(rc));
00270         }
00271 
00272         rc = mbedtls_ecp_point_read_binary(
00273           &kp->grp, &kp->Q, buf.data(), buf.size());
00274         if (rc != 0)
00275         {
00276           throw std::logic_error(
00277             "mbedtls_ecp_point_read_binary failed with: " + error_string(rc));
00278         }
00279 
00280         rc = mbedtls_ecp_check_pubkey(&kp->grp, &kp->Q);
00281         if (rc != 0)
00282         {
00283           throw std::logic_error(
00284             "mbedtls_ecp_check_pubkey failed with: " + error_string(rc));
00285         }
00286 
00287         return PublicKey_k1Bitcoin(std::move(ctx));
00288       }
00289     }
00290   };
00291 
00292   using PublicKeyPtr = std::shared_ptr<PublicKey>;
00293 
00294   /**
00295    * Construct PublicKey from a raw public key in PEM format
00296    *
00297    * @param public_pem Sequence of bytes containing the key in PEM format
00298    * @param use_bitcoin_impl If true, and the key is on secp256k1, then the
00299    * bitcoin secp256k1 library will be used as the implementation rather than
00300    * mbedtls
00301    */
00302   inline PublicKeyPtr make_public_key(
00303     const Pem& public_pem, bool use_bitcoin_impl = prefer_bitcoin_secp256k1)
00304   {
00305     auto ctx = mbedtls::make_unique<mbedtls::PKContext>();
00306 
00307     int rc = mbedtls_pk_parse_public_key(
00308       ctx.get(), public_pem.data(), public_pem.size());
00309 
00310     if (rc != 0)
00311     {
00312       throw std::logic_error(fmt::format(
00313         "Could not parse public key PEM: {}\n\n(Key: {})",
00314         error_string(rc),
00315         public_pem.str()));
00316     }
00317 
00318     const auto curve = get_ec_from_context(*ctx);
00319 
00320     if (curve == MBEDTLS_ECP_DP_SECP256K1 && use_bitcoin_impl)
00321     {
00322       return std::make_shared<PublicKey_k1Bitcoin>(std::move(ctx));
00323     }
00324     else
00325     {
00326       return std::make_shared<PublicKey>(std::move(ctx));
00327     }
00328   }
00329 
00330   /**
00331    * Construct PublicKey from a raw public key in DER format
00332    *
00333    * @param public_der Sequence of bytes containing the key in DER format
00334    * @param use_bitcoin_impl If true, and the key is on secp256k1, then the
00335    * bitcoin secp256k1 library will be used as the implementation rather than
00336    * mbedtls
00337    */
00338   inline PublicKeyPtr make_public_key(
00339     const std::vector<uint8_t> public_der,
00340     bool use_bitcoin_impl = prefer_bitcoin_secp256k1)
00341   {
00342     auto ctx = mbedtls::make_unique<mbedtls::PKContext>();
00343 
00344     int rc = mbedtls_pk_parse_public_key(
00345       ctx.get(), public_der.data(), public_der.size());
00346 
00347     if (rc != 0)
00348     {
00349       throw std::logic_error(
00350         fmt::format("Could not parse public key DER: {}", error_string(rc)));
00351     }
00352 
00353     const auto curve = get_ec_from_context(*ctx);
00354 
00355     if (curve == MBEDTLS_ECP_DP_SECP256K1 && use_bitcoin_impl)
00356     {
00357       return std::make_shared<PublicKey_k1Bitcoin>(std::move(ctx));
00358     }
00359     else
00360     {
00361       return std::make_shared<PublicKey>(std::move(ctx));
00362     }
00363   }
00364 
00365   class KeyPair : public PublicKey
00366   {
00367   public:
00368     /**
00369      * Create a new public / private ECDSA key pair
00370      */
00371     KeyPair(mbedtls_ecp_group_id ec)
00372     {
00373       EntropyPtr entropy = create_entropy();
00374 
00375       int rc = mbedtls_pk_setup(
00376         ctx.get(), mbedtls_pk_info_from_type(MBEDTLS_PK_ECKEY));
00377       if (rc != 0)
00378       {
00379         throw std::logic_error(
00380           "Could not set up ECDSA context: " + error_string(rc));
00381       }
00382 
00383       rc = mbedtls_ecp_gen_key(
00384         ec, mbedtls_pk_ec(*ctx), entropy->get_rng(), entropy->get_data());
00385       if (rc != 0)
00386       {
00387         throw std::logic_error(
00388           "Could not generate ECDSA keypair: " + error_string(rc));
00389       }
00390 
00391       const auto actual_ec = get_ec_from_context(*ctx);
00392       if (actual_ec != ec)
00393       {
00394         throw std::logic_error(
00395           "Created key and received unexpected type: " +
00396           std::to_string(actual_ec) + " != " + error_string(ec));
00397       }
00398     }
00399 
00400     /**
00401      * Initialise from existing pre-parsed key
00402      */
00403     KeyPair(mbedtls::PKContext&& k) : PublicKey(std::move(k)) {}
00404 
00405     KeyPair(const KeyPair&) = delete;
00406 
00407   public:
00408     /**
00409      * Get the private key in PEM format
00410      */
00411     Pem private_key_pem()
00412     {
00413       uint8_t data[max_pem_key_size];
00414 
00415       int rc = mbedtls_pk_write_key_pem(ctx.get(), data, max_pem_key_size);
00416       if (rc != 0)
00417       {
00418         throw std::logic_error("mbedtls_pk_write_key_pem: " + error_string(rc));
00419       }
00420 
00421       const size_t len = strlen((char const*)data);
00422       return Pem(data, len);
00423     }
00424 
00425     /**
00426      * Create signature over hash of data from private key.
00427      *
00428      * @param d data
00429      *
00430      * @return Signature as a vector
00431      */
00432     std::vector<uint8_t> sign(CBuffer d, mbedtls_md_type_t md_type = {}) const
00433     {
00434       HashBytes hash;
00435       do_hash(*ctx, d.p, d.rawSize(), hash, md_type);
00436 
00437       return sign_hash(hash.data(), hash.size());
00438     }
00439 
00440     /**
00441      * Write signature over hash of data, and the size of that signature to
00442      * specified locations.
00443      *
00444      * Important: sig must point somewhere that's at least
00445      * MBEDTLS_E{C,D}DSA_MAX_LEN.
00446      *
00447      * @param d data
00448      * @param sig_size location to which the signature size will be written.
00449      * Initial value should be max size of sig
00450      * @param sig location to which the signature will be written
00451      *
00452      * @return 0 if successful, error code of mbedtls_pk_sign otherwise,
00453      *         or 0xf if the signature_size exceeds that of a uint8_t.
00454      */
00455     int sign(
00456       CBuffer d,
00457       size_t* sig_size,
00458       uint8_t* sig,
00459       mbedtls_md_type_t md_type = {}) const
00460     {
00461       HashBytes hash;
00462       do_hash(*ctx, d.p, d.rawSize(), hash, md_type);
00463 
00464       return sign_hash(hash.data(), hash.size(), sig_size, sig);
00465     }
00466 
00467     /**
00468      * Create signature over hashed data.
00469      *
00470      * @param hash First byte in hash sequence
00471      * @param hash_size Number of bytes in hash sequence
00472      *
00473      * @return Signature as a vector
00474      */
00475     std::vector<uint8_t> sign_hash(const uint8_t* hash, size_t hash_size) const
00476     {
00477       uint8_t sig[MBEDTLS_ECDSA_MAX_LEN];
00478 
00479       size_t written = MBEDTLS_ECDSA_MAX_LEN;
00480       if (sign_hash(hash, hash_size, &written, sig) != 0)
00481       {
00482         return {};
00483       }
00484 
00485       return {sig, sig + written};
00486     }
00487 
00488     virtual int sign_hash(
00489       const uint8_t* hash,
00490       size_t hash_size,
00491       size_t* sig_size,
00492       uint8_t* sig) const
00493     {
00494       EntropyPtr entropy = create_entropy();
00495 
00496       const auto ec = get_ec_from_context(*ctx);
00497       const auto md_type = get_md_for_ec(ec, true);
00498 
00499       return mbedtls_pk_sign(
00500         ctx.get(),
00501         md_type,
00502         hash,
00503         hash_size,
00504         sig,
00505         sig_size,
00506         entropy->get_rng(),
00507         entropy->get_data());
00508     }
00509 
00510     /**
00511      * Create a certificate signing request for this key pair. If we were
00512      * loaded from a private key, there will be no public key available for
00513      * this call.
00514      */
00515     Pem create_csr(const std::string& name)
00516     {
00517       auto csr = mbedtls::make_unique<mbedtls::X509WriteCsr>();
00518       mbedtls_x509write_csr_set_md_alg(csr.get(), MBEDTLS_MD_SHA512);
00519 
00520       if (mbedtls_x509write_csr_set_subject_name(csr.get(), name.c_str()) != 0)
00521         return {};
00522 
00523       mbedtls_x509write_csr_set_key(csr.get(), ctx.get());
00524 
00525       uint8_t buf[4096];
00526       memset(buf, 0, sizeof(buf));
00527       EntropyPtr entropy = create_entropy();
00528 
00529       if (
00530         mbedtls_x509write_csr_pem(
00531           csr.get(),
00532           buf,
00533           sizeof(buf),
00534           entropy->get_rng(),
00535           entropy->get_data()) != 0)
00536         return {};
00537 
00538       auto len = strlen((char*)buf);
00539       return Pem(buf, len);
00540     }
00541 
00542     Pem sign_csr(
00543       const Pem& pem,
00544       const std::string& issuer,
00545       const std::vector<SubjectAltName> subject_alt_names,
00546       bool ca = false)
00547     {
00548       auto entropy = create_entropy();
00549       auto csr = mbedtls::make_unique<mbedtls::X509Csr>();
00550       auto serial = mbedtls::make_unique<mbedtls::MPI>();
00551       auto crt = mbedtls::make_unique<mbedtls::X509WriteCrt>();
00552 
00553       if (mbedtls_x509_csr_parse(csr.get(), pem.data(), pem.size()) != 0)
00554         return {};
00555 
00556       char subject[512];
00557       auto r = mbedtls_x509_dn_gets(subject, sizeof(subject), &csr->subject);
00558 
00559       if (r < 0)
00560         return {};
00561 
00562       mbedtls_x509write_crt_set_md_alg(
00563         crt.get(), get_md_for_ec(get_ec_from_context(*ctx)));
00564       mbedtls_x509write_crt_set_subject_key(crt.get(), &csr->pk);
00565       mbedtls_x509write_crt_set_issuer_key(crt.get(), ctx.get());
00566 
00567       if (
00568         mbedtls_mpi_fill_random(
00569           serial.get(), 16, entropy->get_rng(), entropy->get_data()) != 0)
00570         return {};
00571 
00572       if (mbedtls_x509write_crt_set_subject_name(crt.get(), subject) != 0)
00573         return {};
00574 
00575       if (mbedtls_x509write_crt_set_issuer_name(crt.get(), issuer.c_str()) != 0)
00576         return {};
00577 
00578       if (mbedtls_x509write_crt_set_serial(crt.get(), serial.get()) != 0)
00579         return {};
00580 
00581       // Note: 825-day validity range
00582       // https://support.apple.com/en-us/HT210176
00583       if (
00584         mbedtls_x509write_crt_set_validity(
00585           crt.get(), "20191101000000", "20211231235959") != 0)
00586         return {};
00587 
00588       if (
00589         mbedtls_x509write_crt_set_basic_constraints(crt.get(), ca ? 1 : 0, 0) !=
00590         0)
00591         return {};
00592 
00593       if (mbedtls_x509write_crt_set_subject_key_identifier(crt.get()) != 0)
00594         return {};
00595 
00596       if (mbedtls_x509write_crt_set_authority_key_identifier(crt.get()) != 0)
00597         return {};
00598 
00599       // Because mbedtls does not support parsing x509v3 extensions from a
00600       // CSR (https://github.com/ARMmbed/mbedtls/issues/2912), the CA sets the
00601       // SAN directly instead of reading it from the CSR
00602       try
00603       {
00604         auto rc =
00605           x509write_crt_set_subject_alt_names(crt.get(), subject_alt_names);
00606         if (rc != 0)
00607         {
00608           LOG_FAIL_FMT("Failed to set subject alternative names ({})", rc);
00609           return {};
00610         }
00611       }
00612       catch (const std::logic_error& err)
00613       {
00614         LOG_FAIL_FMT("Error writing SAN: {}", err.what());
00615         return {};
00616       }
00617 
00618       uint8_t buf[4096];
00619       memset(buf, 0, sizeof(buf));
00620 
00621       if (
00622         mbedtls_x509write_crt_pem(
00623           crt.get(),
00624           buf,
00625           sizeof(buf),
00626           entropy->get_rng(),
00627           entropy->get_data()) != 0)
00628         return {};
00629 
00630       auto len = strlen((char*)buf);
00631       return Pem(buf, len);
00632     }
00633 
00634     Pem self_sign(
00635       const std::string& name,
00636       const std::optional<SubjectAltName> subject_alt_name = std::nullopt,
00637       bool ca = true)
00638     {
00639       std::vector<SubjectAltName> sans;
00640       if (subject_alt_name.has_value())
00641         sans.push_back(subject_alt_name.value());
00642       auto csr = create_csr(name);
00643       return sign_csr(csr, name, sans, ca);
00644     }
00645 
00646     Pem self_sign(
00647       const std::string& name,
00648       const std::vector<SubjectAltName> subject_alt_names,
00649       bool ca = true)
00650     {
00651       auto csr = create_csr(name);
00652       return sign_csr(csr, name, subject_alt_names, ca);
00653     }
00654   };
00655 
00656   class KeyPair_k1Bitcoin : public KeyPair
00657   {
00658   protected:
00659     BCk1ContextPtr bc_ctx =
00660       make_bc_context(SECP256K1_CONTEXT_VERIFY | SECP256K1_CONTEXT_SIGN);
00661 
00662     secp256k1_pubkey bc_pub;
00663 
00664     static constexpr size_t privk_size = 32;
00665     uint8_t c4_priv[privk_size] = {0};
00666 
00667   public:
00668     template <typename... Ts>
00669     KeyPair_k1Bitcoin(Ts... ts) : KeyPair(std::forward<Ts>(ts)...)
00670     {
00671       const auto ec = get_ec_from_context(*ctx);
00672       if (ec != MBEDTLS_ECP_DP_SECP256K1)
00673       {
00674         throw std::logic_error(
00675           "Bitcoin implementation cannot extend curve on " +
00676           std::to_string(ec));
00677       }
00678 
00679       int rc = 0;
00680 
00681       rc = mbedtls_mpi_write_binary(
00682         &(mbedtls_pk_ec(*ctx)->d), c4_priv, privk_size);
00683       if (rc != 0)
00684       {
00685         throw std::logic_error(
00686           "Could not extract raw private key: " + error_string(rc));
00687       }
00688 
00689       if (secp256k1_ec_seckey_verify(bc_ctx->p, c4_priv) != 1)
00690       {
00691         throw std::logic_error("secp256k1 private key is not valid");
00692       }
00693 
00694       parse_secp256k_bc(*ctx, bc_ctx->p, &bc_pub);
00695     }
00696 
00697     // Since this inherits from PublicKey (via Keypair), rather than
00698     // PublicKey_k1Bitcoin, we re-override verify_hash here
00699     bool verify_hash(
00700       const uint8_t* hash,
00701       size_t hash_size,
00702       const uint8_t* signature,
00703       size_t signature_size) override
00704     {
00705       bool ok = verify_secp256k_bc(
00706         bc_ctx->p, signature, signature_size, hash, hash_size, &bc_pub);
00707 
00708       return ok;
00709     }
00710 
00711     int sign_hash(
00712       const uint8_t* hash,
00713       size_t hash_size,
00714       size_t* sig_size,
00715       uint8_t* sig) const override
00716     {
00717       if (hash_size != 32)
00718         return -1;
00719 
00720       secp256k1_ecdsa_signature k1_sig;
00721       if (
00722         secp256k1_ecdsa_sign(
00723           bc_ctx->p, &k1_sig, hash, c4_priv, nullptr, nullptr) != 1)
00724         return -2;
00725 
00726       if (
00727         secp256k1_ecdsa_signature_serialize_der(
00728           bc_ctx->p, sig, sig_size, &k1_sig) != 1)
00729         return -3;
00730 
00731       return 0;
00732     }
00733 
00734     RecoverableSignature sign_recoverable_hashed(CBuffer hashed)
00735     {
00736       int rc;
00737 
00738       if (hashed.n != 32)
00739       {
00740         throw std::logic_error(
00741           fmt::format("Expected {} bytes in hash, got {}", 32, hashed.n));
00742       }
00743 
00744       secp256k1_ecdsa_recoverable_signature sig;
00745       rc = secp256k1_ecdsa_sign_recoverable(
00746         bc_ctx->p, &sig, hashed.p, c4_priv, nullptr, nullptr);
00747       if (rc != 1)
00748       {
00749         throw std::logic_error("secp256k1_ecdsa_sign_recoverable failed");
00750       }
00751 
00752       RecoverableSignature ret;
00753       rc = secp256k1_ecdsa_recoverable_signature_serialize_compact(
00754         bc_ctx->p, ret.raw.data(), &ret.recovery_id, &sig);
00755       if (rc != 1)
00756       {
00757         throw std::logic_error(
00758           "secp256k1_ecdsa_recoverable_signature_serialize_compact failed");
00759       }
00760 
00761       return ret;
00762     }
00763   };
00764 
00765   using KeyPairPtr = std::shared_ptr<KeyPair>;
00766 
00767   inline mbedtls::PKContext parse_private_key(
00768     const Pem& pkey, CBuffer pw = nullb)
00769   {
00770     auto key = mbedtls::make_unique<mbedtls::PKContext>();
00771 
00772     // keylen is +1 to include terminating null byte
00773     int rc =
00774       mbedtls_pk_parse_key(key.get(), pkey.data(), pkey.size(), pw.p, pw.n);
00775     if (rc != 0)
00776     {
00777       throw std::logic_error("Could not parse key: " + error_string(rc));
00778     }
00779 
00780     return key;
00781   }
00782 
00783   /**
00784    * Create a new public / private ECDSA key pair on specified curve and
00785    * implementation
00786    */
00787   inline KeyPairPtr make_key_pair(
00788     CurveImpl curve = CurveImpl::service_identity_curve_choice)
00789   {
00790     const auto ec = get_ec_for_curve_impl(curve);
00791     if (curve == CurveImpl::secp256k1_bitcoin)
00792     {
00793       return KeyPairPtr(new KeyPair_k1Bitcoin(ec));
00794     }
00795     else
00796     {
00797       return KeyPairPtr(new KeyPair(ec));
00798     }
00799   }
00800 
00801   /**
00802    * Create a public / private ECDSA key pair from existing private key data
00803    */
00804   inline KeyPairPtr make_key_pair(
00805     const Pem& pkey,
00806     CBuffer pw = nullb,
00807     bool use_bitcoin_impl = prefer_bitcoin_secp256k1)
00808   {
00809     auto key = parse_private_key(pkey, pw);
00810 
00811     const auto curve = get_ec_from_context(*key);
00812 
00813     if (curve == MBEDTLS_ECP_DP_SECP256K1 && use_bitcoin_impl)
00814     {
00815       return std::make_shared<KeyPair_k1Bitcoin>(std::move(key));
00816     }
00817     else
00818     {
00819       return std::make_shared<KeyPair>(std::move(key));
00820     }
00821   }
00822 
00823   static inline tls::Pem public_key_pem_from_cert(const tls::Pem& cert)
00824   {
00825     auto c = mbedtls::make_unique<mbedtls::X509Crt>();
00826     int rc = mbedtls_x509_crt_parse(c.get(), cert.data(), cert.size());
00827     if (rc != 0)
00828     {
00829       throw std::runtime_error(fmt::format(
00830         "Failed to parse certificate, mbedtls_x509_crt_parse: {}", rc));
00831     }
00832     uint8_t data[2048];
00833     rc = mbedtls_pk_write_pubkey_pem(&c->pk, data, max_pem_key_size);
00834     if (rc != 0)
00835     {
00836       throw std::runtime_error(fmt::format(
00837         "Failed to serialise public key, mbedtls_pk_write_pubkey_pem: {}", rc));
00838     }
00839 
00840     size_t len = strlen((char const*)data);
00841     return tls::Pem(data, len);
00842   }
00843 
00844   inline void check_is_cert(CBuffer der)
00845   {
00846     mbedtls_x509_crt cert;
00847     mbedtls_x509_crt_init(&cert);
00848     int rc = mbedtls_x509_crt_parse(&cert, der.p, der.n);
00849     mbedtls_x509_crt_free(&cert);
00850     if (rc != 0)
00851     {
00852       throw std::invalid_argument(fmt::format(
00853         "Failed to parse certificate, mbedtls_x509_crt_parse: {}",
00854         tls::error_string(rc)));
00855     }
00856   }
00857 }
00858 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED FMT_HEADER_ONLY DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/key_pair.h...
Preprocessing /data/git/CCF/src/tls/mbedtls_wrappers.h...
#include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/gcm.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/sha256.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include mbedtls/x509.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include mbedtls/x509_csr.h: not found! skipping...
#include memory: not found! skipping...
Preprocessor output (size: 1939 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 namespace mbedtls
00017 {
00018   template <typename T>
00019   T make_unique();
00020 
00021   #define DEFINE_MBEDTLS_WRAPPER( NEW_TYPE, MBED_TYPE, MBED_INIT_FN, MBED_FREE_FN) 
00022 
00023 
00024 
00025 
00026 
00027 
00028 
00029 
00030 
00031 
00032 
00033 
00034 
00035 
00036 
00037 
00038 
00039 
00040   DEFINE_MBEDTLS_WRAPPER(
00041     CtrDrbg,
00042     mbedtls_ctr_drbg_context,
00043     mbedtls_ctr_drbg_init,
00044     mbedtls_ctr_drbg_free);
00045   DEFINE_MBEDTLS_WRAPPER(
00046     ECDHContext, mbedtls_ecdh_context, mbedtls_ecdh_init, mbedtls_ecdh_free);
00047   DEFINE_MBEDTLS_WRAPPER(
00048     Entropy,
00049     mbedtls_entropy_context,
00050     mbedtls_entropy_init,
00051     mbedtls_entropy_free);
00052   DEFINE_MBEDTLS_WRAPPER(
00053     GcmContext, mbedtls_gcm_context, mbedtls_gcm_init, mbedtls_gcm_free);
00054   DEFINE_MBEDTLS_WRAPPER(MPI, mbedtls_mpi, mbedtls_mpi_init, mbedtls_mpi_free);
00055   DEFINE_MBEDTLS_WRAPPER(
00056     NetContext, mbedtls_net_context, mbedtls_net_init, mbedtls_net_free);
00057   DEFINE_MBEDTLS_WRAPPER(
00058     PKContext, mbedtls_pk_context, mbedtls_pk_init, mbedtls_pk_free);
00059   DEFINE_MBEDTLS_WRAPPER(
00060     SSLConfig,
00061     mbedtls_ssl_config,
00062     mbedtls_ssl_config_init,
00063     mbedtls_ssl_config_free);
00064   DEFINE_MBEDTLS_WRAPPER(
00065     SSLContext, mbedtls_ssl_context, mbedtls_ssl_init, mbedtls_ssl_free);
00066   DEFINE_MBEDTLS_WRAPPER(
00067     X509Crl, mbedtls_x509_crl, mbedtls_x509_crl_init, mbedtls_x509_crl_free);
00068   DEFINE_MBEDTLS_WRAPPER(
00069     X509Crt, mbedtls_x509_crt, mbedtls_x509_crt_init, mbedtls_x509_crt_free);
00070   DEFINE_MBEDTLS_WRAPPER(
00071     X509Csr, mbedtls_x509_csr, mbedtls_x509_csr_init, mbedtls_x509_csr_free);
00072   DEFINE_MBEDTLS_WRAPPER(
00073     X509WriteCrt,
00074     mbedtls_x509write_cert,
00075     mbedtls_x509write_crt_init,
00076     mbedtls_x509write_crt_free);
00077   DEFINE_MBEDTLS_WRAPPER(
00078     X509WriteCsr,
00079     mbedtls_x509write_csr,
00080     mbedtls_x509write_csr_init,
00081     mbedtls_x509write_csr_free);
00082   DEFINE_MBEDTLS_WRAPPER(
00083     SHA256Ctx,
00084     mbedtls_sha256_context,
00085     mbedtls_sha256_init,
00086     mbedtls_sha256_free);
00087 
00088 
00089 }
---------
Macros accessible in this file:
---------
DEFINE_MBEDTLS_WRAPPER 
---------
Parsing file /data/git/CCF/src/tls/mbedtls_wrappers.h...
Preprocessing /data/git/CCF/src/tls/msg_types.h...
#include ../ds/ring_buffer_types.h: already included! skipping...
Preprocessor output (size: 1861 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace tls
00008 {
00009   using ConnID = size_t;
00010 
00011   /// TLS-related ringbuffer messages
00012   /// The body of each message will begin with a connection ID
00013   enum : ringbuffer::Message
00014   {
00015     /// New connection has been opened. This will always be the first message
00016     /// sent regarding a connection. Host -> Enclave
00017     DEFINE_RINGBUFFER_MSG_TYPE(tls_start),
00018 
00019     /// Request for a new connection to a remote peer. Enclave -> Host
00020     DEFINE_RINGBUFFER_MSG_TYPE(tls_connect),
00021 
00022     /// Data read from socket, to be read inside enclave. Host -> Enclave
00023     DEFINE_RINGBUFFER_MSG_TYPE(tls_inbound),
00024 
00025     /// Data sent from the enclave, to be written to socket. Enclave -> Host
00026     DEFINE_RINGBUFFER_MSG_TYPE(tls_outbound),
00027 
00028     /// While processing data, the enclave decided this connection is stopped.
00029     /// Enclave -> Host
00030     DEFINE_RINGBUFFER_MSG_TYPE(tls_stop),
00031 
00032     /// Connection has been invalidated. No more messages will be sent regarding
00033     /// this connection. Host -> Enclave
00034     DEFINE_RINGBUFFER_MSG_TYPE(tls_close),
00035 
00036     /// Enclave session has been deleted. Host can now safely remove the
00037     /// corresponding connection. Enclave -> Host
00038     DEFINE_RINGBUFFER_MSG_TYPE(tls_closed),
00039   };
00040 }
00041 
00042 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(tls::tls_start, tls::ConnID);
00043 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00044   tls::tls_connect, tls::ConnID, std::string, std::string);
00045 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00046   tls::tls_inbound, tls::ConnID, serializer::ByteRange);
00047 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(
00048   tls::tls_outbound, tls::ConnID, serializer::ByteRange);
00049 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(tls::tls_stop, tls::ConnID, std::string);
00050 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(tls::tls_close, tls::ConnID);
00051 DECLARE_RINGBUFFER_MESSAGE_PAYLOAD(tls::tls_closed, tls::ConnID);
---------
Macros accessible in this file:
---------
RINGBUFFER_TRY_WRITE_MESSAGE DEFINE_RINGBUFFER_MSG_TYPE RINGBUFFER_WRITE_MESSAGE DECLARE_RINGBUFFER_MESSAGE_NO_PAYLOAD DECLARE_RINGBUFFER_MESSAGE_PAYLOAD 
---------
Parsing file /data/git/CCF/src/tls/msg_types.h...
Preprocessing /data/git/CCF/src/tls/pem.h...
#include ds/buffer.h: not found! skipping...
#include ds/json.h: not found! skipping...
#include tls.h: already included! skipping...
#include cstring: not found! skipping...
#include exception: not found! skipping...
#include memory: not found! skipping...
#include msgpack/msgpack.hpp: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 2107 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 namespace tls
00016 {
00017   // Convenience class ensuring null termination of PEM-encoded certificates as
00018   // required by mbedTLS
00019   class Pem
00020   {
00021     std::string s;
00022 
00023   public:
00024     Pem() = default;
00025 
00026     Pem(const std::string& s_) : s(s_) {}
00027 
00028     Pem(size_t size) : s(size, '0') {}
00029 
00030     Pem(const uint8_t* data, size_t size)
00031     {
00032       if (size == 0)
00033         throw std::logic_error("Got PEM of size 0.");
00034 
00035       // If it's already null-terminated, don't suffix again
00036       const auto null_terminated = *(data + size - 1) == 0;
00037       if (null_terminated)
00038         size -= 1;
00039 
00040       s.assign(reinterpret_cast<const char*>(data), size);
00041     }
00042 
00043     Pem(const CBuffer& b) : Pem(b.p, b.n) {}
00044 
00045     Pem(const std::vector<uint8_t>& v) : Pem(v.data(), v.size()) {}
00046 
00047     bool operator==(const Pem& rhs) const
00048     {
00049       return s == rhs.s;
00050     }
00051 
00052     bool operator!=(const Pem& rhs) const
00053     {
00054       return !(*this == rhs);
00055     }
00056 
00057     const std::string& str() const
00058     {
00059       return s;
00060     }
00061 
00062     uint8_t* data()
00063     {
00064       return reinterpret_cast<uint8_t*>(s.data());
00065     }
00066 
00067     const uint8_t* data() const
00068     {
00069       return reinterpret_cast<const uint8_t*>(s.data());
00070     }
00071 
00072     size_t size() const
00073     {
00074       // +1 for null termination
00075       return s.size() + 1;
00076     }
00077 
00078     bool empty() const
00079     {
00080       return s.empty();
00081     }
00082 
00083     std::vector<uint8_t> raw() const
00084     {
00085       return {data(), data() + size()};
00086     }
00087 
00088     // Not null-terminated
00089     std::vector<uint8_t> contents() const
00090     {
00091       return {data(), data() + s.size()};
00092     }
00093 
00094     MSGPACK_DEFINE(s);
00095   };
00096 
00097   inline void to_json(nlohmann::json& j, const Pem& p)
00098   {
00099     j = p.str();
00100   }
00101 
00102   inline void from_json(const nlohmann::json& j, Pem& p)
00103   {
00104     if (j.is_string())
00105     {
00106       p = Pem(j.get<std::string>());
00107     }
00108     else if (j.is_array())
00109     {
00110       p = Pem(j.get<std::vector<uint8_t>>());
00111     }
00112     else
00113     {
00114       throw std::runtime_error(
00115         fmt::format("Unable to parse pem from this JSON: {}", j.dump()));
00116     }
00117   }
00118 }
00119 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/pem.h...
Preprocessing /data/git/CCF/src/tls/random_bytes.h...
#include entropy.h: already included! skipping...
#include stddef.h: not found! skipping...
Preprocessor output (size: 234 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 void randombytes(void* buf, size_t n)
00011 {
00012   auto entropy = tls::create_entropy();
00013   entropy->random((unsigned char*)buf, n);
00014 }
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/random_bytes.h...
Reading /data/git/CCF/src/tls/README.md...
Preprocessing /data/git/CCF/src/tls/rsa_key_pair.h...
#include asn1_san.h: already included! skipping...
#include curve.h: already included! skipping...
#include entropy.h: already included! skipping...
#include error_string.h: already included! skipping...
#include hash.h: already included! skipping...
#include mbedtls_wrappers.h: already included! skipping...
#include pem.h: already included! skipping...
#include san.h: already included! skipping...
#include cstring: not found! skipping...
#include iomanip: not found! skipping...
#include limits: not found! skipping...
#include mbedtls/bignum.h: not found! skipping...
#include mbedtls/pem.h: not found! skipping...
#include memory: not found! skipping...
#include optional: not found! skipping...
#include vector: not found! skipping...
Preprocessor output (size: 6665 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 # 5 "/data/git/CCF/src/tls/rsa_key_pair.h" 2
00006 
00007 
00008 
00009 
00010 namespace tls
00011 {
00012   // Compatible with Azure HSM encryption schemes (see
00013   // https://docs.microsoft.com/en-gb/azure/key-vault/keys/about-keys#wrapkeyunwrapkey-encryptdecrypt)
00014   static constexpr auto rsa_padding_mode = MBEDTLS_RSA_PKCS_V21;
00015   static constexpr auto rsa_padding_digest_id = MBEDTLS_MD_SHA256;
00016 
00017   class RSAPublicKey : public PublicKey
00018   {
00019   public:
00020     RSAPublicKey() = default;
00021 
00022     RSAPublicKey(mbedtls::PKContext&& c) : PublicKey(std::move(c)) {}
00023 
00024     /**
00025      * Wrap data using RSA-OAEP-256
00026      *
00027      * @param input Pointer to raw data to wrap
00028      * @param input_size Size of raw data
00029      * @param label Optional string used as label during wrapping
00030      * @param label Optional string used as label during wrapping
00031      *
00032      * @return Wrapped data
00033      */
00034     std::vector<uint8_t> wrap(
00035       const uint8_t* input,
00036       size_t input_size,
00037       const uint8_t* label = nullptr,
00038       size_t label_size = 0)
00039     {
00040       mbedtls_rsa_context* rsa_ctx = mbedtls_pk_rsa(*ctx.get());
00041       mbedtls_rsa_set_padding(rsa_ctx, rsa_padding_mode, rsa_padding_digest_id);
00042 
00043       std::vector<uint8_t> output_buf(rsa_ctx->len);
00044       auto entropy = tls::create_entropy();
00045 
00046       // Note that the maximum input size to wrap is k - 2*hLen - 2
00047       // where hLen is the hash size (32 bytes = SHA256) and
00048       // k the wrapping key modulus size (e.g. 256 bytes = 2048 bits).
00049       // In this example, it would be 190 bytes (1520 bits) max.
00050       // This is enough for wrapping AES keys for example.
00051       auto rc = mbedtls_rsa_rsaes_oaep_encrypt(
00052         rsa_ctx,
00053         entropy->get_rng(),
00054         entropy->get_data(),
00055         MBEDTLS_RSA_PUBLIC,
00056         label,
00057         label_size,
00058         input_size,
00059         input,
00060         output_buf.data());
00061       if (rc != 0)
00062       {
00063         throw std::logic_error(
00064           fmt::format("Error during RSA OEAP wrap: {}", error_string(rc)));
00065       }
00066 
00067       return output_buf;
00068     }
00069 
00070     /**
00071      * Wrap data using RSA-OAEP-256
00072      *
00073      * @param input Raw data to wrap
00074      * @param label Optional string used as label during wrapping
00075      *
00076      * @return Wrapped data
00077      */
00078     std::vector<uint8_t> wrap(
00079       const std::vector<uint8_t>& input,
00080       std::optional<std::string> label = std::nullopt)
00081     {
00082       const unsigned char* label_ = NULL;
00083       size_t label_size = 0;
00084       if (label.has_value())
00085       {
00086         label_ = reinterpret_cast<const unsigned char*>(label->c_str());
00087         label_size = label->size();
00088       }
00089 
00090       return wrap(input.data(), input.size(), label_, label_size);
00091     }
00092   };
00093 
00094   class RSAKeyPair : public RSAPublicKey
00095   {
00096   public:
00097     static constexpr size_t default_public_key_size = 2048;
00098     static constexpr size_t default_public_exponent = 65537;
00099 
00100     /**
00101      * Create a new public / private RSA key pair
00102      */
00103     RSAKeyPair(
00104       size_t public_key_size = default_public_key_size,
00105       size_t public_exponent = default_public_exponent)
00106     {
00107       EntropyPtr entropy = create_entropy();
00108 
00109       int rc =
00110         mbedtls_pk_setup(ctx.get(), mbedtls_pk_info_from_type(MBEDTLS_PK_RSA));
00111       if (rc != 0)
00112       {
00113         throw std::logic_error(
00114           "Could not set up RSA context: " + error_string(rc));
00115       }
00116 
00117       rc = mbedtls_rsa_gen_key(
00118         mbedtls_pk_rsa(*ctx.get()),
00119         entropy->get_rng(),
00120         entropy->get_data(),
00121         public_key_size,
00122         public_exponent);
00123       if (rc != 0)
00124       {
00125         throw std::logic_error(
00126           "Could not generate RSA keypair: " + error_string(rc));
00127       }
00128     }
00129 
00130     RSAKeyPair(mbedtls::PKContext&& k) : RSAPublicKey(std::move(k)) {}
00131 
00132     RSAKeyPair(const RSAKeyPair&) = delete;
00133 
00134     /**
00135      * Unwrap data using RSA-OAEP-256
00136      *
00137      * @param input Raw data to unwrap
00138      * @param label Optional string used as label during unwrapping
00139      *
00140      * @return Unwrapped data
00141      */
00142     std::vector<uint8_t> unwrap(
00143       const std::vector<uint8_t>& input,
00144       std::optional<std::string> label = std::nullopt)
00145     {
00146       mbedtls_rsa_context* rsa_ctx = mbedtls_pk_rsa(*ctx.get());
00147       mbedtls_rsa_set_padding(rsa_ctx, rsa_padding_mode, rsa_padding_digest_id);
00148 
00149       std::vector<uint8_t> output_buf(rsa_ctx->len);
00150       auto entropy = tls::create_entropy();
00151 
00152       const unsigned char* label_ = NULL;
00153       size_t label_size = 0;
00154       if (label.has_value())
00155       {
00156         label_ = reinterpret_cast<const unsigned char*>(label->c_str());
00157         label_size = label->size();
00158       }
00159 
00160       size_t olen;
00161       auto rc = mbedtls_rsa_rsaes_oaep_decrypt(
00162         rsa_ctx,
00163         entropy->get_rng(),
00164         entropy->get_data(),
00165         MBEDTLS_RSA_PRIVATE,
00166         label_,
00167         label_size,
00168         &olen,
00169         input.data(),
00170         output_buf.data(),
00171         output_buf.size());
00172       if (rc != 0)
00173       {
00174         throw std::logic_error(
00175           fmt::format("Error during RSA OEAP unwrap: {}", error_string(rc)));
00176       }
00177 
00178       output_buf.resize(olen);
00179       return output_buf;
00180     }
00181   };
00182 
00183   using RSAKeyPairPtr = std::shared_ptr<RSAKeyPair>;
00184   using RSAPublicKeyPtr = std::shared_ptr<RSAPublicKey>;
00185 
00186   /**
00187    * Create a new public / private RSA key pair with specified size and exponent
00188    */
00189   inline RSAKeyPairPtr make_rsa_key_pair(
00190     size_t public_key_size = RSAKeyPair::default_public_key_size,
00191     size_t public_exponent = RSAKeyPair::default_public_exponent)
00192   {
00193     return RSAKeyPairPtr(new RSAKeyPair(public_key_size, public_exponent));
00194   }
00195 
00196   /**
00197    * Create a public / private RSA key pair from existing private key data
00198    */
00199   inline RSAKeyPairPtr make_rsa_key_pair(const Pem& pkey, CBuffer pw = nullb)
00200   {
00201     auto key = parse_private_key(pkey, pw);
00202     return std::make_shared<RSAKeyPair>(std::move(key));
00203   }
00204 
00205   inline RSAPublicKeyPtr make_rsa_public_key(
00206     const uint8_t* public_pem_data, size_t public_pem_size)
00207   {
00208     auto ctx = mbedtls::make_unique<mbedtls::PKContext>();
00209 
00210     int rc =
00211       mbedtls_pk_parse_public_key(ctx.get(), public_pem_data, public_pem_size);
00212     if (rc != 0)
00213     {
00214       throw std::logic_error(
00215         fmt::format("Could not parse public key PEM: {}", error_string(rc)));
00216     }
00217 
00218     if (ctx->pk_info != mbedtls_pk_info_from_type(MBEDTLS_PK_RSA))
00219     {
00220       throw std::logic_error(
00221         "Could not make RSA public key as PEM does not appear to be valid RSA");
00222     }
00223 
00224     return std::make_shared<RSAPublicKey>(std::move(ctx));
00225   }
00226 
00227   inline RSAPublicKeyPtr make_rsa_public_key(const Pem& public_pem)
00228   {
00229     return make_rsa_public_key(public_pem.data(), public_pem.size());
00230   }
00231 }
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED FMT_HEADER_ONLY DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/rsa_key_pair.h...
Preprocessing /data/git/CCF/src/tls/san.h...
#include msgpack/msgpack.hpp: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 229 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 namespace tls
00009 {
00010   struct SubjectAltName
00011   {
00012     std::string san;
00013     bool is_ip;
00014 
00015     MSGPACK_DEFINE(san, is_ip);
00016   };
00017 }
00018 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/san.h...
Preprocessing /data/git/CCF/src/tls/server.h...
#include context.h: already included! skipping...
Preprocessor output (size: 378 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 namespace tls
00008 {
00009   class Server : public Context
00010   {
00011   private:
00012     std::shared_ptr<Cert> cert;
00013 
00014   public:
00015     Server(std::shared_ptr<Cert> cert_, bool dtls = false) :
00016       Context(false, dtls),
00017       cert(cert_)
00018     {
00019       cert->use(ssl.get(), cfg.get());
00020     }
00021   };
00022 }
00023 
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/server.h...
Preprocessing /data/git/CCF/src/tls/test/bench.cpp...
#include ../key_pair.h: already included! skipping...
#include picobench/picobench.hpp: not found! skipping...
Preprocessor output (size: 6901 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define PICOBENCH_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 using namespace std;
00009 
00010 static const string lorem_ipsum =
00011   "Lorem ipsum dolor sit amet, consectetur adipiscing "
00012   "elit, sed do eiusmod tempor incididunt ut labore et"
00013   " dolore magna aliqua. Ut enim ad minim veniam, quis"
00014   " nostrud exercitation ullamco laboris nisi ut "
00015   "aliquip ex ea commodo consequat. Duis aute irure "
00016   "dolor in reprehenderit in voluptate velit esse "
00017   "cillum dolore eu fugiat nulla pariatur. Excepteur "
00018   "sint occaecat cupidatat non proident, sunt in culpa "
00019   "qui officia deserunt mollit anim id est laborum.";
00020 
00021 template <class A>
00022 inline void do_not_optimize(A const& value)
00023 {
00024   asm volatile("" : : "r,m"(value) : "memory");
00025 }
00026 
00027 inline void clobber_memory()
00028 {
00029   asm volatile("" : : : "memory");
00030 }
00031 
00032 template <size_t NBytes>
00033 vector<uint8_t> make_contents()
00034 {
00035   vector<uint8_t> contents(NBytes);
00036   size_t written = 0;
00037   while (written < NBytes)
00038   {
00039     const auto write_size = min(lorem_ipsum.size(), NBytes - written);
00040     memcpy(contents.data() + written, lorem_ipsum.data(), write_size);
00041     written += write_size;
00042   }
00043   return contents;
00044 }
00045 
00046 template <tls::CurveImpl Curve, size_t NContents>
00047 static void benchmark_sign(picobench::state& s)
00048 {
00049   auto kp = tls::make_key_pair(Curve);
00050   const auto contents = make_contents<NContents>();
00051 
00052   s.start_timer();
00053   for (auto _ : s)
00054   {
00055     (void)_;
00056     auto signature = kp->sign(contents);
00057     do_not_optimize(signature);
00058     clobber_memory();
00059   }
00060   s.stop_timer();
00061 }
00062 
00063 template <tls::CurveImpl Curve, size_t NContents>
00064 static void benchmark_verify(picobench::state& s)
00065 {
00066   auto kp = tls::make_key_pair(Curve);
00067   const auto contents = make_contents<NContents>();
00068 
00069   auto signature = kp->sign(contents);
00070 
00071   const auto public_key = kp->public_key_pem();
00072   auto pubk = tls::make_public_key(
00073     public_key, Curve == tls::CurveImpl::secp256k1_bitcoin);
00074 
00075   s.start_timer();
00076   for (auto _ : s)
00077   {
00078     (void)_;
00079     auto verified = kp->verify(contents, signature);
00080     do_not_optimize(verified);
00081     clobber_memory();
00082   }
00083   s.stop_timer();
00084 }
00085 
00086 template <tls::CurveImpl Curve, size_t NContents>
00087 static void benchmark_hash(picobench::state& s)
00088 {
00089   auto kp = tls::make_key_pair(Curve);
00090   const auto contents = make_contents<NContents>();
00091 
00092   s.start_timer();
00093   for (auto _ : s)
00094   {
00095     (void)_;
00096     std::vector<uint8_t> hash;
00097     tls::do_hash(
00098       *kp->get_raw_context(), contents.data(), contents.size(), hash);
00099     do_not_optimize(hash);
00100     clobber_memory();
00101   }
00102   s.stop_timer();
00103 }
00104 
00105 const std::vector<int> sizes = {1};
00106 
00107 using namespace tls;
00108 
00109 #define PICO_SUFFIX(CURVE) 
00110 
00111 
00112 
00113 PICOBENCH_SUITE("sign");
00114 namespace
00115 {
00116   auto sign_384_1byte = benchmark_sign<CurveImpl::secp384r1, 1>;
00117   PICOBENCH(sign_384_1byte).PICO_SUFFIX(CurveImpl::secp384r1);
00118   auto sign_256k1_mbed_1byte = benchmark_sign<CurveImpl::secp256k1_mbedtls, 1>;
00119   PICOBENCH(sign_256k1_mbed_1byte).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00120   auto sign_256k1_bitc_1byte = benchmark_sign<CurveImpl::secp256k1_bitcoin, 1>;
00121   PICOBENCH(sign_256k1_bitc_1byte).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00122 
00123   auto sign_384_1k = benchmark_sign<CurveImpl::secp384r1, 1024>;
00124   PICOBENCH(sign_384_1k).PICO_SUFFIX(CurveImpl::secp384r1);
00125   auto sign_256k1_mbed_1k = benchmark_sign<CurveImpl::secp256k1_mbedtls, 1024>;
00126   PICOBENCH(sign_256k1_mbed_1k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00127   auto sign_256k1_bitc_1k = benchmark_sign<CurveImpl::secp256k1_bitcoin, 1024>;
00128   PICOBENCH(sign_256k1_bitc_1k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00129 
00130   auto sign_384_100k = benchmark_sign<CurveImpl::secp384r1, 102400>;
00131   PICOBENCH(sign_384_100k).PICO_SUFFIX(CurveImpl::secp384r1);
00132   auto sign_256k1_mbed_100k =
00133     benchmark_sign<CurveImpl::secp256k1_mbedtls, 102400>;
00134   PICOBENCH(sign_256k1_mbed_100k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00135   auto sign_256k1_bitc_100k =
00136     benchmark_sign<CurveImpl::secp256k1_bitcoin, 102400>;
00137   PICOBENCH(sign_256k1_bitc_100k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00138 }
00139 
00140 PICOBENCH_SUITE("verify");
00141 namespace
00142 {
00143   auto verify_384_1byte = benchmark_verify<CurveImpl::secp384r1, 1>;
00144   PICOBENCH(verify_384_1byte).PICO_SUFFIX(CurveImpl::secp384r1);
00145   auto verify_256k1_mbed_1byte =
00146     benchmark_verify<CurveImpl::secp256k1_mbedtls, 1>;
00147   PICOBENCH(verify_256k1_mbed_1byte).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00148   auto verify_256k1_bitc_1byte =
00149     benchmark_verify<CurveImpl::secp256k1_bitcoin, 1>;
00150   PICOBENCH(verify_256k1_bitc_1byte).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00151 
00152   auto verify_384_1k = benchmark_verify<CurveImpl::secp384r1, 1024>;
00153   PICOBENCH(verify_384_1k).PICO_SUFFIX(CurveImpl::secp384r1);
00154   auto verify_256k1_mbed_1k =
00155     benchmark_verify<CurveImpl::secp256k1_mbedtls, 1024>;
00156   PICOBENCH(verify_256k1_mbed_1k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00157   auto verify_256k1_bitc_1k =
00158     benchmark_verify<CurveImpl::secp256k1_bitcoin, 1024>;
00159   PICOBENCH(verify_256k1_bitc_1k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00160 
00161   auto verify_384_100k = benchmark_verify<CurveImpl::secp384r1, 102400>;
00162   PICOBENCH(verify_384_100k).PICO_SUFFIX(CurveImpl::secp384r1);
00163   auto verify_256k1_mbed_100k =
00164     benchmark_verify<CurveImpl::secp256k1_mbedtls, 102400>;
00165   PICOBENCH(verify_256k1_mbed_100k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00166   auto verify_256k1_bitc_100k =
00167     benchmark_verify<CurveImpl::secp256k1_bitcoin, 102400>;
00168   PICOBENCH(verify_256k1_bitc_100k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00169 }
00170 
00171 PICOBENCH_SUITE("hash");
00172 namespace
00173 {
00174   auto hash_384_1byte = benchmark_hash<CurveImpl::secp384r1, 1>;
00175   PICOBENCH(hash_384_1byte).PICO_SUFFIX(CurveImpl::secp384r1);
00176   auto hash_256k1_mbed_1byte = benchmark_hash<CurveImpl::secp256k1_mbedtls, 1>;
00177   PICOBENCH(hash_256k1_mbed_1byte).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00178   auto hash_256k1_bitc_1byte = benchmark_hash<CurveImpl::secp256k1_bitcoin, 1>;
00179   PICOBENCH(hash_256k1_bitc_1byte).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00180 
00181   auto hash_384_1k = benchmark_hash<CurveImpl::secp384r1, 1024>;
00182   PICOBENCH(hash_384_1k).PICO_SUFFIX(CurveImpl::secp384r1);
00183   auto hash_256k1_mbed_1k = benchmark_hash<CurveImpl::secp256k1_mbedtls, 1024>;
00184   PICOBENCH(hash_256k1_mbed_1k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00185   auto hash_256k1_bitc_1k = benchmark_hash<CurveImpl::secp256k1_bitcoin, 1024>;
00186   PICOBENCH(hash_256k1_bitc_1k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00187 
00188   auto hash_384_100k = benchmark_hash<CurveImpl::secp384r1, 102400>;
00189   PICOBENCH(hash_384_100k).PICO_SUFFIX(CurveImpl::secp384r1);
00190   auto hash_256k1_mbed_100k =
00191     benchmark_hash<CurveImpl::secp256k1_mbedtls, 102400>;
00192   PICOBENCH(hash_256k1_mbed_100k).PICO_SUFFIX(CurveImpl::secp256k1_mbedtls);
00193   auto hash_256k1_bitc_100k =
00194     benchmark_hash<CurveImpl::secp256k1_bitcoin, 102400>;
00195   PICOBENCH(hash_256k1_bitc_100k).PICO_SUFFIX(CurveImpl::secp256k1_bitcoin);
00196 }
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER PICOBENCH_IMPLEMENT_WITH_MAIN DRNG_HAS_RDSEED PICO_SUFFIX FMT_HEADER_ONLY DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/test/bench.cpp...
Preprocessing /data/git/CCF/src/tls/test/cert.cpp...
#include ds/nonstd.h: not found! skipping...
#include tls/san.h: not found! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
#include optional: not found! skipping...
#include fmt/format.h: not found! skipping...
#include ../key_pair.h: already included! skipping...
#include CLI11/CLI11.hpp: not found! skipping...
Preprocessor output (size: 892 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 # 3 "/data/git/CCF/src/tls/test/cert.cpp" 2
00004 
00005 
00006 
00007 
00008 int main(int argc, char** argv)
00009 {
00010   CLI::App app{"Cert creation"};
00011   std::string subject_name;
00012   app
00013     .add_option(
00014       "--sn", subject_name, "Subject Name in node certificate, eg. CN=CCF Node")
00015     ->capture_default_str();
00016 
00017   std::vector<tls::SubjectAltName> subject_alternative_names;
00018   cli::add_subject_alternative_name_option(
00019     app,
00020     subject_alternative_names,
00021     "--san",
00022     "Subject Alternative Name in node certificate. Can be either "
00023     "iPAddress:xxx.xxx.xxx.xxx, or dNSName:sub.domain.tld");
00024   CLI11_PARSE(app, argc, argv);
00025 
00026   auto kp = tls::make_key_pair();
00027   auto cert = kp->sign_csr(
00028     kp->create_csr(subject_name), subject_name, subject_alternative_names);
00029 
00030   std::cout << cert.str() << std::endl;
00031   return 0;
00032 }
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED FMT_HEADER_ONLY DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/test/cert.cpp...
Preprocessing /data/git/CCF/src/tls/test/key_exchange.cpp...
#include ds/logger.h: not found! skipping...
#include tls/entropy.h: not found! skipping...
#include tls/error_string.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include iostream: not found! skipping...
#include map: not found! skipping...
#include mbedtls/ecdh.h: not found! skipping...
#include doctest/doctest.h: not found! skipping...
Preprocessor output (size: 2287 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 # 5 "/data/git/CCF/src/tls/test/key_exchange.cpp" 2
00006 
00007 
00008 
00009 TEST_CASE("Simple key exchange")
00010 {
00011   INFO("Try to compute shared secret before peer public have been exchanged");
00012   {
00013     // These key exchange contexts should not be used after negative testing.
00014     tls::KeyExchangeContext peer1_ctx, peer2_ctx;
00015 
00016     // Cannot compute the shared secret until the peer's public has been
00017     // loaded
00018     REQUIRE_THROWS_AS(peer1_ctx.compute_shared_secret(), std::logic_error);
00019     REQUIRE_THROWS_AS(peer2_ctx.compute_shared_secret(), std::logic_error);
00020 
00021     // Trying to load empty peer's public
00022     std::vector<uint8_t> empty_peer;
00023     REQUIRE_THROWS_AS(
00024       peer1_ctx.load_peer_public(empty_peer.data(), empty_peer.size()),
00025       std::logic_error);
00026     REQUIRE_THROWS_AS(
00027       peer2_ctx.load_peer_public(empty_peer.data(), empty_peer.size()),
00028       std::logic_error);
00029 
00030     REQUIRE_THROWS_AS(peer1_ctx.compute_shared_secret(), std::logic_error);
00031     REQUIRE_THROWS_AS(peer2_ctx.compute_shared_secret(), std::logic_error);
00032   }
00033 
00034   INFO("Compute shared secret");
00035   {
00036     tls::KeyExchangeContext peer1_ctx, peer2_ctx;
00037     auto peer1_public = peer1_ctx.get_own_public();
00038     auto peer2_public = peer2_ctx.get_own_public();
00039 
00040     auto peer1_public_ = peer1_ctx.get_own_public();
00041     auto peer2_public_ = peer2_ctx.get_own_public();
00042 
00043     // Calling get_own_public() should always return the same result
00044     REQUIRE(peer1_public == peer1_public_);
00045     REQUIRE(peer2_public == peer2_public_);
00046 
00047     peer1_ctx.load_peer_public(peer2_public.data(), peer2_public.size());
00048     peer2_ctx.load_peer_public(peer1_public.data(), peer1_public.size());
00049 
00050     auto peer1_secret = peer1_ctx.compute_shared_secret();
00051     auto peer2_secret = peer2_ctx.compute_shared_secret();
00052 
00053     REQUIRE(peer1_secret == peer2_secret);
00054   }
00055 }
00056 
00057 TEST_CASE("Key exchange from static shares")
00058 {
00059   auto peer1_kp = tls::make_key_pair();
00060   auto peer2_kp = tls::make_key_pair();
00061 
00062   auto peer1_ctx = tls::KeyExchangeContext(peer1_kp, peer2_kp);
00063   auto peer2_ctx = tls::KeyExchangeContext(peer2_kp, peer1_kp);
00064 
00065   REQUIRE(
00066     peer1_ctx.compute_shared_secret() == peer2_ctx.compute_shared_secret());
00067 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/tls/test/key_exchange.cpp...
Preprocessing /data/git/CCF/src/tls/test/main.cpp...
#include tls/base64.h: not found! skipping...
#include tls/key_pair.h: not found! skipping...
#include tls/rsa_key_pair.h: not found! skipping...
#include tls/verifier.h: not found! skipping...
#include chrono: not found! skipping...
#include doctest/doctest.h: not found! skipping...
#include string: not found! skipping...
Preprocessor output (size: 12680 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 #define DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 using namespace std;
00014 
00015 static const string contents_ =
00016   "Lorem ipsum dolor sit amet, consectetur adipiscing "
00017   "elit, sed do eiusmod tempor incididunt ut labore et"
00018   " dolore magna aliqua. Ut enim ad minim veniam, quis"
00019   " nostrud exercitation ullamco laboris nisi ut "
00020   "aliquip ex ea commodo consequat. Duis aute irure "
00021   "dolor in reprehenderit in voluptate velit esse "
00022   "cillum dolore eu fugiat nulla pariatur. Excepteur "
00023   "sint occaecat cupidatat non proident, sunt in culpa "
00024   "qui officia deserunt mollit anim id est laborum.";
00025 
00026 template <typename T>
00027 void corrupt(T& buf)
00028 {
00029   buf[1]++;
00030   buf[buf.size() / 2]++;
00031   buf[buf.size() - 2]++;
00032 }
00033 
00034 static constexpr tls::CurveImpl supported_curves[] = {
00035   tls::CurveImpl::secp384r1,
00036   tls::CurveImpl::secp256k1_mbedtls,
00037   tls::CurveImpl::secp256k1_bitcoin};
00038 
00039 static constexpr char const* labels[] = {
00040   "secp384r1", "secp256k1_mbedtls", "secp256k1_bitcoin"};
00041 
00042 TEST_CASE("Sign, verify, with KeyPair")
00043 {
00044   for (const auto curve : supported_curves)
00045   {
00046     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00047     auto kp = tls::make_key_pair(curve);
00048     vector<uint8_t> contents(contents_.begin(), contents_.end());
00049     const vector<uint8_t> signature = kp->sign(contents);
00050     CHECK(kp->verify(contents, signature));
00051 
00052     auto kp2 = tls::make_key_pair(kp->private_key_pem());
00053     CHECK(kp2->verify(contents, signature));
00054 
00055     // Signatures won't necessarily be identical due to entropy, but should be
00056     // mutually verifiable
00057     for (auto i = 0; i < 10; ++i)
00058     {
00059       const auto new_sig = kp2->sign(contents);
00060       CHECK(kp->verify(contents, new_sig));
00061       CHECK(kp2->verify(contents, new_sig));
00062     }
00063   }
00064 }
00065 
00066 TEST_CASE("Sign, verify, with PublicKey")
00067 {
00068   for (const auto curve : supported_curves)
00069   {
00070     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00071     auto kp = tls::make_key_pair(curve);
00072     vector<uint8_t> contents(contents_.begin(), contents_.end());
00073     const vector<uint8_t> signature = kp->sign(contents);
00074 
00075     const auto public_key = kp->public_key_pem();
00076     auto pubk = tls::make_public_key(public_key);
00077     CHECK(pubk->verify(contents, signature));
00078   }
00079 }
00080 
00081 TEST_CASE("Sign, fail to verify with bad signature")
00082 {
00083   for (const auto curve : supported_curves)
00084   {
00085     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00086     auto kp = tls::make_key_pair(curve);
00087     vector<uint8_t> contents(contents_.begin(), contents_.end());
00088     vector<uint8_t> signature = kp->sign(contents);
00089 
00090     const auto public_key = kp->public_key_pem();
00091     auto pubk = tls::make_public_key(public_key);
00092     corrupt(signature);
00093     CHECK_FALSE(pubk->verify(contents, signature));
00094   }
00095 }
00096 
00097 TEST_CASE("Sign, fail to verify with bad contents")
00098 {
00099   for (const auto curve : supported_curves)
00100   {
00101     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00102     auto kp = tls::make_key_pair(curve);
00103     vector<uint8_t> contents(contents_.begin(), contents_.end());
00104     vector<uint8_t> signature = kp->sign(contents);
00105 
00106     const auto public_key = kp->public_key_pem();
00107     auto pubk = tls::make_public_key(public_key);
00108     corrupt(contents);
00109     CHECK_FALSE(pubk->verify(contents, signature));
00110   }
00111 }
00112 
00113 TEST_CASE("Sign, fail to verify with wrong key on correct curve")
00114 {
00115   for (const auto curve : supported_curves)
00116   {
00117     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00118     auto kp = tls::make_key_pair(curve);
00119     vector<uint8_t> contents(contents_.begin(), contents_.end());
00120     vector<uint8_t> signature = kp->sign(contents);
00121 
00122     auto kp2 = tls::make_key_pair(curve);
00123     const auto public_key = kp2->public_key_pem();
00124     auto pubk = tls::make_public_key(public_key);
00125     CHECK_FALSE(pubk->verify(contents, signature));
00126   }
00127 }
00128 
00129 TEST_CASE("Sign, fail to verify with wrong key on wrong curve")
00130 {
00131   for (const auto curve : supported_curves)
00132   {
00133     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00134     auto kp = tls::make_key_pair(curve);
00135     vector<uint8_t> contents(contents_.begin(), contents_.end());
00136     vector<uint8_t> signature = kp->sign(contents);
00137 
00138     const auto wrong_curve = curve == tls::CurveImpl::secp384r1 ?
00139       tls::CurveImpl::secp256k1_mbedtls :
00140       tls::CurveImpl::secp384r1;
00141     auto kp2 = tls::make_key_pair(wrong_curve);
00142     const auto public_key = kp2->public_key_pem();
00143     auto pubk = tls::make_public_key(public_key);
00144     CHECK_FALSE(pubk->verify(contents, signature));
00145   }
00146 }
00147 
00148 using CurvePair = std::pair<tls::CurveImpl, tls::CurveImpl>;
00149 std::vector<CurvePair> equivalent_curves{
00150   std::make_pair(
00151     tls::CurveImpl::secp256k1_mbedtls, tls::CurveImpl::secp256k1_bitcoin),
00152   std::make_pair(
00153     tls::CurveImpl::secp256k1_bitcoin, tls::CurveImpl::secp256k1_mbedtls)};
00154 
00155 TEST_CASE("Sign, verify with alternate implementation")
00156 {
00157   for (const auto& curves : equivalent_curves)
00158   {
00159     INFO("Sign impl: " << labels[static_cast<size_t>(curves.first) - 1]);
00160     INFO("Verify impl: " << labels[static_cast<size_t>(curves.second) - 1]);
00161     auto kp = tls::make_key_pair(curves.first);
00162     vector<uint8_t> contents(contents_.begin(), contents_.end());
00163     vector<uint8_t> signature = kp->sign(contents);
00164 
00165     const auto public_key = kp->public_key_pem();
00166     auto pubk = tls::make_public_key(
00167       public_key, curves.second == tls::CurveImpl::secp256k1_bitcoin);
00168     CHECK(pubk->verify(contents, signature));
00169   }
00170 }
00171 
00172 TEST_CASE("Sign, verify with certificate")
00173 {
00174   for (const auto curve : supported_curves)
00175   {
00176     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00177     auto kp = tls::make_key_pair(curve);
00178     vector<uint8_t> contents(contents_.begin(), contents_.end());
00179     const vector<uint8_t> signature = kp->sign(contents);
00180 
00181     auto cert = kp->self_sign("CN=name");
00182     auto verifier = tls::make_verifier(cert);
00183     CHECK(verifier->verify(contents, signature));
00184   }
00185 }
00186 
00187 TEST_CASE("Sign, verify. Fail to verify with bad contents")
00188 {
00189   for (const auto curve : supported_curves)
00190   {
00191     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00192     auto kp = tls::make_key_pair(curve);
00193     vector<uint8_t> contents(contents_.begin(), contents_.end());
00194     const vector<uint8_t> signature = kp->sign(contents);
00195 
00196     auto cert = kp->self_sign("CN=name");
00197     auto verifier = tls::make_verifier(cert);
00198     CHECK(verifier->verify(contents, signature));
00199     corrupt(contents);
00200     CHECK_FALSE(verifier->verify(contents, signature));
00201   }
00202 }
00203 
00204 tls::HashBytes bad_manual_hash(const std::vector<uint8_t>& data)
00205 {
00206   // secp256k1 requires 32-byte hashes, other curves don't care. So use 32 for
00207   // general hasher
00208   constexpr auto n = 32;
00209   tls::HashBytes hash(n);
00210 
00211   for (size_t i = 0; i < data.size(); ++i)
00212   {
00213     hash[i % n] ^= data[i];
00214   }
00215 
00216   return hash;
00217 }
00218 
00219 TEST_CASE("Manually hash, sign, verify, with PublicKey")
00220 {
00221   for (const auto curve : supported_curves)
00222   {
00223     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00224     auto kp = tls::make_key_pair(curve);
00225     vector<uint8_t> contents(contents_.begin(), contents_.end());
00226     tls::HashBytes hash = bad_manual_hash(contents);
00227     const vector<uint8_t> signature = kp->sign_hash(hash.data(), hash.size());
00228 
00229     const auto public_key = kp->public_key_pem();
00230     auto pubk = tls::make_public_key(public_key);
00231     CHECK(pubk->verify_hash(hash, signature));
00232     corrupt(hash);
00233     CHECK_FALSE(pubk->verify_hash(hash, signature));
00234   }
00235 }
00236 
00237 TEST_CASE("Manually hash, sign, verify, with certificate")
00238 {
00239   for (const auto curve : supported_curves)
00240   {
00241     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00242     auto kp = tls::make_key_pair(curve);
00243     vector<uint8_t> contents(contents_.begin(), contents_.end());
00244     tls::HashBytes hash = bad_manual_hash(contents);
00245     const vector<uint8_t> signature = kp->sign_hash(hash.data(), hash.size());
00246 
00247     auto cert = kp->self_sign("CN=name");
00248     auto verifier = tls::make_verifier(cert);
00249     CHECK(verifier->verify_hash(hash, signature));
00250     corrupt(hash);
00251     CHECK_FALSE(verifier->verify(hash, signature));
00252   }
00253 }
00254 
00255 TEST_CASE("Recoverable signatures")
00256 {
00257   auto kp = tls::KeyPair_k1Bitcoin(MBEDTLS_ECP_DP_SECP256K1);
00258 
00259   vector<uint8_t> contents(contents_.begin(), contents_.end());
00260   tls::HashBytes hash = bad_manual_hash(contents);
00261 
00262   auto signature = kp.sign_recoverable_hashed(hash);
00263   const auto target_pem = kp.public_key_pem().str();
00264 
00265   auto recovered = tls::PublicKey_k1Bitcoin::recover_key(signature, hash);
00266 
00267   {
00268     INFO("Normal recovery");
00269     CHECK(target_pem == recovered.public_key_pem().str());
00270   }
00271 
00272   // NB: Incorrect arguments _may_ cause the verification to throw with no
00273   // recoverable key, but they may simply cause a different key to be returned.
00274   // These tests look for either type of failure.
00275 
00276   {
00277     INFO("Corrupted hash");
00278     auto hash2(hash);
00279     corrupt(hash2);
00280     bool recovery_failed = false;
00281     try
00282     {
00283       auto r = tls::PublicKey_k1Bitcoin::recover_key(signature, hash2);
00284       recovery_failed = target_pem != r.public_key_pem().str();
00285     }
00286     catch (const std::exception& e)
00287     {
00288       recovery_failed = true;
00289     }
00290     CHECK(recovery_failed);
00291   }
00292 
00293   {
00294     INFO("Corrupted signature");
00295     auto signature2(signature);
00296     corrupt(signature2.raw);
00297     bool recovery_failed = false;
00298     try
00299     {
00300       auto r = tls::PublicKey_k1Bitcoin::recover_key(signature2, hash);
00301       recovery_failed = target_pem != r.public_key_pem().str();
00302     }
00303     catch (const std::exception& e)
00304     {
00305       recovery_failed = true;
00306     }
00307     CHECK(recovery_failed);
00308   }
00309 
00310   {
00311     INFO("Corrupted recovery_id");
00312     auto signature3(signature);
00313     signature3.recovery_id = (signature3.recovery_id + 1) % 4;
00314     bool recovery_failed = false;
00315     try
00316     {
00317       auto r = tls::PublicKey_k1Bitcoin::recover_key(signature3, hash);
00318       recovery_failed = target_pem != r.public_key_pem().str();
00319     }
00320     catch (const std::exception& e)
00321     {
00322       recovery_failed = true;
00323     }
00324     CHECK(recovery_failed);
00325   }
00326 
00327   {
00328     INFO("Recovered key is useable");
00329 
00330     auto norm_sig = kp.sign(contents);
00331     CHECK(recovered.verify(contents, norm_sig));
00332     corrupt(norm_sig);
00333     CHECK_FALSE(recovered.verify(contents, norm_sig));
00334   }
00335 }
00336 
00337 TEST_CASE("base64")
00338 {
00339   for (size_t length = 1; length < 20; ++length)
00340   {
00341     std::vector<uint8_t> raw(length);
00342     std::generate(raw.begin(), raw.end(), rand);
00343 
00344     const auto encoded = tls::b64_from_raw(raw.data(), raw.size());
00345     const auto decoded = tls::raw_from_b64(encoded);
00346     REQUIRE(decoded == raw);
00347   }
00348 }
00349 
00350 TEST_CASE("base64url")
00351 {
00352   for (size_t length = 1; length < 20; ++length)
00353   {
00354     std::vector<uint8_t> raw(length);
00355     std::generate(raw.begin(), raw.end(), rand);
00356 
00357     auto encoded = tls::b64_from_raw(raw.data(), raw.size());
00358     std::replace(encoded.begin(), encoded.end(), '+', '-');
00359     std::replace(encoded.begin(), encoded.end(), '/', '_');
00360     encoded.erase(
00361       std::find(encoded.begin(), encoded.end(), '='), encoded.end());
00362     const auto decoded = tls::raw_from_b64url(encoded);
00363     REQUIRE(decoded == raw);
00364   }
00365 }
00366 
00367 TEST_CASE("Wrap, unwrap with RSAKeyPair")
00368 {
00369   size_t input_len = 64;
00370   std::vector<uint8_t> input = tls::create_entropy()->random(input_len);
00371 
00372   INFO("Cannot make RSA key from EC key");
00373   {
00374     auto rsa_kp = tls::make_key_pair(); // EC Key
00375 
00376     REQUIRE_THROWS_AS(
00377       tls::make_rsa_public_key(rsa_kp->public_key_pem()), std::logic_error);
00378   }
00379 
00380   INFO("Without label");
00381   {
00382     auto rsa_kp = tls::make_rsa_key_pair();
00383     auto rsa_pub = tls::make_rsa_public_key(rsa_kp->public_key_pem());
00384 
00385     // Public key can wrap
00386     auto wrapped = rsa_pub->wrap(input);
00387 
00388     // Only private key can unwrap
00389     auto unwrapped = rsa_kp->unwrap(wrapped);
00390     // rsa_pub->unwrap(wrapped); // Doesn't compile
00391     REQUIRE(input == unwrapped);
00392 
00393     // Raw data
00394     wrapped = rsa_pub->wrap(input.data(), input.size());
00395     unwrapped = rsa_kp->unwrap(wrapped);
00396     REQUIRE(input == unwrapped);
00397   }
00398 
00399   INFO("With label");
00400   {
00401     auto rsa_kp = tls::make_rsa_key_pair();
00402     auto rsa_pub = tls::make_rsa_public_key(rsa_kp->public_key_pem());
00403     std::string label = "my_label";
00404     auto wrapped = rsa_pub->wrap(input, label);
00405     auto unwrapped = rsa_kp->unwrap(wrapped, label);
00406     REQUIRE(input == unwrapped);
00407   }
00408 }
00409 
00410 TEST_CASE("Extract public key from cert")
00411 {
00412   for (const auto curve : supported_curves)
00413   {
00414     INFO("With curve: " << labels[static_cast<size_t>(curve) - 1]);
00415     auto kp = tls::make_key_pair(curve);
00416     auto pk = kp->public_key_pem();
00417     auto cert = kp->self_sign("CN=name");
00418 
00419     auto pubk = tls::public_key_pem_from_cert(cert);
00420     REQUIRE(pk == pubk);
00421   }
00422 }
---------
Macros accessible in this file:
---------
DOCTEST_CONFIG_IMPLEMENT_WITH_MAIN 
---------
Parsing file /data/git/CCF/src/tls/test/main.cpp...
Preprocessing /data/git/CCF/src/tls/tls.h...
#include mbedtls/ctr_drbg.h: not found! skipping...
#include mbedtls/debug.h: not found! skipping...
#include mbedtls/entropy.h: not found! skipping...
#include mbedtls/entropy_poll.h: not found! skipping...
#include mbedtls/error.h: not found! skipping...
#include mbedtls/net_sockets.h: not found! skipping...
#include mbedtls/oid.h: not found! skipping...
#include mbedtls/rsa.h: not found! skipping...
#include mbedtls/sha256.h: not found! skipping...
#include mbedtls/ssl.h: not found! skipping...
#include mbedtls/x509.h: not found! skipping...
#include mbedtls/x509_crt.h: not found! skipping...
#include mbedtls/x509_csr.h: not found! skipping...
Preprocessor output (size: 118 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 
00013 
00014 
00015 
00016 
00017 
00018 
---------
No macros accessible in this file.
Parsing file /data/git/CCF/src/tls/tls.h...
Preprocessing /data/git/CCF/src/tls/verifier.h...
#include curve.h: already included! skipping...
#include error_string.h: already included! skipping...
#include hash.h: already included! skipping...
#include key_pair.h: already included! skipping...
#include mbedtls/pem.h: not found! skipping...
#include pem.h: already included! skipping...
Preprocessor output (size: 6748 bytes):
---------
00001 // Copyright (c) Microsoft Corporation. All rights reserved.
00002 // Licensed under the Apache 2.0 License.
00003 
00004 
00005 
00006 
00007 
00008 
00009 
00010 
00011 
00012 namespace tls
00013 {
00014   static constexpr size_t max_pem_cert_size = 4096;
00015 
00016   // As these are not exposed by mbedlts, define them here to allow simple
00017   // conversion from DER to PEM format
00018   static constexpr auto PEM_CERTIFICATE_HEADER =
00019     "-----BEGIN CERTIFICATE-----\n";
00020   static constexpr auto PEM_CERTIFICATE_FOOTER = "-----END CERTIFICATE-----\n";
00021 
00022   class Verifier
00023   {
00024   protected:
00025     mutable mbedtls::X509Crt cert;
00026 
00027   public:
00028     /**
00029      * Construct from a pre-parsed cert
00030      *
00031      * @param c Initialised and parsed x509 cert
00032      */
00033     Verifier(mbedtls::X509Crt&& c) : cert(std::move(c)) {}
00034 
00035     Verifier(const Verifier&) = delete;
00036 
00037     virtual ~Verifier() = default;
00038 
00039     /**
00040      * Verify that a signature was produced on a hash with the private key
00041      * associated with the public key contained in the certificate.
00042      *
00043      * @param hash First byte in hash sequence
00044      * @param hash_size Number of bytes in hash sequence
00045      * @param signature First byte in signature sequence
00046      * @param signature_size Number of bytes in signature sequence
00047      * @param md_type Digest algorithm to use. Derived from the
00048      * public key if MBEDTLS_MD_NONE.
00049      *
00050      * @return Whether the signature matches the hash and the key
00051      */
00052     virtual bool verify_hash(
00053       const uint8_t* hash,
00054       size_t hash_size,
00055       const uint8_t* signature,
00056       size_t signature_size,
00057       mbedtls_md_type_t md_type = {}) const
00058     {
00059       if (md_type == MBEDTLS_MD_NONE)
00060         md_type = get_md_for_ec(get_ec_from_context(cert->pk));
00061 
00062       int rc = mbedtls_pk_verify(
00063         &cert->pk, md_type, hash, hash_size, signature, signature_size);
00064 
00065       if (rc)
00066         LOG_DEBUG_FMT("Failed to verify signature: {}", error_string(rc));
00067 
00068       return rc == 0;
00069     }
00070 
00071     /**
00072      * Verify that a signature was produced on a hash with the private key
00073      * associated with the public key contained in the certificate.
00074      *
00075      * @param hash Hash produced from contents as a sequence of bytes
00076      * @param signature Signature as a sequence of bytes
00077      * @param md_type Digest algorithm to use. Derived from the
00078      * public key if MBEDTLS_MD_NONE.
00079      *
00080      * @return Whether the signature matches the hash and the key
00081      */
00082     bool verify_hash(
00083       const std::vector<uint8_t>& hash,
00084       const std::vector<uint8_t>& signature,
00085       mbedtls_md_type_t md_type = {}) const
00086     {
00087       return verify_hash(
00088         hash.data(), hash.size(), signature.data(), signature.size(), md_type);
00089     }
00090 
00091     bool verify_hash(
00092       const std::vector<uint8_t>& hash,
00093       const uint8_t* sig,
00094       size_t sig_size,
00095       mbedtls_md_type_t md_type = {}) const
00096     {
00097       return verify_hash(hash.data(), hash.size(), sig, sig_size, md_type);
00098     }
00099 
00100     /**
00101      * Verify that a signature was produced on contents with the private key
00102      * associated with the public key contained in the certificate.
00103      *
00104      * @param contents Sequence of bytes that was signed
00105      * @param signature Signature as a sequence of bytes
00106      * @param md_type Digest algorithm to use. Derived from the
00107      * public key if MBEDTLS_MD_NONE.
00108      *
00109      * @return Whether the signature matches the contents and the key
00110      */
00111     bool verify(
00112       const std::vector<uint8_t>& contents,
00113       const std::vector<uint8_t>& signature,
00114       mbedtls_md_type_t md_type = {}) const
00115     {
00116       return verify(
00117         contents.data(),
00118         contents.size(),
00119         signature.data(),
00120         signature.size(),
00121         md_type);
00122     }
00123 
00124     bool verify(
00125       const uint8_t* contents,
00126       size_t contents_size,
00127       const uint8_t* sig,
00128       size_t sig_size,
00129       mbedtls_md_type_t md_type = {}) const
00130     {
00131       HashBytes hash;
00132       do_hash(cert->pk, contents, contents_size, hash, md_type);
00133 
00134       return verify_hash(hash, sig, sig_size, md_type);
00135     }
00136 
00137     const mbedtls_x509_crt* raw()
00138     {
00139       return cert.get();
00140     }
00141 
00142     std::vector<uint8_t> der_cert_data()
00143     {
00144       return {cert->raw.p, cert->raw.p + cert->raw.len};
00145     }
00146 
00147     Pem cert_pem()
00148     {
00149       unsigned char buf[max_pem_cert_size];
00150       size_t len;
00151 
00152       auto rc = mbedtls_pem_write_buffer(
00153         PEM_CERTIFICATE_HEADER,
00154         PEM_CERTIFICATE_FOOTER,
00155         cert->raw.p,
00156         cert->raw.len,
00157         buf,
00158         max_pem_cert_size,
00159         &len);
00160 
00161       if (rc != 0)
00162       {
00163         throw std::logic_error(
00164           "mbedtls_pem_write_buffer failed: " + error_string(rc));
00165       }
00166 
00167       return Pem(buf, len);
00168     }
00169   };
00170 
00171   class Verifier_k1Bitcoin : public Verifier
00172   {
00173   protected:
00174     BCk1ContextPtr bc_ctx = make_bc_context(SECP256K1_CONTEXT_VERIFY);
00175 
00176     secp256k1_pubkey bc_pub;
00177 
00178   public:
00179     template <typename... Ts>
00180     Verifier_k1Bitcoin(Ts... ts) : Verifier(std::forward<Ts>(ts)...)
00181     {
00182       parse_secp256k_bc(cert->pk, bc_ctx->p, &bc_pub);
00183     }
00184 
00185     bool verify_hash(
00186       const uint8_t* hash,
00187       size_t hash_size,
00188       const uint8_t* signature,
00189       size_t signature_size,
00190       mbedtls_md_type_t = {}) const override
00191     {
00192       bool ok = verify_secp256k_bc(
00193         bc_ctx->p, signature, signature_size, hash, hash_size, &bc_pub);
00194 
00195       return ok;
00196     }
00197   };
00198 
00199   using VerifierPtr = std::shared_ptr<Verifier>;
00200   using VerifierUniquePtr = std::unique_ptr<Verifier>;
00201   /**
00202    * Construct Verifier from a certificate in DER or PEM format
00203    *
00204    * @param cert Sequence of bytes containing the certificate
00205    */
00206   inline VerifierUniquePtr make_unique_verifier(
00207     const std::vector<uint8_t>& cert,
00208     bool use_bitcoin_impl = prefer_bitcoin_secp256k1)
00209   {
00210     auto x509 = mbedtls::make_unique<mbedtls::X509Crt>();
00211     int rc = mbedtls_x509_crt_parse(x509.get(), cert.data(), cert.size());
00212     if (rc)
00213     {
00214       throw std::invalid_argument(
00215         fmt::format("Failed to parse certificate: {}", error_string(rc)));
00216     }
00217 
00218     if (x509->pk.pk_info == mbedtls_pk_info_from_type(MBEDTLS_PK_ECKEY))
00219     {
00220       const auto curve = get_ec_from_context(x509->pk);
00221 
00222       if (curve == MBEDTLS_ECP_DP_SECP256K1 && use_bitcoin_impl)
00223       {
00224         return std::make_unique<Verifier_k1Bitcoin>(std::move(x509));
00225       }
00226     }
00227 
00228     return std::make_unique<Verifier>(std::move(x509));
00229   }
00230 
00231   inline VerifierPtr make_verifier(
00232     const Pem& cert, bool use_bitcoin_impl = prefer_bitcoin_secp256k1)
00233   {
00234     return make_unique_verifier(cert.raw(), use_bitcoin_impl);
00235   }
00236 
00237   inline tls::Pem cert_der_to_pem(const std::vector<uint8_t>& der_cert_raw)
00238   {
00239     return make_verifier(der_cert_raw)->cert_pem();
00240   }
00241 
00242   inline std::vector<uint8_t> cert_pem_to_der(const std::string& pem_cert_raw)
00243   {
00244     return make_verifier(pem_cert_raw)->der_cert_data();
00245   }
00246 }
---------
Macros accessible in this file:
---------
DRNG_NO_SUPPORT DEFINE_MBEDTLS_WRAPPER DRNG_HAS_RDSEED FMT_HEADER_ONLY DRNG_HAS_RDRAND RDRAND_RETRIES 
---------
Parsing file /data/git/CCF/src/tls/verifier.h...
Building group list...
Building directory list...
Building namespace list...
Building file list...
Building class list...
Associating documentation with classes...
Computing nesting relations for classes...
Building example list...
Searching for enumerations...
Searching for documented typedefs...
Searching for members imported via using declarations...
Searching for included using directives...
Searching for documented variables...
Building interface member list...
Building member list...
Searching for friends...
Searching for documented defines...
Computing class inheritance relations...
Computing class usage relations...
Searching for tag less structs...
Flushing cached template relations that have become invalid...
Computing class relations...
Add enum values to enums...
Searching for member function documentation...
Creating members for template instances...
Building page list...
Search for main page...
Computing page relations...
Determining the scope of groups...
Sorting lists...
Freeing entry tree
Determining which enums are documented
Computing member relations...
Building full member lists recursively...
Adding members to member groups.
Computing member references...
Inheriting documentation...
Generating disk names...
Adding source references...
Adding xrefitems...
Sorting member lists...
Computing dependencies between directories...
Generating citations page...
Counting data structures...
Resolving user defined references...
Finding anchors and sections in the documentation...
Transferring function references...
Combining using relations...
Adding members to index pages...
Generating style sheet...
Generating search indices...
Generating example documentation...
Generating file sources...
Generating code for file src/apps/smallbank/smallbank_serializer.h...
Generating code for file src/clients/rpc_tls_client.h...
Generating code for file src/clients/tls_client.h...
Generating code for file src/consensus/aft/impl/execution.h...
Generating code for file src/consensus/aft/impl/message.h...
Generating code for file src/consensus/aft/impl/request_message.h...
Generating code for file src/consensus/aft/impl/state.h...
Generating code for file src/consensus/aft/impl/view_change_tracker.h...
Generating code for file src/consensus/aft/raft.h...
Generating code for file src/consensus/aft/raft_consensus.h...
Cleaning up...
Exiting...
